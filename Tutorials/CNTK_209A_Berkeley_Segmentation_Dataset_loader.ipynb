{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNTK 209 Part A: Berkeley Segmentation Dataset loader\n",
    "\n",
    "## Preparing the training set\n",
    "\n",
    "<p>This notebook serves as data preparation for the CNTK 209 tutorial. The aim of this tutorial is to showcase how we can use tools from CNTK to train models which will perform image super-resolution. The goal of the <b>single image super-resolution (SISR)</b> problem is to upscale a given image by some factor while keeping as much image details as possible and not making the image blurry. This problem is described in more detail in the remaining notebooks of this tutorial.</p>\n",
    "<p>It is recommended for the user to complete the tutorial CNTK 206 before this. Some basic familiarity with deep convolutional networks is also welcome.</p>\n",
    "<p>We will be using <b>Berkeley Segmetation Dataset (BSDS)</b>. It contains 300 images which we will download and then prepare for training of the models we will use. Image dimensions are 481 x 321 and 321 x 481.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import the relevant modules to be used later\n",
    "import urllib\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve, urlopen\n",
    "except ImportError: \n",
    "    from urllib import urlretrieve, urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data download\n",
    "The data is not present in a .zip, .gz or in a similar packet. It is located in a folder on this <a href=\"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/images/plain/normal/color/\">link</a>. Therefore, we will use regular expression to find all image names and download them one by one into destination folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def download_data(images_dir, link):\n",
    "    if not os.path.exists(images_dir):\n",
    "        os.makedirs(images_dir)\n",
    "    \n",
    "    images_html = urlopen(link).read().decode('utf-8')\n",
    "    \n",
    "    #looking for .jpg images whose names are numbers\n",
    "    image_regex = \"[0-9]+.jpg\"\n",
    "    \n",
    "    #remove duplicates\n",
    "    image_list = set(re.findall(image_regex, images_html))\n",
    "    print(\"Starting download...\")\n",
    "    \n",
    "    for image in image_list:\n",
    "        filename = os.path.join(images_dir, image)\n",
    "        if not os.path.isfile(filename):\n",
    "            urlretrieve(link + image, filename)\n",
    "        else:\n",
    "            print(\"File already exists\", filename)\n",
    "    \n",
    "    print(\"Images available at: \", images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Now we only need to call this function with appropriate parameters. This might take a few minutes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download...\n",
      "Images available at:  Data/BerkeleySegmentationDataset/Images\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset (prefer our default path for the data)\n",
    "data_dir = os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"BerkeleySegmentationDataset\")\n",
    "if not os.path.exists(data_dir):\n",
    "    data_dir = os.path.join(\"Data\", \"BerkeleySegmentationDataset\")\n",
    "\n",
    "#folder for raw images, before preprocess\n",
    "images_dir = os.path.join(data_dir, \"Images\")\n",
    "\n",
    "#link to BSDS dataset\n",
    "link = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/images/plain/normal/color/\"\n",
    "\n",
    "download_data(images_dir, link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data preparation\n",
    "<p>This dataset contains only 300 images which is not enough for super-resolution training. The idea is to split images into 64 x 64 patches which will augment the training data. Function <code>prep_64</code> does exactly that.</p>\n",
    "<p>Once we select some 64 x 64 patch, we downscale it by a factor of 2 and then upscale it by a factor of 2 again using bicubic interpolation. This will give us a blurry version of the original patch. In some approaches in the tutorial, the idea will be to learn the model which turns blurry pathes into clear ones. We will put blurry patches into one folder and normal patches into another. They will serve as minibatch sources for training. We will also sample a few test images here.</p>\n",
    "<p>After processing each patch, we move 42 pixels down/right (so there is some overlapping) as long as we can. This can take a few minutes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#extract 64 x 64 patches from BSDS dataset\n",
    "def prep_64(images_dir, patch_h, patch_w, train64_lr, train64_hr, tests):\n",
    "    if not os.path.exists(train64_lr):\n",
    "        os.makedirs(train64_lr)\n",
    "    \n",
    "    if not os.path.exists(train64_hr):\n",
    "        os.makedirs(train64_hr)\n",
    "    \n",
    "    if not os.path.exists(tests):\n",
    "        os.makedirs(tests)\n",
    "    \n",
    "    k = 0\n",
    "    num = 0\n",
    "    \n",
    "    print(\"Creating 64 x 64 training patches and tests from:\", images_dir)\n",
    "    \n",
    "    for entry in os.listdir(images_dir):\n",
    "        filename = os.path.join(images_dir, entry)\n",
    "        img = Image.open(filename)\n",
    "        rect = np.array(img)\n",
    "    \n",
    "        num = num + 1\n",
    "        \n",
    "        if num % 50 == 0:\n",
    "            img.save(os.path.join(tests, str(num) + \".jpg\"))\n",
    "            continue\n",
    "    \n",
    "        x = 0\n",
    "        y = 0\n",
    "    \n",
    "        while(y + patch_h <= img.width):\n",
    "            x = 0\n",
    "            while(x + patch_w <= img.height):\n",
    "                patch = rect[x : x + patch_h, y : y + patch_w]\n",
    "                img_hr = Image.fromarray(patch, 'RGB')\n",
    "                \n",
    "                img_lr = img_hr.resize((patch_w // 2, patch_h // 2), Image.ANTIALIAS)\n",
    "                img_lr = img_lr.resize((patch_w, patch_h), Image.BICUBIC)\n",
    "                \n",
    "                out_hr = os.path.join(train64_hr, str(k) + \".jpg\")\n",
    "                out_lr = os.path.join(train64_lr, str(k) + \".jpg\")\n",
    "                \n",
    "                k = k + 1\n",
    "                \n",
    "                img_hr.save(out_hr)\n",
    "                img_lr.save(out_lr)\n",
    "                \n",
    "                x = x + 42\n",
    "            y = y + 42\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Since CNTK VGG19 model, which we will also download here and later use in training of <b>SRGAN</b> model, operates strictly on 224 x 224 images, we will need to prepare training data for models which turn 112 x 112 images into 224 x 224 images. We will train two such models (<b>SRResNet</b> and <b>SRGAN</b>) in the later part of this tutorial.</p>\n",
    "<p>We use similar reasoning for augmenting the training data here with <code>prep_224</code>. We will be selecting 224 x 224 patches and downscaling them to 112 x 112 patches. The only difference is that now we also rotate patches to additionally increase the number of training samples because we don't get as much 224 x 224 patches as 64 x 64 patches. Like before, 224 x 224 patches go into one folder and 112 x 112 patches go into another.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#extract 224 x 224 and 112 x 112 patches from BSDS dataset\n",
    "def prep_224(images_dir, patch_h, patch_w, train112, train224):\n",
    "    if not os.path.exists(train112):\n",
    "        os.makedirs(train112)\n",
    "    \n",
    "    if not os.path.exists(train224):\n",
    "        os.makedirs(train224)\n",
    "\n",
    "    k = 0\n",
    "    \n",
    "    print(\"Creating 224 x 224 and 112 x 112 training patches from:\", images_dir)\n",
    "    \n",
    "    for entry in os.listdir(images_dir):\n",
    "        filename = os.path.join(images_dir, entry)\n",
    "        img = Image.open(filename)\n",
    "        rect = np.array(img)\n",
    "    \n",
    "        x = 0\n",
    "        y = 0\n",
    "    \n",
    "        while(y + patch_h <= img.width):\n",
    "            x = 0\n",
    "            while(x + patch_w <= img.height):\n",
    "                patch = rect[x : x + patch_h, y : y + patch_w]\n",
    "                img_hr = Image.fromarray(patch, 'RGB')\n",
    "                \n",
    "                img_lr = img_hr.resize((patch_w // 2, patch_h // 2), Image.ANTIALIAS)\n",
    "                \n",
    "                for i in range(4):\n",
    "                    out_hr = os.path.join(train224, str(k) + \".jpg\")\n",
    "                    out_lr = os.path.join(train112, str(k) + \".jpg\")\n",
    "                \n",
    "                    k = k + 1\n",
    "                \n",
    "                    img_hr.save(out_hr)\n",
    "                    img_lr.save(out_lr)\n",
    "                \n",
    "                    img_hr = img_hr.transpose(Image.ROTATE_90)\n",
    "                    img_lr = img_lr.transpose(Image.ROTATE_90)\n",
    "                \n",
    "                x = x + 64\n",
    "            y = y + 64\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>We take the images we downloaded and run <code>prep</code> functions with adequate parameters. In the end, in the folder <b>Images</b> we will have a little bit less than 300 images from Berkeley Segmentation Dataset, depending on how many go to test set.</p>\n",
    "<p>In the folder <b>train64_LR</b> we will have around 20000 64 x 64 blurry image patches that will be used for training. Their original counterparts will be located in the folder <b>train64_HR</b>.</p>\n",
    "<p>In the folder <b>train224</b> we will have around 12000 original 224 x 224 patches. Their downscaled 112 x 112 counterparts will be located <b>train112</b>. Images that can later be used for testing will be in <b>tests</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 64 x 64 training patches and tests from: Data/BerkeleySegmentationDataset/Images\n",
      "Done!\n",
      "Creating 224 x 224 and 112 x 112 training patches from: Data/BerkeleySegmentationDataset/Images\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#blurry 64x64 destination\n",
    "train64_lr = os.path.join(data_dir, \"train64_LR\")\n",
    "\n",
    "#original 64x64 destination\n",
    "train64_hr = os.path.join(data_dir, \"train64_HR\")\n",
    "\n",
    "#112x112 patches destination\n",
    "train112 = os.path.join(data_dir, \"train112\")\n",
    "\n",
    "#224x224 pathes destination\n",
    "train224 = os.path.join(data_dir, \"train224\")\n",
    "\n",
    "#tests destination\n",
    "tests = os.path.join(data_dir, \"tests\")\n",
    "\n",
    "#prep\n",
    "prep_64(images_dir, 64, 64, train64_lr, train64_hr, tests)\n",
    "prep_224(images_dir, 224, 224, train112, train224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Now we are ready to start the training or we can just experiment with the evaluation of the pretrained models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
