{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNTK 209 Part A: Evaluation of pretrained super-resolution models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation and filters\n",
    "<p>This notebook serves as a guide to experimenting with pre-trained super-resolution CNTK models. Notice that here we only consider evaluation of these models. The tutorial on how to get the training data and train them is contained in the notebooks CNTK 209B and CNTK 209C. All work was done on <b>Python 3.5.2, CNTK 2.0rc1</b>.</p>\n",
    "<p>There are four basic models: <b>VDSR</b>, <b>DRNN</b>, <b>SRResNet</b>, <b>SRGAN</b>. In addition to evaluating them on some example images, we will explore our novel idea of <b>filtering</b>. A <b>filter</b> is any combination of several basic models applied one after another in order to get the final result. One model alone also falls into this definition. Here we will work with four mentioned models. We will describe their working principles in a nutshell. See part C of this tutorial for more details.</p>\n",
    "<ul>\n",
    "<li><b>VDSR</b> model takes a blurry 64 x 64 image patch and outputs the predicted difference of the blurry patch and the original version. After adding that difference to the blurry patch, we obtain our prediction, which is also 64 x 64. The idea is to upscale the target image with bicubic interpolation before running the model, so in the end, after we evaluate patch by patch, we will get a more clear version of the upscaled image.</li>\n",
    "<li><b>DRNN</b> model works the same way as <b>VDSR</b>, but it has a different architecture.</li>\n",
    "<li><b>SRResNet</b> and <b>SRGAN</b> take a 112 x 112 original patch and upscale it to the predicted 224 x 224 version inside the model (there is no pre-upscaling involved). Both have the same architecture, but the loss functions are different.</li>\n",
    "</ul>\n",
    "<p>For example, one filter might consist of <b>SRGAN</b> and <b>VDSR</b>. First, we would apply <b>SRGAN</b> to the starting image and then <b>VDSR</b> to the result, but without doing the bicubic interpolation preprocess, since <b>SRGAN</b> already upscaled the image. Since <b>VDSR</b> was trained to clear up a blurry image, we can expect additional improvement because <b>SRGAN</b> is obviously better at upscaling than bicubic interpolation.</p>\n",
    "<p>Similarly, we could combine <b>VDSR</b> with itself. First, we would upscale the starting image with bicubic interpolation and then clear it up twice in a row with <b>VDSR</b> (no pre-upscaling for the second time).</p>\n",
    "<p>We will need to enable evaluation of arbitrary sized images. Remember that our models expect the input with fixed dimensions. This is easily fixed by evaluating the image patch by patch. Since boundary pixels are sometimes predicted less accurately, we slightly overlap the patches and do not take pixels close to boundary into the account. This will ensure that every pixel is predicted as a non-boundary pixel of some patch, except for those that are really on the image boundary. We must be careful and remember that some of the models are learning residual image only. We also must not forhet to scale back the result by 255.</p>\n",
    "<p>We start with some basic evaluation configuration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from PIL import Image\n",
    "from cntk.ops import relu\n",
    "from cntk.ops.functions import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imsave\n",
    "\n",
    "try:\n",
    "    C.device.try_set_default_device(C.device.gpu(0))\n",
    "except:\n",
    "    print(\"GPU unavailable. Using CPU instead.\")\n",
    "\n",
    "#prefer our default path for the data\n",
    "data_dir = os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"BerkeleySegmentationDataset\")\n",
    "if not os.path.exists(data_dir):\n",
    "    data_dir = os.path.join(\"Data\", \"BerkeleySegmentationDataset\")\n",
    "    \n",
    "#folder with images to be evaluated\n",
    "example_folder = os.path.join(data_dir, \"example_images\")\n",
    "\n",
    "#folders with resulting images\n",
    "results_folder = os.path.join(data_dir, \"example_results\")\n",
    "\n",
    "if not os.path.exists(example_folder):\n",
    "    os.makedirs(example_folder)\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "#names of used models\n",
    "model_names = [\"VDSR\", \"DRNN\", \"SRResNet\", \"SRGAN\"]\n",
    "\n",
    "#output dimensions of models respectively (assumed that output is a square)\n",
    "output_dims = [64, 64, 224, 224]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The evaluation algorithm above is implemented here in function <code>evaluate</code>. See code comments for details about each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#filename - relative path of image being processed\n",
    "#model - the model for super-resolution\n",
    "#outfile - relative path of the image which will be saved\n",
    "\n",
    "#output_dims - dimensions of current model output image\n",
    "#            - it is assumed that model output image is a square\n",
    "\n",
    "#pre_upscale - if True, image will be upscaled by a specified factor with bicubic interpolation at the start\n",
    "#            - the resulting image then replaces the original one in the next operations\n",
    "#            - if False, that step is skipped\n",
    "#            - this should be set on True for models which are clearing up the image and don't make upscaling by themselves\n",
    "\n",
    "#clear_up - if True, the forwarded image will be cleared up by the model and not upscaled\n",
    "#         - this is important to know because step variables are different then (see code)\n",
    "#         - notice that we exit the function if pre_upscale is True and clear_up false because if image was pre-upscaled,\n",
    "#           it should be cleared up afterwards\n",
    "\n",
    "#residual_model - is the model learning residual image only (the difference between blurry and original patch)?\n",
    "#               - if true, residual is added to the low resolutin image to produce the result\n",
    "#               - otherwise, we only need to scale back the result (see code below)\n",
    "def evaluate(filename, model, outfile, output_dims, pre_upscale = False, clear_up = False, residual_model = False):\n",
    "    img = Image.open(filename)\n",
    "    \n",
    "    #upscaling coefficient\n",
    "    coef = 2\n",
    "    \n",
    "    #at each step, we will evaluate subpatch (x : x + range_x, y : y + range_y) of original image\n",
    "    #patch by patch, we will resolve the whole image\n",
    "    range_x = output_dims // coef\n",
    "    range_y = output_dims // coef\n",
    "    \n",
    "    #how many bounding pixels from resulting patch should be excluded?\n",
    "    #this is important because boundaries tend to be predicted less accurately\n",
    "    offset = output_dims // 10\n",
    "    \n",
    "    #after we evaluate a subpatch, how much we move down/right to get the next one\n",
    "    #we subtract offset to cover those pixels which were boundary in the previous subpatch\n",
    "    step_x = range_x - offset\n",
    "    step_y = range_y - offset\n",
    "    \n",
    "    #situation which should not occur, if we need preprocess, we will need to clear up the result\n",
    "    if((pre_upscale) and (not clear_up)):\n",
    "        print(\"Pre-magnified image is not being cleared up.\")\n",
    "        return\n",
    "    \n",
    "    #pre-magnify picture if needed\n",
    "    if(pre_upscale):\n",
    "        img = img.resize((coef * img.width, coef * img.height), Image.BICUBIC)\n",
    "    \n",
    "    #if the current image is being cleared up with no further uspcaling,\n",
    "    #set coef to 1 and other parameters accordingly\n",
    "    if(clear_up):\n",
    "        result = np.zeros((img.height, img.width, 3))\n",
    "        range_x = output_dims\n",
    "        range_y = output_dims\n",
    "        step_x = range_x - 2 * offset\n",
    "        step_y = range_y - 2 * offset\n",
    "        coef = 1\n",
    "    #otherwise, set result to be coef (2 by default) times larger than image\n",
    "    else:\n",
    "        result = np.zeros((coef * img.height, coef * img.width, 3))\n",
    "    \n",
    "    rect = np.array(img, dtype = np.float32)\n",
    "    \n",
    "    #if the image is too small for some models to work on it, pad it with zeros\n",
    "    if(rect.shape[0] < range_y):\n",
    "        pad = np.zeros((range_y - rect.shape[0], rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 0).astype(dtype = np.float32)\n",
    "        \n",
    "    if(rect.shape[1] < range_x):\n",
    "        pad = np.zeros((rect.shape[0], range_x - rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 1).astype(dtype = np.float32)\n",
    "    \n",
    "    x = 0\n",
    "    y = 0\n",
    "    \n",
    "    #take subpatch by subpatch and resolve them to get the final image result\n",
    "    while(y < img.width):\n",
    "        x = 0\n",
    "        while(x < img.height):\n",
    "            rgb_patch = rect[x : x + range_x, y : y + range_y]\n",
    "            rgb_patch = rgb_patch[..., [2, 1, 0]]\n",
    "            rgb_patch = np.ascontiguousarray(np.rollaxis(rgb_patch, 2))\n",
    "            pred = np.squeeze(model.eval({model.arguments[0] : [rgb_patch]}))\n",
    "            \n",
    "            img1 = rgb_patch.transpose(2, 1, 0)\n",
    "            img2 = pred.transpose(2, 1, 0)\n",
    "            \n",
    "            #if model predicts residual image,\n",
    "            #scale back the prediction and add to starting patch\n",
    "            #otherwise just scale back\n",
    "            if(residual_model):\n",
    "                img2 = 255.0 * img2 + img1\n",
    "            else:\n",
    "                img2 = pred.transpose(2, 1, 0)\n",
    "                img2 = img2 * 255.0\n",
    "            \n",
    "            #make sure no pixels are outside [0, 255] interval\n",
    "            for _ in range(2):\n",
    "                img2 = relu(img2).eval()\n",
    "                img2 = np.ones(img2.shape) * 255.0 - img2\n",
    "            \n",
    "            rgb = img2[..., ::-1]\n",
    "            patch = rgb.transpose(1, 0, 2)\n",
    "            \n",
    "            #fill in the pixels in the middle of the subpatch\n",
    "            #don't fill those within offset range to the boundary\n",
    "            for h in range(coef * x + offset, coef * x + output_dims - offset):\n",
    "                for w in range(coef * y + offset, coef * y + output_dims - offset):\n",
    "                    for col in range(0, 3):\n",
    "                        result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "            \n",
    "            #pad top\n",
    "            if(x == 0):\n",
    "                for h in range(offset):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h][w - coef * y][col]\n",
    "            \n",
    "            #pad left\n",
    "            if(y == 0):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(offset):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w][col]\n",
    "                  \n",
    "            #pad bottom\n",
    "            if(x == img.height - range_x):\n",
    "                for h in range(coef * img.height - offset, coef * img.height):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "            \n",
    "            #pad right                \n",
    "            if(y == img.width - range_y):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(coef * img.width - offset, coef * img.width):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "            \n",
    "            #reached bottom of image\n",
    "            if(x == img.height - range_x):\n",
    "                break\n",
    "            #next step by x, we must not go out of bounds\n",
    "            x = min(x + step_x, img.height - range_x)\n",
    "        \n",
    "        #reached right edge of image\n",
    "        if(y == img.width - range_x):\n",
    "            break\n",
    "        #next step by y, we must not go out of bounds\n",
    "        y = min(y + step_y, img.width - range_x)\n",
    "    \n",
    "    #save result\n",
    "    imsave(outfile, result.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Now we load our pretrained models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load models\n",
    "VDSR_model = load_model(os.path.join(\"pretrained_models\", \"VDSR.model\"))\n",
    "DRNN_model = load_model(os.path.join(\"pretrained_models\", \"DRNN.model\"))\n",
    "SRResNet_model = load_model(os.path.join(\"pretrained_models\", \"SRResNet.model\"))\n",
    "SRGAN_model = load_model(os.path.join(\"pretrained_models\", \"SRGAN.model\"))\n",
    "models = [VDSR_model, DRNN_model, SRResNet_model, SRGAN_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>We will take an example image on which we want to try out our models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Data/BerkeleySegmentationDataset/example_images/example_1.jpg',\n",
       " <http.client.HTTPMessage at 0x7f2821cf82e8>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "try:\n",
    "    from urllib.request import urlretrieve, urlopen\n",
    "except ImportError: \n",
    "    from urllib import urlretrieve, urlopen\n",
    "\n",
    "link = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/images/plain/normal/color/253027.jpg\"\n",
    "\n",
    "urlretrieve(link, os.path.join(example_folder, \"example_1.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will also save a copy of bicubic interpolation effect for every image we are testing on, just for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_folder = os.path.join(results_folder, \"bicubic\")\n",
    "\n",
    "#upscale by bicubic and save for reference\n",
    "for entry in os.listdir(example_folder):\n",
    "    filename = os.path.join(example_folder, entry)\n",
    "        \n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    \n",
    "    img = Image.open(filename)\n",
    "    out = img.resize((2 * img.width, 2 * img.height), Image.BICUBIC)\n",
    "    out.save(os.path.join(save_folder, entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>Now we are finally ready to evaluate our models. The code below combines all possible filters for all images. Parameters in the calls of <code>evaluate</code> are set according to the models in question. For example, models on indices 0 and 1 are learning only the residual image, so we set <code>residual_model = True</code>.</p>\n",
    "<p>Also, all upscaling is done in the first element of the filter. Therefore, only <b>VDSR</b> and <b>DRNN</b> can be the second element of the filter and their preprocess part must be skipped in that case. We process the images and save them in appropriate folders. Folder names reflect which filter was used. See code below for additional comments.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating: Data/BerkeleySegmentationDataset/example_results/VDSR_results/example_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/cntk/core.py:74: RuntimeWarning: data is not C contiguous; rearrange your data/computation to avoid costly data conversions\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating: Data/BerkeleySegmentationDataset/example_results/VDSR_VDSR_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/DRNN_VDSR_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/DRNN_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/VDSR_DRNN_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/DRNN_DRNN_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/SRResNet_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/VDSR_SRResNet_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/DRNN_SRResNet_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/SRGAN_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/VDSR_SRGAN_results/example_1.jpg\n",
      "Now creating: Data/BerkeleySegmentationDataset/example_results/DRNN_SRGAN_results/example_1.jpg\n"
     ]
    }
   ],
   "source": [
    "#loop thorugh every model\n",
    "for i in range(4):\n",
    "    save_folder = os.path.join(results_folder, model_names[i] + \"_results\")\n",
    "        \n",
    "    #loop through every image in example_folder\n",
    "    for entry in os.listdir(example_folder):\n",
    "        filename = os.path.join(example_folder, entry)\n",
    "            \n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "                \n",
    "        outfile = os.path.join(save_folder, entry)\n",
    "            \n",
    "        print(\"Now creating: \" + outfile)\n",
    "            \n",
    "        #function calls for different models\n",
    "        if(i < 2):\n",
    "            #residual learning, image is pre-upscaled and then cleared up\n",
    "            evaluate(filename, models[i], outfile, output_dims[i], pre_upscale = True, clear_up = True, residual_model = True)\n",
    "        else:\n",
    "            #all upscaling is within the model\n",
    "            evaluate(filename, models[i], outfile, output_dims[i], pre_upscale = False, clear_up = False, residual_model = False)\n",
    "        \n",
    "    #loop through models which can additionally clear up image after we increased it (DRNN and VDSR)\n",
    "    for j in range(2):\n",
    "        #loop through results of previously applied model\n",
    "        for entry in os.listdir(save_folder):\n",
    "            filename = os.path.join(save_folder, entry)\n",
    "            filter_folder = os.path.join(results_folder, model_names[j] + \"_\" + model_names[i] + \"_results\")\n",
    "                \n",
    "            if not os.path.exists(filter_folder):\n",
    "                os.makedirs(filter_folder)\n",
    "                \n",
    "            outfile = os.path.join(filter_folder, entry)\n",
    "                \n",
    "            print(\"Now creating: \" + outfile)\n",
    "                \n",
    "            #additionally clear up image without pre-magnifying\n",
    "            evaluate(filename, models[j], outfile, output_dims[j], pre_upscale = False, clear_up = True, residual_model = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Result analysis and future work\n",
    "<p>Below is the example of what we were able to get. There is no mathematical formula which would evaluate how good our models perform. The best and most used method would be through opinion scoring, that is, presenting generated images to people so they can grade them from 1 to 5 depending on how realistic they look.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://superresolution.blob.core.windows.net/superresolutionresources/example.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url = \"https://superresolution.blob.core.windows.net/superresolutionresources/example.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>For more detailed analysis, we will present several original images (low resolution), highlight a small piece of them and see how different filters performed and what results we were able to get. We will see that in some examples we accomplished our goal pretty well, but not always.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://superresolution.blob.core.windows.net/superresolutionresources/analysis_zebra.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://superresolution.blob.core.windows.net/superresolutionresources/analysis_zebra.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://superresolution.blob.core.windows.net/superresolutionresources/analysis_village.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://superresolution.blob.core.windows.net/superresolutionresources/analysis_village.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://superresolution.blob.core.windows.net/superresolutionresources/analysis_pot.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = \"https://superresolution.blob.core.windows.net/superresolutionresources/analysis_pot.PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<p>For the <b>future work</b>, it would be wise to attempt to get better results from <b>SRGAN</b> model. The key problem is finding the appropriate coefficients for different pieces of the loss function. In most of our attempts, we would end up with completely unusable and unrecognizable images. After some trying, we were able to get decent results and there is more room for improvement there.</p>\n",
    "<p>The idea of creating model combinations <b>(filters)</b> has provided us with considerably better results. It is visible that the results of combinations of two models usually give better results than just one model by itself.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
