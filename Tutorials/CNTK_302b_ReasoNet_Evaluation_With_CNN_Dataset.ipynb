{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNTK 302b: Evaluation ReasoNet for Machine Comprehension with CNN Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This tutorial loads a pre-trained ReasoNet model and shows how cached models can be used to perform predictions a.k.a evalation on CNN data set that was not used in the training.\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "### Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary data are downloaded to ../Examples/LanguageUnderstanding/ReasoNet/Data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../Examples/LanguageUnderstanding/\")\n",
    "from ReasoNet.prepare_cnn_data import file_exists,merge_files,download_cnn,download\n",
    "\n",
    "# Check for an environment variable defined in CNTK's test infrastructure\n",
    "envvar = 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY'\n",
    "def is_test(): \n",
    "  return envvar in os.environ\n",
    "      \n",
    "data_root = \"../Examples/LanguageUnderstanding/ReasoNet/Data\"\n",
    "\n",
    "if is_test():\n",
    "  raw_train_data=os.path.join(data_root, \"cnn_test/training.txt\")\n",
    "  raw_test_data=os.path.join(data_root, \"cnn_test/test.txt\")\n",
    "else:\n",
    "  raw_train_data=os.path.join(data_root, \"cnn/training.txt\")\n",
    "  raw_test_data=os.path.join(data_root, \"cnn/test.txt\")\n",
    "  if not (file_exists(raw_train_data) and file_exists(raw_test_data)):\n",
    "    download_cnn(data_root)\n",
    "  merge_files(os.path.join(data_root, \"cnn/questions/training\"), raw_train_data)\n",
    "  merge_files(os.path.join(data_root, \"cnn/questions/test\"), raw_test_data)\n",
    "print(\"All necessary data are downloaded to {0}\".format(data_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convert to CNTK Text Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data conversion finished.\n"
     ]
    }
   ],
   "source": [
    "from ReasoNet.wordvocab import *\n",
    "\n",
    "if is_test():\n",
    "  vocab_path=os.path.join(data_root, \"cnn_test/cnn.vocab\")\n",
    "  train_ctf=os.path.join(data_root, \"cnn_test/training.ctf\")\n",
    "  test_ctf=os.path.join(data_root, \"cnn_test/test.ctf\")\n",
    "  test_size=379913\n",
    "else:\n",
    "  vocab_path=os.path.join(data_root, \"cnn/cnn.vocab\")\n",
    "  train_ctf=os.path.join(data_root, \"cnn/training.ctf\")\n",
    "  test_ctf=os.path.join(data_root, \"cnn/test.ctf\")\n",
    "  test_size=2291183\n",
    "vocab_size=101000\n",
    "if not (file_exists(train_ctf) and file_exists(test_ctf)):\n",
    "  entity_vocab, word_vocab = Vocabulary.build_vocab(raw_train_data, vocab_path, vocab_size)\n",
    "  Vocabulary.build_corpus(entity_vocab, word_vocab, raw_test_data, test_ctf)\n",
    "print(\"Data conversion finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to download model to local.\n"
     ]
    }
   ],
   "source": [
    "if is_test():\n",
    "  model_src=\"http://cntk.ai/jup/models/reasonet/model_training.ctf_final.dnn.bin\"\n",
    "  model_path=\"model/model_training.ctf_final.dnn\"\n",
    "else:\n",
    "  model_src=\"http://cntk.ai/jup/models/reasonet/model_cnn.epoch.00.bin\"\n",
    "  model_path=\"model/model_cnn.epoch.00.bin\"\n",
    "if not file_exists(model_path):\n",
    "  download(model_src, model_path)\n",
    "    \n",
    "print(\"Succeeded to download model to local.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Basic CNTK imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import cntk\n",
    "from cntk import device\n",
    "from cntk.ops import sequence, element_times, reshape, greater, slice, hardmax, input\n",
    "from io import open\n",
    "\n",
    "# Select the right target device when this notebook is being tested\n",
    "# Currently supported only for GPU \n",
    "\n",
    "if 'TEST_DEVICE' in os.environ:\n",
    "    if os.environ['TEST_DEVICE'] == 'cpu':\n",
    "        raise ValueError('This notebook is currently not support on CPU') \n",
    "    else:\n",
    "        cntk.device.set_default_device(cntk.device.gpu(0))\n",
    "cntk.device.set_default_device(cntk.device.gpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predict\n",
    "The original CNN data has been pre-processed by replace entities in the text with *@entityXX* and the answer is taken from the entities. Here is an example,\n",
    "\n",
    "* The original paragraph,\n",
    ">april 2 , 2015 an unstable Middle Eastern country has become a potential battlefield for a proxy war . today on CNN Student News , hear an explainer on why Yemen is the focus of global concern . we also report on the origins of April Fools ' Day , we detail how a 1,000 - year - old recipe could cure a modern - day superbug , and we feature a Character Study on a woman who 's steering kids to a better life . on this page you will find today 's show transcript and a place for you to request to be on the CNN Student News Roll Call . transcript click here to access the transcript of today 's CNN Student News program . please note that there may be a delay between the time when the video is available and when the transcript is published . CNN Student News is created by a team of journalists who consider the Common Core State Standards , national standards in different subject areas , and state standards when producing the show . ROLL CALL for a chance to be mentioned on the next CNN Student News , comment on the bottom of this page with your school name , mascot , city and state . we will be selecting schools from the comments of the previous show . you must be a teacher or a student age 13 or older to request a mention on the CNN Student News Roll Call ! thank you for using CNN student news !\n",
    "\n",
    "* The original query,\n",
    ">at the bottom of the page , comment for a chance to be mentioned on CNN Student News . you must be a teacher or a student age 13 or older to request a mention on the @placeholder .\n",
    "\n",
    "* The answer\n",
    ">CNN Student News Roll Call\n",
    "\n",
    "After pre-processing, it will be looks like,\n",
    "\n",
    "* Paragraph\n",
    ">april 2 , 2015 an unstable @entity1 country has become a potential battlefield for a proxy war . today on @entity4 , hear an explainer on why @entity6 is the focus of global concern . we also report on the origins of @entity11 , we detail how a 1,000 - year - old recipe could cure a modern - day superbug , and we feature a @entity14 on a woman who 's steering kids to a better life . on this page you will find today 's show transcript and a place for you to request to be on the @entity22 . transcript click here to access the transcript of today 's @entity25 . please note that there may be a delay between the time when the video is available and when the transcript is published . @entity4 is created by a team of journalists who consider the @entity33 , national standards in different subject areas , and state standards when producing the show . @entity38 for a chance to be mentioned on the next @entity4 , comment on the bottom of this page with your school name , mascot , city and state . we will be selecting schools from the comments of the previous show . you must be a teacher or a student age 13 or older to request a mention on the @entity22 ! thank you for using @entity56 student news !\n",
    "\n",
    "* Query\n",
    ">at the bottom of the page , comment for a chance to be mentioned on @entity4 . you must be a teacher or a student age 13 or older to request a mention on the @placeholder .\n",
    "\n",
    "* Answer\n",
    ">@entity22\n",
    "\n",
    "After we get the model, we can use it to predict answers given a paragraph and a query. The inputs to our `predict` function is the *pre-processed* paragraphs and queries. The output is a one hot vector whose dimention is the number of **unique** entities in the paragraph as we pick answer from the entities in the paragraph. And a 1 in the vector means the entity at that position(*the position index is the same as entity id*) is the predicted answer and 0 means not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from ReasoNet.reasonet import *\n",
    "def predict(model, params):\n",
    "  \"\"\"\n",
    "  Compute the prediction result of the given model\n",
    "  \"\"\"\n",
    "  model_args = {arg.name:arg for arg in model.arguments}\n",
    "    \n",
    "  # entity_ids_mask is a sequence of boolean with the same length \n",
    "  #  as the number of tokens in the paragraph, \n",
    "  #  where none zero means the corresponding token is an entity.\n",
    "  # E.g.\n",
    "  # Paragraph\n",
    "  # Abc efg @entity1 xyz @entity1 @entity3\n",
    "  # The corresponding entity ids mask:\n",
    "  #  0  0  1  0  1  1\n",
    "  entity_ids_mask = model_args['entity_ids_mask']\n",
    "  \n",
    "  # Normalize the input to make all none zero values to 1s\n",
    "  entity_condition = greater(entity_ids_mask, 0, name='condidion')\n",
    "    \n",
    "  # entities_all is sequence of all 1s with the same length of the number of all the enities in the paragraph. \n",
    "  # With gather operation we will create a new dynamic sequence axes.\n",
    "  # E.g. \n",
    "  # The entities in order in the paragraph is  \n",
    "  #  @entity1 @entity1 @entity3\n",
    "  # The output of the operation will be\n",
    "  # 1 1 1  \n",
    "  entities_all = sequence.gather(entity_condition, \n",
    "                                 entity_condition, \n",
    "                                 name='entities_all')\n",
    "\n",
    "  # The model prediction is a sequence of probabilities of all the tokens in the paragraph, \n",
    "  # but we only pick answer from the entities. \n",
    "  # With gather operation, we will filter out the probabilities of none entities.\n",
    "  # E.g.\n",
    "  # The model prediction of the above example would be something like\n",
    "  #  0.1 0.2 0.1 0.3 0.2 0.1\n",
    "  # The probabilities of the entities to be the answer will be\n",
    "  #  0.1 0.2 0.1\n",
    "  # With scatter operation, we assign the dynamic axes of entities_all to answers.\n",
    "  answers = sequence.scatter(\n",
    "                             # Only get the predicted probilities of the entities in the paragraph\n",
    "                             sequence.gather(model.outputs[-1], entity_condition), \n",
    "                             entities_all, \n",
    "                             name='Final_Ans')\n",
    "\n",
    "  # entity_ids is the ids of the entities in the paragraph in order. \n",
    "  # It's a sequence of one hot encoded vector. \n",
    "  # The dimention is the maxium number of unique entities in all the paragraphs.\n",
    "  # E.g. \n",
    "  # The ids for the above example will be\n",
    "  #  1:1 1:1 3:1  \n",
    "  entity_ids = input(shape=(params.entity_dim), \n",
    "                     is_sparse=True,   \n",
    "                     # The sequence length is the same as the number of entities in the paragraph, \n",
    "                     #   so it has the same dynamic axes as entities_all, as well as answers.\n",
    "                     dynamic_axes=entities_all.dynamic_axes,\n",
    "                     name='entity_ids')\n",
    "    \n",
    "  # The global token id zero is used for unknown tokens, and entity ids start with 1. \n",
    "  # So we will trim the first column in the entity id matrix.\n",
    "  # E.g. the output for the above example will be\n",
    "  # [1 0 0] [1 0 0] [0 0 1]\n",
    "  entity_id_matrix = slice(\n",
    "                           # entity_ids is one hot encoded sparse vectors, \n",
    "                           # by reshaping it, we convert them to dense vectors. \n",
    "                           reshape(entity_ids, params.entity_dim),\n",
    "                           # It's the last axis\n",
    "                           axis = -1, \n",
    "                           begin_index = 1, \n",
    "                           end_index = params.entity_dim)\n",
    "\n",
    "  # Now by multiplying answers with entity_id_matrix, we will get a probability matrix like\n",
    "  # [0.1 0 0] [0.2 0 0] [0 0 0.1]\n",
    "  entity_probs = element_times(answers, entity_id_matrix)\n",
    "    \n",
    "  # By reducing sum over the sequence dynamic axis, \n",
    "  # we will aggregate the probabilities of the same entities that \n",
    "  #  present at different positions in the paragraph. \n",
    "  # Then we get the probabilities of unique entities in the paragraph.\n",
    "  # E.g. the output for the above example input will be,\n",
    "  # [0.3 0 0.1]\n",
    "  agg_pred = sequence.reduce_sum(entity_probs)\n",
    "  \n",
    "  # We pick the entities with maxium probability as the answer\n",
    "  # E.g. the output for the above example will be,\n",
    "  # [1 0 0]\n",
    "  pred_max = hardmax(agg_pred, name='pred_max')\n",
    "  return pred_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Mapping the prediction to entities\n",
    "The prediction result is a one hot vector that 1 means the entity at that position is the predicted answer and 0 means not. To make the predition result readable, we can convert that vector to entity id and remapping it back to the real entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log with log file: log/cnn_test_04-17_18.32.09.log\n",
      ".....\n",
      "Evaluated samples: 5 in 1.9201483726501465 seconds\n",
      "===============\n",
      "[0] Doc: ( @entity0 ) -- a @entity2 court of appeals gave @entity3 a thumbs up on wednesday when it ruled that \" likes \" on the social network are protected as free speech under the @entity6 . in 2009 , six employees at the @entity10 in @entity11 lost their jobs after expressing support for their boss ' opponent in an upcoming election for sheriff , some by liking and commenting on the opponent 's facebook page . @entity2 circuit judge @entity23 found that \" liking \" something on the social network was the \" internet equivalent of displaying a political sign in one 's front yard , \" an act the @entity22 has already ruled as protected speech . the decision from the 4th @entity2 @entity33 in @entity34 , @entity11 , was a reversal of an earlier ruling on the case , in which district judge @entity38 said liking a @entity3 page was \" insufficient speech to merit constitutional protection . \" other courts have ruled that posts on the social network are protected as free speech , but @entity38 differentiated between making full statements and just clicking a button to like something . two of the employees , deputy @entity48 and @entity50 , claimed they were fired by @entity51 specifically for liking a @entity3 profile for @entity51 ' opponent , @entity53 . the two also posted messages showing their support on @entity57 's facebook page . eventually , @entity50 said he removed his post on @entity3 after co-workers asked him why he 'd risked his job so close to retirement . @entity51 allegedly confronted @entity48 and said , \" you made your bed , and now you 're going to lie in it -- after the election , you 're gone . \" when @entity51 won his bid for re-election , he did not reinstate a number of employees , including @entity48 . @entity3 and the @entity70 became involved with the case , both filing friend of the court briefs . \" the @entity6 does n't distinguish between ' liking ' a candidate on @entity3 and supporting him in a town meeting or public rally , \" the @entity70 's @entity74 said in a statement . school district hires firm to monitor students ' social media @entity83 faces new pressure to limit hate speech university suspends fraternity over @entity3 posts\n",
      " Query: 4th @placeholder @entity33 rules clicking \" like \" on @entity3 is protected as free speech\n",
      " Answer: @entity3\n",
      " Expected: @entity2\n",
      "=>Unrolled=>\n",
      " Query: b'4th @placeholder Circuit Court of Appeals rules clicking \" like \" on Facebook is protected as free speech'\n",
      " Answer: b'U.S.'\n",
      "\n",
      "===============\n",
      "[1] Doc: ( @entity0 ) -- if you think comic book characters do amazing things in comic books , you wo n't believe what they can do off the page . for starters , @entity8 brought down the @entity10 , and @entity11 raised ships from the ocean floor . 1 . superman defeats the @entity10 in the 1940s , \" @entity17 \" was a radio sensation . kids across the country huddled around their sets as the @entity21 leapt off the page and over the airwaves . although @entity8 had been fighting crime in print since 1938 , the weekly audio episodes fleshed out his storyline even further . it was on the radio that @entity8 first faced kryptonite , met @entity32 reporter @entity31 , and became associated with \" truth , justice , and the @entity36 way . \" so , it 's no wonder that when a young writer and activist named @entity41 decided to expose the secrets of the @entity10 , he looked to a certain superhero for inspiration . in the @entity46 era , the @entity10 experienced a huge resurgence . its membership was skyrocketing , and its political influence was increasing , so @entity41 went undercover to infiltrate the group . by regularly attending meetings , he became privy to the organization 's secrets . but when he took the information to local authorities , they had little interest in using it . the @entity10 had become so powerful and intimidating that police were hesitant to build a case against them . struggling to make use of his findings , @entity41 approached the writers of the @entity8 radio serial . it was perfect timing . with the war over and the @entity70 no longer a threat , the producers were looking for a new villain for @entity8 to fight . the @entity10 was a great fit for the role . in a 16 - episode series titled \" @entity76 , \" the writers pitted the @entity21 against the men in white hoods . as the storyline progressed , the shows exposed many of the @entity10 's most guarded secrets . by revealing everything from code words to rituals , the program completely stripped the @entity10 of its mystique . within two weeks of the broadcast , @entity10 recruitment was down . and by 1948 , people were showing up to klan rallies just to mock them . @entity0 : 5 memorable moments in comic book censorship 2 . @entity11 's scientific breakthrough in 1966 , @entity97 engineer @entity96 developed a method for raising sunken ships off the ocean floor by injecting them with polystyrene foam balls . however , when @entity96 tried to license his invention with the @entity105 patent office , he was denied . @entity11 had beaten him to the punch by 22 years . indeed , @entity108 's concept could be traced back to a @entity11 comic conceived by @entity110 . in addition to being the most celebrated artist of the @entity11 comics , @entity110 was known for his scientific prowess . so in a 1944 story , when @entity11 got a bump on his head that turned him into a genius , the duck managed to mumble , \" if i mix @entity120 [ a methylene compound ] with @entity122 [ ammonium ] and boil the atoms in osmotic fog , i should get speckled nitrogen ! \" although it sounded like nonsense , it was n't . in 1963 , chemists @entity130 and @entity132 wrote a technical article about methylene that included a reference to the @entity11 story . the final paragraph read , \" among experiments which have not , to our knowledge , been carried out as yet is one of a most intriguing nature suggested in the literature of no less than 19 years ago . \" a footnote revealed that \" literature \" as the @entity11 comic . it seems the web - footed children 's hero had deduced the chemical intermediate long before it had been proven to exist . @entity0 : musicians performing on @entity152 but why were these top @entity36 chemists looking to comics for inspiration ? apparently , dr. @entity130 had been a lifelong @entity11 fan , and he 'd rediscovered @entity11 's early reference to methylene while collecting old copies of the classic adventures . @entity130 never disclosed how much his work owed to @entity162 's most famous resident , but then again , how many scientists would confess that they used comic books to bolster their research ? 3 . a @entity166 villain keeps folks out of jail in a 1977 edition of @entity166 , @entity169 has the tables turned on him . the villain , @entity172 , tracks down @entity169 using an electronic transmitter that he 'd fastened to the superhero 's wrist . although @entity172 loses in the end ( he always does ) , one @entity177 judge saw beauty in his plan . inspired by the strip , judge @entity181 turned to computer salesman @entity183 and asked if he could create a similar device to keep track of crime suspects awaiting trial . in 1983 , @entity183 produced his first batch of electronic monitors . authorities in @entity191 then tested the devices on five offenders , using the gadgets as an alternative to incarceration . today , the transmitters are a common sight in courtrooms across the country , usually in the form of electronic ankle bracelets . most famously , @entity203 donned one while she was under house arrest in 2004 . perhaps she would have felt better knowing that the gadget had once nabbed @entity166 , too . @entity0 : truth about lie detectors ( and @entity208 ) 4 . @entity209 saves the bad - hair day like most @entity36 kids in the 1940s , @entity211 fantasized about growing up to be like his favorite comic book superheroes . but it turns out that @entity216 might have been more interested in their fashion statements than their special powers . during his early teen years , @entity211 was obsessed with @entity209 , known as \" @entity36 's most famous boy hero . \" a younger version of @entity224 , the character sported an unusual hairstyle that featured a curly tuft of hair falling over the side of his forehead . sound familiar ? when @entity211 set out to conquer @entity36 with his rock ' n ' roll ways , he copied the ' do , thus making it one of the most famous hairstyles of the 20th century . but that was n't all . @entity224 also gets credit for the short capes @entity211 wore on the back of his jumpsuits , as well as @entity216 's famous @entity243 logo , which bears a striking resemblance to @entity224 's lightning bolt insignia . of course , @entity211 never tried to hide his love for the captain . a copy of @entity209 no. 51 still sits in his preserved childhood bedroom in an apartment in @entity251 , and his full comics collection remains intact in the attic at @entity254 . plus , the admiration was mutual . @entity209 paid tribute to @entity216 in one issue , referring to the singer as \" the greatest modern - day philosopher . \" for more mental_floss articles , visit @entity261 entire contents of this article copyright , @entity263 rights reserved .\n",
      " Query: and @placeholder blocked a scientist from getting a patent\n",
      " Answer: @entity11\n",
      " Expected: @entity11\n",
      "=>Unrolled=>\n",
      " Query: b'and @placeholder blocked a scientist from getting a patent'\n",
      " Answer: b'Donald Duck'\n",
      "\n",
      "===============\n",
      "[2] Doc: ( @entity1 ) the hip - hop world is mourning the death of a $ @entity3 , one of the founding members of the @entity6 - based collective a $ @entity7 . \" always strive and prosper . @entity13 , \" said a post sunday on the group 's official @entity10 page with a black - and - white photo of yams , whose real name is @entity15 . he was 26 years old . \" we bugged out on @entity24 , i did n't know that would be the last time seeing my brother , \" a $ @entity17 , one of the stars who emerged from the a $ @entity7 collective , wrote in a post on @entity22 . \" @entity28 bro . we all love and @entity29 you . \" the group 's record company , @entity31 , said it was \" shocked and saddened to hear of the death of a $ @entity3 , \" according to a statement reported by @entity35 . \" as one of the creative forces behind a $ @entity39 , yams ' vision , humor and dedication to the members of a $ @entity7 will always be remembered , \" the statement said . it was n't immediately clear how @entity46 had died . other hip - hop stars expressed their sadness and paid tribute to his life on social media . \" rest in peace yams . a $ @entity7 is family , \" tweeted @entity54 . \" @entity57 should be remembered as a leader , an innovator and most importantly as an important part of @entity62 youth culture , \" wrote @entity56 . rather than being famous for rapping or mixing , @entity46 is credited with masterminding the rise of a $ @entity7 and launching the careers of a $ @entity17 and the chart - topping a $ @entity65 . \" @entity65 's like @entity70 , and i 'm @entity71 , \" @entity46 said in an interview with the @entity67 in 2013 , explaining their respective roles . \" @entity46 , i love you brother , \" @entity65 posted on @entity10 . \" you were the brilliant mind , you put us on @entity75 , you changed our lives . you changed my life , you changed the world , \" @entity77 wrote on @entity22 next to a photo of him and @entity13 kneeling on stage . yams was born to a @entity84 mother and a @entity86 father , according to the @entity67 interview . he grew up on the southern edge of @entity6 with a lifelong obsession with hip - hop . \" yams is the hip - hop encyclopedia , \" @entity92 said in the article . \" he 's no joke . that 's one person i ca n't front on when it comes to music . \" people we 've lost in 2015\n",
      " Query: \" @entity28 bro . we all love and @entity29 you , \" says a $ @placeholder , one of the stars from a $ @entity7\n",
      " Answer: @entity6\n",
      " Expected: @entity17\n",
      "=>Unrolled=>\n",
      " Query: b'\" R.i.P bro . we all love and Miss you , \" says a $ @placeholder , one of the stars from a $ AP Mob'\n",
      " Answer: b'AP Ferg'\n",
      "\n",
      "===============\n",
      "[3] Doc: ( @entity0 ) -- the world 's top golfers will play together at next week 's @entity3 as organizers have chosen to bring together big names for the season 's second major . top - ranked @entity8 will line up with defending champion @entity9 and no. 3 @entity10 for the first two rounds at @entity13 's @entity12 next thursday and friday . and in another stellar group , 14 - time major winner @entity14 will play with @entity16 champion @entity16 and five - time @entity3 runner - up @entity17 -- ranked fourth , fifth and 12th respectively . @entity14 comes into the tournament on the back of his 73rd @entity22 victory at the @entity23 , where he tied its host @entity26 in second place on the all - time list behind @entity29 . the former world no. 1 's last major win came at the @entity32 , when he triumphed in a playoff despite a serious knee injury . four - time major winner @entity17 pulled out of last week 's @entity36 event after shooting 79 in his opening round , citing fatigue after a hectic schedule including his wife 's 40th birthday . @entity17 's rivalry with @entity14 has provided many of golf 's great moments in the past two decades . they played together at @entity46 in 2008 when @entity14 won his fourth @entity3 , but their last pairing at a major was the @entity49 -- where @entity17 was fifth and @entity14 tied sixth . @entity16 has played only twice since april 's @entity51 triumph , finishing 18th in @entity52 and then missing the cut at @entity54 last week . @entity9 also missed the cut at the @entity56 , his third in a row . the @entity59 is playing at the @entity60 in @entity61 this week , and carded a two - under par 68 in his opening round on thursday . it left him in touch with the early leaders , but the 23 - year - old reach just half of his greens in regulation and found less than half of his fairways in the first round . @entity60 leaderboard he will need to be more accurate at the tree - lined @entity12 , which has been totally revamped since it hosted the @entity3 in 1998 and is expected to provide a stern test . if he wins in @entity61 , he will take back the top spot from @entity8 . @entity8 has taken a break this week after finishing 12th at the @entity56 , and he will be seeking his first major along with fellow @entity82 and former world no. 1 @entity10 . @entity10 is playing at the @entity85 's @entity84 in @entity86 , where he has a three - stroke lead at the halfway stage . the 39 - year - old shot 64 in his second round on thursday as he seeks his third victory at the event , having won it in 2000 and 1996 -- his first professional title . in other notable groups next week , @entity9 's compatriot @entity94 -- the @entity95 champion -- will play with 2003 winner @entity97 and another former world no. 2 , @entity98 of @entity99 . @entity101 's two - time @entity3 champion @entity100 will play with 2006 winner @entity102 of @entity103 and @entity105 's @entity104 , who won it in 2007 and the @entity49 two years later . @entity109 @entity108 captain @entity107 came through monday 's qualifying and will line up alongside @entity112 's three - time major champion @entity111 and fellow @entity109 veteran @entity113 . @entity114 , another @entity101 to have won the tournament twice , will play with former world no. 1 @entity117 and 2007 @entity118 champion @entity118 , who has won once on the @entity22 this season . there will be an all - @entity122 grouping consisting of eight - time @entity22 winner @entity124 , fellow veteran @entity125 ( who famously headed off @entity126 to take the @entity127 ) and promising 25 - year - old @entity128 -- who played for the international team at last year 's @entity130 . the field also includes @entity132 , who came through qualifying this week to earn his first major start since 1998 . the 40 - year - old , now a university coach in @entity137 , needs to use a golf cart due to a circulatory disorder in his leg that means he can not walk 18 holes .\n",
      " Query: @entity14 is seeking his third @placeholder title , while @entity17 has been runner - up five times\n",
      " Answer: @entity16\n",
      " Expected: @entity3\n",
      "=>Unrolled=>\n",
      " Query: b'Woods is seeking his third @placeholder title , while Mickelson has been runner - up five times'\n",
      " Answer: b'U.S. Open'\n",
      "\n",
      "===============\n",
      "[4] Doc: ( @entity0 ) -- @entity3 fishermen suspended their blockade at three @entity6 ports thursday , allowing ferry traffic and freight to move through after two days of disruption , union leaders said . @entity3 fishing boats blockade the port of @entity12 . the @entity3 ports of @entity14 , @entity15 and @entity12 were open again after @entity3 unions met thursday and agreed to stop the blockade . union leaders have yet to agree on how the rest of their protest will develop , and whether the suspension will become permanent . the fishermen began their blockade of the three ports tuesday to protest @entity26 fishing quotas , which they say threaten their livelihoods . the flotillas forced a halt to all @entity31 traffic , including passenger ferries and freighters , stranding tourists on both sides of the waterway and causing a backlog of freight trucks . @entity39 , the largest ferry operator on the @entity6 , said it had resumed running normal services to @entity14 . \" it is our hope that we 'll be able to continue doing that throughout the day , \" spokeswoman @entity42 said . @entity47 , which operates services to @entity12 , said it had canceled four sailings thursday as a result of the dispute . \" we do not yet have any information on whether any of our services will be affected beyond 16th april , \" the company said in a statement . @entity3 fishermen held four hours of talks with @entity58 and fisheries minister @entity59 in @entity60 on wednesday , the @entity3 news agency @entity56 reported . @entity59 offered the local industry â‚¬ 4 million ( $ 5.3 million ) in aid , but refused to budge on the fishermen 's key demand that the @entity26 increase fishing quotas , @entity56 reported . both @entity3 and the @entity26 have ruled out any renegotiation , pointing out that @entity3 cod quotas have already been raised 30 percent since 2008 , @entity56 said .\n",
      " Query: @placeholder fishermen lift port blockades at @entity14 , @entity15 and @entity12\n",
      " Answer: @entity3\n",
      " Expected: @entity3\n",
      "=>Unrolled=>\n",
      " Query: b'@placeholder fishermen lift port blockades at Calais , Dunkirk and Boulogne'\n",
      " Answer: b'French'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cntk.device as device\n",
    "import numpy as np\n",
    "import math\n",
    "from cntk import load_model\n",
    "import time\n",
    "def unroll_entities(doc, entity_dict):\n",
    "  tokens = doc.split(u' ')\n",
    "  for i in range(len(tokens)):\n",
    "    if tokens[i] in entity_dict:\n",
    "      tokens[i] = entity_dict[tokens[i]]    \n",
    "  return u' '.join(tokens).encode('utf-8').strip()  \n",
    "\n",
    "def pred_cnn_model(model_path):\n",
    "  logger.init(\"cnn_test\")\n",
    "  vocab_dim = 101585\n",
    "  entity_dim = 586\n",
    "  hidden_dim=256\n",
    "  max_rl_steps=5\n",
    "  embedding_dim=300\n",
    "  att_dim = 384\n",
    "  minibatch_size=1\n",
    "  share_rnn = True\n",
    "\n",
    "  test_data = create_reader(test_ctf, vocab_dim, entity_dim, False)\n",
    "  embedding_init = None\n",
    "\n",
    "  params = model_params(vocab_dim = vocab_dim, entity_dim = entity_dim, hidden_dim = hidden_dim,\n",
    "                        embedding_dim = embedding_dim, attention_dim=att_dim, max_rl_steps = max_rl_steps,\n",
    "                        embedding_init = embedding_init, dropout_rate = 0.2, share_rnn_param = share_rnn)\n",
    "\n",
    "  entity_table, word_table = Vocabulary.load_vocab(vocab_path)\n",
    "  model = load_model(model_path)\n",
    "  predict_func = predict(model, params)\n",
    "  bind = bind_data(predict_func, test_data)\n",
    "  context_stream = get_context_bind_stream(bind)\n",
    "  samples_sum = 0\n",
    "  i = 0\n",
    "  predicted_results = []\n",
    "  max_num = 5\n",
    "  start = time.time()\n",
    "  while i<test_size:\n",
    "    mbs = min(test_size - i, minibatch_size)\n",
    "    mb = test_data.next_minibatch(mbs, bind)\n",
    "    pred = predict_func.eval(mb)\n",
    "    # Convert entity one hot vector to entity id\n",
    "    ans = np.nonzero(pred)\n",
    "    # Remapping entity id to real entity\n",
    "    for id in ans[1]:\n",
    "      predicted_results += [ entity_table.lookup_by_id(id) ]    \n",
    "    i += mb[context_stream].num_samples\n",
    "    samples = mb[context_stream].num_sequences\n",
    "    samples_sum += samples\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "    if samples_sum >= max_num:\n",
    "      break\n",
    "  end = time.time()\n",
    "  total = end - start\n",
    "  print(\"\")\n",
    "  print(\"Evaluated samples: {0} in {1} seconds\".format(samples_sum, total))\n",
    "  instance_id = 0\n",
    "  with open(raw_test_data, 'r', encoding='utf-8') as raw:\n",
    "    content = raw.readlines()\n",
    "    for record in content:\n",
    "      fields = record.strip().split(u'\\t')\n",
    "      query = fields[0]\n",
    "      answer = fields[1]\n",
    "      doc = fields[2]\n",
    "      entity_dict={}\n",
    "      for i in range(3,len(fields)):\n",
    "        pair=fields[i].split(u':')\n",
    "        entity_dict[pair[0]]=pair[1]\n",
    "      print(\"===============\")\n",
    "      print(\"[{0}] Doc: {1}\\n Query: {2}\\n Answer: {3}\\n Expected: {4}\".format(instance_id, \n",
    "                                                                               doc, \n",
    "                                                                               query, \n",
    "                                                                               predicted_results[instance_id], \n",
    "                                                                               answer))\n",
    "      print(\"=>Unrolled=>\\n Query: {0}\\n Answer: {1}\".format(unroll_entities(query, entity_dict), \n",
    "                                                     unroll_entities(answer, entity_dict)))\n",
    "      print()\n",
    "      instance_id+=1\n",
    "      if instance_id >= len(predicted_results):\n",
    "        break\n",
    "\n",
    "pred_cnn_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
