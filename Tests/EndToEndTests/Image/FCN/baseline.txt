CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz
    Hardware threads: 40
    Total Memory: 264046996 kB
-------------------------------------------------------------------
=== Preparing training and test data
=== Running training
=== Running /mnt/Data/nikmil/cntk/gpu/release/bin/cntk configFile=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/fcn.cntk currentDirectory=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu DataDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data ConfigDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN OutputDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu DeviceId=0 timestamping=true
CNTK 2.0rc1+ (fcn_test 351a32, Apr 13 2017 15:12:35) on ASAUDGPU1 at 2017/04/18 06:26:46

/mnt/Data/nikmil/cntk/gpu/release/bin/cntk  configFile=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/fcn.cntk  currentDirectory=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu  DataDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data  ConfigDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN  OutputDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data
ping [requestnodes (before change)]: 1 nodes pinging each other
ping [requestnodes (after change)]: 1 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 1 out of 1 MPI nodes on a single host (1 requested); we (0) are in (participating)
ping [mpihelper]: 1 nodes pinging each other
04/18/2017 06:26:47: -------------------------------------------------------------------
04/18/2017 06:26:47: Build info: 

04/18/2017 06:26:47: 		Built time: Apr 13 2017 15:11:29
04/18/2017 06:26:47: 		Last modified date: Thu Apr 13 06:08:38 2017
04/18/2017 06:26:47: 		Build type: release
04/18/2017 06:26:47: 		Build target: GPU
04/18/2017 06:26:47: 		With ASGD: yes
04/18/2017 06:26:47: 		Math lib: mkl
04/18/2017 06:26:47: 		CUDA_PATH: /usr/local/cuda-8.0
04/18/2017 06:26:47: 		CUB_PATH: /usr/local/cub-1.4.1
04/18/2017 06:26:47: 		CUDNN_PATH: /usr/local/cudnn-5.1
04/18/2017 06:26:47: 		Build Branch: fcn_test
04/18/2017 06:26:47: 		Build SHA1: 351a329b40cd85556eac8aa837ceec8883a77c82
04/18/2017 06:26:47: 		Built by Source/CNTK/buildinfo.h$$0 on ASAUDGPU1
04/18/2017 06:26:47: 		Build Path: /mnt/Data/nikmil/cntk/
04/18/2017 06:26:47: 		MPI distribution: Open MPI
04/18/2017 06:26:47: 		MPI version: 1.10.2
04/18/2017 06:26:47: -------------------------------------------------------------------
04/18/2017 06:26:47: -------------------------------------------------------------------
04/18/2017 06:26:47: GPU info:

04/18/2017 06:26:47: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11002 MB
04/18/2017 06:26:47: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11437 MB
04/18/2017 06:26:47: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11437 MB
04/18/2017 06:26:47: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11437 MB
04/18/2017 06:26:47: 		Device[4]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11437 MB
04/18/2017 06:26:47: 		Device[5]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11437 MB
04/18/2017 06:26:47: 		Device[6]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11437 MB
04/18/2017 06:26:47: 		Device[7]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11439 MB; free memory = 11437 MB
04/18/2017 06:26:47: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: fcn.cntk:ClassCount=2
configparameters: fcn.cntk:command=TrainFCN8:ConvertFCN8ToFCN4:TrainFCN4:PrepareFCN4ForTest:TestFCN4
configparameters: fcn.cntk:ConfigDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN
configparameters: fcn.cntk:ConvertFCN8ToFCN4=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN8_train"
    NewModel = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_initial"
    editPath = "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/fcn8_to_fcn4.mel"
]

configparameters: fcn.cntk:currentDirectory=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:DataDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:deviceId=0
configparameters: fcn.cntk:Epochs=2
configparameters: fcn.cntk:FcnDataDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Data
configparameters: fcn.cntk:FeatureChannels=16
configparameters: fcn.cntk:ImageChannels=1
configparameters: fcn.cntk:LrPerSample=0.01
configparameters: fcn.cntk:MbSize=16
configparameters: fcn.cntk:ModelDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models
configparameters: fcn.cntk:MomentumTimeConstant=1215
configparameters: fcn.cntk:numMBsToShowResult=1
configparameters: fcn.cntk:OutputDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu
configparameters: fcn.cntk:parallelTrain=true
configparameters: fcn.cntk:precision=float
configparameters: fcn.cntk:PrepareFCN4ForTest=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_train"
    NewModel = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_test"
    editPath = "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/prepare_for_test.mel"
    TestImageHeight = 28
    TestImageWidth = 28
    ImageChannels = 1
    ClassCount = 2
]

configparameters: fcn.cntk:RunDir=/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu
configparameters: fcn.cntk:TestDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:TestFCN4=[
    action = test
    numMBsToShowResult = 20
    modelPath = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_test"
    minibatchSize = 16
distributedMBReading = "true" 
    BrainScriptNetworkBuilder = [
        m = BS.Network.Load("/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_test")
        evaluationNodes = (m.pixelwiseError:m.miouError)
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TestFeaturesDim=784
configparameters: fcn.cntk:TestIgnoreDim=784
configparameters: fcn.cntk:TestImageHeight=28
configparameters: fcn.cntk:TestImageWidth=28
configparameters: fcn.cntk:TestLabelsDim=1568
configparameters: fcn.cntk:timestamping=true
configparameters: fcn.cntk:traceLevel=1
configparameters: fcn.cntk:TrainDataFile=Train_cntk_fcn_text.txt
configparameters: fcn.cntk:TrainFCN4=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        featureChannels = 16
        inModel = BS.Network.Load("/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_initial")
        predictionFCN4 = ConvLayer1x1MSRAInit(inModel.featuresFCN4, featureChannels, classCount, 1, 1)
        upsampledFCN8 = LearnableUpsamplingLayer{classCount, classCount, 4, 2}(inModel.predictionFCN8)
        cropFCN8 = CropAutomatic(upsampledFCN8, predictionFCN4)
        fusionFCN4 = Plus(cropFCN8, predictionFCN4)
        upsampledFCN4 = BilinearUpsamplingLayer{classCount, 8, 4}(fusionFCN4)
        out = CropAutomaticGivenAncestors(upsampledFCN4, inModel.labels, inModel.features, inModel.labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(inModel.labels, out, inModel.ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(inModel.labels, out, inModel.ignoreMask)
        miouError = MeanIOUError(inModel.labels, out, inModel.ignoreMask, classCount = classCount)
        featureNodes    = (inModel.features)
        labelNodes      = (inModel.labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant= 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFCN8=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN8_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        imageWidth = 28
        imageHeight = 28
        imageChannels = 1
        featureChannels = 16
        bnTimeConst = 15992
        features = ImageInput(imageWidth, imageHeight, imageChannels, imageLayout = "cudnn", tag = 'feature')
        labels = ImageInput(imageWidth, imageHeight, classCount, imageLayout = "cudnn", tag = 'label')
        ignoreMask = ImageInput(imageWidth, imageHeight, 1, imageLayout = "cudnn", tag = 'feature')
        featuresFCN4 = Sequential(
            ConvBNReLULayer{featureChannels, /*kernel*/ (7:7), /*stride*/ (2:2), bnTimeConst} :
            MaxPoolingLayer{(3:3), stride = 2, pad = true})(features)
        featuresFCN8 = Sequential(
            ResNetBasicInc{featureChannels, /*stride*/ (2:2), bnTimeConst} :
            ResNetBasic{featureChannels, bnTimeConst})(featuresFCN4)
        predictionFCN8 = ConvLayer1x1MSRAInit(featuresFCN8, featureChannels, classCount, 1, 1)
        upsampledFCN8 = BilinearUpsamplingLayer{classCount, 16, 8}(predictionFCN8)
        out = CropAutomaticGivenAncestors(upsampledFCN8, labels, features, labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(labels, out, ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(labels, out, ignoreMask)
        miouError = MeanIOUError(labels, out, ignoreMask, classCount = classCount)
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant = 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFeaturesDim=784
configparameters: fcn.cntk:TrainIgnoreDim=784
configparameters: fcn.cntk:TrainImageHeight=28
configparameters: fcn.cntk:TrainImageWidth=28
configparameters: fcn.cntk:TrainLabelsDim=1568
configparameters: fcn.cntk:ValDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:WeightDecay=0.00000390625
04/18/2017 06:26:47: Commands: TrainFCN8 ConvertFCN8ToFCN4 TrainFCN4 PrepareFCN4ForTest TestFCN4
04/18/2017 06:26:47: precision = "float"

04/18/2017 06:26:47: ##############################################################################
04/18/2017 06:26:47: #                                                                            #
04/18/2017 06:26:47: # TrainFCN8 command (train action)                                           #
04/18/2017 06:26:47: #                                                                            #
04/18/2017 06:26:47: ##############################################################################

04/18/2017 06:26:47: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[7 x 7 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[1 x 1 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.

Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 108 nodes to process in pass 1.

Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 0 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [7 x 7 x 1 x 16].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[7 x 7 x 1 x 16] <- heNormal(seed=6, init dims=[784 x 49], range=0.202031(0.202031*1.000000), onCPU=true.
)Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *] -> [7 x 7 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=5, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=4, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 0 x 16]
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [1 x 1 x 16 x 16].
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[1 x 1 x 16 x 16] <- heNormal(seed=7, init dims=[16 x 16], range=0.353553(0.353553*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=3, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=2, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 2 x *]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [16 x 16 x 2 x 2], [4 x 4 x 2 x *] -> [40 x 40 x 2 x *]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *]
Validating --> out = Crop (upsampledFCN8, labels, features, labels) : [40 x 40 x 2 x *], [28 x 28 x 2 x *], [28 x 28 x 1 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *] -> [1 x *]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *], [1 x *] -> [1 x *]

Validating network. 64 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using cuDNN convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

04/18/2017 06:26:47: 
Model has 108 nodes. Using GPU 0.

04/18/2017 06:26:47: Training criterion:   CE = ElementTimes

04/18/2017 06:26:47: Evaluation criteria:
04/18/2017 06:26:47: 	pixelwiseError = ElementTimes
04/18/2017 06:26:47: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 159 matrices, 96 are shared as 26, and 63 are not shared.

Here are the ones that share memory:
	{ CE.out_shift : [28 x 28 x 2 x *]
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *] (gradient)
	  upsampledFCN8 : [40 x 40 x 2 x *] }
	{ featuresFCN8 : [4 x 4 x 16 x *]
	  featuresFCN8.b : [4 x 4 x 16 x *]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *] (gradient) }
	{ CE.diff_valid : [28 x 28 x 1 x *] (gradient)
	  CE.logits.r : [28 x 28 x 1 x *] (gradient)
	  CE.out_shift : [28 x 28 x 2 x *] (gradient)
	  featuresFCN4 : [7 x 7 x 16 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.intersection : [28 x 28 x 2 x *]
	  miouError.unionFlat : [784 x 2 x *]
	  pixelwiseError.acc._ : [28 x 28 x 2 x *]
	  pixelwiseError.diffs : [28 x 28 x 1 x *] }
	{ CE : [1] (gradient)
	  CE.norm_factor.z : [1]
	  miouError.miou : [1] }
	{ CE.diff : [28 x 28 x 1 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *] }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.u : [1 x 2] }
	{ featuresFCN8.p : [4 x 4 x 16 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *]
	  miouError.intersectionByClass.r : [1 x 2 x *]
	  miouError.unionByClass.r : [1 x 2 x *]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *] }
	{ CE.ce_unnorm : [1]
	  featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient) }
	{ featuresFCN4.x : [14 x 14 x 16 x *]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *] (gradient) }
	{ CE.out_max.r : [28 x 28 x 1 x *]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] (gradient) }
	{ featuresFCN8.x.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.p : [4 x 4 x 16 x *]
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient) }
	{ featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *] }
	{ featuresFCN8.x.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *] }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *] }
	{ CE.diff : [28 x 28 x 1 x *] (gradient)
	  CE.logits_per_class : [28 x 28 x 2 x *]
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *]
	  out : [28 x 28 x 2 x *] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  out : [28 x 28 x 2 x *] }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.s : [4 x 4 x 16 x *] }
	{ featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ CE.log_sum.r : [28 x 28 x 1 x *]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ CE.log_sum.r : [28 x 28 x 1 x *] (gradient)
	  CE.out_max.r : [28 x 28 x 1 x *] (gradient)
	  featuresFCN8 : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  pixelwiseError.acc.r : [28 x 28 x 1 x *]
	  pixelwiseError.pixelNorm.z.r : [1 x *] }
	{ CE.logits_per_class : [28 x 28 x 2 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *]
	  miouError.intersectionFlat : [784 x 2 x *]
	  miouError.union : [28 x 28 x 2 x *]
	  upsampledFCN8 : [40 x 40 x 2 x *] (gradient) }
	{ CE.diff_valid : [28 x 28 x 1 x *]
	  CE.logits.r : [28 x 28 x 1 x *]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *] }

Here are the ones that don't share memory:
	{upsampledFCN8.W : [16 x 16 x 2 x 2]}
	{predictionFCN8.W : [2 x 16]}
	{labels : [28 x 28 x 2 x *]}
	{ignoreMask : [28 x 28 x 1 x *]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{BS.Constants.One : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{miouError.norm.z : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{features : [28 x 28 x 1 x *]}
	{pixelwiseError : [1 x *]}
	{miouError : [1]}
	{miouError.norm : [1]}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *]}
	{miouError.labelMasked : [28 x 28 x 2 x *]}
	{CE.norm_factor : [1]}
	{CE : [1]}
	{miouError.i : [1 x 2]}
	{featuresFCN4 : [7 x 7 x 16 x *]}
	{pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *]}
	{predictionFCN8.W : [2 x 16] (gradient)}
	{miouError.reciprocalUnion : [1 x 2]}
	{miouError.outHardmax.isMax : [28 x 28 x 2 x *]}
	{pixelwiseError.errSum.r : [1 x *]}
	{pixelwiseError.pixelNorm : [1 x *]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *]}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *]}
	{miouError.outMasked : [28 x 28 x 2 x *]}
	{miouError.iouSum.r : [1]}


04/18/2017 06:26:47: Training 10480 parameters in 19 out of 19 parameter tensors and 51 nodes with gradient:

04/18/2017 06:26:47: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
04/18/2017 06:26:47: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:47: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:47: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:47: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]

Initializing dataParallelSGD with FP32 aggregation.
04/18/2017 06:26:47: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

04/18/2017 06:26:47: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/18/2017 06:26:47: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05358126 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67398942 * 1; time = 0.2586s; samplesPerSecond = 61.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05348113 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67441511 * 1; time = 0.0518s; samplesPerSecond = 309.0
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05336734 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67430866 * 1; time = 0.0038s; samplesPerSecond = 4159.0
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368700 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67455792 * 1; time = 0.0032s; samplesPerSecond = 4964.4
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05335811 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67504084 * 1; time = 0.0032s; samplesPerSecond = 4972.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05369275 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67514026 * 1; time = 0.0047s; samplesPerSecond = 3396.3
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05265899 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67507046 * 1; time = 0.0044s; samplesPerSecond = 3669.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05230937 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67532295 * 1; time = 0.0035s; samplesPerSecond = 4565.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05198928 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67511535 * 1; time = 0.0034s; samplesPerSecond = 4753.1
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05222526 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67508692 * 1; time = 0.0032s; samplesPerSecond = 4924.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05389463 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67506301 * 1; time = 0.0034s; samplesPerSecond = 4700.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05333263 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67526436 * 1; time = 0.0034s; samplesPerSecond = 4678.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05272814 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67540681 * 1; time = 0.0034s; samplesPerSecond = 4745.6
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05209520 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67514801 * 1; time = 0.0033s; samplesPerSecond = 4877.3
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05225395 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67502201 * 1; time = 0.0033s; samplesPerSecond = 4874.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05167080 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67490757 * 1; time = 0.0034s; samplesPerSecond = 4714.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05176315 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.67495865 * 1; time = 0.0033s; samplesPerSecond = 4800.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05266294 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67491806 * 1; time = 0.0034s; samplesPerSecond = 4685.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05159564 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67501092 * 1; time = 0.0032s; samplesPerSecond = 4982.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05183941 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67500412 * 1; time = 0.0034s; samplesPerSecond = 4737.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05289968 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67495602 * 1; time = 0.0034s; samplesPerSecond = 4732.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05099520 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.67506933 * 1; time = 0.0035s; samplesPerSecond = 4528.3
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05251543 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67518258 * 1; time = 0.0032s; samplesPerSecond = 4933.3
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05193302 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67510223 * 1; time = 0.0033s; samplesPerSecond = 4801.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05142954 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67501879 * 1; time = 0.0034s; samplesPerSecond = 4682.7
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05142086 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67494613 * 1; time = 0.0034s; samplesPerSecond = 4750.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05044030 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67490309 * 1; time = 0.0034s; samplesPerSecond = 4736.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05047078 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67470402 * 1; time = 0.0032s; samplesPerSecond = 4973.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05127440 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67464465 * 1; time = 0.0040s; samplesPerSecond = 3970.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05085520 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67467308 * 1; time = 0.0038s; samplesPerSecond = 4163.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05155106 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67465854 * 1; time = 0.0036s; samplesPerSecond = 4460.0
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.05023826 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67464679 * 1; time = 0.0031s; samplesPerSecond = 5139.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.05065093 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67471081 * 1; time = 0.0032s; samplesPerSecond = 4987.6
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.05021257 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67462003 * 1; time = 0.0032s; samplesPerSecond = 4969.1
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.05021331 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67457271 * 1; time = 0.0032s; samplesPerSecond = 4982.4
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04962941 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67442662 * 1; time = 0.0032s; samplesPerSecond = 5060.1
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04995882 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67431754 * 1; time = 0.0032s; samplesPerSecond = 4935.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04905783 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67424846 * 1; time = 0.0034s; samplesPerSecond = 4724.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04903949 * 16; pixelwiseError = 0.49872449 * 16; miouError = 0.67405820 * 1; time = 0.0034s; samplesPerSecond = 4728.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04942059 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67393029 * 1; time = 0.0034s; samplesPerSecond = 4670.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04903770 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.67384571 * 1; time = 0.0033s; samplesPerSecond = 4873.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04925745 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67371136 * 1; time = 0.0033s; samplesPerSecond = 4790.0
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04858891 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67352647 * 1; time = 0.0034s; samplesPerSecond = 4646.7
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04879066 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67342925 * 1; time = 0.0034s; samplesPerSecond = 4694.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04846421 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67336810 * 1; time = 0.0034s; samplesPerSecond = 4715.1
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04976217 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67332262 * 1; time = 0.0033s; samplesPerSecond = 4790.1
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04835905 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67324579 * 1; time = 0.0035s; samplesPerSecond = 4593.4
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04839681 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.67312372 * 1; time = 0.0044s; samplesPerSecond = 3666.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04807592 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67301512 * 1; time = 0.0034s; samplesPerSecond = 4656.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04864993 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.67287576 * 1; time = 0.0033s; samplesPerSecond = 4803.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04807357 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67276663 * 1; time = 0.0035s; samplesPerSecond = 4630.4
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04832945 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67266524 * 1; time = 0.0035s; samplesPerSecond = 4524.9
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04854266 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.67255133 * 1; time = 0.0034s; samplesPerSecond = 4654.0
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04867917 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67244208 * 1; time = 0.0032s; samplesPerSecond = 4934.4
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04762788 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67233753 * 1; time = 0.0033s; samplesPerSecond = 4832.5
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04807315 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67224896 * 1; time = 0.0034s; samplesPerSecond = 4645.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04766793 * 16; pixelwiseError = 0.50071752 * 16; miouError = 0.67212522 * 1; time = 0.0034s; samplesPerSecond = 4691.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04836555 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67193943 * 1; time = 0.0034s; samplesPerSecond = 4650.1
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04791102 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.67184711 * 1; time = 0.0033s; samplesPerSecond = 4823.2
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04734936 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67173970 * 1; time = 0.0034s; samplesPerSecond = 4705.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04762774 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67164236 * 1; time = 0.0034s; samplesPerSecond = 4711.8
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04713606 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67150962 * 1; time = 0.0033s; samplesPerSecond = 4800.4
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09483323 * 8; pixelwiseError = 0.50000000 * 8; miouError = 0.67144477 * 1; time = 0.0053s; samplesPerSecond = 1501.6
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67144477 * 1; time = 0.0008s; samplesPerSecond = 0.0
04/18/2017 06:26:48: Finished Epoch[ 1 of 2]: [Training] CE = 0.05085723 * 1000; pixelwiseError = 0.49977423 * 1000; miouError = 0.67144483 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=0.5283s
04/18/2017 06:26:48: Final Results: Minibatch[1-8]: CE = 0.05367580 * 100; pixelwiseError = 0.50012756 * 100; miouError = 0.66783655 * 1
04/18/2017 06:26:48: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05367580 * 100; pixelwiseError = 0.50012756 * 100; miouError = 0.66783655 * 1
04/18/2017 06:26:48: SGD: Saving checkpoint model '/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN8_train.1'

04/18/2017 06:26:48: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/18/2017 06:26:48: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04700519 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66612023 * 1; time = 0.0036s; samplesPerSecond = 4481.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04714876 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66607058 * 1; time = 0.0032s; samplesPerSecond = 4975.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04765578 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66636401 * 1; time = 0.0034s; samplesPerSecond = 4768.5
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04804923 * 16; pixelwiseError = 0.50079721 * 16; miouError = 0.66675544 * 1; time = 0.0034s; samplesPerSecond = 4724.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04675569 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66669500 * 1; time = 0.0034s; samplesPerSecond = 4665.1
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04724479 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66669518 * 1; time = 0.0032s; samplesPerSecond = 5005.5
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04702438 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66650820 * 1; time = 0.0033s; samplesPerSecond = 4920.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04676031 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66648334 * 1; time = 0.0033s; samplesPerSecond = 4842.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04685747 * 16; pixelwiseError = 0.49944198 * 16; miouError = 0.66642678 * 1; time = 0.0033s; samplesPerSecond = 4917.3
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04695185 * 16; pixelwiseError = 0.50103641 * 16; miouError = 0.66651678 * 1; time = 0.0032s; samplesPerSecond = 4936.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04675236 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.66656190 * 1; time = 0.0031s; samplesPerSecond = 5193.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04688483 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66650724 * 1; time = 0.0033s; samplesPerSecond = 4880.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04710712 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.66653931 * 1; time = 0.0033s; samplesPerSecond = 4897.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04658839 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.66656172 * 1; time = 0.0033s; samplesPerSecond = 4879.8
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04683050 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66656494 * 1; time = 0.0034s; samplesPerSecond = 4661.5
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04657680 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652799 * 1; time = 0.0032s; samplesPerSecond = 4975.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04679916 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66655302 * 1; time = 0.0034s; samplesPerSecond = 4683.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04660954 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652733 * 1; time = 0.0034s; samplesPerSecond = 4690.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04645366 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66646546 * 1; time = 0.0034s; samplesPerSecond = 4693.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04691650 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66647786 * 1; time = 0.0033s; samplesPerSecond = 4828.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04672623 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66648334 * 1; time = 0.0033s; samplesPerSecond = 4788.0
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04685799 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66649449 * 1; time = 0.0034s; samplesPerSecond = 4745.8
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04632717 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.66652137 * 1; time = 0.0034s; samplesPerSecond = 4638.1
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04620084 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652417 * 1; time = 0.0033s; samplesPerSecond = 4810.8
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04644240 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66655266 * 1; time = 0.0032s; samplesPerSecond = 4947.2
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04647168 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.66662544 * 1; time = 0.0034s; samplesPerSecond = 4736.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04656660 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.66658986 * 1; time = 0.0034s; samplesPerSecond = 4719.3
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04652067 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66661507 * 1; time = 0.0034s; samplesPerSecond = 4668.6
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04621993 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66658843 * 1; time = 0.0043s; samplesPerSecond = 3701.3
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04661596 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66662574 * 1; time = 0.0035s; samplesPerSecond = 4552.0
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04641042 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66667020 * 1; time = 0.0038s; samplesPerSecond = 4184.8
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04644848 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66669607 * 1; time = 0.0040s; samplesPerSecond = 3956.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04617932 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66668630 * 1; time = 0.0039s; samplesPerSecond = 4104.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04607057 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66672164 * 1; time = 0.0035s; samplesPerSecond = 4552.1
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04620295 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.66673577 * 1; time = 0.0035s; samplesPerSecond = 4514.0
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04600681 * 16; pixelwiseError = 0.49864474 * 16; miouError = 0.66672814 * 1; time = 0.0035s; samplesPerSecond = 4629.5
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04620455 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66676486 * 1; time = 0.0032s; samplesPerSecond = 4970.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04619166 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66678196 * 1; time = 0.0034s; samplesPerSecond = 4706.0
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04603130 * 16; pixelwiseError = 0.49776784 * 16; miouError = 0.66675991 * 1; time = 0.0035s; samplesPerSecond = 4594.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04587510 * 16; pixelwiseError = 0.49880418 * 16; miouError = 0.66677636 * 1; time = 0.0034s; samplesPerSecond = 4698.3
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04610740 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.66679800 * 1; time = 0.0032s; samplesPerSecond = 4961.3
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04596606 * 16; pixelwiseError = 0.49832585 * 16; miouError = 0.66679817 * 1; time = 0.0032s; samplesPerSecond = 4961.1
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04600767 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.66681063 * 1; time = 0.0051s; samplesPerSecond = 3167.8
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04608699 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66680336 * 1; time = 0.0073s; samplesPerSecond = 2198.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04595220 * 16; pixelwiseError = 0.49784753 * 16; miouError = 0.66678578 * 1; time = 0.0075s; samplesPerSecond = 2122.6
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04611240 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66680759 * 1; time = 0.0074s; samplesPerSecond = 2160.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04594596 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66686183 * 1; time = 0.0054s; samplesPerSecond = 2953.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04565827 * 16; pixelwiseError = 0.49864474 * 16; miouError = 0.66688406 * 1; time = 0.0045s; samplesPerSecond = 3536.0
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04572549 * 16; pixelwiseError = 0.49936226 * 16; miouError = 0.66691160 * 1; time = 0.0046s; samplesPerSecond = 3467.3
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04577861 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66692114 * 1; time = 0.0046s; samplesPerSecond = 3510.2
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04588787 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66695815 * 1; time = 0.0045s; samplesPerSecond = 3533.4
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04579681 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66696715 * 1; time = 0.0036s; samplesPerSecond = 4459.9
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04578757 * 16; pixelwiseError = 0.49968109 * 16; miouError = 0.66698879 * 1; time = 0.0043s; samplesPerSecond = 3716.5
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04561337 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.66702253 * 1; time = 0.0038s; samplesPerSecond = 4245.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04561181 * 16; pixelwiseError = 0.49768811 * 16; miouError = 0.66701943 * 1; time = 0.0046s; samplesPerSecond = 3452.1
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04555615 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66701114 * 1; time = 0.0046s; samplesPerSecond = 3494.2
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04548022 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.66704595 * 1; time = 0.0034s; samplesPerSecond = 4650.3
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04564869 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.66706735 * 1; time = 0.0033s; samplesPerSecond = 4827.2
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04551123 * 16; pixelwiseError = 0.49713007 * 16; miouError = 0.66705430 * 1; time = 0.0033s; samplesPerSecond = 4862.8
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04540705 * 16; pixelwiseError = 0.49736923 * 16; miouError = 0.66704887 * 1; time = 0.0031s; samplesPerSecond = 5105.6
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04547740 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66703582 * 1; time = 0.0033s; samplesPerSecond = 4874.7
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04542789 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66706908 * 1; time = 0.0034s; samplesPerSecond = 4687.6
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09121688 * 8; pixelwiseError = 0.49936226 * 8; miouError = 0.66708285 * 1; time = 0.0056s; samplesPerSecond = 1420.2
04/18/2017 06:26:48:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66708285 * 1; time = 0.0006s; samplesPerSecond = 0.0
04/18/2017 06:26:48: Finished Epoch[ 2 of 2]: [Training] CE = 0.04668318 * 1000; pixelwiseError = 0.49928443 * 1000; miouError = 0.66708285 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=0.250958s
04/18/2017 06:26:48: Final Results: Minibatch[1-8]: CE = 0.05160971 * 100; pixelwiseError = 0.49910715 * 100; miouError = 0.66589987 * 1
04/18/2017 06:26:48: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05160971 * 100; pixelwiseError = 0.49910715 * 100; miouError = 0.66589987 * 1
04/18/2017 06:26:48: SGD: Saving checkpoint model '/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN8_train'

04/18/2017 06:26:48: Action "train" complete.


04/18/2017 06:26:48: ##############################################################################
04/18/2017 06:26:48: #                                                                            #
04/18/2017 06:26:48: # ConvertFCN8ToFCN4 command (edit action)                                    #
04/18/2017 06:26:48: #                                                                            #
04/18/2017 06:26:48: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

04/18/2017 06:26:48: Action "edit" complete.


04/18/2017 06:26:48: ##############################################################################
04/18/2017 06:26:48: #                                                                            #
04/18/2017 06:26:48: # TrainFCN4 command (train action)                                           #
04/18/2017 06:26:48: #                                                                            #
04/18/2017 06:26:48: ##############################################################################

04/18/2017 06:26:48: 
Creating virgin network.
Load: Loading model file: /tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_initial
Post-processing network...

4 roots:
	ignoreMask = InputValue()
	labels = InputValue()
	predictionFCN8 = Convolution()
	upsampledFCN8.W = LearnableParameter()

Validating network. 62 nodes to process in pass 1.

Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *3]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *3] -> [7 x 7 x 16 x *3]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 2 x *3]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]

Validating network. 21 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *2] -> [7 x 7 x 16 x *2]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 2 x *2]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *2] -> [10 x 10 x 2 x *2]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *2] -> [7 x 7 x 2 x *2]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *2] -> [32 x 32 x 2 x *2]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *2]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *2], [28 x 28 x 2 x *2], [28 x 28 x 1 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *2] -> [1 x *2]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *2], [1 x *2] -> [1 x *2]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

upsampledFCN8: using cuDNN convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using cuDNN convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

04/18/2017 06:26:48: 
Model has 114 nodes. Using GPU 0.

04/18/2017 06:26:48: Training criterion:   CE = ElementTimes

04/18/2017 06:26:48: Evaluation criteria:
04/18/2017 06:26:48: 	pixelwiseError = ElementTimes
04/18/2017 06:26:48: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 171 matrices, 107 are shared as 29, and 64 are not shared.

Here are the ones that share memory:
	{ featuresFCN4.x : [14 x 14 x 16 x *2]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *2] (gradient) }
	{ CE.out_max.r : [28 x 28 x 1 x *2]
	  featuresFCN4 : [7 x 7 x 16 x *2] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient) }
	{ featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] }
	{ CE : [1] (gradient)
	  CE.norm_factor.z : [1]
	  miouError.miou : [1] }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN8 : [4 x 4 x 2 x *2] (gradient) }
	{ featuresFCN8.b.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ CE.ce_unnorm : [1]
	  CE.diff : [28 x 28 x 1 x *2] (gradient)
	  cropFCN8 : [7 x 7 x 2 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *2]
	  featuresFCN8.p : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ predictionFCN8.W : [2 x 16] (gradient)
	  upsampledFCN8 : [10 x 10 x 2 x *2] }
	{ CE.diff_valid : [28 x 28 x 1 x *2] (gradient)
	  CE.logits_per_class : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.union : [28 x 28 x 2 x *2]
	  out : [28 x 28 x 2 x *2] (gradient)
	  pixelwiseError.acc._ : [28 x 28 x 2 x *2]
	  pixelwiseError.diffs : [28 x 28 x 1 x *2] }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *2] }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.u : [1 x 2] }
	{ CE.log_sum.r : [28 x 28 x 1 x *2]
	  CE.out_max.r : [28 x 28 x 1 x *2] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *2] }
	{ CE.diff_valid : [28 x 28 x 1 x *2]
	  CE.logits.r : [28 x 28 x 1 x *2]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *2] }
	{ CE.out_shift : [28 x 28 x 2 x *2]
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] }
	{ featuresFCN8.b.x : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s : [4 x 4 x 16 x *2] (gradient) }
	{ cropFCN8 : [7 x 7 x 2 x *2]
	  upsampledFCN8.W : [4 x 4 x 2 x 2] (gradient) }
	{ featuresFCN4.x._ : [14 x 14 x 16 x *2] (gradient)
	  upsampledFCN4 : [32 x 32 x 2 x *2] }
	{ CE.diff : [28 x 28 x 1 x *2]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN4 : [7 x 7 x 16 x *2]
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient) }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  out : [28 x 28 x 2 x *2] }
	{ featuresFCN8 : [4 x 4 x 16 x *2]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient) }
	{ CE.log_sum.r : [28 x 28 x 1 x *2] (gradient)
	  featuresFCN8 : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b : [4 x 4 x 16 x *2]
	  featuresFCN8.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b : [4 x 4 x 16 x *2]
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  fusionFCN4 : [7 x 7 x 2 x *2] (gradient)
	  miouError.intersectionByClass.r : [1 x 2 x *2]
	  miouError.unionByClass.r : [1 x 2 x *2]
	  pixelwiseError.pixelNorm.z.r : [1 x *2]
	  upsampledFCN8 : [10 x 10 x 2 x *2] (gradient) }
	{ fusionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN4.W : [2 x 16] (gradient) }
	{ CE.logits_per_class : [28 x 28 x 2 x *2]
	  miouError.intersection : [28 x 28 x 2 x *2]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *2] }
	{ CE.logits.r : [28 x 28 x 1 x *2] (gradient)
	  CE.out_shift : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *2] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *2]
	  miouError.intersectionFlat : [784 x 2 x *2]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *2]
	  miouError.unionFlat : [784 x 2 x *2]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *2]
	  upsampledFCN4 : [32 x 32 x 2 x *2] (gradient) }

Here are the ones that don't share memory:
	{miouError.norm.z : [1]}
	{pixelwiseError : [1 x *2]}
	{miouError : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{BS.Constants.One : [1]}
	{CE : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *2]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}
	{features : [28 x 28 x 1 x *2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *2]}
	{labels : [28 x 28 x 2 x *2]}
	{predictionFCN8.W : [2 x 16]}
	{miouError.norm : [1]}
	{predictionFCN4.W : [2 x 16]}
	{miouError.iouSum.r : [1]}
	{pixelwiseError.errSum.r : [1 x *2]}
	{CE.norm_factor : [1]}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2]}
	{miouError.labelMasked : [28 x 28 x 2 x *2]}
	{miouError.i : [1 x 2]}
	{featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2]}
	{pixelwiseError.pixelNorm : [1 x *2]}
	{miouError.reciprocalUnion : [1 x 2]}
	{miouError.outMasked : [28 x 28 x 2 x *2]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *2]}
	{pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *2]}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *2]}


04/18/2017 06:26:48: Training 10576 parameters in 21 out of 21 parameter tensors and 57 nodes with gradient:

04/18/2017 06:26:48: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
04/18/2017 06:26:48: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:48: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:48: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/18/2017 06:26:48: 	Node 'predictionFCN4.W' (LearnableParameter operation) : [2 x 16]
04/18/2017 06:26:48: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]
04/18/2017 06:26:48: 	Node 'upsampledFCN8.W' (LearnableParameter operation) : [4 x 4 x 2 x 2]

Initializing dataParallelSGD with FP32 aggregation.
04/18/2017 06:26:48: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

04/18/2017 06:26:48: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/18/2017 06:26:48: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/18/2017 06:26:48:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05408775 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.69101435 * 1; time = 0.1027s; samplesPerSecond = 155.8
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05385992 * 16; pixelwiseError = 0.50015950 * 16; miouError = 0.69340897 * 1; time = 0.0584s; samplesPerSecond = 273.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05385850 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.69396359 * 1; time = 0.0047s; samplesPerSecond = 3406.0
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368470 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.69347245 * 1; time = 0.0047s; samplesPerSecond = 3403.6
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05405251 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.69376075 * 1; time = 0.0047s; samplesPerSecond = 3416.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05423248 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69405150 * 1; time = 0.0047s; samplesPerSecond = 3420.4
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05287198 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.69366407 * 1; time = 0.0048s; samplesPerSecond = 3312.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05354709 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.69346058 * 1; time = 0.0048s; samplesPerSecond = 3367.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05235507 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69276190 * 1; time = 0.0047s; samplesPerSecond = 3374.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05295631 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.69204527 * 1; time = 0.0047s; samplesPerSecond = 3391.6
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05347540 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.69193119 * 1; time = 0.0047s; samplesPerSecond = 3371.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05425305 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.69223964 * 1; time = 0.0048s; samplesPerSecond = 3337.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05330452 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.69225311 * 1; time = 0.0047s; samplesPerSecond = 3413.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05264040 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.69169366 * 1; time = 0.0047s; samplesPerSecond = 3376.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05210487 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.69131744 * 1; time = 0.0040s; samplesPerSecond = 4031.8
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05206263 * 16; pixelwiseError = 0.50135523 * 16; miouError = 0.69083494 * 1; time = 0.0033s; samplesPerSecond = 4804.4
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05233765 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.69061160 * 1; time = 0.0032s; samplesPerSecond = 5030.2
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05247631 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.69038469 * 1; time = 0.0034s; samplesPerSecond = 4730.6
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05215526 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.68994164 * 1; time = 0.0034s; samplesPerSecond = 4689.8
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05162365 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.68971562 * 1; time = 0.0034s; samplesPerSecond = 4714.8
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05161410 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.68927455 * 1; time = 0.0039s; samplesPerSecond = 4129.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05166132 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.68871105 * 1; time = 0.0041s; samplesPerSecond = 3909.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05194513 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68856919 * 1; time = 0.0039s; samplesPerSecond = 4142.5
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05064934 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.68824148 * 1; time = 0.0035s; samplesPerSecond = 4553.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05066132 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68765390 * 1; time = 0.0034s; samplesPerSecond = 4739.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05086559 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.68713498 * 1; time = 0.0038s; samplesPerSecond = 4184.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05032196 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.68656343 * 1; time = 0.0042s; samplesPerSecond = 3776.4
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05003523 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.68584514 * 1; time = 0.0042s; samplesPerSecond = 3826.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05032285 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.68524963 * 1; time = 0.0034s; samplesPerSecond = 4774.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05034604 * 16; pixelwiseError = 0.50119579 * 16; miouError = 0.68489504 * 1; time = 0.0042s; samplesPerSecond = 3848.2
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05042289 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.68453598 * 1; time = 0.0047s; samplesPerSecond = 3392.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.04997972 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68396074 * 1; time = 0.0048s; samplesPerSecond = 3339.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.04988774 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68333328 * 1; time = 0.0055s; samplesPerSecond = 2919.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.04989060 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68268132 * 1; time = 0.0036s; samplesPerSecond = 4410.2
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.04950384 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.68214953 * 1; time = 0.0034s; samplesPerSecond = 4690.8
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04935883 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.68155694 * 1; time = 0.0032s; samplesPerSecond = 5012.6
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04955866 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.68087268 * 1; time = 0.0034s; samplesPerSecond = 4747.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04900101 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.68023229 * 1; time = 0.0034s; samplesPerSecond = 4692.4
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04891431 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67955440 * 1; time = 0.0034s; samplesPerSecond = 4726.6
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04941816 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67893600 * 1; time = 0.0032s; samplesPerSecond = 4989.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04928011 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67836356 * 1; time = 0.0032s; samplesPerSecond = 4957.0
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04905730 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67784262 * 1; time = 0.0034s; samplesPerSecond = 4693.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04904880 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67723447 * 1; time = 0.0034s; samplesPerSecond = 4743.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04888847 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67673409 * 1; time = 0.0035s; samplesPerSecond = 4622.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04921469 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67626268 * 1; time = 0.0033s; samplesPerSecond = 4899.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04886924 * 16; pixelwiseError = 0.49760839 * 16; miouError = 0.67585605 * 1; time = 0.0035s; samplesPerSecond = 4611.4
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04896331 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67539233 * 1; time = 0.0035s; samplesPerSecond = 4615.8
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04925616 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67490518 * 1; time = 0.0055s; samplesPerSecond = 2912.0
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04920718 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67444623 * 1; time = 0.0046s; samplesPerSecond = 3471.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04889720 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67408383 * 1; time = 0.0040s; samplesPerSecond = 4011.6
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04893078 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67369854 * 1; time = 0.0046s; samplesPerSecond = 3500.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04907062 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67328131 * 1; time = 0.0045s; samplesPerSecond = 3560.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04876297 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67292660 * 1; time = 0.0041s; samplesPerSecond = 3949.7
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04880440 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67260426 * 1; time = 0.0041s; samplesPerSecond = 3905.5
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04883906 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67225790 * 1; time = 0.0040s; samplesPerSecond = 3966.2
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04879902 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67195678 * 1; time = 0.0041s; samplesPerSecond = 3925.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04886764 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.67162609 * 1; time = 0.0041s; samplesPerSecond = 3950.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04896065 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67133892 * 1; time = 0.0040s; samplesPerSecond = 3983.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04855736 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67108464 * 1; time = 0.0039s; samplesPerSecond = 4127.4
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04910399 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67081881 * 1; time = 0.0039s; samplesPerSecond = 4140.3
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04917118 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67052627 * 1; time = 0.0039s; samplesPerSecond = 4129.6
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04896244 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67026740 * 1; time = 0.0053s; samplesPerSecond = 3028.1
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09795211 * 8; pixelwiseError = 0.50159436 * 8; miouError = 0.67015719 * 1; time = 0.0048s; samplesPerSecond = 1657.9
04/18/2017 06:26:49:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67015719 * 1; time = 0.0005s; samplesPerSecond = 0.0
04/18/2017 06:26:49: Finished Epoch[ 1 of 2]: [Training] CE = 0.05108460 * 1000; pixelwiseError = 0.49989668 * 1000; miouError = 0.67015719 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=0.414751s
04/18/2017 06:26:49: Final Results: Minibatch[1-8]: CE = 0.05615914 * 100; pixelwiseError = 0.50025512 * 100; miouError = 0.67410243 * 1
04/18/2017 06:26:49: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05615914 * 100; pixelwiseError = 0.50025512 * 100; miouError = 0.67410243 * 1
04/18/2017 06:26:49: SGD: Saving checkpoint model '/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_train.1'

04/18/2017 06:26:49: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/18/2017 06:26:49: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04874099 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67050052 * 1; time = 0.0037s; samplesPerSecond = 4323.2
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04858384 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.67125404 * 1; time = 0.0037s; samplesPerSecond = 4309.6
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04862280 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67129683 * 1; time = 0.0039s; samplesPerSecond = 4106.6
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04852143 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67108727 * 1; time = 0.0035s; samplesPerSecond = 4594.9
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04924892 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67148143 * 1; time = 0.0034s; samplesPerSecond = 4677.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04842562 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67124265 * 1; time = 0.0037s; samplesPerSecond = 4369.7
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04870998 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67147034 * 1; time = 0.0036s; samplesPerSecond = 4393.1
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04856205 * 16; pixelwiseError = 0.50103635 * 16; miouError = 0.67165995 * 1; time = 0.0036s; samplesPerSecond = 4487.7
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04851801 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67176247 * 1; time = 0.0034s; samplesPerSecond = 4717.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04858113 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67185831 * 1; time = 0.0045s; samplesPerSecond = 3563.6
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04842683 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67187923 * 1; time = 0.0041s; samplesPerSecond = 3869.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04870834 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67207670 * 1; time = 0.0041s; samplesPerSecond = 3894.0
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04835904 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67225111 * 1; time = 0.0042s; samplesPerSecond = 3838.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04857202 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67253977 * 1; time = 0.0041s; samplesPerSecond = 3900.7
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04875071 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67262208 * 1; time = 0.0036s; samplesPerSecond = 4506.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04838068 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67275602 * 1; time = 0.0035s; samplesPerSecond = 4563.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04791684 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67270041 * 1; time = 0.0034s; samplesPerSecond = 4697.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04792583 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67268336 * 1; time = 0.0034s; samplesPerSecond = 4645.8
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04791663 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67263246 * 1; time = 0.0034s; samplesPerSecond = 4653.0
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04778190 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67264903 * 1; time = 0.0033s; samplesPerSecond = 4813.6
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04807526 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67282283 * 1; time = 0.0032s; samplesPerSecond = 5072.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04770991 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.67289811 * 1; time = 0.0039s; samplesPerSecond = 4112.1
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04764010 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.67300618 * 1; time = 0.0041s; samplesPerSecond = 3947.4
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04776154 * 16; pixelwiseError = 0.50159442 * 16; miouError = 0.67308676 * 1; time = 0.0035s; samplesPerSecond = 4564.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04778301 * 16; pixelwiseError = 0.50127554 * 16; miouError = 0.67318892 * 1; time = 0.0032s; samplesPerSecond = 4928.1
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04750778 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67319655 * 1; time = 0.0035s; samplesPerSecond = 4585.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04693048 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67312038 * 1; time = 0.0039s; samplesPerSecond = 4154.2
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04714453 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67310631 * 1; time = 0.0040s; samplesPerSecond = 3968.9
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04725985 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67307037 * 1; time = 0.0037s; samplesPerSecond = 4359.7
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04727471 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67294717 * 1; time = 0.0034s; samplesPerSecond = 4690.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04711290 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67284250 * 1; time = 0.0034s; samplesPerSecond = 4707.1
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04695430 * 16; pixelwiseError = 0.49944198 * 16; miouError = 0.67272538 * 1; time = 0.0038s; samplesPerSecond = 4246.2
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04690143 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67259347 * 1; time = 0.0040s; samplesPerSecond = 3978.8
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04688374 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67254496 * 1; time = 0.0036s; samplesPerSecond = 4411.0
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04653953 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67239618 * 1; time = 0.0034s; samplesPerSecond = 4645.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04644160 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.67217219 * 1; time = 0.0034s; samplesPerSecond = 4653.8
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04687496 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67208529 * 1; time = 0.0035s; samplesPerSecond = 4544.7
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04662452 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.67191339 * 1; time = 0.0043s; samplesPerSecond = 3747.9
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04632363 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67169821 * 1; time = 0.0042s; samplesPerSecond = 3807.8
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04650137 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67155451 * 1; time = 0.0036s; samplesPerSecond = 4486.2
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04661700 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67142856 * 1; time = 0.0033s; samplesPerSecond = 4825.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04636487 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67122728 * 1; time = 0.0042s; samplesPerSecond = 3801.6
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04632146 * 16; pixelwiseError = 0.49872446 * 16; miouError = 0.67101306 * 1; time = 0.0041s; samplesPerSecond = 3882.7
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04622528 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.67080212 * 1; time = 0.0035s; samplesPerSecond = 4527.6
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04666244 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67064965 * 1; time = 0.0032s; samplesPerSecond = 4931.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04639157 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67052311 * 1; time = 0.0033s; samplesPerSecond = 4847.9
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04653845 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67040616 * 1; time = 0.0034s; samplesPerSecond = 4701.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04647619 * 16; pixelwiseError = 0.49816644 * 16; miouError = 0.67023802 * 1; time = 0.0040s; samplesPerSecond = 3987.5
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04665386 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.67009914 * 1; time = 0.0035s; samplesPerSecond = 4512.8
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04646945 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66996229 * 1; time = 0.0032s; samplesPerSecond = 4939.9
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04623291 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66985053 * 1; time = 0.0034s; samplesPerSecond = 4694.0
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04638718 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66968495 * 1; time = 0.0034s; samplesPerSecond = 4648.0
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04618829 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66952431 * 1; time = 0.0034s; samplesPerSecond = 4733.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04628293 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66939402 * 1; time = 0.0032s; samplesPerSecond = 4997.9
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04640334 * 16; pixelwiseError = 0.49888390 * 16; miouError = 0.66923887 * 1; time = 0.0034s; samplesPerSecond = 4702.8
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04634196 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.66905260 * 1; time = 0.0034s; samplesPerSecond = 4717.6
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04644904 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66891956 * 1; time = 0.0035s; samplesPerSecond = 4574.7
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04599606 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66880375 * 1; time = 0.0033s; samplesPerSecond = 4819.1
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04626735 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66868013 * 1; time = 0.0032s; samplesPerSecond = 5018.4
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04629908 * 16; pixelwiseError = 0.49880418 * 16; miouError = 0.66854382 * 1; time = 0.0034s; samplesPerSecond = 4743.1
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04630848 * 16; pixelwiseError = 0.49888390 * 16; miouError = 0.66838825 * 1; time = 0.0035s; samplesPerSecond = 4551.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04616680 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66827518 * 1; time = 0.0036s; samplesPerSecond = 4440.3
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09348119 * 8; pixelwiseError = 0.50015944 * 8; miouError = 0.66821980 * 1; time = 0.0045s; samplesPerSecond = 1759.0
04/18/2017 06:26:49:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66821980 * 1; time = 0.0005s; samplesPerSecond = 0.0
04/18/2017 06:26:49: Finished Epoch[ 2 of 2]: [Training] CE = 0.04765253 * 1000; pixelwiseError = 0.49989540 * 1000; miouError = 0.66821975 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=0.234571s
04/18/2017 06:26:49: Final Results: Minibatch[1-8]: CE = 0.05273981 * 100; pixelwiseError = 0.50051021 * 100; miouError = 0.66819537 * 1
04/18/2017 06:26:49: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05273981 * 100; pixelwiseError = 0.50051021 * 100; miouError = 0.66819537 * 1
04/18/2017 06:26:49: SGD: Saving checkpoint model '/tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_train'

04/18/2017 06:26:49: Action "train" complete.


04/18/2017 06:26:49: ##############################################################################
04/18/2017 06:26:49: #                                                                            #
04/18/2017 06:26:49: # PrepareFCN4ForTest command (edit action)                                   #
04/18/2017 06:26:49: #                                                                            #
04/18/2017 06:26:49: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

04/18/2017 06:26:49: Action "edit" complete.


04/18/2017 06:26:49: ##############################################################################
04/18/2017 06:26:49: #                                                                            #
04/18/2017 06:26:49: # TestFCN4 command (test action)                                             #
04/18/2017 06:26:49: #                                                                            #
04/18/2017 06:26:49: ##############################################################################

Load: Loading model file: /tmp/cntk-test-20170418062644.389507/Image_FCN@release_gpu/Models/FCN4_test
Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *6] -> [7 x 7 x 16 x *6]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 2 x *6]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *6] -> [10 x 10 x 2 x *6]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *6] -> [7 x 7 x 2 x *6]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *6] -> [32 x 32 x 2 x *6]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *6]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *6], [28 x 28 x 2 x *6], [28 x 28 x 1 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *6] -> [1 x *6]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *6], [1 x *6] -> [1 x *6]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using cuDNN convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using cuDNN convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

3 roots:
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 103 nodes to process in pass 1.

Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *5] -> [7 x 7 x 16 x *5]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 2 x *5]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *5] -> [10 x 10 x 2 x *5]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *5] -> [7 x 7 x 2 x *5]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *5] -> [32 x 32 x 2 x *5]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *5]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *5], [28 x 28 x 2 x *5], [28 x 28 x 1 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *5] -> [1 x *5]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *5], [1 x *5] -> [1 x *5]

Validating network. 56 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 103 matrices, 54 are shared as 7, and 49 are not shared.

Here are the ones that share memory:
	{ featuresFCN4.x._ : [14 x 14 x 16 x *5]
	  featuresFCN8.x.r : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s : [4 x 4 x 16 x *5]
	  miouError.outMasked : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion : [1 x 2]
	  miouError.u : [1 x 2]
	  miouError.union : [28 x 28 x 2 x *5]
	  predictionFCN4 : [7 x 7 x 2 x *5]
	  upsampledFCN4 : [32 x 32 x 2 x *5] }
	{ featuresFCN8 : [4 x 4 x 16 x *5]
	  featuresFCN8.b : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *5]
	  out : [28 x 28 x 2 x *5]
	  pixelwiseError.acc._ : [28 x 28 x 2 x *5]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *5]
	  pixelwiseError.pixelNorm : [1 x *5]
	  upsampledFCN8 : [10 x 10 x 2 x *5] }
	{ featuresFCN4.x : [14 x 14 x 16 x *5]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *5]
	  miouError.iou : [1 x 2]
	  miouError.labelMasked : [28 x 28 x 2 x *5]
	  miouError.miou : [1]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ cropFCN8 : [7 x 7 x 2 x *5]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *5]
	  miouError.intersection : [28 x 28 x 2 x *5]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  predictionFCN8 : [4 x 4 x 2 x *5] }
	{ featuresFCN4 : [7 x 7 x 16 x *5]
	  fusionFCN4 : [7 x 7 x 2 x *5]
	  miouError.intersectionFlat : [784 x 2 x *5]
	  miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *5]
	  miouError.unionFlat : [784 x 2 x *5]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *5]
	  pixelwiseError.diffs : [28 x 28 x 1 x *5]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  pixelwiseError.pixelNorm.z.r : [1 x *5] }
	{ miouError.intersectionByClass.r : [1 x 2 x *5]
	  miouError.unionByClass.r : [1 x 2 x *5]
	  pixelwiseError.errSum.r : [1 x *5] }
	{ miouError.i : [1 x 2]
	  miouError.iouSum.r : [1] }

Here are the ones that don't share memory:
	{miouError : [1]}
	{miouError.norm : [1]}
	{pixelwiseError : [1 x *5]}
	{BS.Constants.One : [1]}
	{features : [28 x 28 x 1 x *5]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *5]}
	{labels : [28 x 28 x 2 x *5]}
	{miouError.norm.z : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{predictionFCN4.W : [2 x 16]}
	{predictionFCN8.W : [2 x 16]}
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}

04/18/2017 06:26:49: Minibatch[1-8]: pixelwiseError = 0.50051021 * 100; miouError = 0.66819543 * 1
04/18/2017 06:26:49: Final Results: Minibatch[1-8]: pixelwiseError = 0.50051021 * 100; miouError = 0.66819543 * 1

04/18/2017 06:26:49: Action "test" complete.

04/18/2017 06:26:49: __COMPLETED__
~MPIWrapperMpi
=== Deleting training and test data
