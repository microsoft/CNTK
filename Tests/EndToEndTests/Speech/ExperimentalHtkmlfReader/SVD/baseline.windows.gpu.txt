=== Running /cygdrive/e/NetScale/CNTK/git_repos/cplx_master2/x64/debug/cntk.exe configFile=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\SVD/cntk.config RunDir=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu DataDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data ConfigDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\SVD DeviceId=0
-------------------------------------------------------------------
Build info: 

		Built time: Nov 13 2015 22:32:10
		Last modified date: Fri Nov 13 10:07:10 2015
		Built by amitaga on Amitaga-Win-DT3           
		Build Path: E:\NetScale\CNTK\git_repos\cplx_master2\MachineLearning\CNTK\
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
-------------------------------------------------------------------
running on Amitaga-Win-DT3 at 2015/11/14 06:58:48
command line: 
E:\NetScale\CNTK\git_repos\cplx_master2\x64\debug\cntk.exe configFile=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\SVD/cntk.config RunDir=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu DataDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data ConfigDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\SVD DeviceId=0 

>>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
precision=float
command=speechTrain:modelDecomposition:SVDTrain
deviceId=$DeviceId$
speechTrain=[
    action=train
    makeMode=false
    modelPath=$RunDir$/models/cntkSpeech.dnn
    deviceId=$DeviceId$
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=$DataDir$/glob_0000.mlf
        labelMappingFile=$DataDir$/state.list
        labelDim=132
        labelType=Category
    ]
]
modelDecomposition=[
    action=SVD
    modelPath=$RunDir$/models/cntkSpeech.dnn
    outputmodelPath=$RunDir$/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]
SVDTrain=[
    action=train
    makeMode=true
    modelPath=$RunDir$/models/cntkSpeech.svd.dnn
    deviceId=$DeviceId$
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=$RunDir$/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
RunDir=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu
DataDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data
ConfigDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\SVD
DeviceId=0

<<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
precision=float
command=speechTrain:modelDecomposition:SVDTrain
deviceId=0
speechTrain=[
    action=train
    makeMode=false
    modelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.dnn
    deviceId=0
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/glob_0000.mlf
        labelMappingFile=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/state.list
        labelDim=132
        labelType=Category
    ]
]
modelDecomposition=[
    action=SVD
    modelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.dnn
    outputmodelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]
SVDTrain=[
    action=train
    makeMode=true
    modelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.svd.dnn
    deviceId=0
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
RunDir=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu
DataDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data
ConfigDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\SVD
DeviceId=0

<<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.config:command=speechTrain:modelDecomposition:SVDTrain
configparameters: cntk.config:ConfigDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\SVD
configparameters: cntk.config:DataDir=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data
configparameters: cntk.config:deviceId=0
configparameters: cntk.config:modelDecomposition=[
    action=SVD
    modelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.dnn
    outputmodelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]

configparameters: cntk.config:precision=float
configparameters: cntk.config:reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/glob_0000.mlf
        labelMappingFile=E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/state.list
        labelDim=132
        labelType=Category
    ]
]

configparameters: cntk.config:RunDir=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu
configparameters: cntk.config:speechTrain=[
    action=train
    makeMode=false
    modelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.dnn
    deviceId=0
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]

configparameters: cntk.config:SVDTrain=[
    action=train
    makeMode=true
    modelPath=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.svd.dnn
    deviceId=0
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]

<<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
command: speechTrain modelDecomposition SVDTrain 
precision = float
CNTKModelPath: C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.dnn
CNTKCommandTrainInfo: speechTrain : 3
CNTKModelPath: C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.svd.dnn
CNTKCommandTrainInfo: SVDTrain : 2
CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
CNTKCommandTrainBegin: speechTrain
SimpleNetworkBuilder Using GPU 0
reading script file glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/state.list
htkmlfreader: reading MLF file E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
SetUniformRandomValue (GPU): creating curand object with seed 1


Allocating matrices for forward propagation.


Printing Gradient Computation Node Order ... 

CrossEntropyWithSoftmax[0, 0] = CrossEntropyWithSoftmax(labels[132, 3], HLast[0, 0])
HLast[0, 0] = Plus(W2*H1[0, 0], B2[132, 1])
B2[132, 1] = LearnableParameter
W2*H1[0, 0] = Times(W2[132, 512], H2[0, 0])
H2[0, 0] = Sigmoid(W1*H1+B1[0, 0])
W1*H1+B1[0, 0] = Plus(W1*H1[0, 0], B1[512, 1])
B1[512, 1] = LearnableParameter
W1*H1[0, 0] = Times(W1[512, 512], H1[0, 0])
H1[0, 0] = Sigmoid(W0*features+B0[0, 0])
W0*features+B0[0, 0] = Plus(W0*features[0, 0], B0[512, 1])
B0[512, 1] = LearnableParameter
W0*features[0, 0] = Times(W0[512, 363], MVNormalizedFeatures[0, 0])
MVNormalizedFeatures[0, 0] = PerDimMeanVarNormalization(features[363, 3], MeanOfFeatures[0, 0], InvStdOfFeatures[0, 0])
InvStdOfFeatures[0, 0] = InvStdDev(features[363, 3])
MeanOfFeatures[0, 0] = Mean(features[363, 3])
features[363, 3] = InputValue
W0[512, 363] = LearnableParameter
W1[512, 512] = LearnableParameter
W2[132, 512] = LearnableParameter
labels[132, 3] = InputValue

Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood. 11 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood. 9 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.

GetTrainCriterionNodes  ...
GetEvalCriterionNodes  ...


Allocating matrices for gradient computing

Precomputing --> 3 PreCompute nodes found.

	NodeName: InvStdOfFeatures
	NodeName: MeanOfFeatures
	NodeName: Prior
minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms


Validating for node InvStdOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]

Validating for node InvStdOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.



Validating for node MeanOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]

Validating for node MeanOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.



Validating for node Prior. 2 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]

Validating for node Prior, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Precomputing --> Completed.

Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000 
minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 1 of 3]-Minibatch[   1-  10 of 320]: SamplesSeen = 640; TrainLossPerSample =  4.45645981; EvalErr[0]PerSample = 0.92500000; TotalTime = 0.20979s; TotalTimePerSample = 0.32780ms; SamplesPerSecond = 3050
 Epoch[ 1 of 3]-Minibatch[  11-  20 of 320]: SamplesSeen = 640; TrainLossPerSample =  4.22315750; EvalErr[0]PerSample = 0.90156250; TotalTime = 0.19111s; TotalTimePerSample = 0.29861ms; SamplesPerSecond = 3348
 Epoch[ 1 of 3]-Minibatch[  21-  30 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.95180664; EvalErr[0]PerSample = 0.84687500; TotalTime = 0.18243s; TotalTimePerSample = 0.28505ms; SamplesPerSecond = 3508
 Epoch[ 1 of 3]-Minibatch[  31-  40 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.94158020; EvalErr[0]PerSample = 0.89843750; TotalTime = 0.18003s; TotalTimePerSample = 0.28130ms; SamplesPerSecond = 3554
 Epoch[ 1 of 3]-Minibatch[  41-  50 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.85668945; EvalErr[0]PerSample = 0.91093750; TotalTime = 0.18737s; TotalTimePerSample = 0.29277ms; SamplesPerSecond = 3415
 Epoch[ 1 of 3]-Minibatch[  51-  60 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.72866364; EvalErr[0]PerSample = 0.89531250; TotalTime = 0.17414s; TotalTimePerSample = 0.27209ms; SamplesPerSecond = 3675
 Epoch[ 1 of 3]-Minibatch[  61-  70 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.51809235; EvalErr[0]PerSample = 0.82968750; TotalTime = 0.18320s; TotalTimePerSample = 0.28624ms; SamplesPerSecond = 3493
 Epoch[ 1 of 3]-Minibatch[  71-  80 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.48455200; EvalErr[0]PerSample = 0.80781250; TotalTime = 0.20540s; TotalTimePerSample = 0.32094ms; SamplesPerSecond = 3115
 Epoch[ 1 of 3]-Minibatch[  81-  90 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.33829346; EvalErr[0]PerSample = 0.76875000; TotalTime = 0.19201s; TotalTimePerSample = 0.30002ms; SamplesPerSecond = 3333
 Epoch[ 1 of 3]-Minibatch[  91- 100 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.50167236; EvalErr[0]PerSample = 0.79843750; TotalTime = 0.18648s; TotalTimePerSample = 0.29138ms; SamplesPerSecond = 3431
WARNING: The same matrix with dim [1, 1] has been transferred between different devices for 20 times.
 Epoch[ 1 of 3]-Minibatch[ 101- 110 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.22861633; EvalErr[0]PerSample = 0.80000000; TotalTime = 0.18087s; TotalTimePerSample = 0.28261ms; SamplesPerSecond = 3538
 Epoch[ 1 of 3]-Minibatch[ 111- 120 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.32616882; EvalErr[0]PerSample = 0.79062500; TotalTime = 0.17251s; TotalTimePerSample = 0.26954ms; SamplesPerSecond = 3709
 Epoch[ 1 of 3]-Minibatch[ 121- 130 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.16897583; EvalErr[0]PerSample = 0.77968750; TotalTime = 0.17193s; TotalTimePerSample = 0.26865ms; SamplesPerSecond = 3722
 Epoch[ 1 of 3]-Minibatch[ 131- 140 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.08891907; EvalErr[0]PerSample = 0.77656250; TotalTime = 0.16427s; TotalTimePerSample = 0.25667ms; SamplesPerSecond = 3896
 Epoch[ 1 of 3]-Minibatch[ 141- 150 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.06005249; EvalErr[0]PerSample = 0.72968750; TotalTime = 0.16164s; TotalTimePerSample = 0.25256ms; SamplesPerSecond = 3959
 Epoch[ 1 of 3]-Minibatch[ 151- 160 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.91128540; EvalErr[0]PerSample = 0.69531250; TotalTime = 0.15822s; TotalTimePerSample = 0.24722ms; SamplesPerSecond = 4044
 Epoch[ 1 of 3]-Minibatch[ 161- 170 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.90172119; EvalErr[0]PerSample = 0.72968750; TotalTime = 0.15897s; TotalTimePerSample = 0.24838ms; SamplesPerSecond = 4026
 Epoch[ 1 of 3]-Minibatch[ 171- 180 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.73261719; EvalErr[0]PerSample = 0.65312500; TotalTime = 0.15130s; TotalTimePerSample = 0.23641ms; SamplesPerSecond = 4229
 Epoch[ 1 of 3]-Minibatch[ 181- 190 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.66515503; EvalErr[0]PerSample = 0.68437500; TotalTime = 0.14831s; TotalTimePerSample = 0.23173ms; SamplesPerSecond = 4315
 Epoch[ 1 of 3]-Minibatch[ 191- 200 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.67383423; EvalErr[0]PerSample = 0.66406250; TotalTime = 0.14618s; TotalTimePerSample = 0.22841ms; SamplesPerSecond = 4378
 Epoch[ 1 of 3]-Minibatch[ 201- 210 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.52869263; EvalErr[0]PerSample = 0.63593750; TotalTime = 0.14344s; TotalTimePerSample = 0.22412ms; SamplesPerSecond = 4461
 Epoch[ 1 of 3]-Minibatch[ 211- 220 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.60032349; EvalErr[0]PerSample = 0.66718750; TotalTime = 0.14082s; TotalTimePerSample = 0.22003ms; SamplesPerSecond = 4544
 Epoch[ 1 of 3]-Minibatch[ 221- 230 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.51134033; EvalErr[0]PerSample = 0.64843750; TotalTime = 0.14093s; TotalTimePerSample = 0.22020ms; SamplesPerSecond = 4541
 Epoch[ 1 of 3]-Minibatch[ 231- 240 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.45362549; EvalErr[0]PerSample = 0.63750000; TotalTime = 0.14182s; TotalTimePerSample = 0.22160ms; SamplesPerSecond = 4512
 Epoch[ 1 of 3]-Minibatch[ 241- 250 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.41640015; EvalErr[0]PerSample = 0.61562500; TotalTime = 0.14090s; TotalTimePerSample = 0.22015ms; SamplesPerSecond = 4542
 Epoch[ 1 of 3]-Minibatch[ 251- 260 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.39745483; EvalErr[0]PerSample = 0.62812500; TotalTime = 0.14074s; TotalTimePerSample = 0.21991ms; SamplesPerSecond = 4547
 Epoch[ 1 of 3]-Minibatch[ 261- 270 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.16415405; EvalErr[0]PerSample = 0.56718750; TotalTime = 0.14201s; TotalTimePerSample = 0.22189ms; SamplesPerSecond = 4506
 Epoch[ 1 of 3]-Minibatch[ 271- 280 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.30347290; EvalErr[0]PerSample = 0.63593750; TotalTime = 0.19468s; TotalTimePerSample = 0.30419ms; SamplesPerSecond = 3287
 Epoch[ 1 of 3]-Minibatch[ 281- 290 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.24398804; EvalErr[0]PerSample = 0.60937500; TotalTime = 0.18877s; TotalTimePerSample = 0.29496ms; SamplesPerSecond = 3390
 Epoch[ 1 of 3]-Minibatch[ 291- 300 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.15322266; EvalErr[0]PerSample = 0.57968750; TotalTime = 0.18417s; TotalTimePerSample = 0.28776ms; SamplesPerSecond = 3475
 Epoch[ 1 of 3]-Minibatch[ 301- 310 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.21664429; EvalErr[0]PerSample = 0.59531250; TotalTime = 0.19185s; TotalTimePerSample = 0.29977ms; SamplesPerSecond = 3335
 Epoch[ 1 of 3]-Minibatch[ 311- 320 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.25246582; EvalErr[0]PerSample = 0.60156250; TotalTime = 0.17541s; TotalTimePerSample = 0.27408ms; SamplesPerSecond = 3648
Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.0000031; EvalErrPerSample = 0.72836918; AvgLearningRatePerSample = 0.015625; EpochTime=5.464952
Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119 
minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 3]-Minibatch[   1-  10 of 80]: SamplesSeen = 2560; TrainLossPerSample =  2.08151951; EvalErr[0]PerSample = 0.55859375; TotalTime = 0.35915s; TotalTimePerSample = 0.14029ms; SamplesPerSecond = 7127
 Epoch[ 2 of 3]-Minibatch[  11-  20 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.98395710; EvalErr[0]PerSample = 0.54257813; TotalTime = 0.32427s; TotalTimePerSample = 0.12667ms; SamplesPerSecond = 7894
 Epoch[ 2 of 3]-Minibatch[  21-  30 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.98575516; EvalErr[0]PerSample = 0.54492188; TotalTime = 0.30580s; TotalTimePerSample = 0.11945ms; SamplesPerSecond = 8371
 Epoch[ 2 of 3]-Minibatch[  31-  40 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.90485039; EvalErr[0]PerSample = 0.53164062; TotalTime = 0.29181s; TotalTimePerSample = 0.11399ms; SamplesPerSecond = 8772
 Epoch[ 2 of 3]-Minibatch[  41-  50 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.88324280; EvalErr[0]PerSample = 0.52539063; TotalTime = 0.27810s; TotalTimePerSample = 0.10863ms; SamplesPerSecond = 9205
 Epoch[ 2 of 3]-Minibatch[  51-  60 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.89109344; EvalErr[0]PerSample = 0.53359375; TotalTime = 0.27050s; TotalTimePerSample = 0.10566ms; SamplesPerSecond = 9464
 Epoch[ 2 of 3]-Minibatch[  61-  70 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.89496155; EvalErr[0]PerSample = 0.52890625; TotalTime = 0.25877s; TotalTimePerSample = 0.10108ms; SamplesPerSecond = 9893
 Epoch[ 2 of 3]-Minibatch[  71-  80 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.85944366; EvalErr[0]PerSample = 0.52265625; TotalTime = 0.26084s; TotalTimePerSample = 0.10189ms; SamplesPerSecond = 9814
Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 1.935603; EvalErrPerSample = 0.53603518; AvgLearningRatePerSample = 0.001953125; EpochTime=2.392921
Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119 
minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 3 of 3]-Minibatch[   1-  10 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.86752853; EvalErr[0]PerSample = 0.52177734; TotalTime = 0.93443s; TotalTimePerSample = 0.09125ms; SamplesPerSecond = 10958
 Epoch[ 3 of 3]-Minibatch[  11-  20 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.87358818; EvalErr[0]PerSample = 0.51542969; TotalTime = 0.69073s; TotalTimePerSample = 0.06745ms; SamplesPerSecond = 14824
Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8705584; EvalErrPerSample = 0.5186035; AvgLearningRatePerSample = 9.765625146e-005; EpochTime=1.783182
CNTKCommandTrainEnd: speechTrain


Allocating matrices for forward propagation.


Printing Gradient Computation Node Order ... 

CrossEntropyWithSoftmax[0, 0] = CrossEntropyWithSoftmax(labels[132, 0], HLast[0, 0])
HLast[0, 0] = Plus(W2*H1[0, 0], B2[132, 1])
B2[132, 1] = LearnableParameter
W2*H1[0, 0] = Times(W2[132, 512], H2[0, 0])
H2[0, 0] = Sigmoid(W1*H1+B1[0, 0])
W1*H1+B1[0, 0] = Plus(W1*H1[0, 0], B1[512, 1])
B1[512, 1] = LearnableParameter
W1*H1[0, 0] = Times(W1[512, 512], H1[0, 0])
H1[0, 0] = Sigmoid(W0*features+B0[0, 0])
W0*features+B0[0, 0] = Plus(W0*features[0, 0], B0[512, 1])
B0[512, 1] = LearnableParameter
W0*features[0, 0] = Times(W0[512, 363], MVNormalizedFeatures[0, 0])
MVNormalizedFeatures[0, 0] = PerDimMeanVarNormalization(features[363, 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1])
InvStdOfFeatures[363, 1] = InvStdDev(features[363, 0])
MeanOfFeatures[363, 1] = Mean(features[363, 0])
features[363, 0] = InputValue
W0[512, 363] = LearnableParameter
W1[512, 512] = LearnableParameter
W2[132, 512] = LearnableParameter
labels[132, 0] = InputValue

Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 11 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 9 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.

--------------------------------------------------------------------------------------------
ParameterSVD: start to process group 0 with KeepRatio=0.50
--------------------------------------------------------------------------------------------
Performing SVD for a   512-by-363   matrix (node name: W0                  ) ---  computation time  0.30 secs ;  keep 50.0% energy ===> keep   104 svd values (reduce to 49.0% parameters) 
Performing SVD for a   512-by-512   matrix (node name: W1                  ) ---  computation time  0.35 secs ;  keep 50.0% energy ===> keep   128 svd values (reduce to 50.0% parameters) 
Performing SVD for a   132-by-512   matrix (node name: W2                  ) ---  computation time  0.07 secs ;  keep 50.0% energy ===> keep    32 svd values (reduce to 30.5% parameters) 


Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.

CNTKCommandTrainBegin: SVDTrain
NDLBuilder Using GPU 0
reading script file glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/state.list
htkmlfreader: reading MLF file E:\NetScale\CNTK\git_repos\cplx_master2\Tests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20151113225847.730845\Speech_SVD@debug_gpu/models/cntkSpeech.svd.dnn.0.


Allocating matrices for forward propagation.


Printing Gradient Computation Node Order ... 

CrossEntropyWithSoftmax[0, 0] = CrossEntropyWithSoftmax(labels[132, 0], HLast[0, 0])
HLast[0, 0] = Plus(W2*H1[0, 0], B2[132, 1])
B2[132, 1] = LearnableParameter
W2*H1[0, 0] = Times(W2-SVD[0, 0], H2[0, 0])
H2[0, 0] = Sigmoid(W1*H1+B1[0, 0])
W1*H1+B1[0, 0] = Plus(W1*H1[0, 0], B1[512, 1])
B1[512, 1] = LearnableParameter
W1*H1[0, 0] = Times(W1-SVD[0, 0], H1[0, 0])
H1[0, 0] = Sigmoid(W0*features+B0[0, 0])
W0*features+B0[0, 0] = Plus(W0*features[0, 0], B0[512, 1])
B0[512, 1] = LearnableParameter
W0*features[0, 0] = Times(W0-SVD[0, 0], MVNormalizedFeatures[0, 0])
MVNormalizedFeatures[0, 0] = PerDimMeanVarNormalization(features[363, 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1])
InvStdOfFeatures[363, 1] = InvStdDev(features[363, 0])
MeanOfFeatures[363, 1] = Mean(features[363, 0])
features[363, 0] = InputValue
W0-SVD[0, 0] = Times(W0-U[512, 104], W0-V[104, 363])
W0-V[104, 363] = LearnableParameter
W0-U[512, 104] = LearnableParameter
W1-SVD[0, 0] = Times(W1-U[512, 128], W1-V[128, 512])
W1-V[128, 512] = LearnableParameter
W1-U[512, 128] = LearnableParameter
W2-SVD[0, 0] = Times(W2-U[132, 32], W2-V[32, 512])
W2-V[32, 512] = LearnableParameter
W2-U[132, 32] = LearnableParameter
labels[132, 0] = InputValue

Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 15 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.



Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 28 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 14 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

16 out of 28 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 28 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 12 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

16 out of 28 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.

GetTrainCriterionNodes  ...
GetEvalCriterionNodes  ...


Allocating matrices for gradient computing
No PreCompute nodes found, skipping PreCompute step
Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.000098  effective momentum = 0.656119 
minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

Starting minibatch loop.
 Epoch[ 1 of 2]-Minibatch[   1-  10 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.87722015; EvalErr[0]PerSample = 0.51220703; TotalTime = 0.73890s; TotalTimePerSample = 0.07216ms; SamplesPerSecond = 13858
 Epoch[ 1 of 2]-Minibatch[  11-  20 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.79417076; EvalErr[0]PerSample = 0.49912109; TotalTime = 0.62851s; TotalTimePerSample = 0.06138ms; SamplesPerSecond = 16292
Finished Epoch[ 1 of 2]: [Training Set] TrainLossPerSample = 1.8356955; EvalErrPerSample = 0.50566405; AvgLearningRatePerSample = 9.765625146e-005; EpochTime=4.562117
Starting Epoch 2: learning rate per sample = 0.000098  effective momentum = 0.656119 
minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 2]-Minibatch[   1-  10 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.81283226; EvalErr[0]PerSample = 0.50488281; TotalTime = 0.71291s; TotalTimePerSample = 0.06962ms; SamplesPerSecond = 14363
 Epoch[ 2 of 2]-Minibatch[  11-  20 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.78207207; EvalErr[0]PerSample = 0.50322266; TotalTime = 0.63083s; TotalTimePerSample = 0.06160ms; SamplesPerSecond = 16232
Finished Epoch[ 2 of 2]: [Training Set] TrainLossPerSample = 1.7974522; EvalErrPerSample = 0.50405276; AvgLearningRatePerSample = 9.765625146e-005; EpochTime=1.447972
CNTKCommandTrainEnd: SVDTrain
__COMPLETED__
