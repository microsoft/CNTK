=== Running /home/mluser/src/cplx_master/build/debug/bin/cntk configFile=/home/mluser/src/cplx_master/Tests/Speech/SVD/cntk.config RunDir=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu DataDir=/home/mluser/src/cplx_master/Tests/Speech/Data ConfigDir=/home/mluser/src/cplx_master/Tests/Speech/SVD DeviceId=-1
running on localhost at 2015/11/13 23:27:43
command line: 
/home/mluser/src/cplx_master/build/debug/bin/cntk configFile=/home/mluser/src/cplx_master/Tests/Speech/SVD/cntk.config RunDir=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu DataDir=/home/mluser/src/cplx_master/Tests/Speech/Data ConfigDir=/home/mluser/src/cplx_master/Tests/Speech/SVD DeviceId=-1 

>>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
precision=float
command=speechTrain:modelDecomposition:SVDTrain
deviceId=$DeviceId$
speechTrain=[
    action=train
    makeMode=false
    modelPath=$RunDir$/models/cntkSpeech.dnn
    deviceId=$DeviceId$
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=$DataDir$/glob_0000.mlf
        labelMappingFile=$DataDir$/state.list
        labelDim=132
        labelType=Category
    ]
]
modelDecomposition=[
    action=SVD
    modelPath=$RunDir$/models/cntkSpeech.dnn
    outputmodelPath=$RunDir$/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]
SVDTrain=[
    action=train
    makeMode=true
    modelPath=$RunDir$/models/cntkSpeech.svd.dnn
    deviceId=$DeviceId$
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=$RunDir$/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
RunDir=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu
DataDir=/home/mluser/src/cplx_master/Tests/Speech/Data
ConfigDir=/home/mluser/src/cplx_master/Tests/Speech/SVD
DeviceId=-1

<<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
precision=float
command=speechTrain:modelDecomposition:SVDTrain
deviceId=-1
speechTrain=[
    action=train
    makeMode=false
    modelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.dnn
    deviceId=-1
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=/home/mluser/src/cplx_master/Tests/Speech/Data/glob_0000.mlf
        labelMappingFile=/home/mluser/src/cplx_master/Tests/Speech/Data/state.list
        labelDim=132
        labelType=Category
    ]
]
modelDecomposition=[
    action=SVD
    modelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.dnn
    outputmodelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]
SVDTrain=[
    action=train
    makeMode=true
    modelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.svd.dnn
    deviceId=-1
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]
RunDir=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu
DataDir=/home/mluser/src/cplx_master/Tests/Speech/Data
ConfigDir=/home/mluser/src/cplx_master/Tests/Speech/SVD
DeviceId=-1

<<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

>>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.config:command=speechTrain:modelDecomposition:SVDTrain
configparameters: cntk.config:ConfigDir=/home/mluser/src/cplx_master/Tests/Speech/SVD
configparameters: cntk.config:DataDir=/home/mluser/src/cplx_master/Tests/Speech/Data
configparameters: cntk.config:deviceId=-1
configparameters: cntk.config:modelDecomposition=[
    action=SVD
    modelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.dnn
    outputmodelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.svd.dnn.0
    KeepRatio=0.5
    NodeNameRegex=W.*
]

configparameters: cntk.config:precision=float
configparameters: cntk.config:reader=[
    readerType=HTKMLFReader
    readMethod=blockRandomize
    miniBatchMode=Partial
    randomize=Auto
    verbosity=0
    features=[
        dim=363
        type=Real
        scpFile=glob_0000.scp
    ]
    labels=[
        mlfFile=/home/mluser/src/cplx_master/Tests/Speech/Data/glob_0000.mlf
        labelMappingFile=/home/mluser/src/cplx_master/Tests/Speech/Data/state.list
        labelDim=132
        labelType=Category
    ]
]

configparameters: cntk.config:RunDir=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu
configparameters: cntk.config:speechTrain=[
    action=train
    makeMode=false
    modelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.dnn
    deviceId=-1
    traceLevel=1
    SimpleNetworkBuilder=[
        layerSizes=363:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        applyMeanVarNorm=true
        initValueScale=1.0
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=20480
        minibatchSize=64:256:1024
        learningRatesPerMB=1.0:0.5:0.1
        numMBsToShowResult=10
        momentumPerMB=0.9:0.656119
        dropoutRate=0.0
        maxEpochs=3
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]

configparameters: cntk.config:SVDTrain=[
    action=train
    makeMode=true
    modelPath=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.svd.dnn
    deviceId=-1
    traceLevel=1
    NDLNetworkBuilder=[
        NetworkDescription=/tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/nonExistent.ndl
    ]
    SGD=[
        epochSize=20480
        minibatchSize=1024
        learningRatesPerMB=0.1
        numMBsToShowResult=10
        momentumPerMB=0.656119
        dropoutRate=0.0
        maxEpochs=2
        keepCheckPointFiles=false
        clippingThresholdPerSample=1#INF
    ]
]

<<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
command: speechTrain modelDecomposition SVDTrain 
precision = float
CNTKModelPath: /tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.dnn
CNTKCommandTrainInfo: speechTrain : 3
CNTKModelPath: /tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.svd.dnn
CNTKCommandTrainInfo: SVDTrain : 2
CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
CNTKCommandTrainBegin: speechTrain
SimpleNetworkBuilder Using CPU
reading script file glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /home/mluser/src/cplx_master/Tests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/mluser/src/cplx_master/Tests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames


Allocating matrices for forward propagation.


Printing Gradient Computation Node Order ... 

CrossEntropyWithSoftmax[0, 0] = CrossEntropyWithSoftmax(labels[132, 3], HLast[0, 0])
HLast[0, 0] = Plus(W2*H1[0, 0], B2[132, 1])
B2[132, 1] = LearnableParameter
W2*H1[0, 0] = Times(W2[132, 512], H2[0, 0])
H2[0, 0] = Sigmoid(W1*H1+B1[0, 0])
W1*H1+B1[0, 0] = Plus(W1*H1[0, 0], B1[512, 1])
B1[512, 1] = LearnableParameter
W1*H1[0, 0] = Times(W1[512, 512], H1[0, 0])
H1[0, 0] = Sigmoid(W0*features+B0[0, 0])
W0*features+B0[0, 0] = Plus(W0*features[0, 0], B0[512, 1])
B0[512, 1] = LearnableParameter
W0*features[0, 0] = Times(W0[512, 363], MVNormalizedFeatures[0, 0])
MVNormalizedFeatures[0, 0] = PerDimMeanVarNormalization(features[363, 3], MeanOfFeatures[0, 0], InvStdOfFeatures[0, 0])
InvStdOfFeatures[0, 0] = InvStdDev(features[363, 3])
MeanOfFeatures[0, 0] = Mean(features[363, 3])
features[363, 3] = InputValue
W0[512, 363] = LearnableParameter
W1[512, 512] = LearnableParameter
W2[132, 512] = LearnableParameter
labels[132, 3] = InputValue

Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood. 11 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood. 9 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 3], LogOfPrior[132, 1]) -> [132, MBSize 3]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 3], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 3]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 3]) -> [512, MBSize 3]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 3], B0[512, 1]) -> [512, MBSize 3]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 3], B1[512, 1]) -> [512, MBSize 3]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 3]) -> [512, MBSize 3]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 3]) -> [132, MBSize 3]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 3], B2[132, 1]) -> [132, MBSize 3]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 3], HLast[132, MBSize 3]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.

GetTrainCriterionNodes  ...
GetEvalCriterionNodes  ...


Allocating matrices for gradient computing

Precomputing --> 3 PreCompute nodes found.

	NodeName: InvStdOfFeatures
	NodeName: MeanOfFeatures
	NodeName: Prior
minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms


Validating for node InvStdOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]

Validating for node InvStdOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 3]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.



Validating for node MeanOfFeatures. 2 nodes to process in pass 1.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]

Validating for node MeanOfFeatures, final verification.

Validating --> features = InputValue -> [363, MBSize 3]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 3]) -> [363, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.



Validating for node Prior. 2 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]

Validating for node Prior, final verification.

Validating --> labels = InputValue -> [132, MBSize 3]
Validating --> Prior = Mean(labels[132, MBSize 3]) -> [132, 1]

1 out of 2 nodes do not share the minibatch layout with the input data.


Precomputing --> Completed.

Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000 
minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 1 of 3]-Minibatch[   1-  10 of 320]: SamplesSeen = 640; TrainLossPerSample =  4.39181824; EvalErr[0]PerSample = 0.89843750; TotalTime = 0.63097s; TotalTimePerSample = 0.98589ms; SamplesPerSecond = 1014
 Epoch[ 1 of 3]-Minibatch[  11-  20 of 320]: SamplesSeen = 640; TrainLossPerSample =  4.16675262; EvalErr[0]PerSample = 0.87187500; TotalTime = 0.62104s; TotalTimePerSample = 0.97038ms; SamplesPerSecond = 1030
 Epoch[ 1 of 3]-Minibatch[  21-  30 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.98683777; EvalErr[0]PerSample = 0.87812500; TotalTime = 0.65190s; TotalTimePerSample = 1.01860ms; SamplesPerSecond = 981
 Epoch[ 1 of 3]-Minibatch[  31-  40 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.86594696; EvalErr[0]PerSample = 0.87812500; TotalTime = 0.65375s; TotalTimePerSample = 1.02149ms; SamplesPerSecond = 978
 Epoch[ 1 of 3]-Minibatch[  41-  50 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.81006317; EvalErr[0]PerSample = 0.88593750; TotalTime = 0.61977s; TotalTimePerSample = 0.96839ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[  51-  60 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.73426971; EvalErr[0]PerSample = 0.87656250; TotalTime = 0.62086s; TotalTimePerSample = 0.97009ms; SamplesPerSecond = 1030
 Epoch[ 1 of 3]-Minibatch[  61-  70 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.57473755; EvalErr[0]PerSample = 0.81875000; TotalTime = 0.62077s; TotalTimePerSample = 0.96996ms; SamplesPerSecond = 1030
 Epoch[ 1 of 3]-Minibatch[  71-  80 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.43590698; EvalErr[0]PerSample = 0.80781250; TotalTime = 0.62009s; TotalTimePerSample = 0.96890ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[  81-  90 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.36040344; EvalErr[0]PerSample = 0.77343750; TotalTime = 0.62052s; TotalTimePerSample = 0.96957ms; SamplesPerSecond = 1031
 Epoch[ 1 of 3]-Minibatch[  91- 100 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.39382019; EvalErr[0]PerSample = 0.85156250; TotalTime = 0.68852s; TotalTimePerSample = 1.07581ms; SamplesPerSecond = 929
 Epoch[ 1 of 3]-Minibatch[ 101- 110 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.25076599; EvalErr[0]PerSample = 0.76406250; TotalTime = 0.66482s; TotalTimePerSample = 1.03878ms; SamplesPerSecond = 962
 Epoch[ 1 of 3]-Minibatch[ 111- 120 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.35322266; EvalErr[0]PerSample = 0.79375000; TotalTime = 0.67844s; TotalTimePerSample = 1.06006ms; SamplesPerSecond = 943
 Epoch[ 1 of 3]-Minibatch[ 121- 130 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.19603882; EvalErr[0]PerSample = 0.76875000; TotalTime = 0.63003s; TotalTimePerSample = 0.98442ms; SamplesPerSecond = 1015
 Epoch[ 1 of 3]-Minibatch[ 131- 140 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.06107178; EvalErr[0]PerSample = 0.73125000; TotalTime = 0.68597s; TotalTimePerSample = 1.07182ms; SamplesPerSecond = 932
 Epoch[ 1 of 3]-Minibatch[ 141- 150 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.05115662; EvalErr[0]PerSample = 0.75625000; TotalTime = 0.61976s; TotalTimePerSample = 0.96837ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[ 151- 160 of 320]: SamplesSeen = 640; TrainLossPerSample =  3.02470093; EvalErr[0]PerSample = 0.74062500; TotalTime = 0.62011s; TotalTimePerSample = 0.96892ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[ 161- 170 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.89898682; EvalErr[0]PerSample = 0.70781250; TotalTime = 0.62041s; TotalTimePerSample = 0.96939ms; SamplesPerSecond = 1031
 Epoch[ 1 of 3]-Minibatch[ 171- 180 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.75169067; EvalErr[0]PerSample = 0.68125000; TotalTime = 0.61953s; TotalTimePerSample = 0.96801ms; SamplesPerSecond = 1033
 Epoch[ 1 of 3]-Minibatch[ 181- 190 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.83965454; EvalErr[0]PerSample = 0.71875000; TotalTime = 0.61966s; TotalTimePerSample = 0.96821ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[ 191- 200 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.62866821; EvalErr[0]PerSample = 0.65468750; TotalTime = 0.62017s; TotalTimePerSample = 0.96902ms; SamplesPerSecond = 1031
 Epoch[ 1 of 3]-Minibatch[ 201- 210 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.66650391; EvalErr[0]PerSample = 0.67187500; TotalTime = 0.62018s; TotalTimePerSample = 0.96904ms; SamplesPerSecond = 1031
 Epoch[ 1 of 3]-Minibatch[ 211- 220 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.61323853; EvalErr[0]PerSample = 0.65937500; TotalTime = 0.62968s; TotalTimePerSample = 0.98388ms; SamplesPerSecond = 1016
 Epoch[ 1 of 3]-Minibatch[ 221- 230 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.53096313; EvalErr[0]PerSample = 0.63750000; TotalTime = 0.69798s; TotalTimePerSample = 1.09060ms; SamplesPerSecond = 916
 Epoch[ 1 of 3]-Minibatch[ 231- 240 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.43744507; EvalErr[0]PerSample = 0.64375000; TotalTime = 0.62794s; TotalTimePerSample = 0.98116ms; SamplesPerSecond = 1019
 Epoch[ 1 of 3]-Minibatch[ 241- 250 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.41102905; EvalErr[0]PerSample = 0.65312500; TotalTime = 0.63246s; TotalTimePerSample = 0.98822ms; SamplesPerSecond = 1011
 Epoch[ 1 of 3]-Minibatch[ 251- 260 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.48895264; EvalErr[0]PerSample = 0.63750000; TotalTime = 0.62028s; TotalTimePerSample = 0.96920ms; SamplesPerSecond = 1031
 Epoch[ 1 of 3]-Minibatch[ 261- 270 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.34961548; EvalErr[0]PerSample = 0.61093750; TotalTime = 0.61992s; TotalTimePerSample = 0.96862ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[ 271- 280 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.23703613; EvalErr[0]PerSample = 0.57812500; TotalTime = 0.62002s; TotalTimePerSample = 0.96878ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[ 281- 290 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.33130493; EvalErr[0]PerSample = 0.62031250; TotalTime = 0.61910s; TotalTimePerSample = 0.96734ms; SamplesPerSecond = 1033
 Epoch[ 1 of 3]-Minibatch[ 291- 300 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.21602783; EvalErr[0]PerSample = 0.62812500; TotalTime = 0.61986s; TotalTimePerSample = 0.96853ms; SamplesPerSecond = 1032
 Epoch[ 1 of 3]-Minibatch[ 301- 310 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.29106445; EvalErr[0]PerSample = 0.60625000; TotalTime = 0.62023s; TotalTimePerSample = 0.96911ms; SamplesPerSecond = 1031
 Epoch[ 1 of 3]-Minibatch[ 311- 320 of 320]: SamplesSeen = 640; TrainLossPerSample =  2.20531006; EvalErr[0]PerSample = 0.57500000; TotalTime = 0.61718s; TotalTimePerSample = 0.96434ms; SamplesPerSecond = 1036
Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.017344; EvalErrPerSample = 0.73061526; AvgLearningRatePerSample = 0.015625; EpochTime=20.286321
Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119 
minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 3]-Minibatch[   1-  10 of 80]: SamplesSeen = 2560; TrainLossPerSample =  2.05707302; EvalErr[0]PerSample = 0.55000000; TotalTime = 0.84859s; TotalTimePerSample = 0.33148ms; SamplesPerSecond = 3016
 Epoch[ 2 of 3]-Minibatch[  11-  20 of 80]: SamplesSeen = 2560; TrainLossPerSample =  2.02921238; EvalErr[0]PerSample = 0.54648438; TotalTime = 0.84521s; TotalTimePerSample = 0.33016ms; SamplesPerSecond = 3028
 Epoch[ 2 of 3]-Minibatch[  21-  30 of 80]: SamplesSeen = 2560; TrainLossPerSample =  2.02822380; EvalErr[0]PerSample = 0.54843750; TotalTime = 0.84468s; TotalTimePerSample = 0.32995ms; SamplesPerSecond = 3030
 Epoch[ 2 of 3]-Minibatch[  31-  40 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.97091789; EvalErr[0]PerSample = 0.54140625; TotalTime = 0.84657s; TotalTimePerSample = 0.33069ms; SamplesPerSecond = 3023
 Epoch[ 2 of 3]-Minibatch[  41-  50 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.94545746; EvalErr[0]PerSample = 0.53867188; TotalTime = 0.84531s; TotalTimePerSample = 0.33020ms; SamplesPerSecond = 3028
 Epoch[ 2 of 3]-Minibatch[  51-  60 of 80]: SamplesSeen = 2560; TrainLossPerSample =  2.01557617; EvalErr[0]PerSample = 0.54414063; TotalTime = 0.84531s; TotalTimePerSample = 0.33020ms; SamplesPerSecond = 3028
 Epoch[ 2 of 3]-Minibatch[  61-  70 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.94065170; EvalErr[0]PerSample = 0.52500000; TotalTime = 0.84554s; TotalTimePerSample = 0.33029ms; SamplesPerSecond = 3027
 Epoch[ 2 of 3]-Minibatch[  71-  80 of 80]: SamplesSeen = 2560; TrainLossPerSample =  1.94852905; EvalErr[0]PerSample = 0.54023438; TotalTime = 0.83581s; TotalTimePerSample = 0.32649ms; SamplesPerSecond = 3062
Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 1.9919552; EvalErrPerSample = 0.54179686; AvgLearningRatePerSample = 0.001953125; EpochTime=6.772167
Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119 
minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 3 of 3]-Minibatch[   1-  10 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.91941833; EvalErr[0]PerSample = 0.52890625; TotalTime = 1.74051s; TotalTimePerSample = 0.16997ms; SamplesPerSecond = 5883
 Epoch[ 3 of 3]-Minibatch[  11-  20 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.91062393; EvalErr[0]PerSample = 0.52783203; TotalTime = 1.68678s; TotalTimePerSample = 0.16472ms; SamplesPerSecond = 6070
Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9150212; EvalErrPerSample = 0.52836913; AvgLearningRatePerSample = 9.765625146e-05; EpochTime=3.475749
CNTKCommandTrainEnd: speechTrain


Allocating matrices for forward propagation.


Printing Gradient Computation Node Order ... 

CrossEntropyWithSoftmax[0, 0] = CrossEntropyWithSoftmax(labels[132, 0], HLast[0, 0])
HLast[0, 0] = Plus(W2*H1[0, 0], B2[132, 1])
B2[132, 1] = LearnableParameter
W2*H1[0, 0] = Times(W2[132, 512], H2[0, 0])
H2[0, 0] = Sigmoid(W1*H1+B1[0, 0])
W1*H1+B1[0, 0] = Plus(W1*H1[0, 0], B1[512, 1])
B1[512, 1] = LearnableParameter
W1*H1[0, 0] = Times(W1[512, 512], H1[0, 0])
H1[0, 0] = Sigmoid(W0*features+B0[0, 0])
W0*features+B0[0, 0] = Plus(W0*features[0, 0], B0[512, 1])
B0[512, 1] = LearnableParameter
W0*features[0, 0] = Times(W0[512, 363], MVNormalizedFeatures[0, 0])
MVNormalizedFeatures[0, 0] = PerDimMeanVarNormalization(features[363, 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1])
InvStdOfFeatures[363, 1] = InvStdDev(features[363, 0])
MeanOfFeatures[363, 1] = Mean(features[363, 0])
features[363, 0] = InputValue
W0[512, 363] = LearnableParameter
W1[512, 512] = LearnableParameter
W2[132, 512] = LearnableParameter
labels[132, 0] = InputValue

Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node CrossEntropyWithSoftmax. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 11 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 22 nodes to process in pass 1.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 9 nodes to process in pass 2.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

10 out of 22 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 20 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 9 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2 = LearnableParameter -> [132, 512]
Validating --> W1 = LearnableParameter -> [512, 512]
Validating --> W0 = LearnableParameter -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

9 out of 20 nodes do not share the minibatch layout with the input data.

--------------------------------------------------------------------------------------------
ParameterSVD: start to process group 0 with KeepRatio=0.50
--------------------------------------------------------------------------------------------
Performing SVD for a   512-by-363   matrix (node name: W0                  ) ---  computation time  0.15 secs ;  keep 50.0% energy ===> keep   104 svd values (reduce to 49.0% parameters) 
Performing SVD for a   512-by-512   matrix (node name: W1                  ) ---  computation time  0.23 secs ;  keep 50.0% energy ===> keep   128 svd values (reduce to 50.0% parameters) 
Performing SVD for a   132-by-512   matrix (node name: W2                  ) ---  computation time  0.03 secs ;  keep 50.0% energy ===> keep    32 svd values (reduce to 30.5% parameters) 


Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.

CNTKCommandTrainBegin: SVDTrain
NDLBuilder Using CPU
reading script file glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /home/mluser/src/cplx_master/Tests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/mluser/src/cplx_master/Tests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
Starting from checkpoint. Load Network From File /tmp/cntk-test-20151113232743.140123/Speech_SVD@debug_cpu/models/cntkSpeech.svd.dnn.0.


Allocating matrices for forward propagation.


Printing Gradient Computation Node Order ... 

CrossEntropyWithSoftmax[0, 0] = CrossEntropyWithSoftmax(labels[132, 0], HLast[0, 0])
HLast[0, 0] = Plus(W2*H1[0, 0], B2[132, 1])
B2[132, 1] = LearnableParameter
W2*H1[0, 0] = Times(W2-SVD[0, 0], H2[0, 0])
H2[0, 0] = Sigmoid(W1*H1+B1[0, 0])
W1*H1+B1[0, 0] = Plus(W1*H1[0, 0], B1[512, 1])
B1[512, 1] = LearnableParameter
W1*H1[0, 0] = Times(W1-SVD[0, 0], H1[0, 0])
H1[0, 0] = Sigmoid(W0*features+B0[0, 0])
W0*features+B0[0, 0] = Plus(W0*features[0, 0], B0[512, 1])
B0[512, 1] = LearnableParameter
W0*features[0, 0] = Times(W0-SVD[0, 0], MVNormalizedFeatures[0, 0])
MVNormalizedFeatures[0, 0] = PerDimMeanVarNormalization(features[363, 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1])
InvStdOfFeatures[363, 1] = InvStdDev(features[363, 0])
MeanOfFeatures[363, 1] = Mean(features[363, 0])
features[363, 0] = InputValue
W0-SVD[0, 0] = Times(W0-U[512, 104], W0-V[104, 363])
W0-V[104, 363] = LearnableParameter
W0-U[512, 104] = LearnableParameter
W1-SVD[0, 0] = Times(W1-U[512, 128], W1-V[128, 512])
W1-V[128, 512] = LearnableParameter
W1-U[512, 128] = LearnableParameter
W2-SVD[0, 0] = Times(W2-U[132, 32], W2-V[32, 512])
W2-V[32, 512] = LearnableParameter
W2-U[132, 32] = LearnableParameter
labels[132, 0] = InputValue

Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 15 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.



Validating for node CrossEntropyWithSoftmax. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node CrossEntropyWithSoftmax, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 28 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 14 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

16 out of 28 nodes do not share the minibatch layout with the input data.



Validating for node ScaledLogLikelihood. 28 nodes to process in pass 1.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood. 12 nodes to process in pass 2.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

Validating for node ScaledLogLikelihood, final verification.

Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> Prior = Mean(labels[132, MBSize 0]) -> [132, 1]
Validating --> LogOfPrior = Log(Prior[132, 1]) -> [132, 1]
Validating --> ScaledLogLikelihood = Minus(HLast[132, MBSize 0], LogOfPrior[132, 1]) -> [132, MBSize 0]

16 out of 28 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.



Validating for node EvalErrorPrediction. 26 nodes to process in pass 1.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction. 12 nodes to process in pass 2.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

Validating for node EvalErrorPrediction, final verification.

Validating --> labels = InputValue -> [132, MBSize 0]
Validating --> W2-U = LearnableParameter -> [132, 32]
Validating --> W2-V = LearnableParameter -> [32, 512]
Validating --> W2-SVD = Times(W2-U[132, 32], W2-V[32, 512]) -> [132, 512]
Validating --> W1-U = LearnableParameter -> [512, 128]
Validating --> W1-V = LearnableParameter -> [128, 512]
Validating --> W1-SVD = Times(W1-U[512, 128], W1-V[128, 512]) -> [512, 512]
Validating --> W0-U = LearnableParameter -> [512, 104]
Validating --> W0-V = LearnableParameter -> [104, 363]
Validating --> W0-SVD = Times(W0-U[512, 104], W0-V[104, 363]) -> [512, 363]
Validating --> features = InputValue -> [363, MBSize 0]
Validating --> MeanOfFeatures = Mean(features[363, MBSize 0]) -> [363, 1]
Validating --> InvStdOfFeatures = InvStdDev(features[363, MBSize 0]) -> [363, 1]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization(features[363, MBSize 0], MeanOfFeatures[363, 1], InvStdOfFeatures[363, 1]) -> [363, MBSize 0]
Validating --> W0*features = Times(W0-SVD[512, 363], MVNormalizedFeatures[363, MBSize 0]) -> [512, MBSize 0]
Validating --> B0 = LearnableParameter -> [512, 1]
Validating --> W0*features+B0 = Plus(W0*features[512, MBSize 0], B0[512, 1]) -> [512, MBSize 0]
Validating --> H1 = Sigmoid(W0*features+B0[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W1*H1 = Times(W1-SVD[512, 512], H1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> B1 = LearnableParameter -> [512, 1]
Validating --> W1*H1+B1 = Plus(W1*H1[512, MBSize 0], B1[512, 1]) -> [512, MBSize 0]
Validating --> H2 = Sigmoid(W1*H1+B1[512, MBSize 0]) -> [512, MBSize 0]
Validating --> W2*H1 = Times(W2-SVD[132, 512], H2[512, MBSize 0]) -> [132, MBSize 0]
Validating --> B2 = LearnableParameter -> [132, 1]
Validating --> HLast = Plus(W2*H1[132, MBSize 0], B2[132, 1]) -> [132, MBSize 0]
Validating --> EvalErrorPrediction = ErrorPrediction(labels[132, MBSize 0], HLast[132, MBSize 0]) -> [1, 1]

15 out of 26 nodes do not share the minibatch layout with the input data.

GetTrainCriterionNodes  ...
GetEvalCriterionNodes  ...


Allocating matrices for gradient computing
No PreCompute nodes found, skipping PreCompute step
Set Max Temp Mem Size For Convolution Nodes to 0 samples.
Starting Epoch 1: learning rate per sample = 0.000098  effective momentum = 0.656119 
minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

Starting minibatch loop.
 Epoch[ 1 of 2]-Minibatch[   1-  10 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.90709000; EvalErr[0]PerSample = 0.52988281; TotalTime = 1.52806s; TotalTimePerSample = 0.14922ms; SamplesPerSecond = 6701
 Epoch[ 1 of 2]-Minibatch[  11-  20 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.86627007; EvalErr[0]PerSample = 0.51650391; TotalTime = 1.48349s; TotalTimePerSample = 0.14487ms; SamplesPerSecond = 6902
Finished Epoch[ 1 of 2]: [Training Set] TrainLossPerSample = 1.88668; EvalErrPerSample = 0.52319336; AvgLearningRatePerSample = 9.765625146e-05; EpochTime=3.969891
Starting Epoch 2: learning rate per sample = 0.000098  effective momentum = 0.656119 
minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 1, with 1 datapasses

Starting minibatch loop.
 Epoch[ 2 of 2]-Minibatch[   1-  10 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.84089890; EvalErr[0]PerSample = 0.51132813; TotalTime = 1.52045s; TotalTimePerSample = 0.14848ms; SamplesPerSecond = 6734
 Epoch[ 2 of 2]-Minibatch[  11-  20 of 20]: SamplesSeen = 10240; TrainLossPerSample =  1.85902176; EvalErr[0]PerSample = 0.51396484; TotalTime = 1.48188s; TotalTimePerSample = 0.14471ms; SamplesPerSecond = 6910
Finished Epoch[ 2 of 2]: [Training Set] TrainLossPerSample = 1.8499603; EvalErrPerSample = 0.5126465; AvgLearningRatePerSample = 9.765625146e-05; EpochTime=3.049746
CNTKCommandTrainEnd: SVDTrain
__COMPLETED__
