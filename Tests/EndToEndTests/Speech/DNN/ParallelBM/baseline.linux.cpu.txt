=== Running mpiexec -n 2 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/.. OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu DeviceId=-1 timestamping=true numCPUThreads=12 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jun 13 2016 21:56:00
		Last modified date: Mon Jun 13 17:05:37 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
		Built by philly on 373ab38025ce
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Jun 13 2016 21:56:00
		Last modified date: Mon Jun 13 17:05:37 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
		Built by philly on 373ab38025ce
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
06/13/2016 22:02:31: Redirecting stderr to file /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr_speechTrain.logrank0
06/13/2016 22:02:32: Redirecting stderr to file /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr_speechTrain.logrank1
MPI Rank 0: 06/13/2016 22:02:31: -------------------------------------------------------------------
MPI Rank 0: 06/13/2016 22:02:31: Build info: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: 		Built time: Jun 13 2016 21:56:00
MPI Rank 0: 06/13/2016 22:02:31: 		Last modified date: Mon Jun 13 17:05:37 2016
MPI Rank 0: 06/13/2016 22:02:31: 		Build type: release
MPI Rank 0: 06/13/2016 22:02:31: 		Build target: GPU
MPI Rank 0: 06/13/2016 22:02:31: 		With 1bit-SGD: yes
MPI Rank 0: 06/13/2016 22:02:31: 		Math lib: acml
MPI Rank 0: 06/13/2016 22:02:31: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 0: 06/13/2016 22:02:31: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 06/13/2016 22:02:31: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 0: 06/13/2016 22:02:31: 		Build Branch: HEAD
MPI Rank 0: 06/13/2016 22:02:31: 		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
MPI Rank 0: 06/13/2016 22:02:31: 		Built by philly on 373ab38025ce
MPI Rank 0: 06/13/2016 22:02:31: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 06/13/2016 22:02:31: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: Running on localhost at 2016/06/13 22:02:31
MPI Rank 0: 06/13/2016 22:02:31: Command line: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 06/13/2016 22:02:31: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 06/13/2016 22:02:31: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = -1
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=-1
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 0: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 06/13/2016 22:02:31: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 06/13/2016 22:02:31: Commands: speechTrain
MPI Rank 0: 06/13/2016 22:02:31: Precision = "double"
MPI Rank 0: 06/13/2016 22:02:31: Using 12 CPU threads.
MPI Rank 0: 06/13/2016 22:02:31: CNTKModelPath: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn
MPI Rank 0: 06/13/2016 22:02:31: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 06/13/2016 22:02:31: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: ##############################################################################
MPI Rank 0: 06/13/2016 22:02:31: #                                                                            #
MPI Rank 0: 06/13/2016 22:02:31: # Action "train"                                                             #
MPI Rank 0: 06/13/2016 22:02:31: #                                                                            #
MPI Rank 0: 06/13/2016 22:02:31: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using CPU
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: Creating virgin network.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: Created model with 25 nodes on CPU.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: Training criterion node(s):
MPI Rank 0: 06/13/2016 22:02:31: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 0x19b7c28: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 0x19b9b98: {[B2 Value[132 x 1]] }
MPI Rank 0: 0x19bb978: {[W2 Value[132 x 512]] }
MPI Rank 0: 0x19bfe98: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 0x1a09a08: {[Prior Value[132]] }
MPI Rank 0: 0x1a16658: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 0x1a21878: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 0x1a21a38: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 0x1a3c5c8: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 0x1a3c788: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 0x1a3c948: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 0x1a3cb08: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 0x1a3ccc8: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 0x1a6b328: {[W1 Value[512 x 512]] }
MPI Rank 0: 0x1ac01a8: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 0x1ac0338: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 0x1ac04f8: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 0x1ac0d98: {[W0*features Value[512 x *]] }
MPI Rank 0: 0x1ad2638: {[B0 Value[512 x 1]] }
MPI Rank 0: 0x1ad42b8: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 0x1ad4478: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 0x1ad9098: {[features Value[363 x *]] }
MPI Rank 0: 0x1ad9bb8: {[labels Value[132 x *]] }
MPI Rank 0: 0x1ad9cc8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 0x1ad9e88: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 0x1ada088: {[LogOfPrior Value[132]] }
MPI Rank 0: 0x1ada928: {[B1 Value[512 x 1]] }
MPI Rank 0: 0x1ade168: {[W0 Value[512 x 363]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:31: 	MeanOfFeatures = Mean()
MPI Rank 0: 06/13/2016 22:02:31: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 06/13/2016 22:02:31: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:42: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:42: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:02:42: Starting minibatch loop.
MPI Rank 0: 06/13/2016 22:02:43:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.56947300 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.3944s; samplesPerSecond = 486.8
MPI Rank 0: 06/13/2016 22:02:43:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.43406315 * 192; EvalErrorPrediction = 0.93229167 * 192; time = 0.1836s; samplesPerSecond = 1046.0
MPI Rank 0: 06/13/2016 22:02:43:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.27880063 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.1776s; samplesPerSecond = 1081.3
MPI Rank 0: 06/13/2016 22:02:43:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.08751953 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.1716s; samplesPerSecond = 1118.9
MPI Rank 0: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21737559 * 192; EvalErrorPrediction = 0.91145833 * 192; time = 0.2052s; samplesPerSecond = 935.7
MPI Rank 0: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14259750 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.1898s; samplesPerSecond = 1011.4
MPI Rank 0: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.03221539 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1972s; samplesPerSecond = 973.8
MPI Rank 0: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.09889450 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.1893s; samplesPerSecond = 1014.4
MPI Rank 0: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.89612175 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.1892s; samplesPerSecond = 1014.7
MPI Rank 0: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 3.98897999 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.1774s; samplesPerSecond = 1082.1
MPI Rank 0: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.93572978 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.3831s; samplesPerSecond = 501.2
MPI Rank 0: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.76284095 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.1943s; samplesPerSecond = 988.3
MPI Rank 0: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.98522385 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.1853s; samplesPerSecond = 1036.0
MPI Rank 0: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66209590 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.1961s; samplesPerSecond = 979.0
MPI Rank 0: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.96368107 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.1941s; samplesPerSecond = 989.4
MPI Rank 0: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76732554 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.2087s; samplesPerSecond = 919.8
MPI Rank 0: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69456327 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.2382s; samplesPerSecond = 806.1
MPI Rank 0: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.82975145 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.1934s; samplesPerSecond = 992.7
MPI Rank 0: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82370243 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.1964s; samplesPerSecond = 977.8
MPI Rank 0: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.57625565 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.2001s; samplesPerSecond = 959.6
MPI Rank 0: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.38811493 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.3999s; samplesPerSecond = 480.1
MPI Rank 0: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.52208661 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.1717s; samplesPerSecond = 1118.4
MPI Rank 0: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.80866929 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.1665s; samplesPerSecond = 1153.1
MPI Rank 0: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.54345746 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.1863s; samplesPerSecond = 1030.6
MPI Rank 0: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.33936350 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.1835s; samplesPerSecond = 1046.5
MPI Rank 0: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.43672338 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1745s; samplesPerSecond = 1100.5
MPI Rank 0: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.44585129 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.1744s; samplesPerSecond = 1101.1
MPI Rank 0: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.43498669 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.1728s; samplesPerSecond = 1111.3
MPI Rank 0: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31632754 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.1993s; samplesPerSecond = 963.2
MPI Rank 0: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.33946924 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.1835s; samplesPerSecond = 1046.5
MPI Rank 0: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.26118575 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.1941s; samplesPerSecond = 989.1
MPI Rank 0: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.56686839 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.3834s; samplesPerSecond = 500.8
MPI Rank 0: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.36674876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1826s; samplesPerSecond = 1051.3
MPI Rank 0: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.28977127 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.1829s; samplesPerSecond = 1049.6
MPI Rank 0: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.27969909 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.1757s; samplesPerSecond = 1092.5
MPI Rank 0: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.12259596 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.1936s; samplesPerSecond = 991.9
MPI Rank 0: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.41981056 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.1890s; samplesPerSecond = 1015.6
MPI Rank 0: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.38297602 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.1804s; samplesPerSecond = 1064.4
MPI Rank 0: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.41994711 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.1713s; samplesPerSecond = 1121.0
MPI Rank 0: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.24732267 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1971s; samplesPerSecond = 974.0
MPI Rank 0: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.20269035 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.1748s; samplesPerSecond = 1098.1
MPI Rank 0: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.15326365 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.1734s; samplesPerSecond = 1107.3
MPI Rank 0: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.21802066 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.3955s; samplesPerSecond = 485.4
MPI Rank 0: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.26091070 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.1821s; samplesPerSecond = 1054.3
MPI Rank 0: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.94987113 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.1960s; samplesPerSecond = 979.8
MPI Rank 0: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 3.01829231 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.1841s; samplesPerSecond = 1042.7
MPI Rank 0: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.19981302 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.1923s; samplesPerSecond = 998.5
MPI Rank 0: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.01620054 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.1895s; samplesPerSecond = 1013.3
MPI Rank 0: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.07482512 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.1862s; samplesPerSecond = 1031.3
MPI Rank 0: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95940261 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.1892s; samplesPerSecond = 1014.6
MPI Rank 0: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.18955068 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1734s; samplesPerSecond = 1107.5
MPI Rank 0: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.80225800 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.1755s; samplesPerSecond = 1094.1
MPI Rank 0: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.08865913 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.1749s; samplesPerSecond = 1097.5
MPI Rank 0: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.87171438 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.3892s; samplesPerSecond = 493.3
MPI Rank 0: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.90723268 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.1718s; samplesPerSecond = 1117.3
MPI Rank 0: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.96438386 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.1611s; samplesPerSecond = 1191.9
MPI Rank 0: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.85407675 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.1732s; samplesPerSecond = 1108.8
MPI Rank 0: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.64516293 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1847s; samplesPerSecond = 1039.4
MPI Rank 0: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.78779884 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.1931s; samplesPerSecond = 994.1
MPI Rank 0: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77691077 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.1957s; samplesPerSecond = 981.1
MPI Rank 0: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.93466303 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.2164s; samplesPerSecond = 887.3
MPI Rank 0: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.79665615 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.1838s; samplesPerSecond = 1044.9
MPI Rank 0: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.79141433 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.1799s; samplesPerSecond = 1067.2
MPI Rank 0: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.85677634 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.4053s; samplesPerSecond = 473.7
MPI Rank 0: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.60438340 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.1993s; samplesPerSecond = 963.2
MPI Rank 0: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.67867701 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.1821s; samplesPerSecond = 1054.1
MPI Rank 0: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.35420452 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.1815s; samplesPerSecond = 1057.7
MPI Rank 0: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67860524 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.1725s; samplesPerSecond = 1113.0
MPI Rank 0: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.74438644 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.2049s; samplesPerSecond = 936.9
MPI Rank 0: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.61472294 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.1916s; samplesPerSecond = 1001.9
MPI Rank 0: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.56292238 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.1999s; samplesPerSecond = 960.5
MPI Rank 0: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.49905414 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.1915s; samplesPerSecond = 1002.9
MPI Rank 0: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77977518 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.1855s; samplesPerSecond = 1035.0
MPI Rank 0: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.46098943 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1802s; samplesPerSecond = 1065.2
MPI Rank 0: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.53972637 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.3906s; samplesPerSecond = 491.5
MPI Rank 0: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58069409 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.1780s; samplesPerSecond = 1078.4
MPI Rank 0: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.42808307 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.1800s; samplesPerSecond = 1066.7
MPI Rank 0: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.51795774 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.1755s; samplesPerSecond = 1094.0
MPI Rank 0: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.31017953 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.1852s; samplesPerSecond = 1036.7
MPI Rank 0: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42763250 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.1838s; samplesPerSecond = 1044.6
MPI Rank 0: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.38337452 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1734s; samplesPerSecond = 1107.3
MPI Rank 0: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.45688385 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.1760s; samplesPerSecond = 1091.0
MPI Rank 0: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.35065649 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1777s; samplesPerSecond = 1080.5
MPI Rank 0: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.39950363 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.1827s; samplesPerSecond = 1051.0
MPI Rank 0: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.48031632 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.1976s; samplesPerSecond = 971.7
MPI Rank 0: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.62124157 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.4045s; samplesPerSecond = 474.7
MPI Rank 0: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43263192 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.1958s; samplesPerSecond = 980.5
MPI Rank 0: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.13490764 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.1688s; samplesPerSecond = 1137.6
MPI Rank 0: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.52272390 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.1760s; samplesPerSecond = 1091.0
MPI Rank 0: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.31215555 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1746s; samplesPerSecond = 1100.0
MPI Rank 0: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33888920 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1805s; samplesPerSecond = 1063.7
MPI Rank 0: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.19318149 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.1913s; samplesPerSecond = 1003.8
MPI Rank 0: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.19368853 * 192; EvalErrorPrediction = 0.55208333 * 192; time = 0.1768s; samplesPerSecond = 1085.8
MPI Rank 0: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.31322736 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.1994s; samplesPerSecond = 963.1
MPI Rank 0: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21496162 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.1857s; samplesPerSecond = 1034.2
MPI Rank 0: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.38257678 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.1810s; samplesPerSecond = 1060.7
MPI Rank 0: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34785036 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.3939s; samplesPerSecond = 487.5
MPI Rank 0: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.20545861 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1744s; samplesPerSecond = 1100.7
MPI Rank 0: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.08751143 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.1888s; samplesPerSecond = 1017.0
MPI Rank 0: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.28302994 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.1940s; samplesPerSecond = 989.8
MPI Rank 0: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.22267854 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.1832s; samplesPerSecond = 1048.0
MPI Rank 0: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.19855044 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1756s; samplesPerSecond = 1093.1
MPI Rank 0: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.49612283 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.1852s; samplesPerSecond = 1036.8
MPI Rank 0: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25409762 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.1757s; samplesPerSecond = 1092.9
MPI Rank 0: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13085317 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.1761s; samplesPerSecond = 1090.4
MPI Rank 0: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.28902612 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.1714s; samplesPerSecond = 1120.4
MPI Rank 0: 06/13/2016 22:03:04: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=21.8719s
MPI Rank 0: 06/13/2016 22:03:04: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:04: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:04: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:03:05:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.25052560 * 519; EvalErrorPrediction = 0.62042389 * 519; time = 0.5644s; samplesPerSecond = 919.6
MPI Rank 0: 06/13/2016 22:03:05:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.02824382 * 529; EvalErrorPrediction = 0.54442344 * 529; time = 0.4170s; samplesPerSecond = 1268.6
MPI Rank 0: 06/13/2016 22:03:06:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.04039147 * 494; EvalErrorPrediction = 0.55668016 * 494; time = 0.3532s; samplesPerSecond = 1398.6
MPI Rank 0: 06/13/2016 22:03:06:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 1.98880977 * 491; EvalErrorPrediction = 0.55193483 * 491; time = 0.3724s; samplesPerSecond = 1318.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.32-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.32 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.47 seconds since last report (0.03 seconds on comm.); 4331 samples processed by 2 workers (2190 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 1.75k samplesPerSecond , throughputPerWorker = 0.88k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:07:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.12620927 * 488; EvalErrorPrediction = 0.55327869 * 488; time = 1.0093s; samplesPerSecond = 483.5
MPI Rank 0: 06/13/2016 22:03:08:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.00690071 * 485; EvalErrorPrediction = 0.56494845 * 485; time = 0.3701s; samplesPerSecond = 1310.4
MPI Rank 0: 06/13/2016 22:03:08:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 1.99194220 * 529; EvalErrorPrediction = 0.54442344 * 529; time = 0.4005s; samplesPerSecond = 1320.9
MPI Rank 0: 06/13/2016 22:03:08:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 1.96438270 * 468; EvalErrorPrediction = 0.56410256 * 468; time = 0.3402s; samplesPerSecond = 1375.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.45-seconds latency this time; accumulated time on sync point = 0.77 seconds , average latency = 0.39 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.37 seconds since last report (0.18 seconds on comm.); 4232 samples processed by 2 workers (2154 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 1.78k samplesPerSecond , throughputPerWorker = 0.89k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:10:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.00145662 * 499; EvalErrorPrediction = 0.53707415 * 499; time = 1.2109s; samplesPerSecond = 412.1
MPI Rank 0: 06/13/2016 22:03:10:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.18677023 * 494; EvalErrorPrediction = 0.58502024 * 494; time = 0.4513s; samplesPerSecond = 1094.6
MPI Rank 0: 06/13/2016 22:03:10:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 1.97121551 * 479; EvalErrorPrediction = 0.55532359 * 479; time = 0.3829s; samplesPerSecond = 1251.0
MPI Rank 0: 06/13/2016 22:03:11:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.01765091 * 488; EvalErrorPrediction = 0.54303279 * 488; time = 0.3779s; samplesPerSecond = 1291.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.77 seconds , average latency = 0.26 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.19 seconds since last report (0.14 seconds on comm.); 4185 samples processed by 2 workers (2125 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 1.91k samplesPerSecond , throughputPerWorker = 0.96k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:12:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 1.90503909 * 506; EvalErrorPrediction = 0.52173913 * 506; time = 0.7697s; samplesPerSecond = 657.4
MPI Rank 0: 06/13/2016 22:03:12:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 1.87253137 * 512; EvalErrorPrediction = 0.53710938 * 512; time = 0.3718s; samplesPerSecond = 1377.2
MPI Rank 0: 06/13/2016 22:03:12:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.92699152 * 497; EvalErrorPrediction = 0.49899396 * 497; time = 0.3554s; samplesPerSecond = 1398.4
MPI Rank 0: 06/13/2016 22:03:13:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 1.86967957 * 502; EvalErrorPrediction = 0.54581673 * 502; time = 0.3742s; samplesPerSecond = 1341.5
MPI Rank 0: 06/13/2016 22:03:13:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.08077350 * 476; EvalErrorPrediction = 0.57142857 * 476; time = 0.3982s; samplesPerSecond = 1195.2
MPI Rank 0: 06/13/2016 22:03:14:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.00372686 * 487; EvalErrorPrediction = 0.53388090 * 487; time = 0.5839s; samplesPerSecond = 834.0
MPI Rank 0: 06/13/2016 22:03:14:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.92223751 * 499; EvalErrorPrediction = 0.53306613 * 499; time = 0.4282s; samplesPerSecond = 1165.3
MPI Rank 0: 06/13/2016 22:03:14:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96031873 * 475; EvalErrorPrediction = 0.54947368 * 475; time = 0.3945s; samplesPerSecond = 1204.0
MPI Rank 0: 06/13/2016 22:03:15:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.94324612 * 506; EvalErrorPrediction = 0.52964427 * 506; time = 0.3803s; samplesPerSecond = 1330.6
MPI Rank 0: 06/13/2016 22:03:15:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 1.94596052 * 472; EvalErrorPrediction = 0.53389831 * 472; time = 0.3778s; samplesPerSecond = 1249.2
MPI Rank 0: 06/13/2016 22:03:16:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.87864114 * 490; EvalErrorPrediction = 0.54693878 * 490; time = 0.6073s; samplesPerSecond = 806.8
MPI Rank 0: 06/13/2016 22:03:16:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 1.94844616 * 477; EvalErrorPrediction = 0.51153040 * 477; time = 0.3471s; samplesPerSecond = 1374.1
MPI Rank 0: 06/13/2016 22:03:17:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 1.93817444 * 469; EvalErrorPrediction = 0.53091684 * 469; time = 0.3752s; samplesPerSecond = 1250.2
MPI Rank 0: 06/13/2016 22:03:17:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.94722731 * 495; EvalErrorPrediction = 0.53939394 * 495; time = 0.4355s; samplesPerSecond = 1136.7
MPI Rank 0: 06/13/2016 22:03:17:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.88543102 * 322; EvalErrorPrediction = 0.55279503 * 322; time = 0.2869s; samplesPerSecond = 1122.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.77 seconds , average latency = 0.19 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     5.87 seconds since last report (0.07 seconds on comm.); 7732 samples processed by 2 workers (6679 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.32k samplesPerSecond , throughputPerWorker = 0.66k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:17: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.00885273 * 20480; EvalErrorPrediction = 0.55078125 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=12.8969s
MPI Rank 0: 06/13/2016 22:03:18: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:18: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:18: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:03:19:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.87780257 * 1939; EvalErrorPrediction = 0.50644662 * 1939; time = 1.7289s; samplesPerSecond = 1121.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.67 seconds since last report (0.21 seconds on comm.); 4844 samples processed by 2 workers (2583 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 1.81k samplesPerSecond , throughputPerWorker = 0.91k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:21:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.89404862 * 1944; EvalErrorPrediction = 0.52726337 * 1944; time = 1.7307s; samplesPerSecond = 1123.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.83 seconds since last report (0.18 seconds on comm.); 4849 samples processed by 2 workers (2580 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.65k samplesPerSecond , throughputPerWorker = 1.33k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:23:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90812492 * 1918; EvalErrorPrediction = 0.53336809 * 1918; time = 1.6814s; samplesPerSecond = 1140.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.52 seconds since last report (0.06 seconds on comm.); 4868 samples processed by 2 workers (2595 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 1.93k samplesPerSecond , throughputPerWorker = 0.96k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:25:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.89877106 * 1957; EvalErrorPrediction = 0.53449157 * 1957; time = 1.8775s; samplesPerSecond = 1042.3
MPI Rank 0: 06/13/2016 22:03:26:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.88324196 * 1942; EvalErrorPrediction = 0.51956746 * 1942; time = 1.2648s; samplesPerSecond = 1535.4
MPI Rank 0: 06/13/2016 22:03:27:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86867010 * 1929; EvalErrorPrediction = 0.52514256 * 1929; time = 1.5607s; samplesPerSecond = 1236.0
MPI Rank 0: 06/13/2016 22:03:28:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.90242165 * 1290; EvalErrorPrediction = 0.53023256 * 1290; time = 1.0035s; samplesPerSecond = 1285.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.91 seconds since last report (0.06 seconds on comm.); 5919 samples processed by 2 workers (5161 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.51k samplesPerSecond , throughputPerWorker = 0.76k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:28: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.89787888 * 20480; EvalErrorPrediction = 0.52875977 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=10.9443s
MPI Rank 0: 06/13/2016 22:03:29: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:29: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:29: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:03:30:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.91224926 * 1926; EvalErrorPrediction = 0.52803738 * 1926; time = 1.5269s; samplesPerSecond = 1261.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.16 seconds since last report (0.17 seconds on comm.); 4905 samples processed by 2 workers (2581 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.27k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:32:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.80760312 * 1894; EvalErrorPrediction = 0.51108765 * 1894; time = 1.6437s; samplesPerSecond = 1152.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.15 seconds since last report (0.13 seconds on comm.); 4870 samples processed by 2 workers (2537 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.27k samplesPerSecond , throughputPerWorker = 1.13k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:33:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.86234536 * 1931; EvalErrorPrediction = 0.51424133 * 1931; time = 1.7540s; samplesPerSecond = 1100.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.24-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.12 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.34 seconds since last report (0.14 seconds on comm.); 4916 samples processed by 2 workers (2513 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.10k samplesPerSecond , throughputPerWorker = 1.05k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:35:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83816606 * 1880; EvalErrorPrediction = 0.50638298 * 1880; time = 1.7164s; samplesPerSecond = 1095.3
MPI Rank 0: 06/13/2016 22:03:37:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.80548301 * 1880; EvalErrorPrediction = 0.49680851 * 1880; time = 1.5028s; samplesPerSecond = 1251.0
MPI Rank 0: 06/13/2016 22:03:38:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.81476104 * 1861; EvalErrorPrediction = 0.50940355 * 1861; time = 1.4109s; samplesPerSecond = 1319.1
MPI Rank 0: 06/13/2016 22:03:39:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.82832821 * 1263; EvalErrorPrediction = 0.49802059 * 1263; time = 0.7945s; samplesPerSecond = 1589.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.90 seconds since last report (0.16 seconds on comm.); 5789 samples processed by 2 workers (5004 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.48k samplesPerSecond , throughputPerWorker = 0.74k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:39: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.84940336 * 20480; EvalErrorPrediction = 0.51445312 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=10.5692s
MPI Rank 0: 06/13/2016 22:03:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:39: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:03:41:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80847097 * 1897; EvalErrorPrediction = 0.50237217 * 1897; time = 1.5571s; samplesPerSecond = 1218.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.16 seconds since last report (0.14 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.28k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:42:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86742287 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.6602s; samplesPerSecond = 1096.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.15 seconds since last report (0.19 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.28k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:44:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90215948 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.4952s; samplesPerSecond = 1251.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.96 seconds since last report (0.09 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.48k samplesPerSecond , throughputPerWorker = 1.24k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:45:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83673317 * 1870; EvalErrorPrediction = 0.50320856 * 1870; time = 1.5459s; samplesPerSecond = 1209.6
MPI Rank 0: 06/13/2016 22:03:47:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91249924 * 1899; EvalErrorPrediction = 0.52553976 * 1899; time = 1.3756s; samplesPerSecond = 1380.5
MPI Rank 0: 06/13/2016 22:03:48:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87327558 * 1878; EvalErrorPrediction = 0.52183174 * 1878; time = 1.2131s; samplesPerSecond = 1548.1
MPI Rank 0: 06/13/2016 22:03:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87043426 * 1221; EvalErrorPrediction = 0.51678952 * 1221; time = 0.9723s; samplesPerSecond = 1255.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.85 seconds since last report (0.23 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.51k samplesPerSecond , throughputPerWorker = 0.76k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85300231 * 20480; EvalErrorPrediction = 0.51425781 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=10.1173s
MPI Rank 0: 06/13/2016 22:03:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:03:49: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 0: 06/13/2016 22:03:49: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:50: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:03:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:03:51:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80855659 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.4105s; samplesPerSecond = 1344.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.00 seconds since last report (0.15 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.46k samplesPerSecond , throughputPerWorker = 1.23k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:52:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86827725 * 1821; EvalErrorPrediction = 0.51729819 * 1821; time = 1.3872s; samplesPerSecond = 1312.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.32 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:54:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90376996 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.8127s; samplesPerSecond = 1032.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.23 seconds since last report (0.34 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.18k samplesPerSecond , throughputPerWorker = 1.09k samplesPerSecond
MPI Rank 0: 06/13/2016 22:03:56:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83821663 * 1870; EvalErrorPrediction = 0.50641711 * 1870; time = 1.8093s; samplesPerSecond = 1033.5
MPI Rank 0: 06/13/2016 22:03:57:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91393514 * 1899; EvalErrorPrediction = 0.52606635 * 1899; time = 1.3049s; samplesPerSecond = 1455.2
MPI Rank 0: 06/13/2016 22:03:59:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87537660 * 1878; EvalErrorPrediction = 0.52183174 * 1878; time = 1.5147s; samplesPerSecond = 1239.9
MPI Rank 0: 06/13/2016 22:04:00:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87301608 * 1221; EvalErrorPrediction = 0.51842752 * 1221; time = 0.9197s; samplesPerSecond = 1327.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.89 seconds since last report (0.08 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.50k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:00: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85426644 * 20480; EvalErrorPrediction = 0.51508789 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=10.3416s
MPI Rank 0: 06/13/2016 22:04:00: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:00: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 0: 06/13/2016 22:04:00: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:00: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:00: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:04:01:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80860170 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.3514s; samplesPerSecond = 1403.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.20 seconds since last report (0.17 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.23k samplesPerSecond , throughputPerWorker = 1.12k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:03:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86874821 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.7187s; samplesPerSecond = 1059.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.14 seconds since last report (0.23 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.28k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:05:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90471511 * 1871; EvalErrorPrediction = 0.52004276 * 1871; time = 1.7096s; samplesPerSecond = 1094.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.19 seconds since last report (0.25 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:07:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83914326 * 1870; EvalErrorPrediction = 0.50802139 * 1870; time = 1.7491s; samplesPerSecond = 1069.1
MPI Rank 0: 06/13/2016 22:04:08:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91489914 * 1899; EvalErrorPrediction = 0.52817272 * 1899; time = 1.2411s; samplesPerSecond = 1530.1
MPI Rank 0: 06/13/2016 22:04:09:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87668517 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 1.3575s; samplesPerSecond = 1383.5
MPI Rank 0: 06/13/2016 22:04:10:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87427101 * 1221; EvalErrorPrediction = 0.51678952 * 1221; time = 0.8003s; samplesPerSecond = 1525.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.56 seconds since last report (0.13 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.64k samplesPerSecond , throughputPerWorker = 0.82k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:10: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85499692 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=10.0887s
MPI Rank 0: 06/13/2016 22:04:10: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:10: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 0: 06/13/2016 22:04:10: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:10: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:10: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:04:12:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80862485 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.5810s; samplesPerSecond = 1199.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.20 seconds since last report (0.20 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.23k samplesPerSecond , throughputPerWorker = 1.12k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:14:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86899591 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.6103s; samplesPerSecond = 1130.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.00 seconds since last report (0.14 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.44k samplesPerSecond , throughputPerWorker = 1.22k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:15:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90523368 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 1.5901s; samplesPerSecond = 1176.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.04 seconds since last report (0.22 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.38k samplesPerSecond , throughputPerWorker = 1.19k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:17:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83967949 * 1870; EvalErrorPrediction = 0.50695187 * 1870; time = 1.4516s; samplesPerSecond = 1288.3
MPI Rank 0: 06/13/2016 22:04:18:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91551098 * 1899; EvalErrorPrediction = 0.52711954 * 1899; time = 1.4519s; samplesPerSecond = 1308.0
MPI Rank 0: 06/13/2016 22:04:19:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87747996 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 1.2321s; samplesPerSecond = 1524.3
MPI Rank 0: 06/13/2016 22:04:20:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87488056 * 1221; EvalErrorPrediction = 0.51842752 * 1221; time = 0.9755s; samplesPerSecond = 1251.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.76 seconds since last report (0.08 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.55k samplesPerSecond , throughputPerWorker = 0.77k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:20: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85540764 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=9.99959s
MPI Rank 0: 06/13/2016 22:04:20: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:20: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 0: 06/13/2016 22:04:20: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:21: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:21: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:04:22:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80863657 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.6660s; samplesPerSecond = 1138.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.32 seconds since last report (0.13 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.12k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:24:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86912298 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.7049s; samplesPerSecond = 1068.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.22 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:25:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90550621 * 1871; EvalErrorPrediction = 0.52164618 * 1871; time = 1.5612s; samplesPerSecond = 1198.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.11 seconds since last report (0.23 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.30k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:27:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.83997065 * 1870; EvalErrorPrediction = 0.50802139 * 1870; time = 1.7026s; samplesPerSecond = 1098.3
MPI Rank 0: 06/13/2016 22:04:29:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91586450 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.5493s; samplesPerSecond = 1225.7
MPI Rank 0: 06/13/2016 22:04:30:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87793326 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 1.2119s; samplesPerSecond = 1549.6
MPI Rank 0: 06/13/2016 22:04:31:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87518958 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.9470s; samplesPerSecond = 1289.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     4.00 seconds since last report (0.24 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.46k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:31: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85562974 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=10.6376s
MPI Rank 0: 06/13/2016 22:04:31: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:31: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 0: 06/13/2016 22:04:31: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:31: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:04:33:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864247 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.4246s; samplesPerSecond = 1331.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.08 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.13 seconds since last report (0.14 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.31k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:34:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86918735 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.4885s; samplesPerSecond = 1223.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.14-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.11 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.13 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:36:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90564602 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 1.8052s; samplesPerSecond = 1036.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.07 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.18 seconds since last report (0.10 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.22k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:38:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84012271 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.7830s; samplesPerSecond = 1048.8
MPI Rank 0: 06/13/2016 22:04:39:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91605566 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.5186s; samplesPerSecond = 1250.5
MPI Rank 0: 06/13/2016 22:04:41:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87817773 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.2143s; samplesPerSecond = 1546.6
MPI Rank 0: 06/13/2016 22:04:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87534772 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.9698s; samplesPerSecond = 1259.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     4.01 seconds since last report (0.21 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.45k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:42: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85574594 * 20480; EvalErrorPrediction = 0.51606445 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=10.529s
MPI Rank 0: 06/13/2016 22:04:42: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:42: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 0: 06/13/2016 22:04:42: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:42: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:04:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864542 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.3881s; samplesPerSecond = 1366.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.32 seconds since last report (0.30 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.12k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:45:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86921975 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.7012s; samplesPerSecond = 1070.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.19 seconds since last report (0.31 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.23k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:47:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90571684 * 1871; EvalErrorPrediction = 0.52004276 * 1871; time = 1.8843s; samplesPerSecond = 993.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.19 seconds since last report (0.19 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84020046 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.7267s; samplesPerSecond = 1083.0
MPI Rank 0: 06/13/2016 22:04:50:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91615521 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.2287s; samplesPerSecond = 1545.6
MPI Rank 0: 06/13/2016 22:04:51:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87830500 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.3868s; samplesPerSecond = 1354.2
MPI Rank 0: 06/13/2016 22:04:52:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87542816 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.8545s; samplesPerSecond = 1428.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.88 seconds since last report (0.12 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.50k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:53: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85580548 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=10.5836s
MPI Rank 0: 06/13/2016 22:04:53: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:53: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 0: 06/13/2016 22:04:53: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:53: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:04:53: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:04:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864691 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.2939s; samplesPerSecond = 1466.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.04 seconds since last report (0.11 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.41k samplesPerSecond , throughputPerWorker = 1.20k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86923600 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.5175s; samplesPerSecond = 1200.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.28-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.14 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.20 seconds since last report (0.10 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.22k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:57:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90575249 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 1.8604s; samplesPerSecond = 1005.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.12 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.18 seconds since last report (0.14 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.22k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:04:59:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84023978 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.7515s; samplesPerSecond = 1067.7
MPI Rank 0: 06/13/2016 22:05:01:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91620602 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.3138s; samplesPerSecond = 1445.4
MPI Rank 0: 06/13/2016 22:05:02:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87836997 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.4102s; samplesPerSecond = 1331.7
MPI Rank 0: 06/13/2016 22:05:03:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87546879 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.7898s; samplesPerSecond = 1546.0
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.69 seconds since last report (0.14 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.58k samplesPerSecond , throughputPerWorker = 0.79k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:03: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85583563 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=10.1176s
MPI Rank 0: 06/13/2016 22:05:03: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:03: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 0: 06/13/2016 22:05:03: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:03: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:05:05:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864765 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.4417s; samplesPerSecond = 1315.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.13 seconds since last report (0.20 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.31k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:06:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86924414 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.6893s; samplesPerSecond = 1078.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.09 seconds since last report (0.17 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.34k samplesPerSecond , throughputPerWorker = 1.17k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:08:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90577037 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 1.6774s; samplesPerSecond = 1115.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.11 seconds since last report (0.18 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.30k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:09:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84025955 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.5174s; samplesPerSecond = 1232.4
MPI Rank 0: 06/13/2016 22:05:11:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91623169 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.4530s; samplesPerSecond = 1307.0
MPI Rank 0: 06/13/2016 22:05:12:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87840281 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.3964s; samplesPerSecond = 1344.9
MPI Rank 0: 06/13/2016 22:05:13:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87548922 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.8342s; samplesPerSecond = 1463.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     4.00 seconds since last report (0.26 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.45k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:13: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585080 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=10.3353s
MPI Rank 0: 06/13/2016 22:05:13: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:14: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 0: 06/13/2016 22:05:14: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:14: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:05:15:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864802 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.4826s; samplesPerSecond = 1279.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.11 seconds since last report (0.20 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:17:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86924821 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.6276s; samplesPerSecond = 1118.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.10 seconds since last report (0.16 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:18:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90577933 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.5188s; samplesPerSecond = 1231.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.01 seconds since last report (0.06 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.42k samplesPerSecond , throughputPerWorker = 1.21k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:20:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84026946 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.5864s; samplesPerSecond = 1178.8
MPI Rank 0: 06/13/2016 22:05:21:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91624459 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.5481s; samplesPerSecond = 1226.6
MPI Rank 0: 06/13/2016 22:05:23:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87841931 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.2196s; samplesPerSecond = 1539.8
MPI Rank 0: 06/13/2016 22:05:24:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87549946 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.9114s; samplesPerSecond = 1339.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     4.10 seconds since last report (0.35 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.42k samplesPerSecond , throughputPerWorker = 0.71k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:24: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585841 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=10.3186s
MPI Rank 0: 06/13/2016 22:05:24: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:24: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 0: 06/13/2016 22:05:24: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:24: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:24: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:05:26:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864820 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.5263s; samplesPerSecond = 1242.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.11 seconds since last report (0.14 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:27:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925024 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.5224s; samplesPerSecond = 1196.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.06 seconds since last report (0.12 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.37k samplesPerSecond , throughputPerWorker = 1.19k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:29:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578381 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.5409s; samplesPerSecond = 1214.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.25 seconds since last report (0.37 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.16k samplesPerSecond , throughputPerWorker = 1.08k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:31:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027442 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.8208s; samplesPerSecond = 1027.0
MPI Rank 0: 06/13/2016 22:05:32:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625106 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.5426s; samplesPerSecond = 1231.1
MPI Rank 0: 06/13/2016 22:05:33:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87842758 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.3060s; samplesPerSecond = 1438.0
MPI Rank 0: 06/13/2016 22:05:34:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550459 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 1.0239s; samplesPerSecond = 1192.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     4.11 seconds since last report (0.17 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.42k samplesPerSecond , throughputPerWorker = 0.71k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:35: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586222 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=10.5284s
MPI Rank 0: 06/13/2016 22:05:35: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:35: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 0: 06/13/2016 22:05:35: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:35: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:05:36:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864830 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.3313s; samplesPerSecond = 1424.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.29 seconds since last report (0.29 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.15k samplesPerSecond , throughputPerWorker = 1.08k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:38:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925126 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.7982s; samplesPerSecond = 1012.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.23 seconds since last report (0.35 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.19k samplesPerSecond , throughputPerWorker = 1.09k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:40:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578605 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.8417s; samplesPerSecond = 1015.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.22 seconds since last report (0.32 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.19k samplesPerSecond , throughputPerWorker = 1.10k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:42:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027691 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.7567s; samplesPerSecond = 1064.5
MPI Rank 0: 06/13/2016 22:05:43:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625429 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.2881s; samplesPerSecond = 1474.3
MPI Rank 0: 06/13/2016 22:05:44:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843173 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.4714s; samplesPerSecond = 1276.3
MPI Rank 0: 06/13/2016 22:05:45:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550715 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.9699s; samplesPerSecond = 1258.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.98 seconds since last report (0.21 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.46k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586413 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=10.7175s
MPI Rank 0: 06/13/2016 22:05:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:46: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 0: 06/13/2016 22:05:46: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:05:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864834 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.3775s; samplesPerSecond = 1377.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.42 seconds since last report (0.34 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.03k samplesPerSecond , throughputPerWorker = 1.02k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:49:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925177 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.9381s; samplesPerSecond = 939.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.22 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.10k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:51:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578717 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.7840s; samplesPerSecond = 1048.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.30 seconds since last report (0.26 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.11k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027815 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.8226s; samplesPerSecond = 1026.0
MPI Rank 0: 06/13/2016 22:05:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625591 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.4702s; samplesPerSecond = 1291.7
MPI Rank 0: 06/13/2016 22:05:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843380 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.2396s; samplesPerSecond = 1515.0
MPI Rank 0: 06/13/2016 22:05:56:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550844 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.9373s; samplesPerSecond = 1302.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.89 seconds since last report (0.22 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.50k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 0: 06/13/2016 22:05:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586508 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=10.8164s
MPI Rank 0: 06/13/2016 22:05:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:57: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 0: 06/13/2016 22:05:57: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:57: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:05:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:05:58:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864837 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.2543s; samplesPerSecond = 1512.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.00 seconds since last report (0.20 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.46k samplesPerSecond , throughputPerWorker = 1.23k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:00:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925203 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.5770s; samplesPerSecond = 1154.8
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.27-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.14 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.23 seconds since last report (0.17 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.19k samplesPerSecond , throughputPerWorker = 1.09k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:01:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578773 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.8210s; samplesPerSecond = 1027.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.14-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.14 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.09 seconds since last report (0.09 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:03:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027877 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.6581s; samplesPerSecond = 1127.8
MPI Rank 0: 06/13/2016 22:06:04:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625673 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.3202s; samplesPerSecond = 1438.4
MPI Rank 0: 06/13/2016 22:06:06:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843484 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.4184s; samplesPerSecond = 1324.0
MPI Rank 0: 06/13/2016 22:06:07:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550908 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.7341s; samplesPerSecond = 1663.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.72 seconds since last report (0.23 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.57k samplesPerSecond , throughputPerWorker = 0.78k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:07: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586556 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=10.0336s
MPI Rank 0: 06/13/2016 22:06:07: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:07: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 0: 06/13/2016 22:06:07: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:07: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:07: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:08:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864838 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.5035s; samplesPerSecond = 1261.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.11 seconds since last report (0.12 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.17k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:10:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925216 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.5965s; samplesPerSecond = 1140.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.12 seconds since last report (0.23 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.30k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:12:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578801 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.7001s; samplesPerSecond = 1100.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.12-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.06 seconds since last report (0.05 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.35k samplesPerSecond , throughputPerWorker = 1.18k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:13:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027908 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.4873s; samplesPerSecond = 1257.3
MPI Rank 0: 06/13/2016 22:06:15:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625713 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.5058s; samplesPerSecond = 1261.1
MPI Rank 0: 06/13/2016 22:06:16:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843535 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.4111s; samplesPerSecond = 1330.9
MPI Rank 0: 06/13/2016 22:06:17:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550940 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.8067s; samplesPerSecond = 1513.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.86 seconds since last report (0.06 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.51k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:17: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586580 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=10.1561s
MPI Rank 0: 06/13/2016 22:06:17: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:17: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 0: 06/13/2016 22:06:17: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:17: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:19:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864838 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.4334s; samplesPerSecond = 1323.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.22-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.22 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.30 seconds since last report (0.15 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.14k samplesPerSecond , throughputPerWorker = 1.07k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:21:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925222 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.7866s; samplesPerSecond = 1019.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.18-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.20 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.04 seconds since last report (0.05 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.39k samplesPerSecond , throughputPerWorker = 1.19k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:22:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578815 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.5412s; samplesPerSecond = 1214.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.13 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.08 seconds since last report (0.17 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.17k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:24:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027924 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.6589s; samplesPerSecond = 1127.2
MPI Rank 0: 06/13/2016 22:06:25:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625733 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.4669s; samplesPerSecond = 1294.6
MPI Rank 0: 06/13/2016 22:06:26:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843561 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.2651s; samplesPerSecond = 1484.5
MPI Rank 0: 06/13/2016 22:06:27:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550956 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.9437s; samplesPerSecond = 1293.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     4.00 seconds since last report (0.27 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.46k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:28: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586592 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=10.4276s
MPI Rank 0: 06/13/2016 22:06:28: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:28: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 0: 06/13/2016 22:06:28: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:28: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:28: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:30:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80864839 * 1897; EvalErrorPrediction = 0.50184502 * 1897; time = 1.6016s; samplesPerSecond = 1184.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     2.33 seconds since last report (0.25 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 2.11k samplesPerSecond , throughputPerWorker = 1.05k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:31:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86925225 * 1821; EvalErrorPrediction = 0.51784734 * 1821; time = 1.5631s; samplesPerSecond = 1165.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     2.08 seconds since last report (0.18 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 2.35k samplesPerSecond , throughputPerWorker = 1.18k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:33:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90578822 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 1.6650s; samplesPerSecond = 1123.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     2.01 seconds since last report (0.21 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 2.42k samplesPerSecond , throughputPerWorker = 1.21k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:34:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.84027932 * 1870; EvalErrorPrediction = 0.50855615 * 1870; time = 1.5777s; samplesPerSecond = 1185.3
MPI Rank 0: 06/13/2016 22:06:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91625743 * 1899; EvalErrorPrediction = 0.52764613 * 1899; time = 1.3035s; samplesPerSecond = 1456.9
MPI Rank 0: 06/13/2016 22:06:37:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87843574 * 1878; EvalErrorPrediction = 0.52555911 * 1878; time = 1.3483s; samplesPerSecond = 1392.8
MPI Rank 0: 06/13/2016 22:06:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.87550964 * 1221; EvalErrorPrediction = 0.51924652 * 1221; time = 0.7343s; samplesPerSecond = 1662.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     3.62 seconds since last report (0.21 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 1.61k samplesPerSecond , throughputPerWorker = 0.80k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586598 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=10.0326s
MPI Rank 0: 06/13/2016 22:06:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:38: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 0: 06/13/2016 22:06:38: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 06/13/2016 22:06:38: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 0: 06/13/2016 22:06:38: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:38: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:38: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 06/13/2016 22:02:32: -------------------------------------------------------------------
MPI Rank 1: 06/13/2016 22:02:32: Build info: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: 		Built time: Jun 13 2016 21:56:00
MPI Rank 1: 06/13/2016 22:02:32: 		Last modified date: Mon Jun 13 17:05:37 2016
MPI Rank 1: 06/13/2016 22:02:32: 		Build type: release
MPI Rank 1: 06/13/2016 22:02:32: 		Build target: GPU
MPI Rank 1: 06/13/2016 22:02:32: 		With 1bit-SGD: yes
MPI Rank 1: 06/13/2016 22:02:32: 		Math lib: acml
MPI Rank 1: 06/13/2016 22:02:32: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 1: 06/13/2016 22:02:32: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 06/13/2016 22:02:32: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 1: 06/13/2016 22:02:32: 		Build Branch: HEAD
MPI Rank 1: 06/13/2016 22:02:32: 		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
MPI Rank 1: 06/13/2016 22:02:32: 		Built by philly on 373ab38025ce
MPI Rank 1: 06/13/2016 22:02:32: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 06/13/2016 22:02:32: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: Running on localhost at 2016/06/13 22:02:32
MPI Rank 1: 06/13/2016 22:02:32: Command line: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 06/13/2016 22:02:32: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 06/13/2016 22:02:32: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = -1
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=-1
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 1: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 06/13/2016 22:02:32: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 06/13/2016 22:02:32: Commands: speechTrain
MPI Rank 1: 06/13/2016 22:02:32: Precision = "double"
MPI Rank 1: 06/13/2016 22:02:32: Using 12 CPU threads.
MPI Rank 1: 06/13/2016 22:02:32: CNTKModelPath: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn
MPI Rank 1: 06/13/2016 22:02:32: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 06/13/2016 22:02:32: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: ##############################################################################
MPI Rank 1: 06/13/2016 22:02:32: #                                                                            #
MPI Rank 1: 06/13/2016 22:02:32: # Action "train"                                                             #
MPI Rank 1: 06/13/2016 22:02:32: #                                                                            #
MPI Rank 1: 06/13/2016 22:02:32: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using CPU
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: Creating virgin network.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: Created model with 25 nodes on CPU.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: Training criterion node(s):
MPI Rank 1: 06/13/2016 22:02:32: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0x1af5748: {[labels Value[132 x *]] }
MPI Rank 1: 0x1af5918: {[W1 Value[512 x 512]] }
MPI Rank 1: 0x1af5ec8: {[features Value[363 x *]] }
MPI Rank 1: 0x1af8958: {[W2 Value[132 x 512]] }
MPI Rank 1: 0x1afcf38: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0x1b4e358: {[B0 Value[512 x 1]] }
MPI Rank 1: 0x1b85488: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0x1ba7e38: {[B2 Value[132 x 1]] }
MPI Rank 1: 0x1bd0b78: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0x1bd0d38: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0x1bd6448: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0x1bd6608: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0x1bd67c8: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 0x1bf8618: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0x1bf8aa8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0x1bf8c98: {[LogOfPrior Value[132]] }
MPI Rank 1: 0x1c03e58: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0x1c04018: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0x1c041d8: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0x1c04398: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0x1c04558: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0x1c04718: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0x1c05ce8: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0x1c11e58: {[Prior Value[132]] }
MPI Rank 1: 0x1c1c188: {[W0*features Value[512 x *]] }
MPI Rank 1: 0x1c1c398: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0x1c1dd88: {[W0 Value[512 x 363]] }
MPI Rank 1: 0x1c20f28: {[B1 Value[512 x 1]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:32: 	MeanOfFeatures = Mean()
MPI Rank 1: 06/13/2016 22:02:32: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 06/13/2016 22:02:32: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:42: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:43: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:02:43: Starting minibatch loop.
MPI Rank 1: 06/13/2016 22:02:43:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.56947300 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.2464s; samplesPerSecond = 779.1
MPI Rank 1: 06/13/2016 22:02:43:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.43406315 * 192; EvalErrorPrediction = 0.93229167 * 192; time = 0.1774s; samplesPerSecond = 1082.0
MPI Rank 1: 06/13/2016 22:02:43:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.27880063 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.4105s; samplesPerSecond = 467.7
MPI Rank 1: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.08751953 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.1970s; samplesPerSecond = 974.5
MPI Rank 1: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21737559 * 192; EvalErrorPrediction = 0.91145833 * 192; time = 0.1795s; samplesPerSecond = 1069.6
MPI Rank 1: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14259750 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.1733s; samplesPerSecond = 1108.0
MPI Rank 1: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.03221539 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1756s; samplesPerSecond = 1093.1
MPI Rank 1: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.09889450 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.1756s; samplesPerSecond = 1093.5
MPI Rank 1: 06/13/2016 22:02:44:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.89612175 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.1754s; samplesPerSecond = 1094.3
MPI Rank 1: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 3.98897999 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.1750s; samplesPerSecond = 1096.9
MPI Rank 1: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.93572978 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.1696s; samplesPerSecond = 1131.8
MPI Rank 1: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.76284095 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.1691s; samplesPerSecond = 1135.7
MPI Rank 1: 06/13/2016 22:02:45:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.98522385 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.1849s; samplesPerSecond = 1038.2
MPI Rank 1: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66209590 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.4042s; samplesPerSecond = 475.0
MPI Rank 1: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.96368107 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.2046s; samplesPerSecond = 938.6
MPI Rank 1: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76732554 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1921s; samplesPerSecond = 999.4
MPI Rank 1: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69456327 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.1979s; samplesPerSecond = 970.0
MPI Rank 1: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.82975145 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.1969s; samplesPerSecond = 975.0
MPI Rank 1: 06/13/2016 22:02:46:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82370243 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.1711s; samplesPerSecond = 1122.4
MPI Rank 1: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.57625565 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.2157s; samplesPerSecond = 890.0
MPI Rank 1: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.38811493 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.1717s; samplesPerSecond = 1118.1
MPI Rank 1: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.52208661 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.1667s; samplesPerSecond = 1152.1
MPI Rank 1: 06/13/2016 22:02:47:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.80866929 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.1707s; samplesPerSecond = 1125.0
MPI Rank 1: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.54345746 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.3903s; samplesPerSecond = 491.9
MPI Rank 1: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.33936350 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.1813s; samplesPerSecond = 1059.2
MPI Rank 1: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.43672338 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1802s; samplesPerSecond = 1065.5
MPI Rank 1: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.44585129 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.1704s; samplesPerSecond = 1126.8
MPI Rank 1: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.43498669 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.1876s; samplesPerSecond = 1023.2
MPI Rank 1: 06/13/2016 22:02:48:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31632754 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.1767s; samplesPerSecond = 1086.3
MPI Rank 1: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.33946924 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.1977s; samplesPerSecond = 971.2
MPI Rank 1: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.26118575 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.1819s; samplesPerSecond = 1055.4
MPI Rank 1: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.56686839 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1811s; samplesPerSecond = 1060.4
MPI Rank 1: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.36674876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.1752s; samplesPerSecond = 1096.2
MPI Rank 1: 06/13/2016 22:02:49:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.28977127 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.1880s; samplesPerSecond = 1021.5
MPI Rank 1: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.27969909 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.4081s; samplesPerSecond = 470.4
MPI Rank 1: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.12259596 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.2578s; samplesPerSecond = 744.8
MPI Rank 1: 06/13/2016 22:02:50:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.41981056 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.2176s; samplesPerSecond = 882.2
MPI Rank 1: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.38297602 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.1995s; samplesPerSecond = 962.2
MPI Rank 1: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.41994711 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.1920s; samplesPerSecond = 1000.2
MPI Rank 1: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.24732267 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1764s; samplesPerSecond = 1088.2
MPI Rank 1: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.20269035 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.1983s; samplesPerSecond = 968.5
MPI Rank 1: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.15326365 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.1756s; samplesPerSecond = 1093.2
MPI Rank 1: 06/13/2016 22:02:51:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.21802066 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1709s; samplesPerSecond = 1123.4
MPI Rank 1: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.26091070 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.1800s; samplesPerSecond = 1066.7
MPI Rank 1: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.94987113 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.4041s; samplesPerSecond = 475.1
MPI Rank 1: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 3.01829231 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.1760s; samplesPerSecond = 1090.8
MPI Rank 1: 06/13/2016 22:02:52:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.19981302 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.1772s; samplesPerSecond = 1083.5
MPI Rank 1: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.01620054 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.1997s; samplesPerSecond = 961.2
MPI Rank 1: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.07482512 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.1729s; samplesPerSecond = 1110.6
MPI Rank 1: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.95940261 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.1730s; samplesPerSecond = 1109.5
MPI Rank 1: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.18955068 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.1744s; samplesPerSecond = 1100.8
MPI Rank 1: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.80225800 * 192; EvalErrorPrediction = 0.70312500 * 192; time = 0.1786s; samplesPerSecond = 1074.9
MPI Rank 1: 06/13/2016 22:02:53:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.08865913 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.1987s; samplesPerSecond = 966.4
MPI Rank 1: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.87171438 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.1882s; samplesPerSecond = 1019.9
MPI Rank 1: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.90723268 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.1882s; samplesPerSecond = 1020.3
MPI Rank 1: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.96438386 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.3949s; samplesPerSecond = 486.2
MPI Rank 1: 06/13/2016 22:02:54:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.85407675 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.1851s; samplesPerSecond = 1037.5
MPI Rank 1: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.64516293 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1977s; samplesPerSecond = 971.0
MPI Rank 1: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.78779884 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.1926s; samplesPerSecond = 997.1
MPI Rank 1: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77691077 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.2060s; samplesPerSecond = 931.8
MPI Rank 1: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.93466303 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.1952s; samplesPerSecond = 983.8
MPI Rank 1: 06/13/2016 22:02:55:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.79665615 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.1768s; samplesPerSecond = 1086.0
MPI Rank 1: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.79141433 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.1763s; samplesPerSecond = 1089.1
MPI Rank 1: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.85677634 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.1715s; samplesPerSecond = 1119.5
MPI Rank 1: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.60438340 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.1680s; samplesPerSecond = 1143.0
MPI Rank 1: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.67867701 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.1754s; samplesPerSecond = 1094.7
MPI Rank 1: 06/13/2016 22:02:56:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.35420452 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.3899s; samplesPerSecond = 492.4
MPI Rank 1: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67860524 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.1847s; samplesPerSecond = 1039.3
MPI Rank 1: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.74438644 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.1743s; samplesPerSecond = 1101.4
MPI Rank 1: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.61472294 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.1830s; samplesPerSecond = 1049.2
MPI Rank 1: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.56292238 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.1882s; samplesPerSecond = 1020.2
MPI Rank 1: 06/13/2016 22:02:57:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.49905414 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.1835s; samplesPerSecond = 1046.3
MPI Rank 1: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77977518 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.1741s; samplesPerSecond = 1103.0
MPI Rank 1: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.46098943 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1754s; samplesPerSecond = 1094.6
MPI Rank 1: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.53972637 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1749s; samplesPerSecond = 1097.9
MPI Rank 1: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58069409 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.1717s; samplesPerSecond = 1118.5
MPI Rank 1: 06/13/2016 22:02:58:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.42808307 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.1774s; samplesPerSecond = 1082.3
MPI Rank 1: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.51795774 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.4031s; samplesPerSecond = 476.4
MPI Rank 1: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.31017953 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.1807s; samplesPerSecond = 1062.4
MPI Rank 1: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42763250 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.1770s; samplesPerSecond = 1084.6
MPI Rank 1: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.38337452 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1932s; samplesPerSecond = 993.5
MPI Rank 1: 06/13/2016 22:02:59:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.45688385 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.1854s; samplesPerSecond = 1035.6
MPI Rank 1: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.35065649 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1921s; samplesPerSecond = 999.3
MPI Rank 1: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.39950363 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.1738s; samplesPerSecond = 1104.5
MPI Rank 1: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.48031632 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.1769s; samplesPerSecond = 1085.1
MPI Rank 1: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.62124157 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.1743s; samplesPerSecond = 1101.8
MPI Rank 1: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43263192 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.1701s; samplesPerSecond = 1128.5
MPI Rank 1: 06/13/2016 22:03:00:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.13490764 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.1739s; samplesPerSecond = 1104.3
MPI Rank 1: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.52272390 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.3996s; samplesPerSecond = 480.4
MPI Rank 1: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.31215555 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.1878s; samplesPerSecond = 1022.1
MPI Rank 1: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33888920 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1729s; samplesPerSecond = 1110.8
MPI Rank 1: 06/13/2016 22:03:01:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.19318149 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.1727s; samplesPerSecond = 1111.5
MPI Rank 1: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.19368853 * 192; EvalErrorPrediction = 0.55208333 * 192; time = 0.1748s; samplesPerSecond = 1098.5
MPI Rank 1: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.31322736 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.1807s; samplesPerSecond = 1062.6
MPI Rank 1: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21496162 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.1786s; samplesPerSecond = 1074.8
MPI Rank 1: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.38257678 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.1723s; samplesPerSecond = 1114.0
MPI Rank 1: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34785036 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1746s; samplesPerSecond = 1099.6
MPI Rank 1: 06/13/2016 22:03:02:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.20545861 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1672s; samplesPerSecond = 1148.6
MPI Rank 1: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.08751143 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.1730s; samplesPerSecond = 1110.1
MPI Rank 1: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.28302994 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.3832s; samplesPerSecond = 501.0
MPI Rank 1: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.22267854 * 192; EvalErrorPrediction = 0.57291667 * 192; time = 0.1763s; samplesPerSecond = 1088.8
MPI Rank 1: 06/13/2016 22:03:03:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.19855044 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.1763s; samplesPerSecond = 1089.3
MPI Rank 1: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.49612283 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.1723s; samplesPerSecond = 1114.4
MPI Rank 1: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25409762 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.1749s; samplesPerSecond = 1097.8
MPI Rank 1: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13085317 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.1751s; samplesPerSecond = 1096.3
MPI Rank 1: 06/13/2016 22:03:04:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.28902612 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.1745s; samplesPerSecond = 1100.1
MPI Rank 1: 06/13/2016 22:03:04: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.01292779 * 20480; EvalErrorPrediction = 0.72778320 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=21.6571s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:04: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:04: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:03:05:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.08671820 * 249; EvalErrorPrediction = 0.55020080 * 249; time = 0.2463s; samplesPerSecond = 1011.1
MPI Rank 1: 06/13/2016 22:03:05:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.16912508 * 239; EvalErrorPrediction = 0.57740586 * 239; time = 0.4326s; samplesPerSecond = 552.5
MPI Rank 1: 06/13/2016 22:03:05:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.09087687 * 274; EvalErrorPrediction = 0.55109489 * 274; time = 0.2771s; samplesPerSecond = 988.9
MPI Rank 1: 06/13/2016 22:03:06:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.15400834 * 277; EvalErrorPrediction = 0.61371841 * 277; time = 0.2445s; samplesPerSecond = 1132.9
MPI Rank 1: 06/13/2016 22:03:06:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.03468379 * 280; EvalErrorPrediction = 0.54642857 * 280; time = 0.2268s; samplesPerSecond = 1234.7
MPI Rank 1: 06/13/2016 22:03:06:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.12707706 * 283; EvalErrorPrediction = 0.59363958 * 283; time = 0.2295s; samplesPerSecond = 1233.1
MPI Rank 1: 06/13/2016 22:03:06:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.05140796 * 239; EvalErrorPrediction = 0.56903766 * 239; time = 0.2051s; samplesPerSecond = 1165.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.47 seconds since last report (0.30 seconds on comm.); 4331 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 1.75k samplesPerSecond , throughputPerWorker = 0.88k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:07:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.01525982 * 300; EvalErrorPrediction = 0.54666667 * 300; time = 0.6004s; samplesPerSecond = 499.7
MPI Rank 1: 06/13/2016 22:03:07:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.01429833 * 269; EvalErrorPrediction = 0.54646840 * 269; time = 0.4618s; samplesPerSecond = 582.5
MPI Rank 1: 06/13/2016 22:03:08:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.17091946 * 274; EvalErrorPrediction = 0.56569343 * 274; time = 0.2820s; samplesPerSecond = 971.5
MPI Rank 1: 06/13/2016 22:03:08:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.04765590 * 289; EvalErrorPrediction = 0.58823529 * 289; time = 0.2494s; samplesPerSecond = 1158.7
MPI Rank 1: 06/13/2016 22:03:08:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.08198284 * 280; EvalErrorPrediction = 0.62857143 * 280; time = 0.2517s; samplesPerSecond = 1112.4
MPI Rank 1: 06/13/2016 22:03:08:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 2.06262072 * 262; EvalErrorPrediction = 0.53435115 * 262; time = 0.2331s; samplesPerSecond = 1123.7
MPI Rank 1: 06/13/2016 22:03:09:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.08065983 * 256; EvalErrorPrediction = 0.56250000 * 256; time = 0.2324s; samplesPerSecond = 1101.6
MPI Rank 1: 06/13/2016 22:03:09:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.95307697 * 271; EvalErrorPrediction = 0.54243542 * 271; time = 0.2168s; samplesPerSecond = 1250.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.37 seconds since last report (0.17 seconds on comm.); 4232 samples processed by 2 workers (2078 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 1.78k samplesPerSecond , throughputPerWorker = 0.89k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:10:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.05133637 * 266; EvalErrorPrediction = 0.59022556 * 266; time = 0.7332s; samplesPerSecond = 362.8
MPI Rank 1: 06/13/2016 22:03:10:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.16121433 * 292; EvalErrorPrediction = 0.61643836 * 292; time = 0.2355s; samplesPerSecond = 1240.0
MPI Rank 1: 06/13/2016 22:03:10:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.04937835 * 281; EvalErrorPrediction = 0.56939502 * 281; time = 0.2314s; samplesPerSecond = 1214.2
MPI Rank 1: 06/13/2016 22:03:10:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.96573797 * 269; EvalErrorPrediction = 0.50557621 * 269; time = 0.2246s; samplesPerSecond = 1197.5
MPI Rank 1: 06/13/2016 22:03:11:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.96927408 * 293; EvalErrorPrediction = 0.54607509 * 293; time = 0.2403s; samplesPerSecond = 1219.2
MPI Rank 1: 06/13/2016 22:03:11:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.96602409 * 262; EvalErrorPrediction = 0.51526718 * 262; time = 0.2390s; samplesPerSecond = 1096.2
MPI Rank 1: 06/13/2016 22:03:11:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.06123892 * 296; EvalErrorPrediction = 0.55067568 * 296; time = 0.2522s; samplesPerSecond = 1173.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.19 seconds since last report (0.09 seconds on comm.); 4185 samples processed by 2 workers (2060 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 1.91k samplesPerSecond , throughputPerWorker = 0.96k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:12:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.97564922 * 278; EvalErrorPrediction = 0.51079137 * 278; time = 0.4729s; samplesPerSecond = 587.9
MPI Rank 1: 06/13/2016 22:03:12:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.03003870 * 291; EvalErrorPrediction = 0.53951890 * 291; time = 0.4476s; samplesPerSecond = 650.1
MPI Rank 1: 06/13/2016 22:03:12:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.10265344 * 299; EvalErrorPrediction = 0.56187291 * 299; time = 0.2527s; samplesPerSecond = 1183.4
MPI Rank 1: 06/13/2016 22:03:12:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.87884845 * 273; EvalErrorPrediction = 0.51282051 * 273; time = 0.2224s; samplesPerSecond = 1227.6
MPI Rank 1: 06/13/2016 22:03:13:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.91420176 * 190; EvalErrorPrediction = 0.52631579 * 190; time = 0.1539s; samplesPerSecond = 1234.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.56-seconds latency this time; accumulated time on sync point = 0.61 seconds , average latency = 0.15 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     5.87 seconds since last report (4.17 seconds on comm.); 7732 samples processed by 2 workers (1053 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.32k samplesPerSecond , throughputPerWorker = 0.66k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:17: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.00885273 * 20480; EvalErrorPrediction = 0.55078125 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=12.8969s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:18: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:18: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:03:19:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.93776302 * 1133; EvalErrorPrediction = 0.55251545 * 1133; time = 1.1029s; samplesPerSecond = 1027.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.34-seconds latency this time; accumulated time on sync point = 0.34 seconds , average latency = 0.34 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.65 seconds since last report (0.29 seconds on comm.); 4844 samples processed by 2 workers (2261 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 1.83k samplesPerSecond , throughputPerWorker = 0.92k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:20:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.95554942 * 1128; EvalErrorPrediction = 0.53989362 * 1128; time = 1.5408s; samplesPerSecond = 732.1
MPI Rank 1: 06/13/2016 22:03:21:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.86097969 * 1154; EvalErrorPrediction = 0.51039861 * 1154; time = 0.8855s; samplesPerSecond = 1303.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.18 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.85 seconds since last report (0.20 seconds on comm.); 4849 samples processed by 2 workers (2269 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.62k samplesPerSecond , throughputPerWorker = 1.31k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:22:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88714011 * 1115; EvalErrorPrediction = 0.52376682 * 1115; time = 0.9659s; samplesPerSecond = 1154.3
MPI Rank 1: 06/13/2016 22:03:23:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.91141402 * 1130; EvalErrorPrediction = 0.54513274 * 1130; time = 0.9917s; samplesPerSecond = 1139.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.41-seconds latency this time; accumulated time on sync point = 0.77 seconds , average latency = 0.26 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.50 seconds since last report (0.24 seconds on comm.); 4868 samples processed by 2 workers (2273 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 1.95k samplesPerSecond , throughputPerWorker = 0.97k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:25:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.90296336 * 1143; EvalErrorPrediction = 0.53980752 * 1143; time = 1.5092s; samplesPerSecond = 757.4
MPI Rank 1: 06/13/2016 22:03:25:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.93362099 * 758; EvalErrorPrediction = 0.53562005 * 758; time = 0.7151s; samplesPerSecond = 1060.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.05-seconds latency this time; accumulated time on sync point = 1.82 seconds , average latency = 0.46 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.94 seconds since last report (2.12 seconds on comm.); 5919 samples processed by 2 workers (758 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.50k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:28: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.89787888 * 20480; EvalErrorPrediction = 0.52875977 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=10.9443s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:29: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:29: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:03:30:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.84821410 * 1146; EvalErrorPrediction = 0.50872600 * 1146; time = 0.9591s; samplesPerSecond = 1194.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.16 seconds since last report (0.07 seconds on comm.); 4905 samples processed by 2 workers (2324 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.27k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:31:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84074472 * 1178; EvalErrorPrediction = 0.50764007 * 1178; time = 1.1938s; samplesPerSecond = 986.8
MPI Rank 1: 06/13/2016 22:03:32:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89617847 * 1141; EvalErrorPrediction = 0.53198948 * 1141; time = 1.0423s; samplesPerSecond = 1094.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.17 seconds since last report (0.13 seconds on comm.); 4870 samples processed by 2 workers (2333 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.24k samplesPerSecond , throughputPerWorker = 1.12k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:33:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.90122104 * 1192; EvalErrorPrediction = 0.53859060 * 1192; time = 1.1284s; samplesPerSecond = 1056.4
MPI Rank 1: 06/13/2016 22:03:34:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.81959403 * 1192; EvalErrorPrediction = 0.51845638 * 1192; time = 1.0458s; samplesPerSecond = 1139.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.32 seconds since last report (0.21 seconds on comm.); 4916 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.12k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:35:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.83237505 * 1211; EvalErrorPrediction = 0.50949628 * 1211; time = 1.2726s; samplesPerSecond = 951.6
MPI Rank 1: 06/13/2016 22:03:36:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.95195212 * 785; EvalErrorPrediction = 0.54777070 * 785; time = 0.5388s; samplesPerSecond = 1456.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.35-seconds latency this time; accumulated time on sync point = 1.46 seconds , average latency = 0.36 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.92 seconds since last report (1.92 seconds on comm.); 5789 samples processed by 2 workers (785 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.48k samplesPerSecond , throughputPerWorker = 0.74k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:39: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.84940336 * 20480; EvalErrorPrediction = 0.51445312 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=10.5692s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:39: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:03:40:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79235548 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.7934s; samplesPerSecond = 1481.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.16 seconds since last report (0.15 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.28k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:41:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84602168 * 1251; EvalErrorPrediction = 0.52358114 * 1251; time = 1.3612s; samplesPerSecond = 919.1
MPI Rank 1: 06/13/2016 22:03:42:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79460940 * 1201; EvalErrorPrediction = 0.50124896 * 1201; time = 0.7962s; samplesPerSecond = 1508.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.21-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.11 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.15 seconds since last report (0.06 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.28k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:44:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86032081 * 1202; EvalErrorPrediction = 0.50915141 * 1202; time = 1.3497s; samplesPerSecond = 890.6
MPI Rank 1: 06/13/2016 22:03:44:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84149612 * 1173; EvalErrorPrediction = 0.51577153 * 1173; time = 0.7472s; samplesPerSecond = 1569.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.10 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.96 seconds since last report (0.05 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.48k samplesPerSecond , throughputPerWorker = 1.24k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:45:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87763945 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 1.2114s; samplesPerSecond = 985.6
MPI Rank 1: 06/13/2016 22:03:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79221618 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.5895s; samplesPerSecond = 1402.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.17-seconds latency this time; accumulated time on sync point = 1.48 seconds , average latency = 0.37 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.85 seconds since last report (1.91 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.51k samplesPerSecond , throughputPerWorker = 0.76k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85300231 * 20480; EvalErrorPrediction = 0.51425781 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=10.1173s
MPI Rank 1: 06/13/2016 22:03:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:03:49: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:50: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:03:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:03:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79242721 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.7823s; samplesPerSecond = 1502.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.15 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.00 seconds since last report (0.07 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.46k samplesPerSecond , throughputPerWorker = 1.23k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:52:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84627836 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.2107s; samplesPerSecond = 1033.3
MPI Rank 1: 06/13/2016 22:03:52:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79565103 * 1201; EvalErrorPrediction = 0.50707744 * 1201; time = 0.8197s; samplesPerSecond = 1465.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.26-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.09 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:54:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86102857 * 1202; EvalErrorPrediction = 0.50998336 * 1202; time = 1.3880s; samplesPerSecond = 866.0
MPI Rank 1: 06/13/2016 22:03:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84398555 * 1173; EvalErrorPrediction = 0.51832907 * 1173; time = 0.7449s; samplesPerSecond = 1574.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.25-seconds latency this time; accumulated time on sync point = 0.66 seconds , average latency = 0.22 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.23 seconds since last report (0.11 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.18k samplesPerSecond , throughputPerWorker = 1.09k samplesPerSecond
MPI Rank 1: 06/13/2016 22:03:56:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87898732 * 1194; EvalErrorPrediction = 0.52512563 * 1194; time = 1.4919s; samplesPerSecond = 800.3
MPI Rank 1: 06/13/2016 22:03:56:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79405711 * 827; EvalErrorPrediction = 0.51511487 * 827; time = 0.5398s; samplesPerSecond = 1532.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.39-seconds latency this time; accumulated time on sync point = 2.05 seconds , average latency = 0.51 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.89 seconds since last report (1.89 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.50k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:00: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85426644 * 20480; EvalErrorPrediction = 0.51508789 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=10.3416s
MPI Rank 1: 06/13/2016 22:04:00: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:00: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:00: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:00: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:04:01:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79246348 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 1.0430s; samplesPerSecond = 1126.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.20 seconds since last report (0.22 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.23k samplesPerSecond , throughputPerWorker = 1.12k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:02:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84641688 * 1251; EvalErrorPrediction = 0.52358114 * 1251; time = 1.1540s; samplesPerSecond = 1084.0
MPI Rank 1: 06/13/2016 22:04:03:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79624499 * 1201; EvalErrorPrediction = 0.50707744 * 1201; time = 1.0356s; samplesPerSecond = 1159.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.14 seconds since last report (0.16 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.28k samplesPerSecond , throughputPerWorker = 1.14k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:04:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86139356 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.1031s; samplesPerSecond = 1089.6
MPI Rank 1: 06/13/2016 22:04:05:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84547786 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 1.0836s; samplesPerSecond = 1082.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.19 seconds since last report (0.14 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:07:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87969458 * 1194; EvalErrorPrediction = 0.52596315 * 1194; time = 1.1102s; samplesPerSecond = 1075.5
MPI Rank 1: 06/13/2016 22:04:07:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79494286 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.8789s; samplesPerSecond = 940.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.75-seconds latency this time; accumulated time on sync point = 0.80 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.56 seconds since last report (1.87 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.64k samplesPerSecond , throughputPerWorker = 0.82k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:10: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85499692 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=10.0887s
MPI Rank 1: 06/13/2016 22:04:10: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:10: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:10: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:10: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:04:11:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79248172 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 1.0883s; samplesPerSecond = 1079.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.20 seconds since last report (0.19 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.23k samplesPerSecond , throughputPerWorker = 1.12k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:13:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84648880 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.1023s; samplesPerSecond = 1134.9
MPI Rank 1: 06/13/2016 22:04:14:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79656264 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.9970s; samplesPerSecond = 1204.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.02 seconds since last report (0.07 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.42k samplesPerSecond , throughputPerWorker = 1.21k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:15:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86158303 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 1.0035s; samplesPerSecond = 1197.8
MPI Rank 1: 06/13/2016 22:04:15:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84631070 * 1173; EvalErrorPrediction = 0.51406650 * 1173; time = 0.7715s; samplesPerSecond = 1520.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.02 seconds since last report (0.20 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.41k samplesPerSecond , throughputPerWorker = 1.20k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:17:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88007633 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 1.2434s; samplesPerSecond = 960.2
MPI Rank 1: 06/13/2016 22:04:17:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79541620 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.5054s; samplesPerSecond = 1636.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.34-seconds latency this time; accumulated time on sync point = 1.37 seconds , average latency = 0.34 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.76 seconds since last report (1.84 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.55k samplesPerSecond , throughputPerWorker = 0.77k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:20: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85540764 * 20480; EvalErrorPrediction = 0.51547852 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=9.99959s
MPI Rank 1: 06/13/2016 22:04:20: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:20: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:21: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:21: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:04:21:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249087 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8994s; samplesPerSecond = 1306.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.20-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.32 seconds since last report (0.17 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.12k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:23:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84652543 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.4178s; samplesPerSecond = 882.3
MPI Rank 1: 06/13/2016 22:04:24:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79672696 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.8150s; samplesPerSecond = 1473.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.14-seconds latency this time; accumulated time on sync point = 0.34 seconds , average latency = 0.17 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.24 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:25:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86168018 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 1.3940s; samplesPerSecond = 862.3
MPI Rank 1: 06/13/2016 22:04:26:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84675286 * 1173; EvalErrorPrediction = 0.51406650 * 1173; time = 0.8617s; samplesPerSecond = 1361.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.34 seconds , average latency = 0.11 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.11 seconds since last report (0.19 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.30k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:27:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88027824 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 1.2477s; samplesPerSecond = 957.0
MPI Rank 1: 06/13/2016 22:04:28:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79567029 * 827; EvalErrorPrediction = 0.50906892 * 827; time = 0.5392s; samplesPerSecond = 1533.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.40-seconds latency this time; accumulated time on sync point = 1.74 seconds , average latency = 0.43 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     4.00 seconds since last report (1.84 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.46k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:31: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85562974 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=10.6376s
MPI Rank 1: 06/13/2016 22:04:31: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:31: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:31: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:04:32:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249545 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8694s; samplesPerSecond = 1351.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.13 seconds since last report (0.25 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.31k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:33:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84654392 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.2524s; samplesPerSecond = 998.9
MPI Rank 1: 06/13/2016 22:04:34:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79681054 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.7975s; samplesPerSecond = 1506.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.22 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:36:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86172946 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 1.4081s; samplesPerSecond = 853.6
MPI Rank 1: 06/13/2016 22:04:36:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84698096 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.8482s; samplesPerSecond = 1382.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.32-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.11 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.18 seconds since last report (0.19 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.22k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:38:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88038258 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 1.3347s; samplesPerSecond = 894.6
MPI Rank 1: 06/13/2016 22:04:38:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79580336 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.5719s; samplesPerSecond = 1446.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.36-seconds latency this time; accumulated time on sync point = 1.68 seconds , average latency = 0.42 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     4.01 seconds since last report (1.96 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.45k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:42: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85574594 * 20480; EvalErrorPrediction = 0.51606445 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=10.529s
MPI Rank 1: 06/13/2016 22:04:42: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:42: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:42: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:04:43:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249774 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8604s; samplesPerSecond = 1365.7
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.31-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.31 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.32 seconds since last report (0.09 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.12k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:44:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84655321 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.4489s; samplesPerSecond = 863.4
MPI Rank 1: 06/13/2016 22:04:45:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79685269 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.7681s; samplesPerSecond = 1563.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.27-seconds latency this time; accumulated time on sync point = 0.58 seconds , average latency = 0.29 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.19 seconds since last report (0.14 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.23k samplesPerSecond , throughputPerWorker = 1.12k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:47:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86175428 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 1.4218s; samplesPerSecond = 845.4
MPI Rank 1: 06/13/2016 22:04:47:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84709684 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.8219s; samplesPerSecond = 1427.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.36-seconds latency this time; accumulated time on sync point = 0.94 seconds , average latency = 0.31 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.19 seconds since last report (0.08 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88043569 * 1194; EvalErrorPrediction = 0.52931323 * 1194; time = 1.3718s; samplesPerSecond = 870.4
MPI Rank 1: 06/13/2016 22:04:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79587164 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.5670s; samplesPerSecond = 1458.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.26-seconds latency this time; accumulated time on sync point = 2.20 seconds , average latency = 0.55 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.88 seconds since last report (1.96 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.50k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:53: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85580548 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=10.5836s
MPI Rank 1: 06/13/2016 22:04:53: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:04:53: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:53: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:04:53: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:04:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249889 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.9361s; samplesPerSecond = 1255.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.09 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.02 seconds since last report (0.09 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.44k samplesPerSecond , throughputPerWorker = 1.22k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:55:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84655786 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.0699s; samplesPerSecond = 1169.3
MPI Rank 1: 06/13/2016 22:04:56:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79687385 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 1.0659s; samplesPerSecond = 1126.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.23 seconds since last report (0.25 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.19k samplesPerSecond , throughputPerWorker = 1.10k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:57:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86176674 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.1597s; samplesPerSecond = 1036.4
MPI Rank 1: 06/13/2016 22:04:58:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84715525 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.9846s; samplesPerSecond = 1191.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.18 seconds since last report (0.35 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.22k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:04:59:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88046248 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.1989s; samplesPerSecond = 995.9
MPI Rank 1: 06/13/2016 22:05:00:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79590625 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.7665s; samplesPerSecond = 1078.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.96-seconds latency this time; accumulated time on sync point = 1.04 seconds , average latency = 0.26 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.69 seconds since last report (1.87 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.58k samplesPerSecond , throughputPerWorker = 0.79k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:03: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85583563 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=10.1176s
MPI Rank 1: 06/13/2016 22:05:03: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:03: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:03: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:05:04:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249946 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 1.0647s; samplesPerSecond = 1103.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.13 seconds since last report (0.25 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.31k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:05:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656019 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.0631s; samplesPerSecond = 1176.8
MPI Rank 1: 06/13/2016 22:05:06:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79688446 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 1.1092s; samplesPerSecond = 1082.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.09 seconds since last report (0.15 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.34k samplesPerSecond , throughputPerWorker = 1.17k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:07:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177299 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.9806s; samplesPerSecond = 1225.8
MPI Rank 1: 06/13/2016 22:05:08:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84718457 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.7623s; samplesPerSecond = 1538.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.08-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.11 seconds since last report (0.20 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.30k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:09:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88047594 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.3474s; samplesPerSecond = 886.2
MPI Rank 1: 06/13/2016 22:05:10:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79592368 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.5891s; samplesPerSecond = 1403.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.30-seconds latency this time; accumulated time on sync point = 1.38 seconds , average latency = 0.35 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     4.00 seconds since last report (2.00 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.45k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:13: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585080 * 20480; EvalErrorPrediction = 0.51591797 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=10.3353s
MPI Rank 1: 06/13/2016 22:05:13: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:14: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:14: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:05:14:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249975 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8179s; samplesPerSecond = 1436.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.11 seconds since last report (0.17 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:16:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656136 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.2818s; samplesPerSecond = 976.0
MPI Rank 1: 06/13/2016 22:05:17:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79688976 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.7630s; samplesPerSecond = 1574.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.10 seconds since last report (0.16 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:18:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177611 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.3366s; samplesPerSecond = 899.3
MPI Rank 1: 06/13/2016 22:05:19:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84719926 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.8195s; samplesPerSecond = 1431.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.01 seconds since last report (0.09 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.42k samplesPerSecond , throughputPerWorker = 1.21k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:20:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048269 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.1890s; samplesPerSecond = 1004.2
MPI Rank 1: 06/13/2016 22:05:20:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593242 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.5602s; samplesPerSecond = 1476.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.42-seconds latency this time; accumulated time on sync point = 1.52 seconds , average latency = 0.38 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     4.10 seconds since last report (1.79 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.42k samplesPerSecond , throughputPerWorker = 0.71k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:24: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85585841 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=10.3186s
MPI Rank 1: 06/13/2016 22:05:24: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:24: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:24: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:24: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:05:25:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249989 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8782s; samplesPerSecond = 1338.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.11 seconds since last report (0.17 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:26:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656194 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.2292s; samplesPerSecond = 1017.7
MPI Rank 1: 06/13/2016 22:05:27:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689242 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.7781s; samplesPerSecond = 1543.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.37-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.06 seconds since last report (0.08 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.37k samplesPerSecond , throughputPerWorker = 1.19k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:28:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177767 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.2815s; samplesPerSecond = 938.0
MPI Rank 1: 06/13/2016 22:05:29:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84720661 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.7992s; samplesPerSecond = 1467.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.21-seconds latency this time; accumulated time on sync point = 0.61 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.25 seconds since last report (0.11 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.16k samplesPerSecond , throughputPerWorker = 1.08k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:31:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048607 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.4529s; samplesPerSecond = 821.8
MPI Rank 1: 06/13/2016 22:05:31:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593680 * 827; EvalErrorPrediction = 0.51148730 * 827; time = 0.5257s; samplesPerSecond = 1573.1
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.43-seconds latency this time; accumulated time on sync point = 2.04 seconds , average latency = 0.51 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     4.11 seconds since last report (2.10 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.42k samplesPerSecond , throughputPerWorker = 0.71k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:35: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586222 * 20480; EvalErrorPrediction = 0.51582031 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=10.5284s
MPI Rank 1: 06/13/2016 22:05:35: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:35: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:35: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:05:36:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79249996 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8854s; samplesPerSecond = 1327.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.19-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.19 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.31 seconds since last report (0.13 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.13k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:37:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656223 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.4126s; samplesPerSecond = 885.6
MPI Rank 1: 06/13/2016 22:05:38:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689375 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.7849s; samplesPerSecond = 1530.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.20-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.10 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.11k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:39:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177845 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.4225s; samplesPerSecond = 845.0
MPI Rank 1: 06/13/2016 22:05:40:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721029 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.7638s; samplesPerSecond = 1535.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.32-seconds latency this time; accumulated time on sync point = 0.71 seconds , average latency = 0.24 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.22 seconds since last report (0.11 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.19k samplesPerSecond , throughputPerWorker = 1.10k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:42:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048776 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.4513s; samplesPerSecond = 822.7
MPI Rank 1: 06/13/2016 22:05:42:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79593899 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.5818s; samplesPerSecond = 1421.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.33-seconds latency this time; accumulated time on sync point = 2.04 seconds , average latency = 0.51 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.98 seconds since last report (1.98 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.46k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586413 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=10.7175s
MPI Rank 1: 06/13/2016 22:05:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:46: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:46: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:05:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250000 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8868s; samplesPerSecond = 1325.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.20-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.20 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.42 seconds since last report (0.10 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.03k samplesPerSecond , throughputPerWorker = 1.02k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:48:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656238 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.5185s; samplesPerSecond = 823.8
MPI Rank 1: 06/13/2016 22:05:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689441 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.8080s; samplesPerSecond = 1486.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.29-seconds latency this time; accumulated time on sync point = 0.49 seconds , average latency = 0.24 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.21 seconds since last report (0.10 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.21k samplesPerSecond , throughputPerWorker = 1.10k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:50:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177885 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.4038s; samplesPerSecond = 856.2
MPI Rank 1: 06/13/2016 22:05:51:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721213 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.8905s; samplesPerSecond = 1317.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.30-seconds latency this time; accumulated time on sync point = 0.79 seconds , average latency = 0.26 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.30 seconds since last report (0.15 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.11k samplesPerSecond , throughputPerWorker = 1.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:53:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048860 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.4071s; samplesPerSecond = 848.6
MPI Rank 1: 06/13/2016 22:05:53:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594009 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.5424s; samplesPerSecond = 1524.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.34-seconds latency this time; accumulated time on sync point = 2.13 seconds , average latency = 0.53 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.89 seconds since last report (1.91 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.50k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586508 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=10.8164s
MPI Rank 1: 06/13/2016 22:05:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:05:57: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:57: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:05:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:05:58:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250001 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8954s; samplesPerSecond = 1312.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.00 seconds since last report (0.15 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.46k samplesPerSecond , throughputPerWorker = 1.23k samplesPerSecond
MPI Rank 1: 06/13/2016 22:05:59:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656245 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.0921s; samplesPerSecond = 1145.5
MPI Rank 1: 06/13/2016 22:06:00:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689474 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 1.0059s; samplesPerSecond = 1194.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.23 seconds since last report (0.23 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.19k samplesPerSecond , throughputPerWorker = 1.09k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:01:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177904 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.2254s; samplesPerSecond = 980.9
MPI Rank 1: 06/13/2016 22:06:02:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721305 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 1.0170s; samplesPerSecond = 1153.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.09 seconds since last report (0.20 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.16k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:03:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048902 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.0684s; samplesPerSecond = 1117.5
MPI Rank 1: 06/13/2016 22:06:04:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594064 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.8055s; samplesPerSecond = 1026.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.92-seconds latency this time; accumulated time on sync point = 0.97 seconds , average latency = 0.24 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.72 seconds since last report (1.89 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.57k samplesPerSecond , throughputPerWorker = 0.78k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:07: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586556 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=10.0336s
MPI Rank 1: 06/13/2016 22:06:07: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:07: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:07: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:07: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:08:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250002 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.9990s; samplesPerSecond = 1176.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.11 seconds since last report (0.20 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.17k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:09:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656249 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.1038s; samplesPerSecond = 1133.4
MPI Rank 1: 06/13/2016 22:06:10:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689491 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.9944s; samplesPerSecond = 1207.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.13-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.07 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.12 seconds since last report (0.16 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.30k samplesPerSecond , throughputPerWorker = 1.15k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:11:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177914 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.1292s; samplesPerSecond = 1064.5
MPI Rank 1: 06/13/2016 22:06:12:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721351 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 1.0852s; samplesPerSecond = 1080.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.06 seconds since last report (0.10 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.35k samplesPerSecond , throughputPerWorker = 1.18k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:13:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048924 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.9766s; samplesPerSecond = 1222.6
MPI Rank 1: 06/13/2016 22:06:14:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594091 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.5546s; samplesPerSecond = 1491.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.38-seconds latency this time; accumulated time on sync point = 1.52 seconds , average latency = 0.38 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.86 seconds since last report (1.82 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.51k samplesPerSecond , throughputPerWorker = 0.75k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:17: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586580 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=10.1561s
MPI Rank 1: 06/13/2016 22:06:17: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:17: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:17: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:18:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250003 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8885s; samplesPerSecond = 1322.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.30 seconds since last report (0.20 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.14k samplesPerSecond , throughputPerWorker = 1.07k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:20:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656251 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.4069s; samplesPerSecond = 889.2
MPI Rank 1: 06/13/2016 22:06:21:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689499 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.8684s; samplesPerSecond = 1382.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.04 seconds since last report (0.11 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.39k samplesPerSecond , throughputPerWorker = 1.19k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:22:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177919 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.1752s; samplesPerSecond = 1022.8
MPI Rank 1: 06/13/2016 22:06:23:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721374 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.8428s; samplesPerSecond = 1391.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.08 seconds since last report (0.16 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.33k samplesPerSecond , throughputPerWorker = 1.17k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:24:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048934 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.2388s; samplesPerSecond = 963.8
MPI Rank 1: 06/13/2016 22:06:24:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594105 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.5166s; samplesPerSecond = 1600.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.36-seconds latency this time; accumulated time on sync point = 1.38 seconds , average latency = 0.34 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     4.00 seconds since last report (1.89 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.46k samplesPerSecond , throughputPerWorker = 0.73k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:28: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586592 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=10.4276s
MPI Rank 1: 06/13/2016 22:06:28: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:28: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:28: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:28: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:29:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.79250003 * 1175; EvalErrorPrediction = 0.49957447 * 1175; time = 0.8480s; samplesPerSecond = 1385.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.13-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.13 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     2.33 seconds since last report (0.21 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 2.11k samplesPerSecond , throughputPerWorker = 1.05k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:30:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.84656251 * 1251; EvalErrorPrediction = 0.52278177 * 1251; time = 1.4789s; samplesPerSecond = 845.9
MPI Rank 1: 06/13/2016 22:06:31:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.79689503 * 1201; EvalErrorPrediction = 0.50624480 * 1201; time = 0.8167s; samplesPerSecond = 1470.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.11-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.12 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     2.08 seconds since last report (0.04 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 2.35k samplesPerSecond , throughputPerWorker = 1.18k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:32:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.86177921 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 1.2595s; samplesPerSecond = 954.3
MPI Rank 1: 06/13/2016 22:06:33:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84721386 * 1173; EvalErrorPrediction = 0.51491901 * 1173; time = 0.7955s; samplesPerSecond = 1474.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.15-seconds latency this time; accumulated time on sync point = 0.39 seconds , average latency = 0.13 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     2.01 seconds since last report (0.07 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 2.42k samplesPerSecond , throughputPerWorker = 1.21k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:34:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88048939 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 1.2096s; samplesPerSecond = 987.1
MPI Rank 1: 06/13/2016 22:06:35:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79594112 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.5243s; samplesPerSecond = 1577.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 1.36-seconds latency this time; accumulated time on sync point = 1.75 seconds , average latency = 0.44 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     3.62 seconds since last report (1.62 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 1.61k samplesPerSecond , throughputPerWorker = 0.80k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:38: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.85586598 * 20480; EvalErrorPrediction = 0.51577148 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=10.0326s
MPI Rank 1: 06/13/2016 22:06:38: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_cpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:38: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 1: 06/13/2016 22:06:38: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 1: 06/13/2016 22:06:38: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:38: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:38: __COMPLETED__
MPI Rank 1: ~MPIWrapper
