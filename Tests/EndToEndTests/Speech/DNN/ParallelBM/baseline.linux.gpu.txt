=== Running mpiexec -n 2 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/.. OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu DeviceId=0 timestamping=true numCPUThreads=12 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jun 13 2016 21:56:00
		Last modified date: Mon Jun 13 17:05:37 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
		Built by philly on 373ab38025ce
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Jun 13 2016 21:56:00
		Last modified date: Mon Jun 13 17:05:37 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
		Built by philly on 373ab38025ce
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
06/13/2016 22:06:39: Redirecting stderr to file /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr_speechTrain.logrank0
06/13/2016 22:06:39: Redirecting stderr to file /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr_speechTrain.logrank1
MPI Rank 0: 06/13/2016 22:06:39: -------------------------------------------------------------------
MPI Rank 0: 06/13/2016 22:06:39: Build info: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: 		Built time: Jun 13 2016 21:56:00
MPI Rank 0: 06/13/2016 22:06:39: 		Last modified date: Mon Jun 13 17:05:37 2016
MPI Rank 0: 06/13/2016 22:06:39: 		Build type: release
MPI Rank 0: 06/13/2016 22:06:39: 		Build target: GPU
MPI Rank 0: 06/13/2016 22:06:39: 		With 1bit-SGD: yes
MPI Rank 0: 06/13/2016 22:06:39: 		Math lib: acml
MPI Rank 0: 06/13/2016 22:06:39: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 0: 06/13/2016 22:06:39: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 0: 06/13/2016 22:06:39: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 0: 06/13/2016 22:06:39: 		Build Branch: HEAD
MPI Rank 0: 06/13/2016 22:06:39: 		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
MPI Rank 0: 06/13/2016 22:06:39: 		Built by philly on 373ab38025ce
MPI Rank 0: 06/13/2016 22:06:39: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 0: 06/13/2016 22:06:39: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: Running on localhost at 2016/06/13 22:06:39
MPI Rank 0: 06/13/2016 22:06:39: Command line: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 06/13/2016 22:06:39: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 06/13/2016 22:06:39: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = 0
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=12
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=0
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 0: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 06/13/2016 22:06:39: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 06/13/2016 22:06:39: Commands: speechTrain
MPI Rank 0: 06/13/2016 22:06:39: Precision = "double"
MPI Rank 0: 06/13/2016 22:06:39: Using 12 CPU threads.
MPI Rank 0: 06/13/2016 22:06:39: CNTKModelPath: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn
MPI Rank 0: 06/13/2016 22:06:39: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 06/13/2016 22:06:39: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: ##############################################################################
MPI Rank 0: 06/13/2016 22:06:39: #                                                                            #
MPI Rank 0: 06/13/2016 22:06:39: # Action "train"                                                             #
MPI Rank 0: 06/13/2016 22:06:39: #                                                                            #
MPI Rank 0: 06/13/2016 22:06:39: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using GPU 0
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: Creating virgin network.
MPI Rank 0: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: Created model with 25 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: Training criterion node(s):
MPI Rank 0: 06/13/2016 22:06:39: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 0x2310908: {[features Value[363 x *]] }
MPI Rank 0: 0x242aa68: {[B0 Value[512 x 1]] }
MPI Rank 0: 0x2832408: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 0x28328d8: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 0x2833588: {[W0 Value[512 x 363]] }
MPI Rank 0: 0x31931f8: {[W1 Value[512 x 512]] }
MPI Rank 0: 0x3193fc8: {[B1 Value[512 x 1]] }
MPI Rank 0: 0x3195168: {[W2 Value[132 x 512]] }
MPI Rank 0: 0x3195e18: {[B2 Value[132 x 1]] }
MPI Rank 0: 0x3196c48: {[labels Value[132 x *]] }
MPI Rank 0: 0x3197ea8: {[Prior Value[132]] }
MPI Rank 0: 0x319d748: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 0x319da48: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 0x319dc08: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 0x319e098: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 0x319e208: {[LogOfPrior Value[132]] }
MPI Rank 0: 0x347eed8: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 0x347f698: {[W0*features Value[512 x *]] }
MPI Rank 0: 0x347f8a8: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 0x347fa08: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 0x347fb68: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 0x347fd28: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 0x347fee8: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 0x34800a8: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 0x3480c08: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 0x3480dc8: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 0x3480f88: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 0x3481148: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:39: 	MeanOfFeatures = Mean()
MPI Rank 0: 06/13/2016 22:06:39: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 06/13/2016 22:06:39: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:41: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:42: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:42: Starting minibatch loop.
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.57947979 * 192; EvalErrorPrediction = 0.96354167 * 192; time = 0.0205s; samplesPerSecond = 9346.7
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.45832105 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0194s; samplesPerSecond = 9902.5
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.29176856 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0194s; samplesPerSecond = 9906.6
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.15840784 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0194s; samplesPerSecond = 9898.9
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21435783 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0194s; samplesPerSecond = 9910.2
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14020622 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0194s; samplesPerSecond = 9908.1
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.04069876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0194s; samplesPerSecond = 9908.1
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.04991414 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0194s; samplesPerSecond = 9913.8
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.88626656 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0194s; samplesPerSecond = 9908.7
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00467833 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0191s; samplesPerSecond = 10074.0
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.94077029 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0188s; samplesPerSecond = 10233.5
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.78326806 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.94698521 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66011602 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0188s; samplesPerSecond = 10235.1
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.98797978 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76297655 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69909670 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0187s; samplesPerSecond = 10254.8
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.83747989 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82672791 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0187s; samplesPerSecond = 10244.9
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.56520696 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0187s; samplesPerSecond = 10244.9
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.40098566 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0187s; samplesPerSecond = 10243.3
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.50668803 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0187s; samplesPerSecond = 10245.5
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.82314351 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0187s; samplesPerSecond = 10240.0
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.51780740 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0188s; samplesPerSecond = 10237.8
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.32189431 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.42533640 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0187s; samplesPerSecond = 10246.0
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.42902377 * 192; EvalErrorPrediction = 0.81770833 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.42017745 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0188s; samplesPerSecond = 10234.0
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.30346679 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.31343403 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.22956709 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0188s; samplesPerSecond = 10230.2
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.54894307 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0187s; samplesPerSecond = 10248.2
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.33751842 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0188s; samplesPerSecond = 10234.5
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.25951347 * 192; EvalErrorPrediction = 0.80729167 * 192; time = 0.0187s; samplesPerSecond = 10241.6
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.24586699 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.06725828 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.39973653 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0188s; samplesPerSecond = 10235.6
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.34798378 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0187s; samplesPerSecond = 10250.4
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.38133778 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0187s; samplesPerSecond = 10246.6
MPI Rank 0: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.19074044 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0187s; samplesPerSecond = 10247.1
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.14306337 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0187s; samplesPerSecond = 10244.4
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.10036521 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0187s; samplesPerSecond = 10241.6
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.17040971 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0187s; samplesPerSecond = 10245.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.19888148 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.91247084 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0187s; samplesPerSecond = 10252.0
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 2.96972038 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.15632232 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 2.98075176 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03076846 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0188s; samplesPerSecond = 10236.7
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91480722 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.16155322 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0187s; samplesPerSecond = 10243.3
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.76157172 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.06347679 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0187s; samplesPerSecond = 10244.4
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.84053583 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0187s; samplesPerSecond = 10243.3
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.87795860 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0187s; samplesPerSecond = 10240.0
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.92198252 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.81241750 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.62682593 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.75758644 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0187s; samplesPerSecond = 10259.2
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74763961 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.90905834 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.76756973 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0188s; samplesPerSecond = 10236.7
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.76599748 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.83171014 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0187s; samplesPerSecond = 10249.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.59593490 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0188s; samplesPerSecond = 10238.9
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.64965270 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0188s; samplesPerSecond = 10238.9
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.33442260 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0187s; samplesPerSecond = 10260.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67195863 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0188s; samplesPerSecond = 10232.9
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.72367540 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0188s; samplesPerSecond = 10231.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59572337 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0188s; samplesPerSecond = 10226.9
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.53202795 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0188s; samplesPerSecond = 10225.3
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.50336278 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77076318 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0187s; samplesPerSecond = 10244.4
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.45308521 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0187s; samplesPerSecond = 10245.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.54598920 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0187s; samplesPerSecond = 10248.7
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58558089 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0188s; samplesPerSecond = 10233.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.41075660 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.52012028 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0188s; samplesPerSecond = 10220.9
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.30719546 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0187s; samplesPerSecond = 10240.0
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42100657 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0188s; samplesPerSecond = 10231.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.39894546 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0188s; samplesPerSecond = 10237.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.44970724 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0188s; samplesPerSecond = 10234.0
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.33418475 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.37997032 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.47517097 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.60900086 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43300244 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0187s; samplesPerSecond = 10249.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.12996515 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.51181403 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0188s; samplesPerSecond = 10230.2
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.29330120 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0188s; samplesPerSecond = 10225.8
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33352411 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0187s; samplesPerSecond = 10241.6
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.17790026 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0187s; samplesPerSecond = 10242.7
MPI Rank 0: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.18521155 * 192; EvalErrorPrediction = 0.54166667 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.29833071 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0187s; samplesPerSecond = 10242.2
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21483298 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0187s; samplesPerSecond = 10246.0
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.37232627 * 192; EvalErrorPrediction = 0.61979167 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34396058 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0188s; samplesPerSecond = 10238.9
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.18334302 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0188s; samplesPerSecond = 10220.4
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.07753101 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26265833 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0188s; samplesPerSecond = 10234.5
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.21675905 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0187s; samplesPerSecond = 10241.6
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.18990385 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0188s; samplesPerSecond = 10217.1
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.48513433 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0188s; samplesPerSecond = 10234.0
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25336704 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13039619 * 192; EvalErrorPrediction = 0.55729167 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.27299748 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 0: 06/13/2016 22:06:44: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 2.99723568 * 20480; EvalErrorPrediction = 0.72426758 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=2.0149s
MPI Rank 0: 06/13/2016 22:06:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:44: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.25388628 * 519; EvalErrorPrediction = 0.63391137 * 519; time = 0.0348s; samplesPerSecond = 14902.2
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.01477571 * 529; EvalErrorPrediction = 0.53686200 * 529; time = 0.0310s; samplesPerSecond = 17046.4
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.03638222 * 494; EvalErrorPrediction = 0.55060729 * 494; time = 0.0245s; samplesPerSecond = 20196.2
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 1.97591869 * 491; EvalErrorPrediction = 0.54378819 * 491; time = 0.0260s; samplesPerSecond = 18849.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.17 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2190 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 25.81k samplesPerSecond , throughputPerWorker = 12.90k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.12486189 * 488; EvalErrorPrediction = 0.53483607 * 488; time = 0.0690s; samplesPerSecond = 7074.7
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 1.99682461 * 485; EvalErrorPrediction = 0.55670103 * 485; time = 0.0266s; samplesPerSecond = 18206.4
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 1.98681980 * 529; EvalErrorPrediction = 0.55576560 * 529; time = 0.0364s; samplesPerSecond = 14520.6
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 1.94891082 * 468; EvalErrorPrediction = 0.55341880 * 468; time = 0.0261s; samplesPerSecond = 17955.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.15 seconds since last report (0.01 seconds on comm.); 4232 samples processed by 2 workers (2154 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 27.31k samplesPerSecond , throughputPerWorker = 13.65k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 1.99768818 * 499; EvalErrorPrediction = 0.53507014 * 499; time = 0.0547s; samplesPerSecond = 9122.7
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.17844696 * 494; EvalErrorPrediction = 0.57692308 * 494; time = 0.0267s; samplesPerSecond = 18526.9
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 1.96255558 * 479; EvalErrorPrediction = 0.53027140 * 479; time = 0.0272s; samplesPerSecond = 17616.1
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 1.99612126 * 488; EvalErrorPrediction = 0.54303279 * 488; time = 0.0273s; samplesPerSecond = 17855.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2125 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 27.75k samplesPerSecond , throughputPerWorker = 13.87k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 1.89743886 * 506; EvalErrorPrediction = 0.52766798 * 506; time = 0.0597s; samplesPerSecond = 8474.4
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 1.85536959 * 512; EvalErrorPrediction = 0.52929688 * 512; time = 0.0262s; samplesPerSecond = 19507.0
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.92579626 * 497; EvalErrorPrediction = 0.49496982 * 497; time = 0.0230s; samplesPerSecond = 21633.2
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 1.85664750 * 502; EvalErrorPrediction = 0.52988048 * 502; time = 0.0275s; samplesPerSecond = 18280.5
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.05622489 * 476; EvalErrorPrediction = 0.56932773 * 476; time = 0.0216s; samplesPerSecond = 22083.0
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.00110796 * 487; EvalErrorPrediction = 0.53388090 * 487; time = 0.0149s; samplesPerSecond = 32601.4
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.90438413 * 499; EvalErrorPrediction = 0.51903808 * 499; time = 0.0151s; samplesPerSecond = 33061.7
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.93538095 * 475; EvalErrorPrediction = 0.51789474 * 475; time = 0.0148s; samplesPerSecond = 32190.3
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.92688744 * 506; EvalErrorPrediction = 0.53952569 * 506; time = 0.0151s; samplesPerSecond = 33538.8
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 1.93689941 * 472; EvalErrorPrediction = 0.53389831 * 472; time = 0.0148s; samplesPerSecond = 31956.7
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.87278053 * 490; EvalErrorPrediction = 0.53061224 * 490; time = 0.0149s; samplesPerSecond = 32795.7
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 1.93056324 * 477; EvalErrorPrediction = 0.50943396 * 477; time = 0.0148s; samplesPerSecond = 32271.2
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 1.92122823 * 469; EvalErrorPrediction = 0.52878465 * 469; time = 0.0147s; samplesPerSecond = 31976.5
MPI Rank 0: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.92998622 * 495; EvalErrorPrediction = 0.53131313 * 495; time = 0.0150s; samplesPerSecond = 32960.4
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.87322468 * 322; EvalErrorPrediction = 0.54968944 * 322; time = 0.0099s; samplesPerSecond = 32614.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.25 seconds since last report (0.00 seconds on comm.); 7732 samples processed by 2 workers (6679 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 30.49k samplesPerSecond , throughputPerWorker = 15.25k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:45: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 1.99875653 * 20480; EvalErrorPrediction = 0.54526367 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=0.727385s
MPI Rank 0: 06/13/2016 22:06:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:45: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.86678794 * 1939; EvalErrorPrediction = 0.50489943 * 1939; time = 0.0960s; samplesPerSecond = 20198.8
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.13 seconds since last report (0.00 seconds on comm.); 4844 samples processed by 2 workers (2583 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 38.62k samplesPerSecond , throughputPerWorker = 19.31k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.88063301 * 1944; EvalErrorPrediction = 0.53497942 * 1944; time = 0.0785s; samplesPerSecond = 24748.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4849 samples processed by 2 workers (2580 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.14k samplesPerSecond , throughputPerWorker = 20.57k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.90227906 * 1918; EvalErrorPrediction = 0.52346194 * 1918; time = 0.0900s; samplesPerSecond = 21303.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4868 samples processed by 2 workers (2595 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 40.66k samplesPerSecond , throughputPerWorker = 20.33k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88640712 * 1957; EvalErrorPrediction = 0.52376086 * 1957; time = 0.0941s; samplesPerSecond = 20795.9
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.86518475 * 1942; EvalErrorPrediction = 0.52008239 * 1942; time = 0.0614s; samplesPerSecond = 31624.0
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.85598666 * 1929; EvalErrorPrediction = 0.51270088 * 1929; time = 0.0436s; samplesPerSecond = 44216.8
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.88794294 * 1290; EvalErrorPrediction = 0.51937984 * 1290; time = 0.0344s; samplesPerSecond = 37489.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 5919 samples processed by 2 workers (5161 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 39.55k samplesPerSecond , throughputPerWorker = 19.78k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:45: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.88572700 * 20480; EvalErrorPrediction = 0.52416992 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=0.512827s
MPI Rank 0: 06/13/2016 22:06:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:45: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.89976988 * 1926; EvalErrorPrediction = 0.52128764 * 1926; time = 0.0717s; samplesPerSecond = 26844.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4905 samples processed by 2 workers (2581 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.62k samplesPerSecond , throughputPerWorker = 19.81k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:45:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.79499440 * 1894; EvalErrorPrediction = 0.50844773 * 1894; time = 0.0941s; samplesPerSecond = 20128.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4870 samples processed by 2 workers (2537 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.41k samplesPerSecond , throughputPerWorker = 20.71k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.84956803 * 1931; EvalErrorPrediction = 0.51475919 * 1931; time = 0.0980s; samplesPerSecond = 19698.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2513 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 40.99k samplesPerSecond , throughputPerWorker = 20.50k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82336020 * 1880; EvalErrorPrediction = 0.50159574 * 1880; time = 0.0929s; samplesPerSecond = 20239.4
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.79200574 * 1880; EvalErrorPrediction = 0.49627660 * 1880; time = 0.0572s; samplesPerSecond = 32888.4
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.80502326 * 1861; EvalErrorPrediction = 0.50994089 * 1861; time = 0.0421s; samplesPerSecond = 44202.2
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.81515951 * 1263; EvalErrorPrediction = 0.48851940 * 1263; time = 0.0283s; samplesPerSecond = 44619.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5789 samples processed by 2 workers (5004 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.09k samplesPerSecond , throughputPerWorker = 21.05k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:46: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.83787473 * 20480; EvalErrorPrediction = 0.51215820 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=0.499001s
MPI Rank 0: 06/13/2016 22:06:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:46: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80055910 * 1897; EvalErrorPrediction = 0.49868213 * 1897; time = 0.0697s; samplesPerSecond = 27227.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.13 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 38.89k samplesPerSecond , throughputPerWorker = 19.45k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86746838 * 1821; EvalErrorPrediction = 0.51455244 * 1821; time = 0.1019s; samplesPerSecond = 17873.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.87k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89216516 * 1871; EvalErrorPrediction = 0.52057723 * 1871; time = 0.0937s; samplesPerSecond = 19960.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.81k samplesPerSecond , throughputPerWorker = 20.91k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.81968853 * 1870; EvalErrorPrediction = 0.49144385 * 1870; time = 0.0897s; samplesPerSecond = 20855.6
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89739279 * 1899; EvalErrorPrediction = 0.51711427 * 1899; time = 0.0598s; samplesPerSecond = 31778.2
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.85833241 * 1878; EvalErrorPrediction = 0.52236422 * 1878; time = 0.0416s; samplesPerSecond = 45094.4
MPI Rank 0: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86115648 * 1221; EvalErrorPrediction = 0.50696151 * 1221; time = 0.0272s; samplesPerSecond = 44871.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.05k samplesPerSecond , throughputPerWorker = 21.02k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84363929 * 20480; EvalErrorPrediction = 0.51025391 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=0.497837s
MPI Rank 0: 06/13/2016 22:06:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:46: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 0: 06/13/2016 22:06:46: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:47: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:47: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80064927 * 1897; EvalErrorPrediction = 0.49815498 * 1897; time = 0.0725s; samplesPerSecond = 26179.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.03k samplesPerSecond , throughputPerWorker = 20.01k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86833563 * 1821; EvalErrorPrediction = 0.51510159 * 1821; time = 0.0963s; samplesPerSecond = 18917.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.12k samplesPerSecond , throughputPerWorker = 21.06k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89383486 * 1871; EvalErrorPrediction = 0.52111170 * 1871; time = 0.0918s; samplesPerSecond = 20370.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.67k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82119679 * 1870; EvalErrorPrediction = 0.49251337 * 1870; time = 0.0901s; samplesPerSecond = 20763.5
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89901122 * 1899; EvalErrorPrediction = 0.51869405 * 1899; time = 0.0598s; samplesPerSecond = 31772.9
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86037327 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.0419s; samplesPerSecond = 44858.5
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86390618 * 1221; EvalErrorPrediction = 0.50941851 * 1221; time = 0.0272s; samplesPerSecond = 44810.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.86k samplesPerSecond , throughputPerWorker = 20.93k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:47: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84493298 * 20480; EvalErrorPrediction = 0.51040039 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=0.49459s
MPI Rank 0: 06/13/2016 22:06:47: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:47: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 0: 06/13/2016 22:06:47: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:47: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:47: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80069673 * 1897; EvalErrorPrediction = 0.49868213 * 1897; time = 0.0722s; samplesPerSecond = 26279.3
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.66k samplesPerSecond , throughputPerWorker = 19.83k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86881421 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0967s; samplesPerSecond = 18832.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.88k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89481082 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0942s; samplesPerSecond = 19854.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82214273 * 1870; EvalErrorPrediction = 0.49465241 * 1870; time = 0.0895s; samplesPerSecond = 20883.8
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90008573 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.0602s; samplesPerSecond = 31538.6
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86165710 * 1878; EvalErrorPrediction = 0.52289670 * 1878; time = 0.0417s; samplesPerSecond = 45042.5
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86530783 * 1221; EvalErrorPrediction = 0.50941851 * 1221; time = 0.0272s; samplesPerSecond = 44906.2
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.91k samplesPerSecond , throughputPerWorker = 20.96k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:48: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84568574 * 20480; EvalErrorPrediction = 0.51049805 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=0.496175s
MPI Rank 0: 06/13/2016 22:06:48: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:48: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 0: 06/13/2016 22:06:48: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:48: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80072106 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0715s; samplesPerSecond = 26533.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.21k samplesPerSecond , throughputPerWorker = 20.11k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86906602 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0963s; samplesPerSecond = 18907.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.74k samplesPerSecond , throughputPerWorker = 20.87k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89534508 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0936s; samplesPerSecond = 19980.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.80k samplesPerSecond , throughputPerWorker = 20.90k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82269026 * 1870; EvalErrorPrediction = 0.49465241 * 1870; time = 0.0897s; samplesPerSecond = 20838.0
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90075815 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0593s; samplesPerSecond = 32028.5
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86244120 * 1878; EvalErrorPrediction = 0.52342918 * 1878; time = 0.0417s; samplesPerSecond = 44989.6
MPI Rank 0: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86601864 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44952.5
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.14k samplesPerSecond , throughputPerWorker = 21.07k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:48: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84611027 * 20480; EvalErrorPrediction = 0.51083984 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=0.493832s
MPI Rank 0: 06/13/2016 22:06:48: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:48: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 0: 06/13/2016 22:06:48: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:48: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80073339 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0721s; samplesPerSecond = 26296.5
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.00k samplesPerSecond , throughputPerWorker = 20.00k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86919523 * 1821; EvalErrorPrediction = 0.51290500 * 1821; time = 0.0958s; samplesPerSecond = 19000.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.88k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89562551 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0938s; samplesPerSecond = 19953.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.82k samplesPerSecond , throughputPerWorker = 20.91k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82298742 * 1870; EvalErrorPrediction = 0.49625668 * 1870; time = 0.0897s; samplesPerSecond = 20858.9
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90114315 * 1899; EvalErrorPrediction = 0.52238020 * 1899; time = 0.0602s; samplesPerSecond = 31539.1
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86288926 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0416s; samplesPerSecond = 45129.0
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86638702 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44886.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.97k samplesPerSecond , throughputPerWorker = 20.98k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84633999 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=0.494569s
MPI Rank 0: 06/13/2016 22:06:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:49: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 0: 06/13/2016 22:06:49: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:49: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80073959 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0721s; samplesPerSecond = 26318.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.97k samplesPerSecond , throughputPerWorker = 19.99k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86926069 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0959s; samplesPerSecond = 18994.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.84k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89576929 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0939s; samplesPerSecond = 19926.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.69k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82314256 * 1870; EvalErrorPrediction = 0.49679144 * 1870; time = 0.0900s; samplesPerSecond = 20769.9
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90135030 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.0599s; samplesPerSecond = 31720.3
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86313105 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0425s; samplesPerSecond = 44234.0
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86657721 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0275s; samplesPerSecond = 44398.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.23k samplesPerSecond , throughputPerWorker = 20.61k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:50: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84646018 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=0.497643s
MPI Rank 0: 06/13/2016 22:06:50: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:50: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 0: 06/13/2016 22:06:50: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:50: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074270 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0706s; samplesPerSecond = 26888.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.41k samplesPerSecond , throughputPerWorker = 20.21k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86929363 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0972s; samplesPerSecond = 18741.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 42.02k samplesPerSecond , throughputPerWorker = 21.01k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89584210 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0920s; samplesPerSecond = 20342.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.84k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82322186 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.0897s; samplesPerSecond = 20844.7
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90145790 * 1899; EvalErrorPrediction = 0.52185361 * 1899; time = 0.0600s; samplesPerSecond = 31653.7
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86325694 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0417s; samplesPerSecond = 45053.3
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86667428 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0273s; samplesPerSecond = 44697.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.88k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:50: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84652175 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=0.49316s
MPI Rank 0: 06/13/2016 22:06:50: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:50: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 0: 06/13/2016 22:06:50: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:50: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074425 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0721s; samplesPerSecond = 26297.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.93k samplesPerSecond , throughputPerWorker = 19.96k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86931015 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0961s; samplesPerSecond = 18952.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.71k samplesPerSecond , throughputPerWorker = 20.86k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89587874 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0943s; samplesPerSecond = 19847.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.66k samplesPerSecond , throughputPerWorker = 20.83k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82326196 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.0901s; samplesPerSecond = 20765.8
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90151275 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0598s; samplesPerSecond = 31735.7
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86332122 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0416s; samplesPerSecond = 45109.5
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86672338 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44965.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.98k samplesPerSecond , throughputPerWorker = 20.99k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:51: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84655293 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=0.495656s
MPI Rank 0: 06/13/2016 22:06:51: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:51: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 0: 06/13/2016 22:06:51: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:51: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074503 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0719s; samplesPerSecond = 26365.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.04k samplesPerSecond , throughputPerWorker = 20.02k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86931843 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0971s; samplesPerSecond = 18745.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.83k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89589712 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0925s; samplesPerSecond = 20221.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82328212 * 1870; EvalErrorPrediction = 0.49732620 * 1870; time = 0.0901s; samplesPerSecond = 20751.5
MPI Rank 0: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90154044 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0602s; samplesPerSecond = 31558.0
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86335370 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0412s; samplesPerSecond = 45629.0
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86674809 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44959.1
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.07k samplesPerSecond , throughputPerWorker = 21.04k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84656861 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=0.494627s
MPI Rank 0: 06/13/2016 22:06:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:52: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 0: 06/13/2016 22:06:52: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:52: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074542 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0721s; samplesPerSecond = 26309.9
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.01k samplesPerSecond , throughputPerWorker = 20.01k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932257 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0957s; samplesPerSecond = 19037.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.90k samplesPerSecond , throughputPerWorker = 20.95k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89590632 * 1871; EvalErrorPrediction = 0.51897381 * 1871; time = 0.0911s; samplesPerSecond = 20529.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.69k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329223 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0926s; samplesPerSecond = 20204.4
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90155435 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0603s; samplesPerSecond = 31470.6
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86337003 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0418s; samplesPerSecond = 44950.8
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676047 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44889.7
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.85k samplesPerSecond , throughputPerWorker = 20.93k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84657648 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=0.495213s
MPI Rank 0: 06/13/2016 22:06:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:52: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 0: 06/13/2016 22:06:52: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:52: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074562 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0720s; samplesPerSecond = 26337.7
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.09k samplesPerSecond , throughputPerWorker = 20.04k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932464 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0974s; samplesPerSecond = 18694.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.92k samplesPerSecond , throughputPerWorker = 20.96k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591093 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0919s; samplesPerSecond = 20356.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.88k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329729 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0895s; samplesPerSecond = 20891.1
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156133 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0593s; samplesPerSecond = 32050.1
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86337821 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0416s; samplesPerSecond = 45113.9
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676668 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44899.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.26k samplesPerSecond , throughputPerWorker = 21.13k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:53: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658042 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=0.49304s
MPI Rank 0: 06/13/2016 22:06:53: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:53: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 0: 06/13/2016 22:06:53: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:53: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:53: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074571 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0716s; samplesPerSecond = 26512.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.14k samplesPerSecond , throughputPerWorker = 20.07k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932568 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0964s; samplesPerSecond = 18884.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.60k samplesPerSecond , throughputPerWorker = 20.80k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591323 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0945s; samplesPerSecond = 19794.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.62k samplesPerSecond , throughputPerWorker = 20.81k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82329983 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0897s; samplesPerSecond = 20847.5
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156482 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0593s; samplesPerSecond = 32040.9
MPI Rank 0: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338231 * 1878; EvalErrorPrediction = 0.52396166 * 1878; time = 0.0416s; samplesPerSecond = 45126.9
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86676978 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44907.9
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.19k samplesPerSecond , throughputPerWorker = 21.09k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:54: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658239 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=0.494765s
MPI Rank 0: 06/13/2016 22:06:54: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:54: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 0: 06/13/2016 22:06:54: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:54: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:54: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074576 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0720s; samplesPerSecond = 26341.0
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.06k samplesPerSecond , throughputPerWorker = 20.03k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932620 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0957s; samplesPerSecond = 19025.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.92k samplesPerSecond , throughputPerWorker = 20.96k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591438 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0905s; samplesPerSecond = 20682.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330109 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0933s; samplesPerSecond = 20041.8
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156657 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0598s; samplesPerSecond = 31755.3
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338436 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0417s; samplesPerSecond = 45020.9
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677134 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0273s; samplesPerSecond = 44764.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.01k samplesPerSecond , throughputPerWorker = 21.01k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:54: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658338 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=0.494539s
MPI Rank 0: 06/13/2016 22:06:54: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:54: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 0: 06/13/2016 22:06:54: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:54: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:54: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074579 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0710s; samplesPerSecond = 26730.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 40.38k samplesPerSecond , throughputPerWorker = 20.19k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932646 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0957s; samplesPerSecond = 19030.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.42k samplesPerSecond , throughputPerWorker = 20.71k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591496 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0918s; samplesPerSecond = 20382.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.84k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330173 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0928s; samplesPerSecond = 20153.5
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156744 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0599s; samplesPerSecond = 31710.2
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338539 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0417s; samplesPerSecond = 44987.4
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677211 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0273s; samplesPerSecond = 44769.6
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 41.95k samplesPerSecond , throughputPerWorker = 20.97k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658387 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=0.494694s
MPI Rank 0: 06/13/2016 22:06:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:55: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 0: 06/13/2016 22:06:55: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:55: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:55: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074580 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0722s; samplesPerSecond = 26278.6
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.91k samplesPerSecond , throughputPerWorker = 19.95k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932659 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0977s; samplesPerSecond = 18630.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.85k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591525 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0921s; samplesPerSecond = 20317.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.61k samplesPerSecond , throughputPerWorker = 20.81k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330204 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0902s; samplesPerSecond = 20723.4
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156788 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0592s; samplesPerSecond = 32054.4
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338590 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0417s; samplesPerSecond = 45078.1
MPI Rank 0: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677250 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0273s; samplesPerSecond = 44715.4
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.15k samplesPerSecond , throughputPerWorker = 21.08k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658412 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=0.494929s
MPI Rank 0: 06/13/2016 22:06:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:56: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 0: 06/13/2016 22:06:56: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:56: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074581 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0723s; samplesPerSecond = 26256.1
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.93k samplesPerSecond , throughputPerWorker = 19.96k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932665 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0959s; samplesPerSecond = 18997.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.70k samplesPerSecond , throughputPerWorker = 20.85k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591539 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0943s; samplesPerSecond = 19846.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.71k samplesPerSecond , throughputPerWorker = 20.86k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330220 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0899s; samplesPerSecond = 20802.5
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156809 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0592s; samplesPerSecond = 32064.7
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338616 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0416s; samplesPerSecond = 45100.9
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677270 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0273s; samplesPerSecond = 44713.8
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.18k samplesPerSecond , throughputPerWorker = 21.09k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:56: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658424 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=0.494874s
MPI Rank 0: 06/13/2016 22:06:56: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:56: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 0: 06/13/2016 22:06:56: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:56: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.80074581 * 1897; EvalErrorPrediction = 0.49762783 * 1897; time = 0.0736s; samplesPerSecond = 25776.2
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4916 samples processed by 2 workers (2490 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 39.88k samplesPerSecond , throughputPerWorker = 19.94k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.86932668 * 1821; EvalErrorPrediction = 0.51345415 * 1821; time = 0.0947s; samplesPerSecond = 19227.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4884 samples processed by 2 workers (2481 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 41.83k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89591546 * 1871; EvalErrorPrediction = 0.51950828 * 1871; time = 0.0940s; samplesPerSecond = 19914.2
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4855 samples processed by 2 workers (2488 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 41.66k samplesPerSecond , throughputPerWorker = 20.83k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.82330228 * 1870; EvalErrorPrediction = 0.49786096 * 1870; time = 0.0900s; samplesPerSecond = 20782.4
MPI Rank 0: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.90156820 * 1899; EvalErrorPrediction = 0.52132701 * 1899; time = 0.0598s; samplesPerSecond = 31737.3
MPI Rank 0: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86338629 * 1878; EvalErrorPrediction = 0.52449414 * 1878; time = 0.0417s; samplesPerSecond = 45080.3
MPI Rank 0: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.86677279 * 1221; EvalErrorPrediction = 0.51187551 * 1221; time = 0.0272s; samplesPerSecond = 44901.3
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.00 seconds on comm.); 5825 samples processed by 2 workers (4998 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 42.05k samplesPerSecond , throughputPerWorker = 21.02k samplesPerSecond
MPI Rank 0: 06/13/2016 22:06:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658431 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=0.495259s
MPI Rank 0: 06/13/2016 22:06:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:57: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 0: 06/13/2016 22:06:57: SGD: revoke back to and update checkpoint file for epoch 4
MPI Rank 0: 06/13/2016 22:06:57: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 0: 06/13/2016 22:06:57: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:57: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 06/13/2016 22:06:57: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 06/13/2016 22:06:39: -------------------------------------------------------------------
MPI Rank 1: 06/13/2016 22:06:39: Build info: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: 		Built time: Jun 13 2016 21:56:00
MPI Rank 1: 06/13/2016 22:06:39: 		Last modified date: Mon Jun 13 17:05:37 2016
MPI Rank 1: 06/13/2016 22:06:39: 		Build type: release
MPI Rank 1: 06/13/2016 22:06:39: 		Build target: GPU
MPI Rank 1: 06/13/2016 22:06:39: 		With 1bit-SGD: yes
MPI Rank 1: 06/13/2016 22:06:39: 		Math lib: acml
MPI Rank 1: 06/13/2016 22:06:39: 		CUDA_PATH: /usr/local/cuda-7.5
MPI Rank 1: 06/13/2016 22:06:39: 		CUB_PATH: /usr/local/cub-1.4.1
MPI Rank 1: 06/13/2016 22:06:39: 		CUDNN_PATH: /usr/local/cudnn-4.0
MPI Rank 1: 06/13/2016 22:06:39: 		Build Branch: HEAD
MPI Rank 1: 06/13/2016 22:06:39: 		Build SHA1: 3ff048fd3b24e43a44a560a1fe677bac74da4ad9
MPI Rank 1: 06/13/2016 22:06:39: 		Built by philly on 373ab38025ce
MPI Rank 1: 06/13/2016 22:06:39: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
MPI Rank 1: 06/13/2016 22:06:39: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: Running on localhost at 2016/06/13 22:06:39
MPI Rank 1: 06/13/2016 22:06:39: Command line: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/../ParallelBM/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..  OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=12  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 06/13/2016 22:06:39: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 06/13/2016 22:06:39: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = 0
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=12
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/ParallelBM/..
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=0
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=12
MPI Rank 1: configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=/tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 06/13/2016 22:06:39: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 06/13/2016 22:06:39: Commands: speechTrain
MPI Rank 1: 06/13/2016 22:06:39: Precision = "double"
MPI Rank 1: 06/13/2016 22:06:39: Using 12 CPU threads.
MPI Rank 1: 06/13/2016 22:06:39: CNTKModelPath: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn
MPI Rank 1: 06/13/2016 22:06:39: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 06/13/2016 22:06:39: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: ##############################################################################
MPI Rank 1: 06/13/2016 22:06:39: #                                                                            #
MPI Rank 1: 06/13/2016 22:06:39: # Action "train"                                                             #
MPI Rank 1: 06/13/2016 22:06:39: #                                                                            #
MPI Rank 1: 06/13/2016 22:06:39: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using GPU 0
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:39: Creating virgin network.
MPI Rank 1: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:40: Created model with 25 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:40: Training criterion node(s):
MPI Rank 1: 06/13/2016 22:06:40: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:40: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:40: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: (nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0x29d7c48: {[features Value[363 x *]] }
MPI Rank 1: 0x337ee98: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0x339f9e8: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0x33a0718: {[W0 Value[512 x 363]] }
MPI Rank 1: 0x38a2348: {[W1 Value[512 x 512]] }
MPI Rank 1: 0x38a3118: {[B1 Value[512 x 1]] }
MPI Rank 1: 0x38a42b8: {[W2 Value[132 x 512]] }
MPI Rank 1: 0x38a4f68: {[B2 Value[132 x 1]] }
MPI Rank 1: 0x38a5d98: {[labels Value[132 x *]] }
MPI Rank 1: 0x38a6ff8: {[Prior Value[132]] }
MPI Rank 1: 0x38ac898: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0x38acb98: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0x38acd58: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0x38ad1e8: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0x38ad358: {[LogOfPrior Value[132]] }
MPI Rank 1: 0x38b2958: {[B0 Value[512 x 1]] }
MPI Rank 1: 0x3b8e028: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0x3b8e7e8: {[W0*features Value[512 x *]] }
MPI Rank 1: 0x3b8e9f8: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0x3b8eb58: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0x3b8ecb8: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0x3b8ee78: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0x3b8f038: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0x3b8f1f8: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0x3b8fd58: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0x3b8ff18: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0x3b900d8: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0x3b90298: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:40: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:40: 	MeanOfFeatures = Mean()
MPI Rank 1: 06/13/2016 22:06:40: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 06/13/2016 22:06:40: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:42: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:42: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:42: Starting minibatch loop.
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.57947979 * 192; EvalErrorPrediction = 0.96354167 * 192; time = 0.0206s; samplesPerSecond = 9302.3
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.45832105 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0194s; samplesPerSecond = 9898.9
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.29176856 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0194s; samplesPerSecond = 9907.1
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.15840784 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0194s; samplesPerSecond = 9897.4
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.21435783 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0194s; samplesPerSecond = 9911.2
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.62%]: CrossEntropyWithSoftmax = 4.14020622 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0194s; samplesPerSecond = 9905.1
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.04069876 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0194s; samplesPerSecond = 9908.7
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.04991414 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0194s; samplesPerSecond = 9912.7
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.88626656 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0194s; samplesPerSecond = 9909.7
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00467833 * 192; EvalErrorPrediction = 0.88020833 * 192; time = 0.0184s; samplesPerSecond = 10437.1
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 3.94077029 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0174s; samplesPerSecond = 11050.4
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.78326806 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.94698521 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0187s; samplesPerSecond = 10247.7
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.12%]: CrossEntropyWithSoftmax = 3.66011602 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0188s; samplesPerSecond = 10232.4
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.98797978 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0188s; samplesPerSecond = 10234.5
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.76297655 * 192; EvalErrorPrediction = 0.87500000 * 192; time = 0.0187s; samplesPerSecond = 10240.0
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.69909670 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0187s; samplesPerSecond = 10252.0
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.83747989 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0187s; samplesPerSecond = 10247.7
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.82672791 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.56520696 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0187s; samplesPerSecond = 10246.6
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.40098566 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0187s; samplesPerSecond = 10241.6
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.62%]: CrossEntropyWithSoftmax = 3.50668803 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0187s; samplesPerSecond = 10243.3
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.82314351 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.51780740 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.32189431 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.42533640 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0187s; samplesPerSecond = 10244.9
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.42902377 * 192; EvalErrorPrediction = 0.81770833 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.42017745 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.30346679 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.12%]: CrossEntropyWithSoftmax = 3.31343403 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.22956709 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0187s; samplesPerSecond = 10240.0
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.54894307 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0187s; samplesPerSecond = 10247.1
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.33751842 * 192; EvalErrorPrediction = 0.85416667 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.25951347 * 192; EvalErrorPrediction = 0.80729167 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.24586699 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.06725828 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0188s; samplesPerSecond = 10237.8
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.39973653 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0188s; samplesPerSecond = 10235.6
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.62%]: CrossEntropyWithSoftmax = 3.34798378 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0187s; samplesPerSecond = 10247.1
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.38133778 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0187s; samplesPerSecond = 10246.6
MPI Rank 1: 06/13/2016 22:06:42:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.19074044 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0187s; samplesPerSecond = 10247.1
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.14306337 * 192; EvalErrorPrediction = 0.74479167 * 192; time = 0.0187s; samplesPerSecond = 10247.1
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.10036521 * 192; EvalErrorPrediction = 0.72916667 * 192; time = 0.0187s; samplesPerSecond = 10240.0
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.17040971 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.19888148 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 2.91247084 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0187s; samplesPerSecond = 10244.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.12%]: CrossEntropyWithSoftmax = 2.96972038 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0187s; samplesPerSecond = 10242.2
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.15632232 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0188s; samplesPerSecond = 10240.0
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 2.98075176 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0188s; samplesPerSecond = 10240.0
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03076846 * 192; EvalErrorPrediction = 0.77604167 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 2.91480722 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0188s; samplesPerSecond = 10240.0
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.16155322 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0187s; samplesPerSecond = 10242.7
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 2.76157172 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0188s; samplesPerSecond = 10234.0
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.06347679 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0187s; samplesPerSecond = 10249.8
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.62%]: CrossEntropyWithSoftmax = 2.84053583 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0187s; samplesPerSecond = 10244.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 2.87795860 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 2.92198252 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.81241750 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 2.62682593 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.75758644 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.74763961 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0187s; samplesPerSecond = 10244.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 2.90905834 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0188s; samplesPerSecond = 10238.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.76756973 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0188s; samplesPerSecond = 10235.1
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.76599748 * 192; EvalErrorPrediction = 0.75520833 * 192; time = 0.0187s; samplesPerSecond = 10242.7
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.83171014 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0187s; samplesPerSecond = 10246.6
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.59593490 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.64965270 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0188s; samplesPerSecond = 10240.0
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.33442260 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.67195863 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0188s; samplesPerSecond = 10225.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.72367540 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0188s; samplesPerSecond = 10234.5
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.62%]: CrossEntropyWithSoftmax = 2.59572337 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0188s; samplesPerSecond = 10223.1
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.53202795 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0188s; samplesPerSecond = 10222.0
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.50336278 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77076318 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0187s; samplesPerSecond = 10242.7
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.45308521 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0187s; samplesPerSecond = 10249.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.54598920 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0187s; samplesPerSecond = 10243.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.58558089 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0188s; samplesPerSecond = 10238.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.41075660 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0188s; samplesPerSecond = 10237.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.12%]: CrossEntropyWithSoftmax = 2.52012028 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0188s; samplesPerSecond = 10220.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.30719546 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0187s; samplesPerSecond = 10250.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.42100657 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0188s; samplesPerSecond = 10225.8
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.39894546 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0188s; samplesPerSecond = 10238.9
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.44970724 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0188s; samplesPerSecond = 10231.3
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.33418475 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0187s; samplesPerSecond = 10245.5
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.37997032 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0188s; samplesPerSecond = 10238.4
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.47517097 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0188s; samplesPerSecond = 10234.5
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.62%]: CrossEntropyWithSoftmax = 2.60900086 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.43300244 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0187s; samplesPerSecond = 10244.4
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.12996515 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.51181403 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0188s; samplesPerSecond = 10236.7
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.29330120 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0188s; samplesPerSecond = 10224.7
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.33352411 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0188s; samplesPerSecond = 10236.7
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.17790026 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0188s; samplesPerSecond = 10236.2
MPI Rank 1: 06/13/2016 22:06:43:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.18521155 * 192; EvalErrorPrediction = 0.54166667 * 192; time = 0.0187s; samplesPerSecond = 10242.7
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.12%]: CrossEntropyWithSoftmax = 2.29833071 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0187s; samplesPerSecond = 10243.8
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.21483298 * 192; EvalErrorPrediction = 0.61458333 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.37232627 * 192; EvalErrorPrediction = 0.61979167 * 192; time = 0.0187s; samplesPerSecond = 10240.5
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.34396058 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0188s; samplesPerSecond = 10235.6
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.18334302 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0188s; samplesPerSecond = 10219.3
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.07753101 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0188s; samplesPerSecond = 10239.5
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26265833 * 192; EvalErrorPrediction = 0.63020833 * 192; time = 0.0188s; samplesPerSecond = 10234.5
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.21675905 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0187s; samplesPerSecond = 10247.1
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.62%]: CrossEntropyWithSoftmax = 2.18990385 * 192; EvalErrorPrediction = 0.58333333 * 192; time = 0.0188s; samplesPerSecond = 10211.1
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.48513433 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0188s; samplesPerSecond = 10235.1
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.25336704 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0188s; samplesPerSecond = 10237.8
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.13039619 * 192; EvalErrorPrediction = 0.55729167 * 192; time = 0.0188s; samplesPerSecond = 10236.7
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.27299748 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0187s; samplesPerSecond = 10241.1
MPI Rank 1: 06/13/2016 22:06:44: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 2.99723568 * 20480; EvalErrorPrediction = 0.72426758 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=2.01283s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:44: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:44: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.06713643 * 249; EvalErrorPrediction = 0.52208835 * 249; time = 0.0172s; samplesPerSecond = 14517.3
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.16835808 * 239; EvalErrorPrediction = 0.57740586 * 239; time = 0.0213s; samplesPerSecond = 11244.4
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.07984091 * 274; EvalErrorPrediction = 0.55109489 * 274; time = 0.0261s; samplesPerSecond = 10508.1
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.16277557 * 277; EvalErrorPrediction = 0.60288809 * 277; time = 0.0270s; samplesPerSecond = 10251.3
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.02360967 * 280; EvalErrorPrediction = 0.54642857 * 280; time = 0.0251s; samplesPerSecond = 11142.1
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.11391771 * 283; EvalErrorPrediction = 0.59717314 * 283; time = 0.0156s; samplesPerSecond = 18181.8
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.06691231 * 239; EvalErrorPrediction = 0.57322176 * 239; time = 0.0103s; samplesPerSecond = 23120.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.17 seconds since last report (0.00 seconds on comm.); 4331 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 25.83k samplesPerSecond , throughputPerWorker = 12.92k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.00607609 * 300; EvalErrorPrediction = 0.53666667 * 300; time = 0.0224s; samplesPerSecond = 13421.0
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 1.99849291 * 269; EvalErrorPrediction = 0.53159851 * 269; time = 0.0206s; samplesPerSecond = 13074.8
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.14699482 * 274; EvalErrorPrediction = 0.57299270 * 274; time = 0.0233s; samplesPerSecond = 11764.2
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.04126317 * 289; EvalErrorPrediction = 0.58477509 * 289; time = 0.0147s; samplesPerSecond = 19669.2
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.06113963 * 280; EvalErrorPrediction = 0.61785714 * 280; time = 0.0217s; samplesPerSecond = 12930.6
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 2.05149355 * 262; EvalErrorPrediction = 0.53435115 * 262; time = 0.0223s; samplesPerSecond = 11771.6
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.07615796 * 256; EvalErrorPrediction = 0.56640625 * 256; time = 0.0243s; samplesPerSecond = 10528.9
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 1.93205618 * 271; EvalErrorPrediction = 0.53874539 * 271; time = 0.0110s; samplesPerSecond = 24661.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 4232 samples processed by 2 workers (2078 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 27.30k samplesPerSecond , throughputPerWorker = 13.65k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.05205732 * 266; EvalErrorPrediction = 0.58270677 * 266; time = 0.0232s; samplesPerSecond = 11474.4
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.14681400 * 292; EvalErrorPrediction = 0.60616438 * 292; time = 0.0226s; samplesPerSecond = 12906.6
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.06088333 * 281; EvalErrorPrediction = 0.56583630 * 281; time = 0.0245s; samplesPerSecond = 11454.4
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 1.96455898 * 269; EvalErrorPrediction = 0.51672862 * 269; time = 0.0206s; samplesPerSecond = 13082.4
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 1.95106467 * 293; EvalErrorPrediction = 0.52559727 * 293; time = 0.0227s; samplesPerSecond = 12895.6
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 1.95943138 * 262; EvalErrorPrediction = 0.51145038 * 262; time = 0.0223s; samplesPerSecond = 11732.6
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.07155768 * 296; EvalErrorPrediction = 0.54729730 * 296; time = 0.0110s; samplesPerSecond = 27027.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.15 seconds since last report (0.00 seconds on comm.); 4185 samples processed by 2 workers (2060 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 27.75k samplesPerSecond , throughputPerWorker = 13.87k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 1.95713212 * 278; EvalErrorPrediction = 0.50719424 * 278; time = 0.0201s; samplesPerSecond = 13803.4
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.03053119 * 291; EvalErrorPrediction = 0.53608247 * 291; time = 0.0209s; samplesPerSecond = 13905.5
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.09969286 * 299; EvalErrorPrediction = 0.55852843 * 299; time = 0.0318s; samplesPerSecond = 9404.3
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 1.85965889 * 273; EvalErrorPrediction = 0.50183150 * 273; time = 0.0240s; samplesPerSecond = 11373.1
MPI Rank 1: 06/13/2016 22:06:44:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 1.89805579 * 190; EvalErrorPrediction = 0.51578947 * 190; time = 0.0132s; samplesPerSecond = 14421.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.25 seconds since last report (0.15 seconds on comm.); 7732 samples processed by 2 workers (1053 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 30.47k samplesPerSecond , throughputPerWorker = 15.24k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:45: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 1.99875653 * 20480; EvalErrorPrediction = 0.54526367 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=0.727379s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:45: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.92990384 * 1133; EvalErrorPrediction = 0.54368932 * 1133; time = 0.0468s; samplesPerSecond = 24210.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.13 seconds since last report (0.02 seconds on comm.); 4844 samples processed by 2 workers (2261 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 38.66k samplesPerSecond , throughputPerWorker = 19.33k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.93806210 * 1128; EvalErrorPrediction = 0.52659574 * 1128; time = 0.0754s; samplesPerSecond = 14955.3
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.84931024 * 1154; EvalErrorPrediction = 0.51473137 * 1154; time = 0.0591s; samplesPerSecond = 19521.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4849 samples processed by 2 workers (2269 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.14k samplesPerSecond , throughputPerWorker = 20.57k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88039762 * 1115; EvalErrorPrediction = 0.51748879 * 1115; time = 0.0586s; samplesPerSecond = 19030.2
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.89689671 * 1130; EvalErrorPrediction = 0.54336283 * 1130; time = 0.0442s; samplesPerSecond = 25578.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.01 seconds on comm.); 4868 samples processed by 2 workers (2273 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 40.67k samplesPerSecond , throughputPerWorker = 20.33k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.88822901 * 1143; EvalErrorPrediction = 0.53893263 * 1143; time = 0.0754s; samplesPerSecond = 15167.6
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.92708667 * 758; EvalErrorPrediction = 0.53693931 * 758; time = 0.0510s; samplesPerSecond = 14863.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.15 seconds since last report (0.08 seconds on comm.); 5919 samples processed by 2 workers (758 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 39.55k samplesPerSecond , throughputPerWorker = 19.77k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:45: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 1.88572700 * 20480; EvalErrorPrediction = 0.52416992 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-05; epochTime=0.512823s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:45: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.83907230 * 1146; EvalErrorPrediction = 0.51308901 * 1146; time = 0.0626s; samplesPerSecond = 18315.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2324 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.66k samplesPerSecond , throughputPerWorker = 19.83k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83174615 * 1178; EvalErrorPrediction = 0.50509338 * 1178; time = 0.0579s; samplesPerSecond = 20348.6
MPI Rank 1: 06/13/2016 22:06:45:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.89682396 * 1141; EvalErrorPrediction = 0.53812445 * 1141; time = 0.0582s; samplesPerSecond = 19607.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4870 samples processed by 2 workers (2333 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.41k samplesPerSecond , throughputPerWorker = 20.71k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.88667869 * 1192; EvalErrorPrediction = 0.53271812 * 1192; time = 0.0592s; samplesPerSecond = 20123.6
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.80769004 * 1192; EvalErrorPrediction = 0.52265101 * 1192; time = 0.0591s; samplesPerSecond = 20155.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 40.99k samplesPerSecond , throughputPerWorker = 20.50k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.82030293 * 1211; EvalErrorPrediction = 0.49958712 * 1211; time = 0.0606s; samplesPerSecond = 19981.8
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.94035074 * 785; EvalErrorPrediction = 0.54267516 * 785; time = 0.0414s; samplesPerSecond = 18950.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5789 samples processed by 2 workers (785 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.07k samplesPerSecond , throughputPerWorker = 21.04k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:46: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 1.83787473 * 20480; EvalErrorPrediction = 0.51215820 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-05; epochTime=0.498994s
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:46: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:46: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78955055 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0614s; samplesPerSecond = 19142.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.13 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 38.93k samplesPerSecond , throughputPerWorker = 19.46k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83857800 * 1251; EvalErrorPrediction = 0.51239009 * 1251; time = 0.0618s; samplesPerSecond = 20235.2
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78033156 * 1201; EvalErrorPrediction = 0.50374688 * 1201; time = 0.0611s; samplesPerSecond = 19649.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.87k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85251684 * 1202; EvalErrorPrediction = 0.51331115 * 1202; time = 0.0553s; samplesPerSecond = 21721.8
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.83755982 * 1173; EvalErrorPrediction = 0.50809889 * 1173; time = 0.0576s; samplesPerSecond = 20364.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.81k samplesPerSecond , throughputPerWorker = 20.90k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86874300 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0583s; samplesPerSecond = 20463.8
MPI Rank 1: 06/13/2016 22:06:46:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.78761926 * 827; EvalErrorPrediction = 0.51753325 * 827; time = 0.0361s; samplesPerSecond = 22891.5
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.05k samplesPerSecond , throughputPerWorker = 21.02k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:46: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84363929 * 20480; EvalErrorPrediction = 0.51025391 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.7656251e-05; epochTime=0.497839s
MPI Rank 1: 06/13/2016 22:06:46: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:46: learnRatePerSample reduced to 4.8828126e-05
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:47: Starting Epoch 5: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:47: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78962087 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0598s; samplesPerSecond = 19639.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.06k samplesPerSecond , throughputPerWorker = 20.03k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83882454 * 1251; EvalErrorPrediction = 0.50759392 * 1251; time = 0.0598s; samplesPerSecond = 20931.6
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78134486 * 1201; EvalErrorPrediction = 0.50208160 * 1201; time = 0.0594s; samplesPerSecond = 20221.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.12k samplesPerSecond , throughputPerWorker = 21.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85328151 * 1202; EvalErrorPrediction = 0.51247920 * 1202; time = 0.0564s; samplesPerSecond = 21311.7
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84014759 * 1173; EvalErrorPrediction = 0.50895141 * 1173; time = 0.0576s; samplesPerSecond = 20371.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.67k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.86995428 * 1194; EvalErrorPrediction = 0.52847571 * 1194; time = 0.0587s; samplesPerSecond = 20327.6
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.78946637 * 827; EvalErrorPrediction = 0.51511487 * 827; time = 0.0361s; samplesPerSecond = 22906.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 41.86k samplesPerSecond , throughputPerWorker = 20.93k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:47: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84493298 * 20480; EvalErrorPrediction = 0.51040039 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.8828126e-05; epochTime=0.494597s
MPI Rank 1: 06/13/2016 22:06:47: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:47: learnRatePerSample reduced to 2.4414063e-05
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:47: Starting Epoch 5: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:47: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78965640 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0615s; samplesPerSecond = 19103.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.71k samplesPerSecond , throughputPerWorker = 19.86k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83895707 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0590s; samplesPerSecond = 21211.3
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78192244 * 1201; EvalErrorPrediction = 0.50208160 * 1201; time = 0.0611s; samplesPerSecond = 19647.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.87k samplesPerSecond , throughputPerWorker = 20.93k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85367784 * 1202; EvalErrorPrediction = 0.51497504 * 1202; time = 0.0553s; samplesPerSecond = 21717.1
MPI Rank 1: 06/13/2016 22:06:47:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84169854 * 1173; EvalErrorPrediction = 0.50809889 * 1173; time = 0.0581s; samplesPerSecond = 20199.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87059172 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0582s; samplesPerSecond = 20507.4
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79036013 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0366s; samplesPerSecond = 22607.4
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 41.92k samplesPerSecond , throughputPerWorker = 20.96k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:48: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84568574 * 20480; EvalErrorPrediction = 0.51049805 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.4414063e-05; epochTime=0.496177s
MPI Rank 1: 06/13/2016 22:06:48: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:48: learnRatePerSample reduced to 1.2207031e-05
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:48: Starting Epoch 5: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78967425 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0608s; samplesPerSecond = 19340.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.25k samplesPerSecond , throughputPerWorker = 20.12k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83902575 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21480.5
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78223129 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0615s; samplesPerSecond = 19516.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.74k samplesPerSecond , throughputPerWorker = 20.87k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85388363 * 1202; EvalErrorPrediction = 0.51580699 * 1202; time = 0.0553s; samplesPerSecond = 21734.4
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84256302 * 1173; EvalErrorPrediction = 0.51065644 * 1173; time = 0.0575s; samplesPerSecond = 20386.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.81k samplesPerSecond , throughputPerWorker = 20.90k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87093833 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0584s; samplesPerSecond = 20440.7
MPI Rank 1: 06/13/2016 22:06:48:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79083879 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0357s; samplesPerSecond = 23197.8
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.13k samplesPerSecond , throughputPerWorker = 21.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:48: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84611027 * 20480; EvalErrorPrediction = 0.51083984 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.2207031e-05; epochTime=0.493832s
MPI Rank 1: 06/13/2016 22:06:48: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:48: learnRatePerSample reduced to 6.1035157e-06
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:48: Starting Epoch 5: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968320 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0615s; samplesPerSecond = 19117.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.04k samplesPerSecond , throughputPerWorker = 20.02k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83906070 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21503.0
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78239105 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0611s; samplesPerSecond = 19664.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.88k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85398908 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0554s; samplesPerSecond = 21702.2
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84302155 * 1173; EvalErrorPrediction = 0.51150895 * 1173; time = 0.0576s; samplesPerSecond = 20364.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.82k samplesPerSecond , throughputPerWorker = 20.91k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87112259 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0583s; samplesPerSecond = 20477.1
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79109571 * 827; EvalErrorPrediction = 0.51269649 * 827; time = 0.0366s; samplesPerSecond = 22600.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 41.97k samplesPerSecond , throughputPerWorker = 20.98k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:49: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84633999 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 6.1035157e-06; epochTime=0.49457s
MPI Rank 1: 06/13/2016 22:06:49: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:49: learnRatePerSample reduced to 3.0517579e-06
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:49: Starting Epoch 5: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968768 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0614s; samplesPerSecond = 19122.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.01k samplesPerSecond , throughputPerWorker = 20.00k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83907833 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21482.3
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78247230 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0610s; samplesPerSecond = 19677.6
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.84k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85404253 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0555s; samplesPerSecond = 21640.1
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84325796 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0576s; samplesPerSecond = 20376.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:49:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87121808 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0588s; samplesPerSecond = 20304.4
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79123019 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0361s; samplesPerSecond = 22878.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 41.25k samplesPerSecond , throughputPerWorker = 20.63k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:50: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84646018 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.0517579e-06; epochTime=0.497637s
MPI Rank 1: 06/13/2016 22:06:50: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:50: learnRatePerSample reduced to 1.5258789e-06
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:50: Starting Epoch 5: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78968993 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0603s; samplesPerSecond = 19476.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.45k samplesPerSecond , throughputPerWorker = 20.22k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83908718 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0583s; samplesPerSecond = 21473.8
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78251328 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0594s; samplesPerSecond = 20203.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 42.02k samplesPerSecond , throughputPerWorker = 21.01k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85406946 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0566s; samplesPerSecond = 21226.6
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84337803 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0575s; samplesPerSecond = 20407.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.82k samplesPerSecond , throughputPerWorker = 20.91k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87126675 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0585s; samplesPerSecond = 20406.1
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79129918 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0325s; samplesPerSecond = 25415.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 41.91k samplesPerSecond , throughputPerWorker = 20.95k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:50: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84652175 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.5258789e-06; epochTime=0.493167s
MPI Rank 1: 06/13/2016 22:06:50: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:50: learnRatePerSample reduced to 7.6293946e-07
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:50: Starting Epoch 5: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:50: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:50:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969105 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0614s; samplesPerSecond = 19123.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.97k samplesPerSecond , throughputPerWorker = 19.98k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909162 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0584s; samplesPerSecond = 21432.2
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78253385 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0611s; samplesPerSecond = 19652.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.71k samplesPerSecond , throughputPerWorker = 20.85k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85408297 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0559s; samplesPerSecond = 21506.1
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84343854 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0576s; samplesPerSecond = 20361.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.64k samplesPerSecond , throughputPerWorker = 20.82k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87129133 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0588s; samplesPerSecond = 20306.5
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79133413 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0361s; samplesPerSecond = 22883.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.00k samplesPerSecond , throughputPerWorker = 21.00k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:51: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84655293 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 7.6293946e-07; epochTime=0.495663s
MPI Rank 1: 06/13/2016 22:06:51: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:51: learnRatePerSample reduced to 3.8146973e-07
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:51: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969161 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0611s; samplesPerSecond = 19243.7
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.08k samplesPerSecond , throughputPerWorker = 20.04k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909384 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21479.3
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78254416 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0594s; samplesPerSecond = 20205.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.83k samplesPerSecond , throughputPerWorker = 20.91k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85408974 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0571s; samplesPerSecond = 21033.5
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84346892 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0575s; samplesPerSecond = 20404.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87130368 * 1194; EvalErrorPrediction = 0.52763819 * 1194; time = 0.0588s; samplesPerSecond = 20304.1
MPI Rank 1: 06/13/2016 22:06:51:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79135174 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0366s; samplesPerSecond = 22611.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.07k samplesPerSecond , throughputPerWorker = 21.03k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84656861 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 3.8146973e-07; epochTime=0.494629s
MPI Rank 1: 06/13/2016 22:06:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:52: learnRatePerSample reduced to 1.9073487e-07
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:52: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969189 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0616s; samplesPerSecond = 19087.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.05k samplesPerSecond , throughputPerWorker = 20.03k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909495 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0579s; samplesPerSecond = 21597.3
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78254932 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0611s; samplesPerSecond = 19655.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.90k samplesPerSecond , throughputPerWorker = 20.95k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409313 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0553s; samplesPerSecond = 21743.1
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84348413 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0609s; samplesPerSecond = 19245.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.68k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87130987 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0554s; samplesPerSecond = 21545.3
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136057 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0366s; samplesPerSecond = 22579.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 41.87k samplesPerSecond , throughputPerWorker = 20.93k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:52: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84657648 * 20480; EvalErrorPrediction = 0.51118164 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.9073487e-07; epochTime=0.495214s
MPI Rank 1: 06/13/2016 22:06:52: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:52: learnRatePerSample reduced to 9.5367433e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:52: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:52:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969203 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0614s; samplesPerSecond = 19150.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.12k samplesPerSecond , throughputPerWorker = 20.06k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909551 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0581s; samplesPerSecond = 21549.3
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255190 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0598s; samplesPerSecond = 20074.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.92k samplesPerSecond , throughputPerWorker = 20.96k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409482 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0565s; samplesPerSecond = 21280.0
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349175 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0576s; samplesPerSecond = 20381.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.88k samplesPerSecond , throughputPerWorker = 20.94k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131297 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0582s; samplesPerSecond = 20513.0
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136499 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0356s; samplesPerSecond = 23203.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.26k samplesPerSecond , throughputPerWorker = 21.13k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:53: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658042 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 9.5367433e-08; epochTime=0.493042s
MPI Rank 1: 06/13/2016 22:06:53: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:53: learnRatePerSample reduced to 4.7683717e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:53: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:53: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969210 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0609s; samplesPerSecond = 19304.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.17k samplesPerSecond , throughputPerWorker = 20.09k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909579 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0584s; samplesPerSecond = 21431.9
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255320 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0615s; samplesPerSecond = 19525.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.61k samplesPerSecond , throughputPerWorker = 20.80k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409567 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0557s; samplesPerSecond = 21569.4
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349556 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0580s; samplesPerSecond = 20230.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.62k samplesPerSecond , throughputPerWorker = 20.81k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131452 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0584s; samplesPerSecond = 20437.9
MPI Rank 1: 06/13/2016 22:06:53:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136720 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0366s; samplesPerSecond = 22614.2
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.19k samplesPerSecond , throughputPerWorker = 21.09k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:54: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658239 * 20480; EvalErrorPrediction = 0.51123047 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 4.7683717e-08; epochTime=0.494767s
MPI Rank 1: 06/13/2016 22:06:54: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:54: learnRatePerSample reduced to 2.3841858e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:54: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:54: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969213 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0613s; samplesPerSecond = 19153.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.10k samplesPerSecond , throughputPerWorker = 20.05k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909593 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0581s; samplesPerSecond = 21530.0
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255384 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0610s; samplesPerSecond = 19683.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.91k samplesPerSecond , throughputPerWorker = 20.95k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409609 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0554s; samplesPerSecond = 21714.8
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349747 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0601s; samplesPerSecond = 19505.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.69k samplesPerSecond , throughputPerWorker = 20.84k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131530 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0561s; samplesPerSecond = 21269.4
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136831 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0361s; samplesPerSecond = 22921.3
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.01k samplesPerSecond , throughputPerWorker = 21.00k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:54: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658338 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.3841858e-08; epochTime=0.49453s
MPI Rank 1: 06/13/2016 22:06:54: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:54: learnRatePerSample reduced to 1.1920929e-08
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:54: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:54: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969215 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0604s; samplesPerSecond = 19458.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 40.40k samplesPerSecond , throughputPerWorker = 20.20k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:54:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909600 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21506.3
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255416 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0610s; samplesPerSecond = 19684.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.46k samplesPerSecond , throughputPerWorker = 20.73k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409630 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0566s; samplesPerSecond = 21246.5
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349842 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0585s; samplesPerSecond = 20043.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.81k samplesPerSecond , throughputPerWorker = 20.91k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131569 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0574s; samplesPerSecond = 20790.2
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136886 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0325s; samplesPerSecond = 25408.6
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 41.97k samplesPerSecond , throughputPerWorker = 20.98k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658387 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.1920929e-08; epochTime=0.494695s
MPI Rank 1: 06/13/2016 22:06:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:55: learnRatePerSample reduced to 5.9604646e-09
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:55: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:55: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969216 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0615s; samplesPerSecond = 19099.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.95k samplesPerSecond , throughputPerWorker = 19.97k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909603 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0583s; samplesPerSecond = 21454.3
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255433 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0599s; samplesPerSecond = 20042.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.84k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409641 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0566s; samplesPerSecond = 21228.9
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349890 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0576s; samplesPerSecond = 20372.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.61k samplesPerSecond , throughputPerWorker = 20.81k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131588 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0589s; samplesPerSecond = 20264.4
MPI Rank 1: 06/13/2016 22:06:55:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136914 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0366s; samplesPerSecond = 22612.9
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.15k samplesPerSecond , throughputPerWorker = 21.08k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:55: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658412 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 5.9604646e-09; epochTime=0.49493s
MPI Rank 1: 06/13/2016 22:06:55: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:56: learnRatePerSample reduced to 2.9802323e-09
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:56: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969217 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0616s; samplesPerSecond = 19073.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.97k samplesPerSecond , throughputPerWorker = 19.98k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909605 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0582s; samplesPerSecond = 21499.6
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255441 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0611s; samplesPerSecond = 19657.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.70k samplesPerSecond , throughputPerWorker = 20.85k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409646 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0559s; samplesPerSecond = 21486.5
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349913 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0575s; samplesPerSecond = 20386.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.71k samplesPerSecond , throughputPerWorker = 20.86k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131598 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0587s; samplesPerSecond = 20352.2
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136928 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0380s; samplesPerSecond = 21759.7
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.18k samplesPerSecond , throughputPerWorker = 21.09k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:56: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658424 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 2.9802323e-09; epochTime=0.494883s
MPI Rank 1: 06/13/2016 22:06:56: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:56: learnRatePerSample reduced to 1.4901161e-09
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:56: Starting Epoch 5: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:56: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 1.78969217 * 1175; EvalErrorPrediction = 0.49021277 * 1175; time = 0.0605s; samplesPerSecond = 19434.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4916 samples processed by 2 workers (2426 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 39.91k samplesPerSecond , throughputPerWorker = 19.96k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 1.83909606 * 1251; EvalErrorPrediction = 0.50839329 * 1251; time = 0.0594s; samplesPerSecond = 21060.3
MPI Rank 1: 06/13/2016 22:06:56:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 1.78255445 * 1201; EvalErrorPrediction = 0.50291424 * 1201; time = 0.0611s; samplesPerSecond = 19663.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4884 samples processed by 2 workers (2403 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 41.83k samplesPerSecond , throughputPerWorker = 20.92k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.85409649 * 1202; EvalErrorPrediction = 0.51663894 * 1202; time = 0.0555s; samplesPerSecond = 21654.9
MPI Rank 1: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 1.84349925 * 1173; EvalErrorPrediction = 0.51236147 * 1173; time = 0.0577s; samplesPerSecond = 20346.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.12 seconds since last report (0.00 seconds on comm.); 4855 samples processed by 2 workers (2367 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 41.66k samplesPerSecond , throughputPerWorker = 20.83k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.87131603 * 1194; EvalErrorPrediction = 0.52680067 * 1194; time = 0.0587s; samplesPerSecond = 20338.6
MPI Rank 1: 06/13/2016 22:06:57:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 1.79136935 * 827; EvalErrorPrediction = 0.51027811 * 827; time = 0.0362s; samplesPerSecond = 22863.0
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats) 4-th sync:     0.14 seconds since last report (0.07 seconds on comm.); 5825 samples processed by 2 workers (827 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 42.05k samplesPerSecond , throughputPerWorker = 21.02k samplesPerSecond
MPI Rank 1: 06/13/2016 22:06:57: Finished Epoch[ 5 of 5]: [Training] CrossEntropyWithSoftmax = 1.84658431 * 20480; EvalErrorPrediction = 0.51127930 * 20480; totalSamplesSeen = 102400; learningRatePerSample = 1.4901161e-09; epochTime=0.495261s
MPI Rank 1: 06/13/2016 22:06:57: Loading (rolling back to) previous model with best training-criterion value: /tmp/cntk-test-20160613220153.398671/Speech/DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.4.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].06/13/2016 22:06:57: learnRatePerSample reduced to 7.4505807e-10
MPI Rank 1: 06/13/2016 22:06:57: Learn Rate Per Sample for Epoch[5] = 7.4505807e-10 is less than minLearnRate 9.9999997e-10. Training complete.
MPI Rank 1: 06/13/2016 22:06:57: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:57: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 06/13/2016 22:06:57: __COMPLETED__
MPI Rank 1: ~MPIWrapper
