precision = "float"
command = speechTrain
deviceId = $DeviceId$

parallelTrain = true

speechTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech.dnn"
    deviceId = $DeviceId$
    traceLevel = 1

    BrainScriptNetworkBuilder = [
        layerSizes = 363:512:512:512:132
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes[i:1..Length(layerSizes)-2]=Sigmoid
        applyMeanVarNorm = true
        initValueScale=1.0
        uniformInit=true

        BFF(in, rows, cols) = [ B = Parameter(rows, 1, init = 'fixedValue', value = 0) ; W = Parameter(rows, cols, init = if uniformInit then 'uniform' else 'gaussian'/*, initValueScale from outer scope*/) ; z = W*in+B ]
        GBFF(f, in, rows, cols) = [ Eh = Dropout(f(BFF(in, rows, cols).z)) ]

        L = Length(layerSizes)-1    // number of model layers
        features = Input(layerSizes[0], tag='feature') ; labels = Input(layerSizes[L], tag='label')
        featNorm = if applyMeanVarNorm
                   then MeanVarNorm(features)
                   else features
        layers[layer:1..L-1] = if layer > 1
                               then GBFF(layerTypes[layer], layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
                               else GBFF(layerTypes[layer], featNorm, layerSizes[layer], layerSizes[layer-1])

        link = Parameter(1, 1, init='fixedValue', value=1, learningRateMultiplier=0)
        finalHiddenToPlus = Scale(Dropout(link), layers[L-1].Eh)
        outLayer = BFF(Plus(finalHiddenToPlus, layers[L-2].Eh), layerSizes[L], layerSizes[L-1])

        outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
        ce = trainingCriterion(labels, outZ, tag='criterion')
        err = evalCriterion(labels, outZ, tag='evaluation')
        logPrior = LogPrior(labels)
        // TODO: how to add a tag to an infix operation?
        scaledLogLikelihood = Minus (outZ, logPrior, tag='output')
    ]

    SGD = [
        epochSize = 20480
        minibatchSize = 256
        learningRatesPerSample = 0.001953125
        numMBsToShowResult = 10
        momentumPerMB = 0.9
        dropoutRate = 0.1*2:0.15*2:0
        maxEpochs = 5
        keepCheckPointFiles = true
        clippingThresholdPerSample = 1#INF

        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = true
            parallelizationStartEpoch = 2
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]

    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        useMersenneTwisterRand=true

        features = [
            dim = 363
            type = "real"
            scpFile = "glob_0000.scp"
        ]
    
        labels = [
            mlfFile = "$DataDir$/glob_0000.mlf"
            labelMappingFile = "$DataDir$/state.list"
            labelDim = 132
            labelType = "category"
        ]
    ]
]
