dataDir: ../../Data
tags:
     # running for gpu build SKU on every BVT job in 'S' (Speech) leg in Debug-GPU and Release-CPU configurations:
     - bvt-s  (build_sku == 'gpu') and ((flavor=='debug') ^ (device=='cpu'))
     # running for gpu build SKU  on every Nightly job in 'S' leg
     - nightly-s (build_sku == 'gpu')

testCases:
  Must train epochs in exactly same order and parameters for each MPI Rank:
    patterns:
      - ^MPI Rank {{integer}}
      - Starting Epoch {{integer}}
      - learning rate per sample = {{float}}
      - momentum = {{float}}

  Epochs must be finished with expected results for each MPI Rank:
    patterns:
      - ^MPI Rank {{integer}}
      - Finished Epoch[{{integer}} of {{integer}}]
      - ce = {{float,tolerance=0.2%}}
      - err = {{float,tolerance=0.2%}}
      - learningRatePerSample = {{float,tolerance=0.001%}}

  Per-minibatch training results must match for each MPI Rank:
    patterns:
      - ^MPI Rank {{integer}}
      - Epoch[{{integer}} of {{integer}}]-Minibatch[{{integer}}-{{integer}}
      - " * {{integer}}; "
      - ce = {{float,tolerance=0.2%}}
      - err = {{float,tolerance=0.2%}}

  DataParallelSGD training parameters must match for each MPI Rank:
    patterns:
      - ^MPI Rank {{integer}}
      - Starting minibatch loop
      - DataParallelSGD training
      - myRank = {{integer}}
      - numNodes = 2
      - numGradientBits = 32
      - distributed reading is ENABLED
