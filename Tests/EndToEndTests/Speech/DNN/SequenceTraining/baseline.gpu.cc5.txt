CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 12
    Total Memory: 57702824 kB
-------------------------------------------------------------------
=== Running /home/ubuntu/workspace/build/gpu/release/bin/cntk configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk currentDirectory=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData RunDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu DataDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining OutputDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.1+ (HEAD cefff1, Sep 12 2017 17:06:52) on a306de370df1 at 2017/09/13 08:05:59

/home/ubuntu/workspace/build/gpu/release/bin/cntk  configFile=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk  currentDirectory=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData  RunDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu  DataDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData  ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining  OutputDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData
09/13/2017 08:06:00: -------------------------------------------------------------------
09/13/2017 08:06:00: Build info: 

09/13/2017 08:06:00: 		Built time: Sep 12 2017 17:03:13
09/13/2017 08:06:00: 		Last modified date: Mon Sep 11 12:53:42 2017
09/13/2017 08:06:00: 		Build type: release
09/13/2017 08:06:00: 		Build target: GPU
09/13/2017 08:06:00: 		With 1bit-SGD: no
09/13/2017 08:06:00: 		With ASGD: yes
09/13/2017 08:06:00: 		Math lib: mkl
09/13/2017 08:06:00: 		CUDA_PATH: /usr/local/cuda-8.0
09/13/2017 08:06:00: 		CUB_PATH: /usr/local/cub-1.4.1
09/13/2017 08:06:00: 		CUDNN_PATH: /usr/local/cudnn-6.0
09/13/2017 08:06:00: 		Build Branch: HEAD
09/13/2017 08:06:00: 		Build SHA1: cefff1fc5f90334dab95988beaeada4617c4fe49
09/13/2017 08:06:00: 		Built by Source/CNTK/buildinfo.h$$0 on a709d2fc41a3
09/13/2017 08:06:00: 		Build Path: /home/ubuntu/workspace
09/13/2017 08:06:00: 		MPI distribution: Open MPI
09/13/2017 08:06:00: 		MPI version: 1.10.7
09/13/2017 08:06:00: -------------------------------------------------------------------
09/13/2017 08:06:00: -------------------------------------------------------------------
09/13/2017 08:06:00: GPU info:

09/13/2017 08:06:00: 		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8123 MB; free memory = 8121 MB
09/13/2017 08:06:00: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData
configparameters: cntk_sequence.cntk:DataDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/ubuntu/workspace/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
09/13/2017 08:06:00: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
09/13/2017 08:06:00: precision = "float"

09/13/2017 08:06:00: ##############################################################################
09/13/2017 08:06:00: #                                                                            #
09/13/2017 08:06:00: # dptPre1 command (train action)                                             #
09/13/2017 08:06:00: #                                                                            #
09/13/2017 08:06:00: ##############################################################################

09/13/2017 08:06:00: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
09/13/2017 08:06:00: 
Model has 19 nodes. Using GPU 0.

09/13/2017 08:06:00: Training criterion:   ce = CrossEntropyWithSoftmax
09/13/2017 08:06:00: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 2 are aliased.
	OL.t (gradient) reuses OL.z (gradient)

Memory Sharing: Out of 29 matrices, 12 are shared as 3, and 17 are not shared.

Here are the ones that share memory:
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *]
	  HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *]
	  OL.t : [132 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.t : [512 x *]
	  HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] }

Here are the ones that don't share memory:
	{scaledLogLikelihood : [132 x 1 x *]}
	{features : [363 x *]}
	{featNorm : [363 x *]}
	{labels : [132 x *]}
	{globalMean : [363 x 1]}
	{globalInvStd : [363 x 1]}
	{globalPrior : [132 x 1]}
	{HL1.W : [512 x 363]}
	{HL1.b : [512 x 1]}
	{OL.W : [132 x 512]}
	{OL.b : [132 x 1]}
	{OL.W : [132 x 512] (gradient)}
	{ce : [1] (gradient)}
	{err : [1]}
	{OL.b : [132 x 1] (gradient)}
	{logPrior : [132 x 1]}
	{ce : [1]}


09/13/2017 08:06:00: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

09/13/2017 08:06:00: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
09/13/2017 08:06:00: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:00: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
09/13/2017 08:06:00: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

09/13/2017 08:06:00: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

09/13/2017 08:06:00: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

09/13/2017 08:06:00: Starting minibatch loop.
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.74183807 * 2560; err = 0.80195313 * 2560; time = 0.1730s; samplesPerSecond = 14800.8
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.91124802 * 2560; err = 0.70898438 * 2560; time = 0.0080s; samplesPerSecond = 319876.0
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.58016052 * 2560; err = 0.66640625 * 2560; time = 0.0077s; samplesPerSecond = 334107.7
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.27427139 * 2560; err = 0.58750000 * 2560; time = 0.0076s; samplesPerSecond = 336771.2
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 2.05503540 * 2560; err = 0.56093750 * 2560; time = 0.0074s; samplesPerSecond = 348180.9
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.91055145 * 2560; err = 0.52812500 * 2560; time = 0.0075s; samplesPerSecond = 339702.8
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.81562805 * 2560; err = 0.51171875 * 2560; time = 0.0075s; samplesPerSecond = 342626.2
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.68803253 * 2560; err = 0.48476562 * 2560; time = 0.0075s; samplesPerSecond = 340475.3
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.57382050 * 2560; err = 0.45429687 * 2560; time = 0.0073s; samplesPerSecond = 351875.5
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62090302 * 2560; err = 0.47304687 * 2560; time = 0.0077s; samplesPerSecond = 330395.1
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.59272614 * 2560; err = 0.47500000 * 2560; time = 0.0075s; samplesPerSecond = 343587.3
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.51520386 * 2560; err = 0.44531250 * 2560; time = 0.0075s; samplesPerSecond = 342136.2
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.49181824 * 2560; err = 0.45039062 * 2560; time = 0.0072s; samplesPerSecond = 353405.7
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53703613 * 2560; err = 0.44804688 * 2560; time = 0.0076s; samplesPerSecond = 335799.4
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.43095093 * 2560; err = 0.41640625 * 2560; time = 0.0075s; samplesPerSecond = 341433.5
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.41503601 * 2560; err = 0.40078125 * 2560; time = 0.0075s; samplesPerSecond = 341278.7
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.38912964 * 2560; err = 0.41132812 * 2560; time = 0.0073s; samplesPerSecond = 349698.1
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.41208496 * 2560; err = 0.42226562 * 2560; time = 0.0076s; samplesPerSecond = 337250.4
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.39965820 * 2560; err = 0.40664062 * 2560; time = 0.0073s; samplesPerSecond = 350622.5
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42728577 * 2560; err = 0.42617187 * 2560; time = 0.0076s; samplesPerSecond = 337918.1
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.41336060 * 2560; err = 0.42304687 * 2560; time = 0.0073s; samplesPerSecond = 351382.9
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.33195801 * 2560; err = 0.39960937 * 2560; time = 0.0077s; samplesPerSecond = 332493.4
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.28579712 * 2560; err = 0.38671875 * 2560; time = 0.0073s; samplesPerSecond = 352166.0
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.34128113 * 2560; err = 0.40937500 * 2560; time = 0.0074s; samplesPerSecond = 345120.5
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.32663879 * 2560; err = 0.39648438 * 2560; time = 0.0073s; samplesPerSecond = 352069.1
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.21426086 * 2560; err = 0.37187500 * 2560; time = 0.0077s; samplesPerSecond = 332912.9
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.23750000 * 2560; err = 0.37382813 * 2560; time = 0.0074s; samplesPerSecond = 346179.9
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.29968262 * 2560; err = 0.39062500 * 2560; time = 0.0075s; samplesPerSecond = 339869.6
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.21239929 * 2560; err = 0.37382813 * 2560; time = 0.0073s; samplesPerSecond = 351604.9
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20531006 * 2560; err = 0.36796875 * 2560; time = 0.0076s; samplesPerSecond = 337459.3
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23578796 * 2560; err = 0.37187500 * 2560; time = 0.0073s; samplesPerSecond = 350814.7
09/13/2017 08:06:00:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.25570068 * 2560; err = 0.37968750 * 2560; time = 0.0073s; samplesPerSecond = 352889.3
09/13/2017 08:06:00: Finished Epoch[ 1 of 2]: [Training] ce = 1.62944050 * 81920; err = 0.46015625 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.510544s
09/13/2017 08:06:00: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

09/13/2017 08:06:00: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

09/13/2017 08:06:00: Starting minibatch loop.
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.23324184 * 2560; err = 0.38164063 * 2560; time = 0.0085s; samplesPerSecond = 302175.4
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.20339603 * 2560; err = 0.37226562 * 2560; time = 0.0078s; samplesPerSecond = 327772.3
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.28589058 * 2560; err = 0.37773438 * 2560; time = 0.0074s; samplesPerSecond = 344818.3
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.23064728 * 2560; err = 0.37773438 * 2560; time = 0.0086s; samplesPerSecond = 296234.6
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.18116455 * 2560; err = 0.35585937 * 2560; time = 0.0074s; samplesPerSecond = 347575.8
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.28143578 * 2560; err = 0.37929687 * 2560; time = 0.0076s; samplesPerSecond = 335429.8
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.22316818 * 2560; err = 0.37226562 * 2560; time = 0.0073s; samplesPerSecond = 349035.4
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17917328 * 2560; err = 0.36679688 * 2560; time = 0.0078s; samplesPerSecond = 326755.7
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.23667755 * 2560; err = 0.36210938 * 2560; time = 0.0073s; samplesPerSecond = 350023.2
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18298416 * 2560; err = 0.37382813 * 2560; time = 0.0077s; samplesPerSecond = 333611.3
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.20064545 * 2560; err = 0.36562500 * 2560; time = 0.0073s; samplesPerSecond = 352680.2
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18663025 * 2560; err = 0.35156250 * 2560; time = 0.0076s; samplesPerSecond = 336006.5
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16763000 * 2560; err = 0.35546875 * 2560; time = 0.0073s; samplesPerSecond = 351214.2
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.13098907 * 2560; err = 0.35039063 * 2560; time = 0.0077s; samplesPerSecond = 333824.5
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.09752045 * 2560; err = 0.32265625 * 2560; time = 0.0074s; samplesPerSecond = 343831.8
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.09747925 * 2560; err = 0.33710937 * 2560; time = 0.0075s; samplesPerSecond = 340122.5
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.19010925 * 2560; err = 0.35625000 * 2560; time = 0.0073s; samplesPerSecond = 351614.5
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.16201630 * 2560; err = 0.36015625 * 2560; time = 0.0075s; samplesPerSecond = 343067.0
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11661987 * 2560; err = 0.34375000 * 2560; time = 0.0073s; samplesPerSecond = 351682.2
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11697693 * 2560; err = 0.34765625 * 2560; time = 0.0077s; samplesPerSecond = 333707.0
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.09923859 * 2560; err = 0.33125000 * 2560; time = 0.0075s; samplesPerSecond = 339329.0
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.12601929 * 2560; err = 0.33789062 * 2560; time = 0.0079s; samplesPerSecond = 324992.7
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.14013977 * 2560; err = 0.35429688 * 2560; time = 0.0073s; samplesPerSecond = 352777.4
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.29293518 * 2560; err = 0.38867188 * 2560; time = 0.0076s; samplesPerSecond = 335812.6
09/13/2017 08:06:00:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.18086853 * 2560; err = 0.35898438 * 2560; time = 0.0075s; samplesPerSecond = 340285.3
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.14109802 * 2560; err = 0.36171875 * 2560; time = 0.0087s; samplesPerSecond = 293837.4
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.14666138 * 2560; err = 0.34492187 * 2560; time = 0.0073s; samplesPerSecond = 349073.5
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.15356140 * 2560; err = 0.35000000 * 2560; time = 0.0077s; samplesPerSecond = 332640.3
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.07240295 * 2560; err = 0.33867188 * 2560; time = 0.0073s; samplesPerSecond = 350368.2
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08450623 * 2560; err = 0.33007812 * 2560; time = 0.0074s; samplesPerSecond = 345311.3
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.07801514 * 2560; err = 0.33164063 * 2560; time = 0.0073s; samplesPerSecond = 352437.5
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06560974 * 2560; err = 0.33281250 * 2560; time = 0.0076s; samplesPerSecond = 338785.7
09/13/2017 08:06:01: Finished Epoch[ 2 of 2]: [Training] ce = 1.16517038 * 81920; err = 0.35534668 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.249559s
09/13/2017 08:06:01: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

09/13/2017 08:06:01: Action "train" complete.


09/13/2017 08:06:01: ##############################################################################
09/13/2017 08:06:01: #                                                                            #
09/13/2017 08:06:01: # addLayer2 command (edit action)                                            #
09/13/2017 08:06:01: #                                                                            #
09/13/2017 08:06:01: ##############################################################################


09/13/2017 08:06:01: Action "edit" complete.


09/13/2017 08:06:01: ##############################################################################
09/13/2017 08:06:01: #                                                                            #
09/13/2017 08:06:01: # dptPre2 command (train action)                                             #
09/13/2017 08:06:01: #                                                                            #
09/13/2017 08:06:01: ##############################################################################

09/13/2017 08:06:01: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
09/13/2017 08:06:01: 
Model has 24 nodes. Using GPU 0.

09/13/2017 08:06:01: Training criterion:   ce = CrossEntropyWithSoftmax
09/13/2017 08:06:01: Evaluation criterion: err = ClassificationError

09/13/2017 08:06:01: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

09/13/2017 08:06:01: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
09/13/2017 08:06:01: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:01: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
09/13/2017 08:06:01: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:01: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
09/13/2017 08:06:01: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

09/13/2017 08:06:01: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

09/13/2017 08:06:01: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

09/13/2017 08:06:01: Starting minibatch loop.
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 4.65436707 * 2560; err = 0.81132812 * 2560; time = 0.0147s; samplesPerSecond = 174727.3
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.87611237 * 2560; err = 0.70664063 * 2560; time = 0.0107s; samplesPerSecond = 239062.4
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.30106964 * 2560; err = 0.59882813 * 2560; time = 0.0105s; samplesPerSecond = 243872.2
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.96660919 * 2560; err = 0.52539062 * 2560; time = 0.0105s; samplesPerSecond = 243770.1
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.74655914 * 2560; err = 0.48398438 * 2560; time = 0.0108s; samplesPerSecond = 237730.4
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.62835999 * 2560; err = 0.46210937 * 2560; time = 0.0105s; samplesPerSecond = 243605.4
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57696533 * 2560; err = 0.45468750 * 2560; time = 0.0105s; samplesPerSecond = 243918.7
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.47685089 * 2560; err = 0.42695312 * 2560; time = 0.0106s; samplesPerSecond = 242318.7
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.39075470 * 2560; err = 0.40625000 * 2560; time = 0.0109s; samplesPerSecond = 235549.6
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.41970062 * 2560; err = 0.42421875 * 2560; time = 0.0108s; samplesPerSecond = 236208.1
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41201630 * 2560; err = 0.43476562 * 2560; time = 0.0105s; samplesPerSecond = 243709.7
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.38169403 * 2560; err = 0.41562500 * 2560; time = 0.0105s; samplesPerSecond = 242736.9
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.34602051 * 2560; err = 0.41093750 * 2560; time = 0.0110s; samplesPerSecond = 232943.3
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.38628082 * 2560; err = 0.39843750 * 2560; time = 0.0105s; samplesPerSecond = 243842.0
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.32571716 * 2560; err = 0.39023438 * 2560; time = 0.0108s; samplesPerSecond = 236094.8
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.31520691 * 2560; err = 0.39140625 * 2560; time = 0.0106s; samplesPerSecond = 240438.8
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.26128540 * 2560; err = 0.37539062 * 2560; time = 0.0105s; samplesPerSecond = 243974.5
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.28179016 * 2560; err = 0.38593750 * 2560; time = 0.0107s; samplesPerSecond = 240319.2
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29704285 * 2560; err = 0.39062500 * 2560; time = 0.0105s; samplesPerSecond = 244466.1
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.28553772 * 2560; err = 0.39218750 * 2560; time = 0.0116s; samplesPerSecond = 220632.6
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.26621399 * 2560; err = 0.38828125 * 2560; time = 0.0106s; samplesPerSecond = 242330.2
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.21440430 * 2560; err = 0.36796875 * 2560; time = 0.0105s; samplesPerSecond = 244463.8
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.21631470 * 2560; err = 0.36992188 * 2560; time = 0.0106s; samplesPerSecond = 241381.9
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.24478760 * 2560; err = 0.37812500 * 2560; time = 0.0111s; samplesPerSecond = 231605.0
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.22629700 * 2560; err = 0.37734375 * 2560; time = 0.0106s; samplesPerSecond = 241646.2
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.15057373 * 2560; err = 0.34765625 * 2560; time = 0.0113s; samplesPerSecond = 225797.3
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.16724548 * 2560; err = 0.35156250 * 2560; time = 0.0105s; samplesPerSecond = 243881.5
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.22637939 * 2560; err = 0.36601563 * 2560; time = 0.0107s; samplesPerSecond = 239346.3
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.16267090 * 2560; err = 0.35976562 * 2560; time = 0.0106s; samplesPerSecond = 240918.5
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.16969299 * 2560; err = 0.35820313 * 2560; time = 0.0105s; samplesPerSecond = 243742.2
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.16425781 * 2560; err = 0.35195312 * 2560; time = 0.0105s; samplesPerSecond = 243447.8
09/13/2017 08:06:01:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.17123108 * 2560; err = 0.35234375 * 2560; time = 0.0106s; samplesPerSecond = 240775.7
09/13/2017 08:06:01: Finished Epoch[ 1 of 2]: [Training] ce = 1.52218781 * 81920; err = 0.42672119 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.447162s
09/13/2017 08:06:01: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

09/13/2017 08:06:01: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

09/13/2017 08:06:01: Starting minibatch loop.
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.14802532 * 2560; err = 0.35117188 * 2560; time = 0.0119s; samplesPerSecond = 214346.1
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.17314568 * 2560; err = 0.36015625 * 2560; time = 0.0117s; samplesPerSecond = 218996.2
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.23122158 * 2560; err = 0.37265625 * 2560; time = 0.0107s; samplesPerSecond = 240220.0
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.17969055 * 2560; err = 0.35898438 * 2560; time = 0.0105s; samplesPerSecond = 243962.9
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.13304825 * 2560; err = 0.34843750 * 2560; time = 0.0107s; samplesPerSecond = 238383.5
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.22006378 * 2560; err = 0.36953125 * 2560; time = 0.0106s; samplesPerSecond = 242353.1
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14098816 * 2560; err = 0.34726563 * 2560; time = 0.0106s; samplesPerSecond = 240701.0
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.12340546 * 2560; err = 0.34921875 * 2560; time = 0.0105s; samplesPerSecond = 244149.0
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.14668121 * 2560; err = 0.33945313 * 2560; time = 0.0107s; samplesPerSecond = 240321.4
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12819672 * 2560; err = 0.34960938 * 2560; time = 0.0105s; samplesPerSecond = 244158.3
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14891510 * 2560; err = 0.34687500 * 2560; time = 0.0111s; samplesPerSecond = 229650.0
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13158951 * 2560; err = 0.34296875 * 2560; time = 0.0106s; samplesPerSecond = 240694.3
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.11186981 * 2560; err = 0.33671875 * 2560; time = 0.0105s; samplesPerSecond = 243484.9
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.06695404 * 2560; err = 0.32382813 * 2560; time = 0.0106s; samplesPerSecond = 241243.2
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.05429382 * 2560; err = 0.30937500 * 2560; time = 0.0107s; samplesPerSecond = 240332.7
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.06546631 * 2560; err = 0.32851562 * 2560; time = 0.0105s; samplesPerSecond = 243746.8
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.13989563 * 2560; err = 0.34335938 * 2560; time = 0.0105s; samplesPerSecond = 243795.6
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13786621 * 2560; err = 0.35976562 * 2560; time = 0.0108s; samplesPerSecond = 236090.5
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.07601318 * 2560; err = 0.33125000 * 2560; time = 0.0105s; samplesPerSecond = 244305.1
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.06908112 * 2560; err = 0.33476563 * 2560; time = 0.0107s; samplesPerSecond = 238826.0
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.05689087 * 2560; err = 0.32656250 * 2560; time = 0.0115s; samplesPerSecond = 223128.7
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.08632202 * 2560; err = 0.32890625 * 2560; time = 0.0133s; samplesPerSecond = 192358.3
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.11229401 * 2560; err = 0.34375000 * 2560; time = 0.0105s; samplesPerSecond = 244375.1
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12421875 * 2560; err = 0.34960938 * 2560; time = 0.0108s; samplesPerSecond = 237461.4
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.08749695 * 2560; err = 0.33593750 * 2560; time = 0.0107s; samplesPerSecond = 238681.3
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.06223145 * 2560; err = 0.32812500 * 2560; time = 0.0105s; samplesPerSecond = 244237.5
09/13/2017 08:06:01:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.06559448 * 2560; err = 0.32500000 * 2560; time = 0.0106s; samplesPerSecond = 240490.8
09/13/2017 08:06:02:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.10242615 * 2560; err = 0.33007812 * 2560; time = 0.0110s; samplesPerSecond = 232281.7
09/13/2017 08:06:02:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.02162476 * 2560; err = 0.32539062 * 2560; time = 0.0105s; samplesPerSecond = 244067.5
09/13/2017 08:06:02:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.06609802 * 2560; err = 0.32617188 * 2560; time = 0.0105s; samplesPerSecond = 244744.2
09/13/2017 08:06:02:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.05944214 * 2560; err = 0.32304688 * 2560; time = 0.0105s; samplesPerSecond = 243965.2
09/13/2017 08:06:02:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.05012207 * 2560; err = 0.33242187 * 2560; time = 0.0105s; samplesPerSecond = 244819.1
09/13/2017 08:06:02: Finished Epoch[ 2 of 2]: [Training] ce = 1.11003666 * 81920; err = 0.33996582 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.348824s
09/13/2017 08:06:02: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

09/13/2017 08:06:02: Action "train" complete.


09/13/2017 08:06:02: ##############################################################################
09/13/2017 08:06:02: #                                                                            #
09/13/2017 08:06:02: # addLayer3 command (edit action)                                            #
09/13/2017 08:06:02: #                                                                            #
09/13/2017 08:06:02: ##############################################################################


09/13/2017 08:06:02: Action "edit" complete.


09/13/2017 08:06:02: ##############################################################################
09/13/2017 08:06:02: #                                                                            #
09/13/2017 08:06:02: # speechTrain command (train action)                                         #
09/13/2017 08:06:02: #                                                                            #
09/13/2017 08:06:02: ##############################################################################

09/13/2017 08:06:02: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
09/13/2017 08:06:02: 
Model has 29 nodes. Using GPU 0.

09/13/2017 08:06:02: Training criterion:   ce = CrossEntropyWithSoftmax
09/13/2017 08:06:02: Evaluation criterion: err = ClassificationError

09/13/2017 08:06:02: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

09/13/2017 08:06:02: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
09/13/2017 08:06:02: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:02: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
09/13/2017 08:06:02: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:02: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
09/13/2017 08:06:02: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:02: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
09/13/2017 08:06:02: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

09/13/2017 08:06:02: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

09/13/2017 08:06:02: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

09/13/2017 08:06:02: Starting minibatch loop.
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 3.98617706 * 2560; err = 0.81132812 * 2560; time = 0.0162s; samplesPerSecond = 158057.9
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.65327377 * 2560; err = 0.64609375 * 2560; time = 0.0137s; samplesPerSecond = 186729.1
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.04344254 * 2560; err = 0.54882812 * 2560; time = 0.0138s; samplesPerSecond = 185726.6
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.75020447 * 2560; err = 0.47851562 * 2560; time = 0.0137s; samplesPerSecond = 187194.7
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.57851944 * 2560; err = 0.44960937 * 2560; time = 0.0141s; samplesPerSecond = 181854.3
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.47935410 * 2560; err = 0.42226562 * 2560; time = 0.0140s; samplesPerSecond = 182606.7
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.43710175 * 2560; err = 0.41054687 * 2560; time = 0.0140s; samplesPerSecond = 183137.1
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.36245575 * 2560; err = 0.39609375 * 2560; time = 0.0137s; samplesPerSecond = 187285.1
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.27734070 * 2560; err = 0.37539062 * 2560; time = 0.0142s; samplesPerSecond = 180608.6
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30455475 * 2560; err = 0.39843750 * 2560; time = 0.0139s; samplesPerSecond = 183877.7
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.28724823 * 2560; err = 0.38984375 * 2560; time = 0.0139s; samplesPerSecond = 183772.1
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27779541 * 2560; err = 0.38398437 * 2560; time = 0.0146s; samplesPerSecond = 174806.1
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24093323 * 2560; err = 0.38359375 * 2560; time = 0.0138s; samplesPerSecond = 184913.6
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.31192780 * 2560; err = 0.38750000 * 2560; time = 0.0137s; samplesPerSecond = 187146.8
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.25088348 * 2560; err = 0.36796875 * 2560; time = 0.0140s; samplesPerSecond = 182818.0
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.26782379 * 2560; err = 0.38085938 * 2560; time = 0.0138s; samplesPerSecond = 185987.0
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.19906921 * 2560; err = 0.35820313 * 2560; time = 0.0137s; samplesPerSecond = 187374.2
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20673828 * 2560; err = 0.36679688 * 2560; time = 0.0142s; samplesPerSecond = 179851.1
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21287537 * 2560; err = 0.36953125 * 2560; time = 0.0139s; samplesPerSecond = 184701.5
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.20243225 * 2560; err = 0.37617187 * 2560; time = 0.0136s; samplesPerSecond = 187625.5
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.20143738 * 2560; err = 0.37460938 * 2560; time = 0.0137s; samplesPerSecond = 186525.0
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.13604126 * 2560; err = 0.34414062 * 2560; time = 0.0138s; samplesPerSecond = 185047.3
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.14999695 * 2560; err = 0.34687500 * 2560; time = 0.0136s; samplesPerSecond = 187631.0
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.18746033 * 2560; err = 0.35703125 * 2560; time = 0.0231s; samplesPerSecond = 110936.8
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.17141724 * 2560; err = 0.36210938 * 2560; time = 0.0237s; samplesPerSecond = 107921.7
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.08553772 * 2560; err = 0.33867188 * 2560; time = 0.0211s; samplesPerSecond = 121198.9
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.11324768 * 2560; err = 0.34335938 * 2560; time = 0.0138s; samplesPerSecond = 185340.7
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.17917480 * 2560; err = 0.35351562 * 2560; time = 0.0138s; samplesPerSecond = 185633.7
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.11235657 * 2560; err = 0.34375000 * 2560; time = 0.0138s; samplesPerSecond = 186152.0
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.13317871 * 2560; err = 0.34257813 * 2560; time = 0.0140s; samplesPerSecond = 183072.9
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12384949 * 2560; err = 0.34062500 * 2560; time = 0.0142s; samplesPerSecond = 180847.2
09/13/2017 08:06:02:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.12303772 * 2560; err = 0.34257813 * 2560; time = 0.0141s; samplesPerSecond = 181606.7
09/13/2017 08:06:02: Finished Epoch[ 1 of 4]: [Training] ce = 1.40771523 * 81920; err = 0.40285645 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.575239s
09/13/2017 08:06:02: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

09/13/2017 08:06:02: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

09/13/2017 08:06:02: Starting minibatch loop.
09/13/2017 08:06:02:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.50690136 * 5120; err = 0.41445312 * 5120; time = 0.0202s; samplesPerSecond = 253916.6
09/13/2017 08:06:02:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.43394032 * 5120; err = 0.40312500 * 5120; time = 0.0196s; samplesPerSecond = 261868.5
09/13/2017 08:06:02:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.19498672 * 5120; err = 0.36425781 * 5120; time = 0.0184s; samplesPerSecond = 278265.4
09/13/2017 08:06:02:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.13462753 * 5120; err = 0.34609375 * 5120; time = 0.0190s; samplesPerSecond = 270137.7
09/13/2017 08:06:02:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.12732811 * 5120; err = 0.34101562 * 5120; time = 0.0184s; samplesPerSecond = 277699.4
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.13973351 * 5120; err = 0.34941406 * 5120; time = 0.0188s; samplesPerSecond = 271974.4
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.09274750 * 5120; err = 0.33613281 * 5120; time = 0.0184s; samplesPerSecond = 277960.2
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07956161 * 5120; err = 0.33359375 * 5120; time = 0.0184s; samplesPerSecond = 277720.5
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.14393692 * 5120; err = 0.35195312 * 5120; time = 0.0186s; samplesPerSecond = 274884.6
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06811905 * 5120; err = 0.33457031 * 5120; time = 0.0184s; samplesPerSecond = 278440.9
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.06341400 * 5120; err = 0.33496094 * 5120; time = 0.0184s; samplesPerSecond = 278170.2
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.12287140 * 5120; err = 0.35117188 * 5120; time = 0.0192s; samplesPerSecond = 266841.8
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.09922638 * 5120; err = 0.34550781 * 5120; time = 0.0184s; samplesPerSecond = 278515.2
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.08422241 * 5120; err = 0.32832031 * 5120; time = 0.0184s; samplesPerSecond = 278528.8
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.03713837 * 5120; err = 0.32539062 * 5120; time = 0.0191s; samplesPerSecond = 268048.8
09/13/2017 08:06:03:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05823059 * 5120; err = 0.32636719 * 5120; time = 0.0184s; samplesPerSecond = 278656.1
09/13/2017 08:06:03: Finished Epoch[ 2 of 4]: [Training] ce = 1.14918661 * 81920; err = 0.34914551 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.303098s
09/13/2017 08:06:03: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

09/13/2017 08:06:03: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

09/13/2017 08:06:03: Starting minibatch loop.
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.11066446 * 5120; err = 0.34218750 * 5120; time = 0.0191s; samplesPerSecond = 267645.2
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10631495 * 5120; err = 0.34511719 * 5120; time = 0.0184s; samplesPerSecond = 277785.3
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.09502583 * 5120; err = 0.34394531 * 5120; time = 0.0188s; samplesPerSecond = 272352.0
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.14925079 * 5120; err = 0.34570312 * 5120; time = 0.0186s; samplesPerSecond = 275016.0
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.13400726 * 5120; err = 0.34199219 * 5120; time = 0.0187s; samplesPerSecond = 273685.6
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.07996712 * 5120; err = 0.33652344 * 5120; time = 0.0191s; samplesPerSecond = 268075.5
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.07324677 * 5120; err = 0.33085938 * 5120; time = 0.0184s; samplesPerSecond = 278038.7
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.06941147 * 5120; err = 0.33046875 * 5120; time = 0.0184s; samplesPerSecond = 277954.2
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.02541656 * 5120; err = 0.31171875 * 5120; time = 0.0187s; samplesPerSecond = 274210.3
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.04684372 * 5120; err = 0.31835938 * 5120; time = 0.0189s; samplesPerSecond = 270906.6
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05219879 * 5120; err = 0.33691406 * 5120; time = 0.0184s; samplesPerSecond = 278195.9
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07827148 * 5120; err = 0.33300781 * 5120; time = 0.0208s; samplesPerSecond = 246156.2
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05986786 * 5120; err = 0.32187500 * 5120; time = 0.0185s; samplesPerSecond = 276752.3
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02186890 * 5120; err = 0.31972656 * 5120; time = 0.0195s; samplesPerSecond = 262957.9
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.04579926 * 5120; err = 0.32832031 * 5120; time = 0.0184s; samplesPerSecond = 278404.6
09/13/2017 08:06:03:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.02374115 * 5120; err = 0.32285156 * 5120; time = 0.0188s; samplesPerSecond = 272252.1
09/13/2017 08:06:03: Finished Epoch[ 3 of 4]: [Training] ce = 1.07324352 * 81920; err = 0.33184814 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.304397s
09/13/2017 08:06:03: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

09/13/2017 08:06:03: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

09/13/2017 08:06:03: Starting minibatch loop.
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02762766 * 5120; err = 0.31425781 * 5120; time = 0.0189s; samplesPerSecond = 270403.0
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.04846405 * 4926; err = 0.32866423 * 4926; time = 0.0589s; samplesPerSecond = 83593.1
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.01424675 * 5120; err = 0.32382813 * 5120; time = 0.0193s; samplesPerSecond = 265848.4
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 0.99905319 * 5120; err = 0.31582031 * 5120; time = 0.0184s; samplesPerSecond = 278351.6
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 0.99530144 * 5120; err = 0.31191406 * 5120; time = 0.0189s; samplesPerSecond = 271236.7
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00318260 * 5120; err = 0.32304688 * 5120; time = 0.0188s; samplesPerSecond = 272700.2
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01893272 * 5120; err = 0.31933594 * 5120; time = 0.0185s; samplesPerSecond = 276804.6
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 0.99314346 * 5120; err = 0.31054688 * 5120; time = 0.0184s; samplesPerSecond = 278955.2
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99949417 * 5120; err = 0.30625000 * 5120; time = 0.0184s; samplesPerSecond = 278223.1
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.99980240 * 5120; err = 0.31035156 * 5120; time = 0.0186s; samplesPerSecond = 275952.8
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.02506561 * 5120; err = 0.31738281 * 5120; time = 0.0184s; samplesPerSecond = 278691.0
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.03906784 * 5120; err = 0.32265625 * 5120; time = 0.0184s; samplesPerSecond = 278091.6
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.97148972 * 5120; err = 0.29550781 * 5120; time = 0.0187s; samplesPerSecond = 274436.7
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.97292023 * 5120; err = 0.30605469 * 5120; time = 0.0193s; samplesPerSecond = 264928.1
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.98358307 * 5120; err = 0.31269531 * 5120; time = 0.0187s; samplesPerSecond = 273811.4
09/13/2017 08:06:03:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.98013763 * 5120; err = 0.29785156 * 5120; time = 0.0195s; samplesPerSecond = 262164.8
09/13/2017 08:06:03: Finished Epoch[ 4 of 4]: [Training] ce = 1.00425825 * 81920; err = 0.31357422 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.344105s
09/13/2017 08:06:04: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech'

09/13/2017 08:06:04: Action "train" complete.


09/13/2017 08:06:04: ##############################################################################
09/13/2017 08:06:04: #                                                                            #
09/13/2017 08:06:04: # replaceCriterionNode command (edit action)                                 #
09/13/2017 08:06:04: #                                                                            #
09/13/2017 08:06:04: ##############################################################################


09/13/2017 08:06:04: Action "edit" complete.


09/13/2017 08:06:04: ##############################################################################
09/13/2017 08:06:04: #                                                                            #
09/13/2017 08:06:04: # sequenceTrain command (train action)                                       #
09/13/2017 08:06:04: #                                                                            #
09/13/2017 08:06:04: ##############################################################################

09/13/2017 08:06:04: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/model.overalltying', '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list', '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/TestData/CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
09/13/2017 08:06:04: 
Model has 29 nodes. Using GPU 0.

09/13/2017 08:06:04: Training criterion:   ce = SequenceWithSoftmax
09/13/2017 08:06:04: Evaluation criterion: err = ClassificationError

09/13/2017 08:06:04: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

09/13/2017 08:06:04: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
09/13/2017 08:06:04: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:04: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
09/13/2017 08:06:04: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:04: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
09/13/2017 08:06:04: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
09/13/2017 08:06:04: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
09/13/2017 08:06:04: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

09/13/2017 08:06:04: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-10
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

09/13/2017 08:06:04: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

09/13/2017 08:06:08: Starting minibatch loop.
dengamma value 1.008841
dengamma value 1.085194
dengamma value 1.025338
dengamma value 1.074486
dengamma value 1.034135
dengamma value 1.067884
dengamma value 1.018817
dengamma value 1.016073
dengamma value 1.140176
dengamma value 0.947565
dengamma value 1.000704
dengamma value 1.053940
dengamma value 1.038855
dengamma value 1.065405
dengamma value 1.027088
dengamma value 1.075509
dengamma value 1.058584
dengamma value 1.076742
dengamma value 0.998571
dengamma value 1.033484
dengamma value 1.042010
dengamma value 1.068278
09/13/2017 08:06:10:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08750310 * 5566; err = 0.32375135 * 5566; time = 1.8487s; samplesPerSecond = 3010.7
dengamma value 0.991744
dengamma value 1.040674
dengamma value 1.028861
dengamma value 1.016841
dengamma value 1.017190
dengamma value 1.060319
dengamma value 1.118875
dengamma value 1.030734
dengamma value 1.024671
dengamma value 0.988820
dengamma value 0.989111
dengamma value 1.063772
dengamma value 1.027828
dengamma value 0.996721
dengamma value 1.039789
dengamma value 0.994413
dengamma value 1.002801
dengamma value 1.050477
dengamma value 1.018514
dengamma value 1.086582
dengamma value 1.030897
dengamma value 1.069502
dengamma value 1.046400
dengamma value 1.192164
dengamma value 1.056906
dengamma value 1.057931
09/13/2017 08:06:11:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08130391 * 7398; err = 0.30778589 * 7398; time = 0.9260s; samplesPerSecond = 7989.5
dengamma value 1.103977
dengamma value 0.988252
dengamma value 1.034532
dengamma value 0.974476
dengamma value 1.040092
dengamma value 1.053154
dengamma value 1.074843
dengamma value 1.053740
dengamma value 1.085527
dengamma value 1.081460
dengamma value 1.009842
dengamma value 1.063315
dengamma value 1.039252
dengamma value 0.938136
dengamma value 1.094459
dengamma value 1.034039
dengamma value 1.101370
dengamma value 1.008088
dengamma value 1.020526
dengamma value 1.049726
dengamma value 1.040296
dengamma value 1.043515
dengamma value 1.029769
dengamma value 1.108316
dengamma value 1.084725
09/13/2017 08:06:12:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07942883 * 6300; err = 0.33619048 * 6300; time = 0.6371s; samplesPerSecond = 9888.8
dengamma value 1.093486
dengamma value 1.178901
dengamma value 1.061327
dengamma value 1.047943
dengamma value 1.025990
dengamma value 0.992539
dengamma value 0.997466
dengamma value 1.049416
dengamma value 1.107488
dengamma value 1.030212
dengamma value 1.034844
dengamma value 1.061938
dengamma value 1.081900
dengamma value 1.039091
dengamma value 1.101087
dengamma value 1.045482
dengamma value 0.997426
dengamma value 1.038248
dengamma value 1.011327
dengamma value 0.982059
dengamma value 0.931988
dengamma value 1.043640
09/13/2017 08:06:12:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08143162 * 5636; err = 0.31334280 * 5636; time = 0.5593s; samplesPerSecond = 10076.2
dengamma value 1.039318
dengamma value 1.026706
dengamma value 1.040453
dengamma value 1.062576
dengamma value 1.049323
dengamma value 1.072130
dengamma value 1.051233
dengamma value 1.026497
dengamma value 0.943670
dengamma value 1.033379
dengamma value 1.016051
dengamma value 1.055629
dengamma value 1.046404
dengamma value 0.952629
dengamma value 1.047428
dengamma value 0.986414
dengamma value 1.081676
dengamma value 1.023222
dengamma value 1.055470
dengamma value 0.963920
09/13/2017 08:06:13:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08225159 * 6970; err = 0.33486370 * 6970; time = 0.7143s; samplesPerSecond = 9758.3
dengamma value 1.057528
dengamma value 1.037151
dengamma value 1.046926
dengamma value 1.040665
dengamma value 1.060579
dengamma value 1.062784
dengamma value 1.043095
dengamma value 1.068987
dengamma value 1.050567
dengamma value 1.046452
dengamma value 1.009937
dengamma value 1.055749
dengamma value 1.027543
dengamma value 1.054878
dengamma value 1.010436
dengamma value 1.084317
dengamma value 1.049647
dengamma value 0.990676
dengamma value 1.120230
dengamma value 1.000082
dengamma value 1.003248
dengamma value 1.061295
09/13/2017 08:06:14:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08136405 * 6996; err = 0.31303602 * 6996; time = 0.7405s; samplesPerSecond = 9448.0
dengamma value 1.073056
dengamma value 1.019430
dengamma value 1.052450
dengamma value 1.044859
dengamma value 0.992916
dengamma value 1.003975
dengamma value 1.033589
dengamma value 0.978712
dengamma value 1.117399
dengamma value 1.000439
dengamma value 1.040897
dengamma value 0.993711
dengamma value 1.072628
dengamma value 1.084370
dengamma value 1.093115
dengamma value 0.978209
dengamma value 0.987798
dengamma value 1.041859
dengamma value 1.023424
dengamma value 1.113575
dengamma value 1.027061
dengamma value 1.057993
dengamma value 1.084030
dengamma value 1.018223
dengamma value 1.008533
09/13/2017 08:06:14:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08628917 * 6180; err = 0.32928803 * 6180; time = 0.6451s; samplesPerSecond = 9579.6
dengamma value 1.038358
dengamma value 1.061339
dengamma value 1.128848
dengamma value 1.001496
dengamma value 1.071049
dengamma value 1.034228
dengamma value 0.996200
dengamma value 1.056987
dengamma value 1.024025
dengamma value 1.038541
dengamma value 1.026122
dengamma value 1.030853
dengamma value 1.082026
dengamma value 0.970105
dengamma value 1.107367
dengamma value 1.040175
dengamma value 1.036684
dengamma value 1.108900
dengamma value 1.052140
dengamma value 1.111189
09/13/2017 08:06:15:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08514133 * 4860; err = 0.32613169 * 4860; time = 0.4861s; samplesPerSecond = 9998.9
dengamma value 1.023447
dengamma value 0.964223
dengamma value 1.015667
dengamma value 1.064445
dengamma value 1.027814
dengamma value 1.075037
dengamma value 1.001812
dengamma value 1.061933
dengamma value 1.013729
dengamma value 0.990792
dengamma value 1.028593
dengamma value 0.944542
dengamma value 1.027259
dengamma value 1.070704
dengamma value 1.042022
dengamma value 1.094154
dengamma value 1.055867
dengamma value 1.038127
dengamma value 1.036081
dengamma value 1.011426
dengamma value 1.097986
dengamma value 1.063161
09/13/2017 08:06:15:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.07797180 * 6046; err = 0.32385048 * 6046; time = 0.6299s; samplesPerSecond = 9597.9
dengamma value 1.038962
dengamma value 1.001267
dengamma value 1.008710
dengamma value 0.962693
dengamma value 1.017697
dengamma value 1.095322
dengamma value 1.032947
dengamma value 0.991282
dengamma value 1.031265
dengamma value 1.052870
dengamma value 0.993829
dengamma value 1.021595
dengamma value 1.048342
dengamma value 1.075945
dengamma value 0.986916
dengamma value 1.055220
dengamma value 1.000935
dengamma value 1.009760
dengamma value 0.994788
dengamma value 1.000459
dengamma value 0.992584
dengamma value 1.060021
dengamma value 1.016328
dengamma value 1.027118
09/13/2017 08:06:16:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08762370 * 6942; err = 0.33448574 * 6942; time = 0.6841s; samplesPerSecond = 10148.3
dengamma value 1.014677
dengamma value 1.040413
dengamma value 0.999303
dengamma value 0.933811
dengamma value 1.063008
dengamma value 1.083882
dengamma value 1.134624
dengamma value 1.010726
dengamma value 1.027117
dengamma value 1.102374
dengamma value 1.063599
dengamma value 1.004636
dengamma value 1.058152
dengamma value 1.024431
dengamma value 1.103674
dengamma value 1.011564
dengamma value 1.034909
dengamma value 1.050767
dengamma value 1.005300
dengamma value 1.002198
dengamma value 0.974519
dengamma value 1.060513
dengamma value 1.059235
09/13/2017 08:06:17:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08880767 * 5784; err = 0.32538036 * 5784; time = 0.5615s; samplesPerSecond = 10300.7
dengamma value 1.071071
dengamma value 1.076211
dengamma value 1.009339
dengamma value 1.008009
dengamma value 1.119732
dengamma value 0.993566
dengamma value 0.963221
dengamma value 0.959549
dengamma value 0.939643
dengamma value 1.025511
dengamma value 1.029979
dengamma value 0.982482
dengamma value 1.060550
dengamma value 1.025388
dengamma value 1.061591
dengamma value 0.978702
dengamma value 1.012145
dengamma value 1.040040
dengamma value 1.060201
dengamma value 0.984428
dengamma value 1.095838
09/13/2017 08:06:17:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08952369 * 6258; err = 0.33349313 * 6258; time = 0.6192s; samplesPerSecond = 10106.5
dengamma value 1.096456
dengamma value 1.069737
dengamma value 1.065284
dengamma value 1.070971
dengamma value 1.017988
dengamma value 1.109675
dengamma value 1.067634
dengamma value 1.017616
dengamma value 1.035989
dengamma value 1.015318
dengamma value 1.020681
dengamma value 1.060468
dengamma value 1.041688
dengamma value 1.071516
dengamma value 0.961953
dengamma value 1.003899
dengamma value 1.055702
dengamma value 1.012114
dengamma value 1.096132
dengamma value 1.000168
dengamma value 1.021164
dengamma value 0.964921
09/13/2017 08:06:18:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08373600 * 6116; err = 0.31916285 * 6116; time = 0.6214s; samplesPerSecond = 9841.9
dengamma value 1.036081
dengamma value 1.043018
dengamma value 1.003546
dengamma value 1.043051
09/13/2017 08:06:18: Finished Epoch[ 1 of 3]: [Training] ce = 0.08413421 * 82574; err = 0.32436360 * 82574; totalSamplesSeen = 82574; learningRatePerSample = 2e-06; epochTime=14.2179s
09/13/2017 08:06:18: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

09/13/2017 08:06:18: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 82146), data subset 0 of 1, with 1 datapasses

09/13/2017 08:06:18: Starting minibatch loop.
dengamma value 1.026234
dengamma value 1.001366
dengamma value 0.985253
dengamma value 1.068898
dengamma value 1.066866
dengamma value 1.002745
dengamma value 1.053431
dengamma value 1.005789
dengamma value 1.025691
dengamma value 1.028875
dengamma value 1.037931
dengamma value 0.998758
dengamma value 1.046749
dengamma value 1.091506
dengamma value 0.966711
dengamma value 0.991190
dengamma value 1.016062
dengamma value 1.019956
dengamma value 1.056815
dengamma value 1.042773
dengamma value 1.059856
dengamma value 1.081251
09/13/2017 08:06:19:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08402468 * 5826; err = 0.33539307 * 5826; time = 0.6014s; samplesPerSecond = 9687.0
dengamma value 1.062408
dengamma value 1.096100
dengamma value 1.079043
dengamma value 1.044474
dengamma value 1.041381
dengamma value 1.005939
dengamma value 1.085112
dengamma value 1.083315
dengamma value 1.094617
dengamma value 1.043673
dengamma value 1.033490
dengamma value 0.953517
dengamma value 1.073397
dengamma value 1.072804
dengamma value 1.036389
dengamma value 1.044346
dengamma value 1.033287
dengamma value 1.024943
dengamma value 1.050379
dengamma value 1.009537
09/13/2017 08:06:19:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08047001 * 6380; err = 0.30909091 * 6380; time = 0.6828s; samplesPerSecond = 9344.4
dengamma value 1.096152
dengamma value 1.021241
dengamma value 1.113126
dengamma value 0.940178
dengamma value 1.020854
dengamma value 1.071345
dengamma value 1.105526
dengamma value 1.035080
dengamma value 1.068225
dengamma value 1.020310
dengamma value 0.987172
dengamma value 1.082961
dengamma value 1.019599
dengamma value 1.054024
dengamma value 1.013099
dengamma value 1.017769
dengamma value 1.051272
dengamma value 1.070711
dengamma value 1.036566
dengamma value 1.033150
dengamma value 1.080119
dengamma value 1.060028
dengamma value 0.989505
09/13/2017 08:06:20:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07858492 * 6574; err = 0.31928810 * 6574; time = 0.7299s; samplesPerSecond = 9007.3
dengamma value 1.073607
dengamma value 1.047425
dengamma value 1.051628
dengamma value 1.052244
dengamma value 0.929417
dengamma value 0.959502
dengamma value 1.123960
dengamma value 1.075783
dengamma value 1.022401
dengamma value 1.025976
dengamma value 1.047565
dengamma value 0.968774
dengamma value 1.050725
dengamma value 1.003764
dengamma value 0.959882
dengamma value 1.078518
dengamma value 1.055962
dengamma value 1.092586
dengamma value 0.990887
dengamma value 0.984946
dengamma value 1.072782
dengamma value 1.115612
dengamma value 1.006176
09/13/2017 08:06:21:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08820159 * 6324; err = 0.32748261 * 6324; time = 0.6228s; samplesPerSecond = 10153.9
dengamma value 0.959746
dengamma value 0.939973
dengamma value 0.938430
dengamma value 1.052494
dengamma value 1.072435
dengamma value 1.097949
dengamma value 1.042134
dengamma value 1.140450
dengamma value 1.027290
dengamma value 0.980654
dengamma value 1.007722
dengamma value 1.013903
dengamma value 0.959916
dengamma value 1.089715
dengamma value 1.040172
dengamma value 0.994134
dengamma value 0.941357
dengamma value 0.996071
dengamma value 1.015786
dengamma value 1.045942
09/13/2017 08:06:21:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.09160568 * 4800; err = 0.35354167 * 4800; time = 0.4609s; samplesPerSecond = 10414.7
dengamma value 0.997079
dengamma value 1.042612
dengamma value 1.046828
dengamma value 1.043382
dengamma value 1.038758
dengamma value 1.114746
dengamma value 1.087490
dengamma value 1.023579
dengamma value 1.063902
dengamma value 1.010815
dengamma value 1.066814
dengamma value 1.013893
dengamma value 0.978798
dengamma value 0.992032
dengamma value 1.057654
dengamma value 1.024759
dengamma value 1.022264
dengamma value 1.014779
dengamma value 1.013870
dengamma value 1.035180
dengamma value 1.019749
dengamma value 1.051035
09/13/2017 08:06:22:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08248320 * 6176; err = 0.34536917 * 6176; time = 0.5935s; samplesPerSecond = 10406.8
dengamma value 1.081082
dengamma value 1.053723
dengamma value 1.059441
dengamma value 0.985692
dengamma value 1.073489
dengamma value 1.045836
dengamma value 1.081961
dengamma value 0.958697
dengamma value 1.059378
dengamma value 1.032676
dengamma value 1.066407
dengamma value 1.018589
dengamma value 1.061937
dengamma value 0.998456
dengamma value 1.070245
dengamma value 1.037019
dengamma value 1.083580
dengamma value 1.133505
dengamma value 1.035149
dengamma value 0.971782
dengamma value 1.078471
dengamma value 1.051742
dengamma value 1.040464
09/13/2017 08:06:22:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.09001567 * 5534; err = 0.30701120 * 5534; time = 0.5946s; samplesPerSecond = 9306.4
dengamma value 1.059127
dengamma value 1.003320
dengamma value 0.990941
dengamma value 1.030535
dengamma value 1.112549
dengamma value 0.954646
dengamma value 1.072236
dengamma value 1.063881
dengamma value 1.050130
dengamma value 1.047795
dengamma value 1.099023
dengamma value 1.103293
dengamma value 1.038908
dengamma value 1.078620
dengamma value 1.044640
dengamma value 1.038535
dengamma value 1.047188
dengamma value 0.987904
dengamma value 1.065102
dengamma value 1.032622
dengamma value 0.991319
dengamma value 1.064365
09/13/2017 08:06:23:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08346603 * 5936; err = 0.30727763 * 5936; time = 0.6903s; samplesPerSecond = 8599.3
dengamma value 0.916645
dengamma value 1.066881
dengamma value 1.067936
dengamma value 1.053333
dengamma value 1.068814
dengamma value 1.007284
dengamma value 1.073793
dengamma value 1.028003
dengamma value 1.028576
dengamma value 1.061948
dengamma value 0.905227
dengamma value 1.061401
dengamma value 1.111943
dengamma value 1.072979
dengamma value 0.999714
dengamma value 1.086076
dengamma value 1.086277
dengamma value 1.075488
dengamma value 1.094804
dengamma value 1.095705
dengamma value 1.056962
09/13/2017 08:06:24:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08399349 * 5248; err = 0.31535823 * 5248; time = 0.5325s; samplesPerSecond = 9855.8
dengamma value 1.039215
dengamma value 1.032820
dengamma value 1.050025
dengamma value 1.016757
dengamma value 1.058063
dengamma value 1.062193
dengamma value 1.040324
dengamma value 0.985286
dengamma value 1.055850
dengamma value 1.029734
dengamma value 1.108974
dengamma value 1.077926
dengamma value 0.975938
dengamma value 1.060539
dengamma value 1.097365
dengamma value 1.021031
dengamma value 1.090736
dengamma value 1.105321
dengamma value 1.049869
dengamma value 1.026719
dengamma value 1.005483
dengamma value 1.052210
dengamma value 1.040125
dengamma value 1.059011
dengamma value 1.025624
dengamma value 1.067472
09/13/2017 08:06:24:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08245729 * 6888; err = 0.30778165 * 6888; time = 0.7190s; samplesPerSecond = 9580.2
dengamma value 1.047058
dengamma value 1.066428
dengamma value 1.022881
dengamma value 1.045800
dengamma value 1.015040
dengamma value 1.028773
dengamma value 1.011271
dengamma value 1.085342
dengamma value 1.066984
dengamma value 1.020837
dengamma value 1.033176
dengamma value 1.084169
dengamma value 1.073746
dengamma value 1.005096
dengamma value 1.089204
dengamma value 1.010405
dengamma value 1.002802
dengamma value 1.103518
dengamma value 1.055227
dengamma value 1.028560
dengamma value 1.014090
dengamma value 1.017507
dengamma value 0.976535
dengamma value 1.031833
09/13/2017 08:06:25:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08702462 * 6572; err = 0.32942788 * 6572; time = 0.6572s; samplesPerSecond = 9999.2
dengamma value 0.995057
dengamma value 1.078018
dengamma value 1.009170
dengamma value 1.084809
dengamma value 1.040553
dengamma value 1.010623
dengamma value 1.008191
dengamma value 1.064831
dengamma value 1.030258
dengamma value 1.002878
dengamma value 1.059475
dengamma value 1.058126
dengamma value 1.059002
dengamma value 1.041974
dengamma value 1.027803
dengamma value 1.027157
dengamma value 1.019621
dengamma value 1.099196
dengamma value 0.998418
dengamma value 1.051362
dengamma value 1.048469
dengamma value 1.126825
dengamma value 1.065290
dengamma value 1.025583
09/13/2017 08:06:26:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08715083 * 6622; err = 0.31168831 * 6622; time = 0.7273s; samplesPerSecond = 9105.1
dengamma value 1.030361
dengamma value 1.083473
dengamma value 1.013755
dengamma value 0.985148
dengamma value 1.034568
dengamma value 1.012207
dengamma value 0.949544
dengamma value 0.979111
dengamma value 0.945821
dengamma value 1.043741
dengamma value 1.070050
dengamma value 1.133418
dengamma value 1.089148
dengamma value 1.090626
dengamma value 1.021437
dengamma value 1.040010
dengamma value 1.000978
dengamma value 1.043711
dengamma value 1.024109
dengamma value 0.967698
dengamma value 1.041114
dengamma value 1.086178
dengamma value 1.032429
09/13/2017 08:06:26:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08842217 * 5824; err = 0.31713599 * 5824; time = 0.5535s; samplesPerSecond = 10522.6
dengamma value 0.972154
dengamma value 1.034843
dengamma value 1.099476
dengamma value 0.966951
dengamma value 1.010185
dengamma value 1.091867
dengamma value 1.059874
dengamma value 1.146718
dengamma value 1.031308
09/13/2017 08:06:27: Finished Epoch[ 2 of 3]: [Training] ce = 0.08496348 * 81776; err = 0.32074203 * 81776; totalSamplesSeen = 164350; learningRatePerSample = 2e-06; epochTime=8.50828s
09/13/2017 08:06:27: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

09/13/2017 08:06:27: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163922), data subset 0 of 1, with 1 datapasses

09/13/2017 08:06:27: Starting minibatch loop.
dengamma value 1.073804
dengamma value 1.030240
dengamma value 1.057527
dengamma value 1.079466
dengamma value 1.084639
dengamma value 0.997173
dengamma value 1.031587
dengamma value 0.996669
dengamma value 1.005953
dengamma value 1.002350
dengamma value 1.040235
dengamma value 1.039280
dengamma value 1.023068
dengamma value 1.051712
dengamma value 1.053113
dengamma value 1.117158
dengamma value 1.005309
dengamma value 1.110323
dengamma value 1.020123
dengamma value 1.069409
dengamma value 0.994036
dengamma value 1.044465
dengamma value 1.096410
09/13/2017 08:06:27:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08337985 * 5074; err = 0.32893181 * 5074; time = 0.5501s; samplesPerSecond = 9224.3
dengamma value 1.001123
dengamma value 1.091521
dengamma value 1.056386
dengamma value 1.067119
dengamma value 0.988121
dengamma value 0.985186
dengamma value 0.995445
dengamma value 0.990105
dengamma value 1.099170
dengamma value 1.065730
dengamma value 1.032188
dengamma value 1.025247
dengamma value 1.029333
dengamma value 1.025129
dengamma value 1.086401
dengamma value 1.086628
dengamma value 1.028774
dengamma value 1.037732
dengamma value 1.082319
dengamma value 0.959281
dengamma value 1.039561
dengamma value 1.018666
09/13/2017 08:06:28:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08112655 * 7136; err = 0.31460202 * 7136; time = 0.7118s; samplesPerSecond = 10024.7
dengamma value 1.091115
dengamma value 1.012088
dengamma value 0.988859
dengamma value 1.007703
dengamma value 1.069467
dengamma value 1.023944
dengamma value 1.104907
dengamma value 0.990211
dengamma value 1.019103
dengamma value 1.051252
dengamma value 1.082593
dengamma value 1.044986
dengamma value 1.091374
dengamma value 1.009803
dengamma value 1.069108
dengamma value 1.022206
dengamma value 1.036131
dengamma value 1.012256
dengamma value 1.099589
dengamma value 1.110977
dengamma value 1.022396
dengamma value 1.003570
dengamma value 1.006993
09/13/2017 08:06:29:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.09322603 * 5504; err = 0.33466570 * 5504; time = 0.5828s; samplesPerSecond = 9444.1
dengamma value 1.050987
dengamma value 1.056841
dengamma value 1.052149
dengamma value 1.071806
dengamma value 1.052082
dengamma value 0.992502
dengamma value 1.062953
dengamma value 1.081206
dengamma value 1.016491
dengamma value 1.117841
dengamma value 1.041248
dengamma value 1.054823
dengamma value 1.045902
dengamma value 1.093822
dengamma value 0.972674
dengamma value 1.055520
dengamma value 0.999790
dengamma value 1.019816
dengamma value 0.934512
dengamma value 1.133695
dengamma value 1.051241
09/13/2017 08:06:29:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08478160 * 6028; err = 0.32232913 * 6028; time = 0.6432s; samplesPerSecond = 9372.1
dengamma value 1.053125
dengamma value 1.093209
dengamma value 1.048194
dengamma value 1.060971
dengamma value 0.984667
dengamma value 0.975141
dengamma value 1.037959
dengamma value 0.996440
dengamma value 1.035971
dengamma value 1.103849
dengamma value 1.067413
dengamma value 1.027395
dengamma value 1.060371
dengamma value 1.055101
dengamma value 1.048785
dengamma value 1.007918
dengamma value 1.016432
dengamma value 1.140498
dengamma value 1.014446
dengamma value 1.034749
dengamma value 1.026881
09/13/2017 08:06:30:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08553974 * 6028; err = 0.32548109 * 6028; time = 0.5946s; samplesPerSecond = 10137.3
dengamma value 1.024626
dengamma value 1.044267
dengamma value 1.011789
dengamma value 0.989843
dengamma value 1.047754
dengamma value 1.095171
dengamma value 1.087591
dengamma value 1.062788
dengamma value 0.972271
dengamma value 1.162016
dengamma value 0.991897
dengamma value 0.986547
dengamma value 1.056259
dengamma value 1.034452
dengamma value 1.035406
dengamma value 1.076275
dengamma value 0.989412
dengamma value 0.982504
dengamma value 1.051448
dengamma value 1.010935
dengamma value 1.051228
dengamma value 1.032403
dengamma value 1.006143
dengamma value 1.017157
09/13/2017 08:06:30:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08525310 * 6782; err = 0.32335594 * 6782; time = 0.6811s; samplesPerSecond = 9958.1
dengamma value 1.063194
dengamma value 1.052038
dengamma value 1.096642
dengamma value 1.019889
dengamma value 1.092369
dengamma value 1.038445
dengamma value 1.089841
dengamma value 1.101643
dengamma value 1.069613
dengamma value 1.008538
dengamma value 1.068704
dengamma value 1.093538
dengamma value 0.993018
dengamma value 1.124641
dengamma value 1.118679
dengamma value 1.003281
dengamma value 1.044743
dengamma value 1.107166
dengamma value 1.061776
dengamma value 0.987723
dengamma value 1.022270
09/13/2017 08:06:31:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07928934 * 5458; err = 0.29094907 * 5458; time = 0.6193s; samplesPerSecond = 8813.4
dengamma value 1.058295
dengamma value 1.013550
dengamma value 1.071634
dengamma value 1.059917
dengamma value 1.209002
dengamma value 1.093331
dengamma value 0.975356
dengamma value 1.073239
dengamma value 1.075979
dengamma value 1.041129
dengamma value 1.040477
dengamma value 1.074668
dengamma value 1.119160
dengamma value 1.152678
dengamma value 1.039656
dengamma value 1.063701
dengamma value 1.014873
dengamma value 1.014979
dengamma value 1.001323
dengamma value 1.102249
dengamma value 1.075165
dengamma value 1.111298
dengamma value 1.083456
dengamma value 1.094303
dengamma value 1.012786
09/13/2017 08:06:32:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08024230 * 6610; err = 0.28986384 * 6610; time = 0.6930s; samplesPerSecond = 9537.7
dengamma value 1.067045
dengamma value 1.063641
dengamma value 1.096127
dengamma value 1.071858
dengamma value 1.058292
dengamma value 0.968467
dengamma value 1.022181
dengamma value 1.067187
dengamma value 1.074484
dengamma value 1.058501
dengamma value 1.023547
dengamma value 0.949855
dengamma value 1.114869
dengamma value 1.090560
dengamma value 1.012478
dengamma value 1.040599
dengamma value 0.910799
dengamma value 1.053711
dengamma value 1.101502
dengamma value 1.052039
dengamma value 1.025512
dengamma value 1.076053
dengamma value 1.031103
09/13/2017 08:06:32:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08545289 * 5854; err = 0.31311923 * 5854; time = 0.5695s; samplesPerSecond = 10278.6
dengamma value 1.053573
dengamma value 1.122645
dengamma value 1.091665
dengamma value 0.876864
dengamma value 1.040731
dengamma value 1.058929
dengamma value 0.973770
dengamma value 1.074116
dengamma value 1.013218
dengamma value 1.015741
dengamma value 1.021158
dengamma value 1.004133
dengamma value 1.097489
dengamma value 1.043709
dengamma value 1.099812
dengamma value 1.072597
dengamma value 1.042430
dengamma value 1.099120
dengamma value 1.026386
dengamma value 0.969443
dengamma value 1.027531
dengamma value 1.061105
dengamma value 1.020049
09/13/2017 08:06:33:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08941345 * 4674; err = 0.32477535 * 4674; time = 0.4783s; samplesPerSecond = 9772.8
dengamma value 0.997440
dengamma value 1.030560
dengamma value 1.053682
dengamma value 1.073568
dengamma value 1.029928
dengamma value 1.068867
dengamma value 1.038221
dengamma value 1.004388
dengamma value 1.110721
dengamma value 1.035630
dengamma value 1.031283
dengamma value 1.056553
dengamma value 1.061519
dengamma value 1.000451
dengamma value 0.915717
dengamma value 0.977689
dengamma value 1.000977
dengamma value 1.049161
dengamma value 1.030410
dengamma value 0.974899
dengamma value 1.082388
09/13/2017 08:06:33:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08215160 * 6248; err = 0.32314341 * 6248; time = 0.6279s; samplesPerSecond = 9950.9
dengamma value 0.968392
dengamma value 1.046338
dengamma value 1.045796
dengamma value 1.065776
dengamma value 1.124346
dengamma value 1.023105
dengamma value 1.046735
dengamma value 1.049853
dengamma value 1.087243
dengamma value 1.002535
dengamma value 0.995024
dengamma value 1.011844
dengamma value 1.048742
dengamma value 1.053105
dengamma value 0.982066
dengamma value 1.082923
dengamma value 1.107378
dengamma value 1.021477
dengamma value 1.040225
dengamma value 1.139513
dengamma value 1.085593
dengamma value 1.044447
dengamma value 1.068438
09/13/2017 08:06:34:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.07907011 * 7094; err = 0.31646462 * 7094; time = 0.7196s; samplesPerSecond = 9857.7
dengamma value 1.043054
dengamma value 1.068796
dengamma value 1.048601
dengamma value 1.052349
dengamma value 1.038001
dengamma value 1.046261
dengamma value 1.048123
dengamma value 0.971866
dengamma value 0.988654
dengamma value 1.049286
dengamma value 1.060037
dengamma value 1.020494
dengamma value 1.006351
dengamma value 1.080904
dengamma value 0.993443
dengamma value 1.085502
dengamma value 1.056526
dengamma value 1.047366
dengamma value 1.026659
dengamma value 1.038006
dengamma value 1.053382
dengamma value 1.027465
09/13/2017 08:06:35:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08670706 * 6246; err = 0.30963817 * 6246; time = 0.6556s; samplesPerSecond = 9527.0
dengamma value 1.002140
dengamma value 1.049773
dengamma value 1.038921
dengamma value 1.072004
dengamma value 1.031729
dengamma value 0.960499
dengamma value 0.999646
dengamma value 1.122768
dengamma value 1.063643
dengamma value 0.979709
dengamma value 0.945210
dengamma value 1.057180
dengamma value 1.057180
09/13/2017 08:06:35: Finished Epoch[ 3 of 3]: [Training] ce = 0.08436975 * 81970; err = 0.31715262 * 81970; totalSamplesSeen = 246320; learningRatePerSample = 2e-06; epochTime=8.47954s
09/13/2017 08:06:35: SGD: Saving checkpoint model '/tmp/cntk-test-20170913080554.565638/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

09/13/2017 08:06:35: Action "train" complete.

09/13/2017 08:06:35: __COMPLETED__