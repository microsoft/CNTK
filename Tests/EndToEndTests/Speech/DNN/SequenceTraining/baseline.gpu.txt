CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk currentDirectory=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData RunDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu DataDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining OutputDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta6.0+ (HEAD bf0ca9, Dec 20 2016 11:40:12) on localhost at 2016/12/20 16:01:52

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk  currentDirectory=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData  RunDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu  DataDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining  OutputDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData
12/20/2016 16:01:53: -------------------------------------------------------------------
12/20/2016 16:01:53: Build info: 

12/20/2016 16:01:53: 		Built time: Dec 20 2016 11:40:12
12/20/2016 16:01:53: 		Last modified date: Tue Dec 20 11:38:27 2016
12/20/2016 16:01:53: 		Build type: release
12/20/2016 16:01:53: 		Build target: GPU
12/20/2016 16:01:53: 		With 1bit-SGD: no
12/20/2016 16:01:53: 		With ASGD: yes
12/20/2016 16:01:53: 		Math lib: mkl
12/20/2016 16:01:53: 		CUDA_PATH: /usr/local/cuda-8.0
12/20/2016 16:01:53: 		CUB_PATH: /usr/local/cub-1.4.1
12/20/2016 16:01:53: 		CUDNN_PATH: /usr/local
12/20/2016 16:01:53: 		Build Branch: HEAD
12/20/2016 16:01:53: 		Build SHA1: bf0ca998cd077aa28c04371fd2093770e819ffd0
12/20/2016 16:01:53: 		Built by Source/CNTK/buildinfo.h$$0 on b4b39bc07965
12/20/2016 16:01:53: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
12/20/2016 16:01:53: -------------------------------------------------------------------
12/20/2016 16:01:54: -------------------------------------------------------------------
12/20/2016 16:01:54: GPU info:

12/20/2016 16:01:54: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:54: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:54: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:54: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:54: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData
configparameters: cntk_sequence.cntk:DataDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
12/20/2016 16:01:54: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
12/20/2016 16:01:54: precision = "float"

12/20/2016 16:01:54: ##############################################################################
12/20/2016 16:01:54: #                                                                            #
12/20/2016 16:01:54: # dptPre1 command (train action)                                             #
12/20/2016 16:01:54: #                                                                            #
12/20/2016 16:01:54: ##############################################################################

12/20/2016 16:01:54: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/20/2016 16:01:54: 
Model has 19 nodes. Using GPU 0.

12/20/2016 16:01:54: Training criterion:   ce = CrossEntropyWithSoftmax
12/20/2016 16:01:54: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }


12/20/2016 16:01:54: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/20/2016 16:01:54: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/20/2016 16:01:54: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:54: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/20/2016 16:01:54: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/20/2016 16:01:54: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/20/2016 16:01:54: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/20/2016 16:01:54: Starting minibatch loop.
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.74183846 * 2560; err = 0.80195313 * 2560; time = 0.1368s; samplesPerSecond = 18719.5
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.91124763 * 2560; err = 0.70898438 * 2560; time = 0.0079s; samplesPerSecond = 325285.9
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.58015976 * 2560; err = 0.66640625 * 2560; time = 0.0077s; samplesPerSecond = 334378.3
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.27427139 * 2560; err = 0.58750000 * 2560; time = 0.0075s; samplesPerSecond = 341606.6
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 2.05503616 * 2560; err = 0.56093750 * 2560; time = 0.0075s; samplesPerSecond = 342200.2
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.91055145 * 2560; err = 0.52812500 * 2560; time = 0.0075s; samplesPerSecond = 341789.1
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.81562805 * 2560; err = 0.51171875 * 2560; time = 0.0075s; samplesPerSecond = 341561.0
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.68803253 * 2560; err = 0.48476562 * 2560; time = 0.0074s; samplesPerSecond = 344086.0
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.57382050 * 2560; err = 0.45429687 * 2560; time = 0.0075s; samplesPerSecond = 339928.3
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62090302 * 2560; err = 0.47304687 * 2560; time = 0.0075s; samplesPerSecond = 343071.6
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.59272614 * 2560; err = 0.47500000 * 2560; time = 0.0075s; samplesPerSecond = 341697.8
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.51520233 * 2560; err = 0.44531250 * 2560; time = 0.0075s; samplesPerSecond = 342612.4
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.49181976 * 2560; err = 0.45039062 * 2560; time = 0.0075s; samplesPerSecond = 341015.1
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53703613 * 2560; err = 0.44804688 * 2560; time = 0.0075s; samplesPerSecond = 341105.9
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.43095093 * 2560; err = 0.41640625 * 2560; time = 0.0075s; samplesPerSecond = 343209.5
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.41503906 * 2560; err = 0.40078125 * 2560; time = 0.0075s; samplesPerSecond = 341515.5
12/20/2016 16:01:54:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.38913269 * 2560; err = 0.41132812 * 2560; time = 0.0075s; samplesPerSecond = 342429.1
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.41208191 * 2560; err = 0.42226562 * 2560; time = 0.0075s; samplesPerSecond = 342474.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.39966431 * 2560; err = 0.40664062 * 2560; time = 0.0075s; samplesPerSecond = 341606.6
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42729187 * 2560; err = 0.42617187 * 2560; time = 0.0075s; samplesPerSecond = 341424.4
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.41336365 * 2560; err = 0.42343750 * 2560; time = 0.0076s; samplesPerSecond = 336266.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.33192749 * 2560; err = 0.39921875 * 2560; time = 0.0075s; samplesPerSecond = 339522.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.28583069 * 2560; err = 0.38671875 * 2560; time = 0.0075s; samplesPerSecond = 343163.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.34125366 * 2560; err = 0.40976563 * 2560; time = 0.0075s; samplesPerSecond = 339567.6
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.32662354 * 2560; err = 0.39687500 * 2560; time = 0.0076s; samplesPerSecond = 338803.6
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.21427002 * 2560; err = 0.37187500 * 2560; time = 0.0075s; samplesPerSecond = 340289.8
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.23751526 * 2560; err = 0.37382813 * 2560; time = 0.0075s; samplesPerSecond = 340199.3
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.29967346 * 2560; err = 0.39062500 * 2560; time = 0.0075s; samplesPerSecond = 341060.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.21246338 * 2560; err = 0.37382813 * 2560; time = 0.0075s; samplesPerSecond = 341515.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20534058 * 2560; err = 0.36835937 * 2560; time = 0.0075s; samplesPerSecond = 341880.3
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23593445 * 2560; err = 0.37187500 * 2560; time = 0.0075s; samplesPerSecond = 342154.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.25566101 * 2560; err = 0.38007812 * 2560; time = 0.0073s; samplesPerSecond = 350301.0
12/20/2016 16:01:55: Finished Epoch[ 1 of 2]: [Training] ce = 1.62944660 * 81920; err = 0.46020508 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.474607s
12/20/2016 16:01:55: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

12/20/2016 16:01:55: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:55: Starting minibatch loop.
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.23269291 * 2560; err = 0.38164063 * 2560; time = 0.0089s; samplesPerSecond = 287964.0
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.20291767 * 2560; err = 0.37304688 * 2560; time = 0.0076s; samplesPerSecond = 337241.5
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.28558159 * 2560; err = 0.37695312 * 2560; time = 0.0075s; samplesPerSecond = 341743.4
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.22916222 * 2560; err = 0.37421875 * 2560; time = 0.0075s; samplesPerSecond = 341333.3
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.18205528 * 2560; err = 0.35585937 * 2560; time = 0.0075s; samplesPerSecond = 341834.7
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.28033676 * 2560; err = 0.37890625 * 2560; time = 0.0075s; samplesPerSecond = 341834.7
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.22179184 * 2560; err = 0.37421875 * 2560; time = 0.0075s; samplesPerSecond = 341469.9
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17912292 * 2560; err = 0.36640625 * 2560; time = 0.0075s; samplesPerSecond = 341926.0
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.23585739 * 2560; err = 0.35976562 * 2560; time = 0.0075s; samplesPerSecond = 342017.4
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18168030 * 2560; err = 0.37460938 * 2560; time = 0.0075s; samplesPerSecond = 342750.0
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.19452591 * 2560; err = 0.35859375 * 2560; time = 0.0075s; samplesPerSecond = 343531.9
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18433685 * 2560; err = 0.34609375 * 2560; time = 0.0075s; samplesPerSecond = 342429.1
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16999817 * 2560; err = 0.36562500 * 2560; time = 0.0075s; samplesPerSecond = 340380.3
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.13339691 * 2560; err = 0.35507813 * 2560; time = 0.0075s; samplesPerSecond = 341015.1
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.10162354 * 2560; err = 0.32734375 * 2560; time = 0.0075s; samplesPerSecond = 342841.8
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.10350647 * 2560; err = 0.33593750 * 2560; time = 0.0076s; samplesPerSecond = 337597.3
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.19208984 * 2560; err = 0.35781250 * 2560; time = 0.0075s; samplesPerSecond = 340425.5
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.16002197 * 2560; err = 0.35468750 * 2560; time = 0.0074s; samplesPerSecond = 343901.1
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11639099 * 2560; err = 0.34453125 * 2560; time = 0.0075s; samplesPerSecond = 341971.7
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.12366943 * 2560; err = 0.35234375 * 2560; time = 0.0075s; samplesPerSecond = 340244.6
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.09730225 * 2560; err = 0.32656250 * 2560; time = 0.0075s; samplesPerSecond = 340969.6
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13167572 * 2560; err = 0.34296875 * 2560; time = 0.0075s; samplesPerSecond = 342154.5
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.13528748 * 2560; err = 0.34882812 * 2560; time = 0.0076s; samplesPerSecond = 337108.2
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.29873352 * 2560; err = 0.39023438 * 2560; time = 0.0075s; samplesPerSecond = 343347.6
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.18422852 * 2560; err = 0.35937500 * 2560; time = 0.0075s; samplesPerSecond = 339792.9
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.13612366 * 2560; err = 0.35507813 * 2560; time = 0.0075s; samplesPerSecond = 339567.6
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.14573059 * 2560; err = 0.34843750 * 2560; time = 0.0075s; samplesPerSecond = 342795.9
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.14446716 * 2560; err = 0.34726563 * 2560; time = 0.0075s; samplesPerSecond = 342063.1
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.06778870 * 2560; err = 0.33476563 * 2560; time = 0.0075s; samplesPerSecond = 343439.8
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.09552002 * 2560; err = 0.33398438 * 2560; time = 0.0075s; samplesPerSecond = 341971.7
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08288879 * 2560; err = 0.33671875 * 2560; time = 0.0075s; samplesPerSecond = 342474.9
12/20/2016 16:01:55:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06622925 * 2560; err = 0.33281250 * 2560; time = 0.0073s; samplesPerSecond = 350253.1
12/20/2016 16:01:55: Finished Epoch[ 2 of 2]: [Training] ce = 1.16552296 * 81920; err = 0.35533447 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.24444s
12/20/2016 16:01:55: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

12/20/2016 16:01:55: Action "train" complete.


12/20/2016 16:01:55: ##############################################################################
12/20/2016 16:01:55: #                                                                            #
12/20/2016 16:01:55: # addLayer2 command (edit action)                                            #
12/20/2016 16:01:55: #                                                                            #
12/20/2016 16:01:55: ##############################################################################


12/20/2016 16:01:55: Action "edit" complete.


12/20/2016 16:01:55: ##############################################################################
12/20/2016 16:01:55: #                                                                            #
12/20/2016 16:01:55: # dptPre2 command (train action)                                             #
12/20/2016 16:01:55: #                                                                            #
12/20/2016 16:01:55: ##############################################################################

12/20/2016 16:01:55: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/20/2016 16:01:55: 
Model has 24 nodes. Using GPU 0.

12/20/2016 16:01:55: Training criterion:   ce = CrossEntropyWithSoftmax
12/20/2016 16:01:55: Evaluation criterion: err = ClassificationError

12/20/2016 16:01:55: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/20/2016 16:01:55: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/20/2016 16:01:55: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:55: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:55: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:55: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/20/2016 16:01:55: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/20/2016 16:01:55: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/20/2016 16:01:55: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/20/2016 16:01:55: Starting minibatch loop.
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 4.68542328 * 2560; err = 0.81210938 * 2560; time = 0.0145s; samplesPerSecond = 177125.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.87754745 * 2560; err = 0.70429688 * 2560; time = 0.0105s; samplesPerSecond = 243670.3
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.30694504 * 2560; err = 0.60078125 * 2560; time = 0.0104s; samplesPerSecond = 246224.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.97322769 * 2560; err = 0.53046875 * 2560; time = 0.0103s; samplesPerSecond = 248857.8
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.74820175 * 2560; err = 0.48515625 * 2560; time = 0.0103s; samplesPerSecond = 247989.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.62830963 * 2560; err = 0.45898438 * 2560; time = 0.0103s; samplesPerSecond = 249124.2
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57729797 * 2560; err = 0.45742187 * 2560; time = 0.0102s; samplesPerSecond = 249975.6
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.47783203 * 2560; err = 0.42539063 * 2560; time = 0.0102s; samplesPerSecond = 249829.2
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.38961029 * 2560; err = 0.40312500 * 2560; time = 0.0103s; samplesPerSecond = 248616.1
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.42050476 * 2560; err = 0.42500000 * 2560; time = 0.0104s; samplesPerSecond = 246224.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41446533 * 2560; err = 0.43398437 * 2560; time = 0.0102s; samplesPerSecond = 249780.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.38064575 * 2560; err = 0.41562500 * 2560; time = 0.0103s; samplesPerSecond = 248399.0
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.34983063 * 2560; err = 0.41093750 * 2560; time = 0.0105s; samplesPerSecond = 244438.1
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.38891449 * 2560; err = 0.40039062 * 2560; time = 0.0107s; samplesPerSecond = 239633.1
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.32506714 * 2560; err = 0.39218750 * 2560; time = 0.0101s; samplesPerSecond = 252739.7
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.31689453 * 2560; err = 0.39375000 * 2560; time = 0.0101s; samplesPerSecond = 254195.2
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.25972900 * 2560; err = 0.37382813 * 2560; time = 0.0101s; samplesPerSecond = 254447.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.28251343 * 2560; err = 0.38828125 * 2560; time = 0.0101s; samplesPerSecond = 253766.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29806213 * 2560; err = 0.39609375 * 2560; time = 0.0101s; samplesPerSecond = 252739.7
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.28545227 * 2560; err = 0.39296875 * 2560; time = 0.0101s; samplesPerSecond = 252914.4
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.26422424 * 2560; err = 0.38710937 * 2560; time = 0.0102s; samplesPerSecond = 251671.3
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.21907654 * 2560; err = 0.37070313 * 2560; time = 0.0102s; samplesPerSecond = 250931.2
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.21932678 * 2560; err = 0.37304688 * 2560; time = 0.0102s; samplesPerSecond = 252018.1
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.25006714 * 2560; err = 0.37890625 * 2560; time = 0.0101s; samplesPerSecond = 253314.9
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.22711792 * 2560; err = 0.37773438 * 2560; time = 0.0101s; samplesPerSecond = 252939.4
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.15191956 * 2560; err = 0.34804687 * 2560; time = 0.0102s; samplesPerSecond = 251943.7
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.16685791 * 2560; err = 0.35078125 * 2560; time = 0.0102s; samplesPerSecond = 249926.8
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.22696533 * 2560; err = 0.36875000 * 2560; time = 0.0101s; samplesPerSecond = 253114.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.16452332 * 2560; err = 0.36250000 * 2560; time = 0.0101s; samplesPerSecond = 252889.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.16859436 * 2560; err = 0.35468750 * 2560; time = 0.0101s; samplesPerSecond = 253064.5
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.16826782 * 2560; err = 0.35859375 * 2560; time = 0.0104s; samplesPerSecond = 246509.4
12/20/2016 16:01:55:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.17040100 * 2560; err = 0.35039063 * 2560; time = 0.0102s; samplesPerSecond = 251276.0
12/20/2016 16:01:55: Finished Epoch[ 1 of 2]: [Training] ce = 1.52449427 * 81920; err = 0.42756348 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.432919s
12/20/2016 16:01:55: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

12/20/2016 16:01:55: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:55: Starting minibatch loop.
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.15134373 * 2560; err = 0.35312500 * 2560; time = 0.0113s; samplesPerSecond = 227091.3
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.17376041 * 2560; err = 0.36132812 * 2560; time = 0.0101s; samplesPerSecond = 252266.5
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.22741013 * 2560; err = 0.37031250 * 2560; time = 0.0102s; samplesPerSecond = 251522.9
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.18026123 * 2560; err = 0.35937500 * 2560; time = 0.0101s; samplesPerSecond = 252540.2
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.13496513 * 2560; err = 0.34804687 * 2560; time = 0.0102s; samplesPerSecond = 251572.3
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.21739044 * 2560; err = 0.36562500 * 2560; time = 0.0102s; samplesPerSecond = 251177.4
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.13920593 * 2560; err = 0.34140625 * 2560; time = 0.0102s; samplesPerSecond = 252018.1
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.12614746 * 2560; err = 0.35468750 * 2560; time = 0.0101s; samplesPerSecond = 252440.6
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.14790039 * 2560; err = 0.34375000 * 2560; time = 0.0101s; samplesPerSecond = 253214.6
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12684402 * 2560; err = 0.34765625 * 2560; time = 0.0116s; samplesPerSecond = 220937.3
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14334641 * 2560; err = 0.34648438 * 2560; time = 0.0103s; samplesPerSecond = 249172.7
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.12968216 * 2560; err = 0.34687500 * 2560; time = 0.0102s; samplesPerSecond = 250857.4
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.11384888 * 2560; err = 0.34335938 * 2560; time = 0.0104s; samplesPerSecond = 246011.9
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.06927795 * 2560; err = 0.32656250 * 2560; time = 0.0103s; samplesPerSecond = 249464.0
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.05675964 * 2560; err = 0.31250000 * 2560; time = 0.0102s; samplesPerSecond = 250024.4
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.06755219 * 2560; err = 0.32812500 * 2560; time = 0.0102s; samplesPerSecond = 250685.5
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.14282532 * 2560; err = 0.34570312 * 2560; time = 0.0103s; samplesPerSecond = 248761.1
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.14160461 * 2560; err = 0.35781250 * 2560; time = 0.0102s; samplesPerSecond = 250832.8
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.08101654 * 2560; err = 0.33320312 * 2560; time = 0.0102s; samplesPerSecond = 251745.5
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.07025604 * 2560; err = 0.33710937 * 2560; time = 0.0103s; samplesPerSecond = 249512.7
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.06245575 * 2560; err = 0.32890625 * 2560; time = 0.0102s; samplesPerSecond = 250857.4
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.08775940 * 2560; err = 0.33320312 * 2560; time = 0.0103s; samplesPerSecond = 248302.6
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.11305237 * 2560; err = 0.34765625 * 2560; time = 0.0104s; samplesPerSecond = 245210.7
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12844849 * 2560; err = 0.35234375 * 2560; time = 0.0102s; samplesPerSecond = 251399.4
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.09436340 * 2560; err = 0.33515625 * 2560; time = 0.0103s; samplesPerSecond = 249099.9
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.06695557 * 2560; err = 0.33320312 * 2560; time = 0.0102s; samplesPerSecond = 251152.8
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.06651611 * 2560; err = 0.32773438 * 2560; time = 0.0101s; samplesPerSecond = 253114.5
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.10426941 * 2560; err = 0.33671875 * 2560; time = 0.0101s; samplesPerSecond = 254069.1
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.02084045 * 2560; err = 0.32187500 * 2560; time = 0.0101s; samplesPerSecond = 253565.8
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.07205505 * 2560; err = 0.33710937 * 2560; time = 0.0102s; samplesPerSecond = 252117.4
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.06188965 * 2560; err = 0.32734375 * 2560; time = 0.0102s; samplesPerSecond = 250244.4
12/20/2016 16:01:56:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.05428772 * 2560; err = 0.33398438 * 2560; time = 0.0103s; samplesPerSecond = 247654.1
12/20/2016 16:01:56: Finished Epoch[ 2 of 2]: [Training] ce = 1.11169662 * 81920; err = 0.34182129 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.332536s
12/20/2016 16:01:56: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

12/20/2016 16:01:56: Action "train" complete.


12/20/2016 16:01:56: ##############################################################################
12/20/2016 16:01:56: #                                                                            #
12/20/2016 16:01:56: # addLayer3 command (edit action)                                            #
12/20/2016 16:01:56: #                                                                            #
12/20/2016 16:01:56: ##############################################################################


12/20/2016 16:01:56: Action "edit" complete.


12/20/2016 16:01:56: ##############################################################################
12/20/2016 16:01:56: #                                                                            #
12/20/2016 16:01:56: # speechTrain command (train action)                                         #
12/20/2016 16:01:56: #                                                                            #
12/20/2016 16:01:56: ##############################################################################

12/20/2016 16:01:56: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/20/2016 16:01:56: 
Model has 29 nodes. Using GPU 0.

12/20/2016 16:01:56: Training criterion:   ce = CrossEntropyWithSoftmax
12/20/2016 16:01:56: Evaluation criterion: err = ClassificationError

12/20/2016 16:01:56: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

12/20/2016 16:01:56: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/20/2016 16:01:56: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:56: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:56: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:56: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:56: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:56: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/20/2016 16:01:56: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/20/2016 16:01:56: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/20/2016 16:01:56: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/20/2016 16:01:56: Starting minibatch loop.
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 4.01191254 * 2560; err = 0.81992188 * 2560; time = 0.0172s; samplesPerSecond = 148414.4
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.65419159 * 2560; err = 0.65117187 * 2560; time = 0.0136s; samplesPerSecond = 187545.8
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.04179306 * 2560; err = 0.54921875 * 2560; time = 0.0136s; samplesPerSecond = 188429.3
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.74536972 * 2560; err = 0.47382812 * 2560; time = 0.0136s; samplesPerSecond = 188290.7
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.57696991 * 2560; err = 0.44765625 * 2560; time = 0.0136s; samplesPerSecond = 187862.3
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.47850189 * 2560; err = 0.41914062 * 2560; time = 0.0136s; samplesPerSecond = 187642.0
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.43680878 * 2560; err = 0.40937500 * 2560; time = 0.0136s; samplesPerSecond = 188526.4
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.36164856 * 2560; err = 0.39492187 * 2560; time = 0.0137s; samplesPerSecond = 187257.7
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.27849426 * 2560; err = 0.37656250 * 2560; time = 0.0136s; samplesPerSecond = 187765.9
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30459900 * 2560; err = 0.39960937 * 2560; time = 0.0136s; samplesPerSecond = 187986.5
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.28589325 * 2560; err = 0.38984375 * 2560; time = 0.0136s; samplesPerSecond = 188526.4
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27590027 * 2560; err = 0.38359375 * 2560; time = 0.0136s; samplesPerSecond = 188263.0
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24400330 * 2560; err = 0.38710937 * 2560; time = 0.0136s; samplesPerSecond = 188124.6
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.31191101 * 2560; err = 0.38710937 * 2560; time = 0.0136s; samplesPerSecond = 187710.8
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.25154419 * 2560; err = 0.36523438 * 2560; time = 0.0137s; samplesPerSecond = 186847.7
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.26658783 * 2560; err = 0.38281250 * 2560; time = 0.0136s; samplesPerSecond = 187848.5
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.19905701 * 2560; err = 0.36015625 * 2560; time = 0.0136s; samplesPerSecond = 188512.5
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20682678 * 2560; err = 0.36523438 * 2560; time = 0.0136s; samplesPerSecond = 188860.2
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21596069 * 2560; err = 0.37109375 * 2560; time = 0.0136s; samplesPerSecond = 188693.2
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.20121765 * 2560; err = 0.37617187 * 2560; time = 0.0136s; samplesPerSecond = 187903.7
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.20172424 * 2560; err = 0.37031250 * 2560; time = 0.0136s; samplesPerSecond = 188014.1
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.13780823 * 2560; err = 0.34453125 * 2560; time = 0.0136s; samplesPerSecond = 188069.4
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.14899597 * 2560; err = 0.35078125 * 2560; time = 0.0136s; samplesPerSecond = 187986.5
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.19089355 * 2560; err = 0.35859375 * 2560; time = 0.0137s; samplesPerSecond = 187257.7
12/20/2016 16:01:56:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.17016296 * 2560; err = 0.36054687 * 2560; time = 0.0137s; samplesPerSecond = 187079.8
12/20/2016 16:01:57:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.08495178 * 2560; err = 0.34062500 * 2560; time = 0.0136s; samplesPerSecond = 188263.0
12/20/2016 16:01:57:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.11389771 * 2560; err = 0.34375000 * 2560; time = 0.0137s; samplesPerSecond = 187339.9
12/20/2016 16:01:57:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.18205566 * 2560; err = 0.35234375 * 2560; time = 0.0137s; samplesPerSecond = 186875.0
12/20/2016 16:01:57:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.11204224 * 2560; err = 0.34648438 * 2560; time = 0.0137s; samplesPerSecond = 187449.7
12/20/2016 16:01:57:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.13517761 * 2560; err = 0.34765625 * 2560; time = 0.0136s; samplesPerSecond = 187752.1
12/20/2016 16:01:57:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12517700 * 2560; err = 0.34062500 * 2560; time = 0.0136s; samplesPerSecond = 188429.3
12/20/2016 16:01:57:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.12189941 * 2560; err = 0.34453125 * 2560; time = 0.0136s; samplesPerSecond = 188415.4
12/20/2016 16:01:57: Finished Epoch[ 1 of 4]: [Training] ce = 1.40856180 * 81920; err = 0.40345459 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.543861s
12/20/2016 16:01:57: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

12/20/2016 16:01:57: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:57: Starting minibatch loop.
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.50099545 * 5120; err = 0.41503906 * 5120; time = 0.0245s; samplesPerSecond = 208639.0
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.29802551 * 5120; err = 0.38847656 * 5120; time = 0.0212s; samplesPerSecond = 241452.5
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.19228306 * 5120; err = 0.36269531 * 5120; time = 0.0213s; samplesPerSecond = 240454.6
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.12583389 * 5120; err = 0.34511719 * 5120; time = 0.0213s; samplesPerSecond = 239992.5
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.12678490 * 5120; err = 0.34101562 * 5120; time = 0.0213s; samplesPerSecond = 240590.2
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.13744774 * 5120; err = 0.35234375 * 5120; time = 0.0213s; samplesPerSecond = 240420.7
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.09439240 * 5120; err = 0.33496094 * 5120; time = 0.0212s; samplesPerSecond = 241954.5
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.06660385 * 5120; err = 0.32656250 * 5120; time = 0.0213s; samplesPerSecond = 240714.6
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.17267303 * 5120; err = 0.36406250 * 5120; time = 0.0212s; samplesPerSecond = 241225.0
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.10358582 * 5120; err = 0.34316406 * 5120; time = 0.0213s; samplesPerSecond = 240274.1
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05820389 * 5120; err = 0.32832031 * 5120; time = 0.0213s; samplesPerSecond = 240386.9
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.12881165 * 5120; err = 0.35273437 * 5120; time = 0.0212s; samplesPerSecond = 241338.7
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.10886230 * 5120; err = 0.34492187 * 5120; time = 0.0213s; samplesPerSecond = 240522.4
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.08949432 * 5120; err = 0.32812500 * 5120; time = 0.0213s; samplesPerSecond = 240488.5
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.03984833 * 5120; err = 0.32441406 * 5120; time = 0.0214s; samplesPerSecond = 239521.0
12/20/2016 16:01:57:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05730286 * 5120; err = 0.32304688 * 5120; time = 0.0212s; samplesPerSecond = 241009.2
12/20/2016 16:01:57: Finished Epoch[ 2 of 4]: [Training] ce = 1.14382181 * 81920; err = 0.34843750 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.347007s
12/20/2016 16:01:57: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

12/20/2016 16:01:57: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:57: Starting minibatch loop.
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.10878077 * 5120; err = 0.33847656 * 5120; time = 0.0221s; samplesPerSecond = 231213.9
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.11130934 * 5120; err = 0.34375000 * 5120; time = 0.0213s; samplesPerSecond = 240353.0
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.10591621 * 5120; err = 0.34628906 * 5120; time = 0.0213s; samplesPerSecond = 240827.8
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.13425102 * 5120; err = 0.34160156 * 5120; time = 0.0213s; samplesPerSecond = 240364.3
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.12513046 * 5120; err = 0.34238281 * 5120; time = 0.0213s; samplesPerSecond = 240578.9
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.07461128 * 5120; err = 0.33535156 * 5120; time = 0.0213s; samplesPerSecond = 240015.0
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.07328949 * 5120; err = 0.33144531 * 5120; time = 0.0213s; samplesPerSecond = 240737.3
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07549820 * 5120; err = 0.33007812 * 5120; time = 0.0214s; samplesPerSecond = 238984.3
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.02875366 * 5120; err = 0.31386719 * 5120; time = 0.0213s; samplesPerSecond = 240386.9
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.04900742 * 5120; err = 0.31718750 * 5120; time = 0.0213s; samplesPerSecond = 240624.1
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05542603 * 5120; err = 0.33769531 * 5120; time = 0.0213s; samplesPerSecond = 240386.9
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.08413391 * 5120; err = 0.33515625 * 5120; time = 0.0213s; samplesPerSecond = 240409.4
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05125275 * 5120; err = 0.32050781 * 5120; time = 0.0213s; samplesPerSecond = 239891.3
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02265320 * 5120; err = 0.32695313 * 5120; time = 0.0213s; samplesPerSecond = 239970.0
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.04138031 * 5120; err = 0.32832031 * 5120; time = 0.0213s; samplesPerSecond = 240499.8
12/20/2016 16:01:57:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.01894073 * 5120; err = 0.32285156 * 5120; time = 0.0213s; samplesPerSecond = 240759.9
12/20/2016 16:01:57: Finished Epoch[ 3 of 4]: [Training] ce = 1.07252092 * 81920; err = 0.33199463 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.344854s
12/20/2016 16:01:57: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

12/20/2016 16:01:57: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:57: Starting minibatch loop.
12/20/2016 16:01:57:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.03330860 * 5120; err = 0.31738281 * 5120; time = 0.0222s; samplesPerSecond = 230932.3
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.03593001 * 4926; err = 0.32399513 * 4926; time = 0.0638s; samplesPerSecond = 77208.8
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.00798683 * 5120; err = 0.31757812 * 5120; time = 0.0214s; samplesPerSecond = 239722.8
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 0.99057846 * 5120; err = 0.31171875 * 5120; time = 0.0213s; samplesPerSecond = 240895.8
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 0.99319420 * 5120; err = 0.31582031 * 5120; time = 0.0212s; samplesPerSecond = 241281.8
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99868736 * 5120; err = 0.31835938 * 5120; time = 0.0213s; samplesPerSecond = 240873.2
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01183434 * 5120; err = 0.31406250 * 5120; time = 0.0212s; samplesPerSecond = 241168.2
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.00435257 * 5120; err = 0.31601563 * 5120; time = 0.0213s; samplesPerSecond = 240918.5
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99865494 * 5120; err = 0.30976562 * 5120; time = 0.0233s; samplesPerSecond = 220148.8
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.99832916 * 5120; err = 0.31074219 * 5120; time = 0.0217s; samplesPerSecond = 235890.3
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.02309341 * 5120; err = 0.31660156 * 5120; time = 0.0213s; samplesPerSecond = 240782.5
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.05355072 * 5120; err = 0.33144531 * 5120; time = 0.0213s; samplesPerSecond = 240420.7
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.97934952 * 5120; err = 0.29902344 * 5120; time = 0.0213s; samplesPerSecond = 240229.0
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96725616 * 5120; err = 0.30214844 * 5120; time = 0.0213s; samplesPerSecond = 240026.3
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97408600 * 5120; err = 0.31152344 * 5120; time = 0.0214s; samplesPerSecond = 239151.8
12/20/2016 16:01:58:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97509308 * 5120; err = 0.29433594 * 5120; time = 0.0213s; samplesPerSecond = 240646.7
12/20/2016 16:01:58: Finished Epoch[ 4 of 4]: [Training] ce = 1.00266399 * 81920; err = 0.31325684 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.391022s
12/20/2016 16:01:58: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech'

12/20/2016 16:01:58: Action "train" complete.


12/20/2016 16:01:58: ##############################################################################
12/20/2016 16:01:58: #                                                                            #
12/20/2016 16:01:58: # replaceCriterionNode command (edit action)                                 #
12/20/2016 16:01:58: #                                                                            #
12/20/2016 16:01:58: ##############################################################################


12/20/2016 16:01:58: Action "edit" complete.


12/20/2016 16:01:58: ##############################################################################
12/20/2016 16:01:58: #                                                                            #
12/20/2016 16:01:58: # sequenceTrain command (train action)                                       #
12/20/2016 16:01:58: #                                                                            #
12/20/2016 16:01:58: ##############################################################################

12/20/2016 16:01:58: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/model.overalltying', '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list', '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/TestData/CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
12/20/2016 16:01:58: 
Model has 29 nodes. Using GPU 0.

12/20/2016 16:01:58: Training criterion:   ce = SequenceWithSoftmax
12/20/2016 16:01:58: Evaluation criterion: err = ClassificationError

12/20/2016 16:01:58: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

12/20/2016 16:01:58: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/20/2016 16:01:58: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:58: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:58: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:58: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:58: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:58: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/20/2016 16:01:58: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/20/2016 16:01:58: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-10
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

12/20/2016 16:01:58: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/20/2016 16:02:03: Starting minibatch loop.
dengamma value 1.006863
dengamma value 1.076726
dengamma value 1.021282
dengamma value 1.071934
dengamma value 1.035840
dengamma value 1.070977
dengamma value 1.017756
dengamma value 1.014051
dengamma value 1.141197
dengamma value 0.947160
dengamma value 0.999889
dengamma value 1.057862
dengamma value 1.042335
dengamma value 1.062237
dengamma value 1.027882
dengamma value 1.078353
dengamma value 1.055012
dengamma value 1.081793
dengamma value 0.999289
dengamma value 1.032549
dengamma value 1.039615
dengamma value 1.066485
12/20/2016 16:02:04:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08594932 * 5566; err = 0.32752425 * 5566; time = 1.3716s; samplesPerSecond = 4058.1
dengamma value 0.995418
dengamma value 1.043829
dengamma value 1.027023
dengamma value 1.020094
dengamma value 1.016498
dengamma value 1.055279
dengamma value 1.112832
dengamma value 1.038774
dengamma value 1.025762
dengamma value 0.993411
dengamma value 0.995034
dengamma value 1.061966
dengamma value 1.028966
dengamma value 0.993991
dengamma value 1.041589
dengamma value 0.988791
dengamma value 1.001614
dengamma value 1.047575
dengamma value 1.016090
dengamma value 1.087561
dengamma value 1.028722
dengamma value 1.068312
dengamma value 1.042325
dengamma value 1.196348
dengamma value 1.059266
dengamma value 1.054649
12/20/2016 16:02:05:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08009718 * 7398; err = 0.30981346 * 7398; time = 0.5942s; samplesPerSecond = 12450.1
dengamma value 1.100683
dengamma value 0.987513
dengamma value 1.036569
dengamma value 0.976904
dengamma value 1.040700
dengamma value 1.058532
dengamma value 1.072338
dengamma value 1.060317
dengamma value 1.089726
dengamma value 1.085907
dengamma value 1.016045
dengamma value 1.066792
dengamma value 1.047403
dengamma value 0.940520
dengamma value 1.093985
dengamma value 1.033631
dengamma value 1.104728
dengamma value 1.012986
dengamma value 1.018983
dengamma value 1.053249
dengamma value 1.047294
dengamma value 1.035895
dengamma value 1.034338
dengamma value 1.106082
dengamma value 1.080786
12/20/2016 16:02:05:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07857835 * 6300; err = 0.33888889 * 6300; time = 0.4954s; samplesPerSecond = 12717.0
dengamma value 1.098741
dengamma value 1.172885
dengamma value 1.060977
dengamma value 1.052580
dengamma value 1.028724
dengamma value 0.992041
dengamma value 0.997987
dengamma value 1.049903
dengamma value 1.107361
dengamma value 1.030137
dengamma value 1.039191
dengamma value 1.062776
dengamma value 1.082695
dengamma value 1.043989
dengamma value 1.100543
dengamma value 1.046670
dengamma value 0.997646
dengamma value 1.039555
dengamma value 1.017338
dengamma value 0.982996
dengamma value 0.933232
dengamma value 1.046204
12/20/2016 16:02:06:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.07975051 * 5636; err = 0.32523066 * 5636; time = 0.4367s; samplesPerSecond = 12906.2
dengamma value 1.038769
dengamma value 1.027744
dengamma value 1.039448
dengamma value 1.058685
dengamma value 1.048647
dengamma value 1.076718
dengamma value 1.053376
dengamma value 1.027307
dengamma value 0.945339
dengamma value 1.035984
dengamma value 1.017093
dengamma value 1.060678
dengamma value 1.047557
dengamma value 0.948682
dengamma value 1.044801
dengamma value 0.985225
dengamma value 1.081916
dengamma value 1.020182
dengamma value 1.057349
dengamma value 0.966733
12/20/2016 16:02:06:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08121576 * 6970; err = 0.33888092 * 6970; time = 0.5472s; samplesPerSecond = 12737.6
dengamma value 1.059845
dengamma value 1.034712
dengamma value 1.053989
dengamma value 1.039827
dengamma value 1.066691
dengamma value 1.066682
dengamma value 1.044290
dengamma value 1.068901
dengamma value 1.055804
dengamma value 1.045783
dengamma value 1.003016
dengamma value 1.055721
dengamma value 1.028676
dengamma value 1.055206
dengamma value 1.010691
dengamma value 1.083310
dengamma value 1.047736
dengamma value 0.991717
dengamma value 1.125428
dengamma value 1.001771
dengamma value 1.005708
dengamma value 1.059523
12/20/2016 16:02:07:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08025900 * 6996; err = 0.31918239 * 6996; time = 0.5798s; samplesPerSecond = 12066.9
dengamma value 1.076109
dengamma value 1.021011
dengamma value 1.052051
dengamma value 1.043349
dengamma value 0.993440
dengamma value 1.003753
dengamma value 1.034696
dengamma value 0.978320
dengamma value 1.116521
dengamma value 1.004398
dengamma value 1.045039
dengamma value 1.002051
dengamma value 1.071572
dengamma value 1.081746
dengamma value 1.096831
dengamma value 0.977018
dengamma value 0.989094
dengamma value 1.043077
dengamma value 1.024988
dengamma value 1.125334
dengamma value 1.022724
dengamma value 1.061335
dengamma value 1.081863
dengamma value 1.019897
dengamma value 1.009519
12/20/2016 16:02:07:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08543662 * 6180; err = 0.33576052 * 6180; time = 0.5027s; samplesPerSecond = 12294.4
dengamma value 1.038925
dengamma value 1.062939
dengamma value 1.129292
dengamma value 1.005669
dengamma value 1.073673
dengamma value 1.038169
dengamma value 0.991413
dengamma value 1.059573
dengamma value 1.028797
dengamma value 1.045309
dengamma value 1.031369
dengamma value 1.039449
dengamma value 1.084486
dengamma value 0.969557
dengamma value 1.109369
dengamma value 1.042534
dengamma value 1.042464
dengamma value 1.106001
dengamma value 1.050151
dengamma value 1.109548
12/20/2016 16:02:08:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08466782 * 4860; err = 0.33148148 * 4860; time = 0.3830s; samplesPerSecond = 12689.3
dengamma value 1.027109
dengamma value 0.967233
dengamma value 1.020813
dengamma value 1.062381
dengamma value 1.031821
dengamma value 1.073602
dengamma value 1.005169
dengamma value 1.069811
dengamma value 1.015763
dengamma value 0.988120
dengamma value 1.034201
dengamma value 0.945225
dengamma value 1.025771
dengamma value 1.070876
dengamma value 1.041344
dengamma value 1.095692
dengamma value 1.059328
dengamma value 1.038477
dengamma value 1.041350
dengamma value 1.016779
dengamma value 1.099936
dengamma value 1.066919
12/20/2016 16:02:08:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.07690018 * 6046; err = 0.32765465 * 6046; time = 0.4891s; samplesPerSecond = 12361.0
dengamma value 1.040266
dengamma value 1.002487
dengamma value 1.009864
dengamma value 0.963713
dengamma value 1.019287
dengamma value 1.095173
dengamma value 1.036092
dengamma value 0.988907
dengamma value 1.024800
dengamma value 1.052525
dengamma value 0.991275
dengamma value 1.020982
dengamma value 1.047997
dengamma value 1.073758
dengamma value 0.988141
dengamma value 1.052408
dengamma value 1.003975
dengamma value 1.007387
dengamma value 0.997932
dengamma value 0.999872
dengamma value 0.990748
dengamma value 1.062821
dengamma value 1.021640
dengamma value 1.034660
12/20/2016 16:02:09:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08686208 * 6942; err = 0.33938346 * 6942; time = 0.5273s; samplesPerSecond = 13165.2
dengamma value 1.011380
dengamma value 1.036708
dengamma value 1.000018
dengamma value 0.932035
dengamma value 1.062897
dengamma value 1.084469
dengamma value 1.132822
dengamma value 1.008325
dengamma value 1.026811
dengamma value 1.107075
dengamma value 1.061840
dengamma value 1.005030
dengamma value 1.054522
dengamma value 1.024733
dengamma value 1.102784
dengamma value 1.013778
dengamma value 1.036938
dengamma value 1.055268
dengamma value 1.006672
dengamma value 1.004206
dengamma value 0.976817
dengamma value 1.062452
dengamma value 1.058561
12/20/2016 16:02:09:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08793115 * 5784; err = 0.32555325 * 5784; time = 0.4377s; samplesPerSecond = 13215.9
dengamma value 1.074496
dengamma value 1.078124
dengamma value 1.009661
dengamma value 1.006846
dengamma value 1.121623
dengamma value 0.996558
dengamma value 0.956061
dengamma value 0.960314
dengamma value 0.935304
dengamma value 1.026964
dengamma value 1.029889
dengamma value 0.983464
dengamma value 1.060634
dengamma value 1.030787
dengamma value 1.063768
dengamma value 0.986319
dengamma value 1.016549
dengamma value 1.042679
dengamma value 1.061996
dengamma value 0.983276
dengamma value 1.098684
12/20/2016 16:02:10:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08909775 * 6258; err = 0.33541067 * 6258; time = 0.4834s; samplesPerSecond = 12945.4
dengamma value 1.098457
dengamma value 1.076916
dengamma value 1.064929
dengamma value 1.074470
dengamma value 1.020649
dengamma value 1.109226
dengamma value 1.072592
dengamma value 1.016075
dengamma value 1.038168
dengamma value 1.021410
dengamma value 1.022388
dengamma value 1.061723
dengamma value 1.044999
dengamma value 1.070712
dengamma value 0.961046
dengamma value 1.003724
dengamma value 1.064932
dengamma value 1.011829
dengamma value 1.099325
dengamma value 0.998795
dengamma value 1.023735
dengamma value 0.961909
12/20/2016 16:02:10:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08275162 * 6116; err = 0.31965337 * 6116; time = 0.4882s; samplesPerSecond = 12526.7
dengamma value 1.038860
dengamma value 1.045746
dengamma value 0.999766
dengamma value 1.045776
12/20/2016 16:02:10: Finished Epoch[ 1 of 3]: [Training] ce = 0.08315556 * 82574; err = 0.32836002 * 82574; totalSamplesSeen = 82574; learningRatePerSample = 2e-06; epochTime=12.1664s
12/20/2016 16:02:10: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

12/20/2016 16:02:10: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 82146), data subset 0 of 1, with 1 datapasses

12/20/2016 16:02:10: Starting minibatch loop.
dengamma value 1.026422
dengamma value 0.999206
dengamma value 0.982717
dengamma value 1.070101
dengamma value 1.064777
dengamma value 1.004418
dengamma value 1.050103
dengamma value 1.013166
dengamma value 1.028247
dengamma value 1.027323
dengamma value 1.036799
dengamma value 0.995468
dengamma value 1.048513
dengamma value 1.090507
dengamma value 0.965721
dengamma value 0.997045
dengamma value 1.017410
dengamma value 1.022557
dengamma value 1.059693
dengamma value 1.042650
dengamma value 1.059991
dengamma value 1.089000
12/20/2016 16:02:11:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08358627 * 5826; err = 0.33848266 * 5826; time = 0.4722s; samplesPerSecond = 12337.8
dengamma value 1.062078
dengamma value 1.096534
dengamma value 1.084650
dengamma value 1.046730
dengamma value 1.045238
dengamma value 1.005834
dengamma value 1.086091
dengamma value 1.084805
dengamma value 1.089635
dengamma value 1.045781
dengamma value 1.028026
dengamma value 0.953832
dengamma value 1.075278
dengamma value 1.071569
dengamma value 1.036369
dengamma value 1.042793
dengamma value 1.033462
dengamma value 1.024221
dengamma value 1.044277
dengamma value 1.014361
12/20/2016 16:02:11:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.07964599 * 6380; err = 0.31520376 * 6380; time = 0.5268s; samplesPerSecond = 12110.1
dengamma value 1.096614
dengamma value 1.021470
dengamma value 1.117343
dengamma value 0.947568
dengamma value 1.026852
dengamma value 1.071693
dengamma value 1.107590
dengamma value 1.038520
dengamma value 1.070194
dengamma value 1.020270
dengamma value 0.989566
dengamma value 1.084466
dengamma value 1.016793
dengamma value 1.052211
dengamma value 1.014611
dengamma value 1.014493
dengamma value 1.052520
dengamma value 1.080496
dengamma value 1.032959
dengamma value 1.033682
dengamma value 1.086661
dengamma value 1.062410
dengamma value 0.986894
12/20/2016 16:02:12:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07719984 * 6574; err = 0.32187405 * 6574; time = 0.5671s; samplesPerSecond = 11592.4
dengamma value 1.075134
dengamma value 1.053402
dengamma value 1.049077
dengamma value 1.053553
dengamma value 0.926433
dengamma value 0.960124
dengamma value 1.127155
dengamma value 1.080496
dengamma value 1.027681
dengamma value 1.023398
dengamma value 1.050464
dengamma value 0.967391
dengamma value 1.051451
dengamma value 1.009550
dengamma value 0.960826
dengamma value 1.078494
dengamma value 1.057943
dengamma value 1.093421
dengamma value 0.993407
dengamma value 0.982165
dengamma value 1.077586
dengamma value 1.116585
dengamma value 1.001485
12/20/2016 16:02:13:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08715830 * 6324; err = 0.33364959 * 6324; time = 0.4899s; samplesPerSecond = 12909.1
dengamma value 0.961874
dengamma value 0.939280
dengamma value 0.934499
dengamma value 1.052157
dengamma value 1.074650
dengamma value 1.105266
dengamma value 1.037411
dengamma value 1.136033
dengamma value 1.027966
dengamma value 0.982069
dengamma value 1.008651
dengamma value 1.010087
dengamma value 0.960261
dengamma value 1.087317
dengamma value 1.040507
dengamma value 0.992781
dengamma value 0.943041
dengamma value 0.994735
dengamma value 1.019306
dengamma value 1.050748
12/20/2016 16:02:13:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.09048014 * 4800; err = 0.35645833 * 4800; time = 0.3621s; samplesPerSecond = 13256.3
dengamma value 0.991064
dengamma value 1.043734
dengamma value 1.043998
dengamma value 1.049206
dengamma value 1.042427
dengamma value 1.119868
dengamma value 1.087231
dengamma value 1.021940
dengamma value 1.063128
dengamma value 1.008088
dengamma value 1.070509
dengamma value 1.011091
dengamma value 0.982512
dengamma value 0.995444
dengamma value 1.060659
dengamma value 1.020899
dengamma value 1.025934
dengamma value 1.015451
dengamma value 1.014009
dengamma value 1.036071
dengamma value 1.019429
dengamma value 1.054271
12/20/2016 16:02:13:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08112513 * 6176; err = 0.34876943 * 6176; time = 0.4677s; samplesPerSecond = 13205.4
dengamma value 1.086239
dengamma value 1.054758
dengamma value 1.066532
dengamma value 0.982178
dengamma value 1.075391
dengamma value 1.042828
dengamma value 1.085406
dengamma value 0.958574
dengamma value 1.061349
dengamma value 1.028756
dengamma value 1.064351
dengamma value 1.023375
dengamma value 1.063009
dengamma value 0.998331
dengamma value 1.068912
dengamma value 1.040433
dengamma value 1.085958
dengamma value 1.133832
dengamma value 1.035166
dengamma value 0.963648
dengamma value 1.080165
dengamma value 1.051803
dengamma value 1.041655
12/20/2016 16:02:14:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08963371 * 5534; err = 0.31387785 * 5534; time = 0.4650s; samplesPerSecond = 11900.3
dengamma value 1.055753
dengamma value 1.002714
dengamma value 0.984974
dengamma value 1.031356
dengamma value 1.110693
dengamma value 0.955688
dengamma value 1.069133
dengamma value 1.062240
dengamma value 1.051912
dengamma value 1.043233
dengamma value 1.101155
dengamma value 1.107201
dengamma value 1.041808
dengamma value 1.078212
dengamma value 1.041916
dengamma value 1.032960
dengamma value 1.042128
dengamma value 0.999490
dengamma value 1.067177
dengamma value 1.035245
dengamma value 0.992431
dengamma value 1.064358
12/20/2016 16:02:14:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08223578 * 5936; err = 0.31570081 * 5936; time = 0.5320s; samplesPerSecond = 11157.4
dengamma value 0.915898
dengamma value 1.071559
dengamma value 1.065648
dengamma value 1.052928
dengamma value 1.069983
dengamma value 1.011225
dengamma value 1.073847
dengamma value 1.034834
dengamma value 1.026168
dengamma value 1.063217
dengamma value 0.900485
dengamma value 1.061543
dengamma value 1.117813
dengamma value 1.071831
dengamma value 1.001438
dengamma value 1.086272
dengamma value 1.091109
dengamma value 1.076237
dengamma value 1.094920
dengamma value 1.097089
dengamma value 1.057575
12/20/2016 16:02:15:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08267640 * 5248; err = 0.32507622 * 5248; time = 0.4207s; samplesPerSecond = 12475.6
dengamma value 1.041004
dengamma value 1.033665
dengamma value 1.055423
dengamma value 1.016553
dengamma value 1.060489
dengamma value 1.064918
dengamma value 1.038146
dengamma value 0.985519
dengamma value 1.056323
dengamma value 1.034278
dengamma value 1.110867
dengamma value 1.077486
dengamma value 0.973834
dengamma value 1.062588
dengamma value 1.101752
dengamma value 1.025143
dengamma value 1.088630
dengamma value 1.101725
dengamma value 1.051718
dengamma value 1.028286
dengamma value 1.002809
dengamma value 1.049238
dengamma value 1.045264
dengamma value 1.062436
dengamma value 1.026394
dengamma value 1.067727
12/20/2016 16:02:15:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08167099 * 6888; err = 0.31024971 * 6888; time = 0.5613s; samplesPerSecond = 12272.2
dengamma value 1.045349
dengamma value 1.067176
dengamma value 1.030940
dengamma value 1.044776
dengamma value 1.022844
dengamma value 1.029732
dengamma value 1.014092
dengamma value 1.084153
dengamma value 1.069231
dengamma value 1.023380
dengamma value 1.033607
dengamma value 1.082692
dengamma value 1.069161
dengamma value 1.005219
dengamma value 1.094318
dengamma value 1.011997
dengamma value 1.004433
dengamma value 1.105037
dengamma value 1.052158
dengamma value 1.024533
dengamma value 1.017131
dengamma value 1.020307
dengamma value 0.979409
dengamma value 1.030634
12/20/2016 16:02:16:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08633061 * 6572; err = 0.33368837 * 6572; time = 0.5143s; samplesPerSecond = 12779.4
dengamma value 0.993713
dengamma value 1.078894
dengamma value 1.007993
dengamma value 1.086259
dengamma value 1.038500
dengamma value 1.007038
dengamma value 1.007464
dengamma value 1.066742
dengamma value 1.032112
dengamma value 1.002604
dengamma value 1.059966
dengamma value 1.052242
dengamma value 1.056178
dengamma value 1.035489
dengamma value 1.026724
dengamma value 1.031965
dengamma value 1.022975
dengamma value 1.099876
dengamma value 0.997524
dengamma value 1.048673
dengamma value 1.050681
dengamma value 1.126007
dengamma value 1.065569
dengamma value 1.027174
12/20/2016 16:02:16:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08653845 * 6622; err = 0.31350045 * 6622; time = 0.5645s; samplesPerSecond = 11731.6
dengamma value 1.026566
dengamma value 1.089870
dengamma value 1.014205
dengamma value 0.981280
dengamma value 1.034647
dengamma value 1.014682
dengamma value 0.948463
dengamma value 0.980706
dengamma value 0.939395
dengamma value 1.045969
dengamma value 1.069264
dengamma value 1.136427
dengamma value 1.088328
dengamma value 1.091544
dengamma value 1.019554
dengamma value 1.042613
dengamma value 0.994045
dengamma value 1.040274
dengamma value 1.025537
dengamma value 0.962728
dengamma value 1.039614
dengamma value 1.089513
dengamma value 1.034471
12/20/2016 16:02:17:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08802074 * 5824; err = 0.32228709 * 5824; time = 0.4360s; samplesPerSecond = 13358.0
dengamma value 0.970587
dengamma value 1.033712
dengamma value 1.102219
dengamma value 0.965871
dengamma value 1.016397
dengamma value 1.093221
dengamma value 1.061043
dengamma value 1.150184
dengamma value 1.034397
12/20/2016 16:02:17: Finished Epoch[ 2 of 3]: [Training] ce = 0.08407320 * 81776; err = 0.32522990 * 81776; totalSamplesSeen = 164350; learningRatePerSample = 2e-06; epochTime=6.64619s
12/20/2016 16:02:17: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

12/20/2016 16:02:17: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163922), data subset 0 of 1, with 1 datapasses

12/20/2016 16:02:17: Starting minibatch loop.
dengamma value 1.078789
dengamma value 1.030453
dengamma value 1.058080
dengamma value 1.081221
dengamma value 1.086825
dengamma value 1.002083
dengamma value 1.037549
dengamma value 1.000106
dengamma value 1.012095
dengamma value 1.004430
dengamma value 1.040228
dengamma value 1.038987
dengamma value 1.023485
dengamma value 1.049729
dengamma value 1.047929
dengamma value 1.112697
dengamma value 1.003396
dengamma value 1.110372
dengamma value 1.025726
dengamma value 1.070689
dengamma value 0.994006
dengamma value 1.043803
dengamma value 1.096460
12/20/2016 16:02:18:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08265500 * 5074; err = 0.32834056 * 5074; time = 0.4325s; samplesPerSecond = 11731.6
dengamma value 1.006399
dengamma value 1.095889
dengamma value 1.058443
dengamma value 1.067033
dengamma value 0.986926
dengamma value 0.986665
dengamma value 0.995864
dengamma value 0.994126
dengamma value 1.097254
dengamma value 1.066725
dengamma value 1.031736
dengamma value 1.022746
dengamma value 1.035091
dengamma value 1.022566
dengamma value 1.087674
dengamma value 1.087211
dengamma value 1.028095
dengamma value 1.043504
dengamma value 1.076954
dengamma value 0.962188
dengamma value 1.039198
dengamma value 1.022857
12/20/2016 16:02:18:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08045937 * 7136; err = 0.31754484 * 7136; time = 0.5765s; samplesPerSecond = 12377.9
dengamma value 1.091183
dengamma value 1.013832
dengamma value 0.984360
dengamma value 1.008287
dengamma value 1.070741
dengamma value 1.025753
dengamma value 1.106484
dengamma value 0.992086
dengamma value 1.018619
dengamma value 1.054996
dengamma value 1.084853
dengamma value 1.045653
dengamma value 1.093444
dengamma value 1.015022
dengamma value 1.064364
dengamma value 1.021514
dengamma value 1.043582
dengamma value 1.017226
dengamma value 1.096917
dengamma value 1.110367
dengamma value 1.030228
dengamma value 1.002501
dengamma value 1.008921
12/20/2016 16:02:19:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.09197325 * 5504; err = 0.34393169 * 5504; time = 0.4818s; samplesPerSecond = 11424.5
dengamma value 1.049649
dengamma value 1.050447
dengamma value 1.057212
dengamma value 1.076604
dengamma value 1.054829
dengamma value 0.993612
dengamma value 1.060331
dengamma value 1.078277
dengamma value 1.019480
dengamma value 1.116631
dengamma value 1.042739
dengamma value 1.055810
dengamma value 1.044727
dengamma value 1.089649
dengamma value 0.973752
dengamma value 1.052143
dengamma value 0.999856
dengamma value 1.021146
dengamma value 0.933905
dengamma value 1.123655
dengamma value 1.051053
12/20/2016 16:02:19:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08375779 * 6028; err = 0.32581287 * 6028; time = 0.5223s; samplesPerSecond = 11542.3
dengamma value 1.054790
dengamma value 1.092617
dengamma value 1.059417
dengamma value 1.063710
dengamma value 0.985154
dengamma value 0.975720
dengamma value 1.037727
dengamma value 0.994491
dengamma value 1.040335
dengamma value 1.104326
dengamma value 1.063656
dengamma value 1.023660
dengamma value 1.057519
dengamma value 1.048204
dengamma value 1.049812
dengamma value 1.009224
dengamma value 1.015804
dengamma value 1.134448
dengamma value 1.012165
dengamma value 1.041159
dengamma value 1.029857
12/20/2016 16:02:20:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08466745 * 6028; err = 0.33145322 * 6028; time = 0.4692s; samplesPerSecond = 12848.5
dengamma value 1.027204
dengamma value 1.037831
dengamma value 1.014375
dengamma value 0.987489
dengamma value 1.047029
dengamma value 1.093937
dengamma value 1.092176
dengamma value 1.063726
dengamma value 0.962995
dengamma value 1.166090
dengamma value 0.989000
dengamma value 0.986259
dengamma value 1.055298
dengamma value 1.035782
dengamma value 1.037720
dengamma value 1.079651
dengamma value 0.992981
dengamma value 0.982608
dengamma value 1.050909
dengamma value 1.011955
dengamma value 1.053767
dengamma value 1.041978
dengamma value 1.005994
dengamma value 1.016839
12/20/2016 16:02:20:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08446380 * 6782; err = 0.33456208 * 6782; time = 0.5308s; samplesPerSecond = 12777.0
dengamma value 1.063379
dengamma value 1.052313
dengamma value 1.105613
dengamma value 1.018010
dengamma value 1.092914
dengamma value 1.040720
dengamma value 1.092854
dengamma value 1.093319
dengamma value 1.072235
dengamma value 1.010360
dengamma value 1.074232
dengamma value 1.099671
dengamma value 0.990092
dengamma value 1.128348
dengamma value 1.123019
dengamma value 0.998646
dengamma value 1.048018
dengamma value 1.115648
dengamma value 1.062792
dengamma value 0.990261
dengamma value 1.016200
12/20/2016 16:02:21:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07822180 * 5458; err = 0.29168193 * 5458; time = 0.4845s; samplesPerSecond = 11266.2
dengamma value 1.057919
dengamma value 1.018209
dengamma value 1.072006
dengamma value 1.062543
dengamma value 1.207962
dengamma value 1.091540
dengamma value 0.974182
dengamma value 1.069207
dengamma value 1.074497
dengamma value 1.040475
dengamma value 1.044826
dengamma value 1.075648
dengamma value 1.120824
dengamma value 1.146609
dengamma value 1.037548
dengamma value 1.065531
dengamma value 1.017099
dengamma value 1.015259
dengamma value 0.999700
dengamma value 1.093916
dengamma value 1.076890
dengamma value 1.117583
dengamma value 1.082416
dengamma value 1.088343
dengamma value 1.009784
12/20/2016 16:02:21:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.07973215 * 6610; err = 0.29183056 * 6610; time = 0.5399s; samplesPerSecond = 12242.4
dengamma value 1.069624
dengamma value 1.060800
dengamma value 1.101717
dengamma value 1.069384
dengamma value 1.061370
dengamma value 0.970520
dengamma value 1.022864
dengamma value 1.071220
dengamma value 1.078129
dengamma value 1.061282
dengamma value 1.031065
dengamma value 0.950482
dengamma value 1.114151
dengamma value 1.094002
dengamma value 1.008162
dengamma value 1.038709
dengamma value 0.908190
dengamma value 1.055314
dengamma value 1.106881
dengamma value 1.050261
dengamma value 1.025150
dengamma value 1.079210
dengamma value 1.035925
12/20/2016 16:02:22:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08455177 * 5854; err = 0.31790229 * 5854; time = 0.4465s; samplesPerSecond = 13111.1
dengamma value 1.049542
dengamma value 1.123807
dengamma value 1.093679
dengamma value 0.877132
dengamma value 1.044272
dengamma value 1.060620
dengamma value 0.971853
dengamma value 1.079361
dengamma value 1.021036
dengamma value 1.018464
dengamma value 1.023737
dengamma value 1.006413
dengamma value 1.092625
dengamma value 1.049847
dengamma value 1.108025
dengamma value 1.078137
dengamma value 1.044088
dengamma value 1.099574
dengamma value 1.034357
dengamma value 0.968193
dengamma value 1.025245
dengamma value 1.059594
dengamma value 1.019977
12/20/2016 16:02:22:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08881370 * 4674; err = 0.32862644 * 4674; time = 0.3775s; samplesPerSecond = 12380.6
dengamma value 0.992799
dengamma value 1.027053
dengamma value 1.056393
dengamma value 1.070617
dengamma value 1.028633
dengamma value 1.068012
dengamma value 1.036424
dengamma value 0.999990
dengamma value 1.113173
dengamma value 1.036618
dengamma value 1.027260
dengamma value 1.053541
dengamma value 1.061644
dengamma value 1.000534
dengamma value 0.916166
dengamma value 0.970848
dengamma value 1.003365
dengamma value 1.053082
dengamma value 1.031433
dengamma value 0.978986
dengamma value 1.078258
12/20/2016 16:02:23:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08137401 * 6248; err = 0.32570423 * 6248; time = 0.4929s; samplesPerSecond = 12675.1
dengamma value 0.963636
dengamma value 1.045714
dengamma value 1.044621
dengamma value 1.065415
dengamma value 1.128077
dengamma value 1.022988
dengamma value 1.047534
dengamma value 1.046489
dengamma value 1.092607
dengamma value 1.000033
dengamma value 0.999314
dengamma value 1.013837
dengamma value 1.048409
dengamma value 1.050613
dengamma value 0.989481
dengamma value 1.078696
dengamma value 1.106206
dengamma value 1.022428
dengamma value 1.037218
dengamma value 1.140517
dengamma value 1.089525
dengamma value 1.046260
dengamma value 1.077538
12/20/2016 16:02:23:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.07785291 * 7094; err = 0.31942487 * 7094; time = 0.5664s; samplesPerSecond = 12525.8
dengamma value 1.046170
dengamma value 1.069117
dengamma value 1.049764
dengamma value 1.056037
dengamma value 1.042047
dengamma value 1.046143
dengamma value 1.048396
dengamma value 0.965730
dengamma value 0.989867
dengamma value 1.047404
dengamma value 1.063675
dengamma value 1.026480
dengamma value 1.009490
dengamma value 1.076302
dengamma value 0.996252
dengamma value 1.086671
dengamma value 1.054705
dengamma value 1.049500
dengamma value 1.025935
dengamma value 1.037173
dengamma value 1.056090
dengamma value 1.035116
12/20/2016 16:02:24:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08639248 * 6246; err = 0.31364073 * 6246; time = 0.5134s; samplesPerSecond = 12165.9
dengamma value 1.004479
dengamma value 1.051038
dengamma value 1.040064
dengamma value 1.077011
dengamma value 1.034544
dengamma value 0.960288
dengamma value 1.001882
dengamma value 1.123456
dengamma value 1.061002
dengamma value 0.982714
dengamma value 0.945535
dengamma value 1.061520
dengamma value 1.061520
12/20/2016 16:02:24: Finished Epoch[ 3 of 3]: [Training] ce = 0.08355509 * 81970; err = 0.32149567 * 81970; totalSamplesSeen = 246320; learningRatePerSample = 2e-06; epochTime=6.70795s
12/20/2016 16:02:24: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

12/20/2016 16:02:24: Action "train" complete.

12/20/2016 16:02:24: __COMPLETED__