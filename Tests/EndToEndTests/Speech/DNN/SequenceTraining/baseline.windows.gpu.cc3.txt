CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-SlaveTest/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 1.7.2+ (HEAD f564f7, Oct 13 2016 07:56:09) on DPHAIM-22 at 2016/10/14 09:31:41

C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData
10/14/2016 09:31:42: -------------------------------------------------------------------
10/14/2016 09:31:42: Build info: 

10/14/2016 09:31:42: 		Built time: Oct 13 2016 07:56:09
10/14/2016 09:31:42: 		Last modified date: Wed Oct 12 00:57:03 2016
10/14/2016 09:31:42: 		Build type: Release
10/14/2016 09:31:42: 		Build target: GPU
10/14/2016 09:31:42: 		With 1bit-SGD: no
10/14/2016 09:31:42: 		Math lib: mkl
10/14/2016 09:31:42: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
10/14/2016 09:31:42: 		CUB_PATH: c:\src\cub-1.4.1
10/14/2016 09:31:42: 		CUDNN_PATH: C:\local\cudnn-8.0-windows10-x64-v5.1
10/14/2016 09:31:42: 		Build Branch: HEAD
10/14/2016 09:31:42: 		Build SHA1: f564f708c8ad80bf7fabe9c840bbb0c63b34f138
10/14/2016 09:31:42: 		Built by svcphil on LIANA-09-w
10/14/2016 09:31:42: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
10/14/2016 09:31:42: -------------------------------------------------------------------
10/14/2016 09:31:42: -------------------------------------------------------------------
10/14/2016 09:31:42: GPU info:

10/14/2016 09:31:42: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
10/14/2016 09:31:42: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
10/14/2016 09:31:42: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
        labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying"
            transpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
10/14/2016 09:31:42: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
10/14/2016 09:31:42: precision = "float"

10/14/2016 09:31:42: ##############################################################################
10/14/2016 09:31:42: #                                                                            #
10/14/2016 09:31:42: # dptPre1 command (train action)                                             #
10/14/2016 09:31:42: #                                                                            #
10/14/2016 09:31:42: ##############################################################################

10/14/2016 09:31:42: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
10/14/2016 09:31:43: 
Model has 19 nodes. Using GPU 0.

10/14/2016 09:31:43: Training criterion:   ce = CrossEntropyWithSoftmax
10/14/2016 09:31:43: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }


10/14/2016 09:31:43: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

10/14/2016 09:31:43: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
10/14/2016 09:31:43: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:43: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
10/14/2016 09:31:43: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

10/14/2016 09:31:43: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

10/14/2016 09:31:43: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

10/14/2016 09:31:43: Starting minibatch loop.
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.89978218 * 2560; err = 0.84375000 * 2560; time = 0.2294s; samplesPerSecond = 11161.7
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.96755714 * 2560; err = 0.72031250 * 2560; time = 0.0175s; samplesPerSecond = 146520.1
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.55723495 * 2560; err = 0.65859375 * 2560; time = 0.0174s; samplesPerSecond = 146991.3
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.29642715 * 2560; err = 0.61992187 * 2560; time = 0.0173s; samplesPerSecond = 147848.7
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 2.02396469 * 2560; err = 0.55117187 * 2560; time = 0.0173s; samplesPerSecond = 148019.7
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87309265 * 2560; err = 0.51484375 * 2560; time = 0.0173s; samplesPerSecond = 147746.3
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.78157196 * 2560; err = 0.50507813 * 2560; time = 0.0173s; samplesPerSecond = 148199.6
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.75391235 * 2560; err = 0.50781250 * 2560; time = 0.0173s; samplesPerSecond = 147891.4
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66460266 * 2560; err = 0.45742187 * 2560; time = 0.0172s; samplesPerSecond = 148681.6
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62184448 * 2560; err = 0.47968750 * 2560; time = 0.0173s; samplesPerSecond = 147703.7
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.65328217 * 2560; err = 0.47265625 * 2560; time = 0.0173s; samplesPerSecond = 148233.9
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.50686798 * 2560; err = 0.44921875 * 2560; time = 0.0173s; samplesPerSecond = 147729.2
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.46723938 * 2560; err = 0.42304687 * 2560; time = 0.0173s; samplesPerSecond = 148165.3
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.49163513 * 2560; err = 0.44140625 * 2560; time = 0.0173s; samplesPerSecond = 148294.0
10/14/2016 09:31:43:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46437683 * 2560; err = 0.43398437 * 2560; time = 0.0173s; samplesPerSecond = 147934.1
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43047180 * 2560; err = 0.43867187 * 2560; time = 0.0173s; samplesPerSecond = 147976.9
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.42106018 * 2560; err = 0.41992188 * 2560; time = 0.0172s; samplesPerSecond = 148759.4
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.46538086 * 2560; err = 0.42421875 * 2560; time = 0.0173s; samplesPerSecond = 148079.6
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.47427673 * 2560; err = 0.44062500 * 2560; time = 0.0172s; samplesPerSecond = 148638.4
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42846985 * 2560; err = 0.44023438 * 2560; time = 0.0173s; samplesPerSecond = 148122.4
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.34077454 * 2560; err = 0.41171875 * 2560; time = 0.0172s; samplesPerSecond = 148509.1
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.39475098 * 2560; err = 0.42734375 * 2560; time = 0.0173s; samplesPerSecond = 148105.3
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.40151062 * 2560; err = 0.41250000 * 2560; time = 0.0173s; samplesPerSecond = 147951.2
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.39343872 * 2560; err = 0.42734375 * 2560; time = 0.0173s; samplesPerSecond = 148139.6
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.32482300 * 2560; err = 0.40195313 * 2560; time = 0.0173s; samplesPerSecond = 147618.5
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.27031250 * 2560; err = 0.39843750 * 2560; time = 0.0172s; samplesPerSecond = 148785.3
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.32369690 * 2560; err = 0.39296875 * 2560; time = 0.0173s; samplesPerSecond = 148079.6
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25391541 * 2560; err = 0.38281250 * 2560; time = 0.0173s; samplesPerSecond = 148071.0
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.23369446 * 2560; err = 0.36953125 * 2560; time = 0.0172s; samplesPerSecond = 148423.0
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20872803 * 2560; err = 0.36015625 * 2560; time = 0.0173s; samplesPerSecond = 148276.9
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23682861 * 2560; err = 0.36757812 * 2560; time = 0.0172s; samplesPerSecond = 148819.9
10/14/2016 09:31:44:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.22942505 * 2560; err = 0.37460938 * 2560; time = 0.0168s; samplesPerSecond = 152408.2
10/14/2016 09:31:44: Finished Epoch[ 1 of 2]: [Training] ce = 1.65171719 * 81920; err = 0.46779785 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.930151s
10/14/2016 09:31:44: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

10/14/2016 09:31:44: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:44: Starting minibatch loop.
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.21853390 * 2560; err = 0.37031250 * 2560; time = 0.0195s; samplesPerSecond = 131504.6
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18339520 * 2560; err = 0.36640625 * 2560; time = 0.0176s; samplesPerSecond = 145678.0
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.17222099 * 2560; err = 0.35859375 * 2560; time = 0.0173s; samplesPerSecond = 147627.0
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.20084305 * 2560; err = 0.35742188 * 2560; time = 0.0174s; samplesPerSecond = 147244.9
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.19529877 * 2560; err = 0.37773438 * 2560; time = 0.0174s; samplesPerSecond = 147372.1
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.16530914 * 2560; err = 0.34570313 * 2560; time = 0.0173s; samplesPerSecond = 147678.1
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.13811340 * 2560; err = 0.34843750 * 2560; time = 0.0174s; samplesPerSecond = 147304.2
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.19432220 * 2560; err = 0.37265625 * 2560; time = 0.0174s; samplesPerSecond = 147312.7
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.24415894 * 2560; err = 0.37929687 * 2560; time = 0.0174s; samplesPerSecond = 146721.7
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18925095 * 2560; err = 0.36523438 * 2560; time = 0.0174s; samplesPerSecond = 147431.5
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.16683502 * 2560; err = 0.35859375 * 2560; time = 0.0175s; samplesPerSecond = 146285.7
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.24675751 * 2560; err = 0.38125000 * 2560; time = 0.0173s; samplesPerSecond = 148208.2
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.19025574 * 2560; err = 0.35195312 * 2560; time = 0.0173s; samplesPerSecond = 148251.1
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.22029724 * 2560; err = 0.37382813 * 2560; time = 0.0172s; samplesPerSecond = 148621.2
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.20153046 * 2560; err = 0.37343750 * 2560; time = 0.0174s; samplesPerSecond = 147516.4
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.14394226 * 2560; err = 0.34101562 * 2560; time = 0.0173s; samplesPerSecond = 148148.1
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.14187469 * 2560; err = 0.35742188 * 2560; time = 0.0172s; samplesPerSecond = 148405.8
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.17012939 * 2560; err = 0.34687500 * 2560; time = 0.0174s; samplesPerSecond = 147295.7
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.15014648 * 2560; err = 0.35546875 * 2560; time = 0.0173s; samplesPerSecond = 148302.6
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08505096 * 2560; err = 0.33359375 * 2560; time = 0.0173s; samplesPerSecond = 147925.6
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.14442139 * 2560; err = 0.34726563 * 2560; time = 0.0172s; samplesPerSecond = 149158.1
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.17172089 * 2560; err = 0.36093750 * 2560; time = 0.0173s; samplesPerSecond = 147814.5
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.19044189 * 2560; err = 0.37382813 * 2560; time = 0.0173s; samplesPerSecond = 148182.4
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.14433289 * 2560; err = 0.34453125 * 2560; time = 0.0172s; samplesPerSecond = 148664.3
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.14347839 * 2560; err = 0.35039063 * 2560; time = 0.0172s; samplesPerSecond = 148569.4
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07991028 * 2560; err = 0.32812500 * 2560; time = 0.0173s; samplesPerSecond = 147737.8
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.09500122 * 2560; err = 0.34335938 * 2560; time = 0.0173s; samplesPerSecond = 147558.9
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.06157837 * 2560; err = 0.33085938 * 2560; time = 0.0172s; samplesPerSecond = 148845.9
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09024658 * 2560; err = 0.33476563 * 2560; time = 0.0172s; samplesPerSecond = 148681.6
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.14956360 * 2560; err = 0.35742188 * 2560; time = 0.0173s; samplesPerSecond = 147865.8
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.11126099 * 2560; err = 0.34609375 * 2560; time = 0.0172s; samplesPerSecond = 148569.4
10/14/2016 09:31:44:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07835693 * 2560; err = 0.32343750 * 2560; time = 0.0167s; samplesPerSecond = 152972.8
10/14/2016 09:31:44: Finished Epoch[ 2 of 2]: [Training] ce = 1.15870562 * 81920; err = 0.35488281 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.55853s
10/14/2016 09:31:44: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

10/14/2016 09:31:44: Action "train" complete.


10/14/2016 09:31:44: ##############################################################################
10/14/2016 09:31:44: #                                                                            #
10/14/2016 09:31:44: # addLayer2 command (edit action)                                            #
10/14/2016 09:31:44: #                                                                            #
10/14/2016 09:31:44: ##############################################################################


10/14/2016 09:31:44: Action "edit" complete.


10/14/2016 09:31:44: ##############################################################################
10/14/2016 09:31:44: #                                                                            #
10/14/2016 09:31:44: # dptPre2 command (train action)                                             #
10/14/2016 09:31:44: #                                                                            #
10/14/2016 09:31:44: ##############################################################################

10/14/2016 09:31:44: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
10/14/2016 09:31:45: 
Model has 24 nodes. Using GPU 0.

10/14/2016 09:31:45: Training criterion:   ce = CrossEntropyWithSoftmax
10/14/2016 09:31:45: Evaluation criterion: err = ClassificationError

10/14/2016 09:31:45: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

10/14/2016 09:31:45: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
10/14/2016 09:31:45: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:45: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:45: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:45: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
10/14/2016 09:31:45: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

10/14/2016 09:31:45: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

10/14/2016 09:31:45: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

10/14/2016 09:31:45: Starting minibatch loop.
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 4.45637283 * 2560; err = 0.80781250 * 2560; time = 0.0293s; samplesPerSecond = 87407.8
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.80688400 * 2560; err = 0.68906250 * 2560; time = 0.0213s; samplesPerSecond = 119962.5
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.24392319 * 2560; err = 0.59335938 * 2560; time = 0.0212s; samplesPerSecond = 120516.0
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.90253754 * 2560; err = 0.51367188 * 2560; time = 0.0213s; samplesPerSecond = 120436.6
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.68644791 * 2560; err = 0.46835938 * 2560; time = 0.0211s; samplesPerSecond = 121361.5
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.58258362 * 2560; err = 0.45546875 * 2560; time = 0.0212s; samplesPerSecond = 120771.8
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.48594055 * 2560; err = 0.43554688 * 2560; time = 0.0212s; samplesPerSecond = 120561.4
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.48547668 * 2560; err = 0.43007812 * 2560; time = 0.0212s; samplesPerSecond = 120697.8
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.45441132 * 2560; err = 0.42187500 * 2560; time = 0.0211s; samplesPerSecond = 121206.4
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.41602020 * 2560; err = 0.41015625 * 2560; time = 0.0210s; samplesPerSecond = 121725.1
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.42062378 * 2560; err = 0.41406250 * 2560; time = 0.0212s; samplesPerSecond = 120965.8
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.33938751 * 2560; err = 0.39140625 * 2560; time = 0.0212s; samplesPerSecond = 120891.6
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.31747437 * 2560; err = 0.38789062 * 2560; time = 0.0367s; samplesPerSecond = 69737.7
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33400879 * 2560; err = 0.40000000 * 2560; time = 0.0259s; samplesPerSecond = 98826.4
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.32040405 * 2560; err = 0.39218750 * 2560; time = 0.0236s; samplesPerSecond = 108350.6
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.27135620 * 2560; err = 0.38164063 * 2560; time = 0.0241s; samplesPerSecond = 106030.5
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.29650574 * 2560; err = 0.38710937 * 2560; time = 0.0238s; samplesPerSecond = 107676.1
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.32416992 * 2560; err = 0.38828125 * 2560; time = 0.0241s; samplesPerSecond = 106409.5
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.34054260 * 2560; err = 0.41328125 * 2560; time = 0.0244s; samplesPerSecond = 104982.6
10/14/2016 09:31:45:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32275391 * 2560; err = 0.41250000 * 2560; time = 0.0243s; samplesPerSecond = 105224.2
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.23507996 * 2560; err = 0.37617187 * 2560; time = 0.0243s; samplesPerSecond = 105172.3
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.27051697 * 2560; err = 0.38867188 * 2560; time = 0.0245s; samplesPerSecond = 104592.3
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.26447144 * 2560; err = 0.37421875 * 2560; time = 0.0243s; samplesPerSecond = 105449.6
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.23878479 * 2560; err = 0.37031250 * 2560; time = 0.0244s; samplesPerSecond = 105025.6
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.21479797 * 2560; err = 0.36875000 * 2560; time = 0.0245s; samplesPerSecond = 104622.2
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.18688049 * 2560; err = 0.36757812 * 2560; time = 0.0243s; samplesPerSecond = 105289.1
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.24023438 * 2560; err = 0.36914063 * 2560; time = 0.0243s; samplesPerSecond = 105471.3
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.18505554 * 2560; err = 0.36015625 * 2560; time = 0.0244s; samplesPerSecond = 104935.2
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.16905823 * 2560; err = 0.35429688 * 2560; time = 0.0243s; samplesPerSecond = 105536.5
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.14624023 * 2560; err = 0.34609375 * 2560; time = 0.0244s; samplesPerSecond = 104913.7
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.17507324 * 2560; err = 0.35000000 * 2560; time = 0.0243s; samplesPerSecond = 105241.5
10/14/2016 09:31:46:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.18778687 * 2560; err = 0.36796875 * 2560; time = 0.0235s; samplesPerSecond = 109117.3
10/14/2016 09:31:46: Finished Epoch[ 1 of 2]: [Training] ce = 1.51005640 * 81920; err = 0.42459717 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.925192s
10/14/2016 09:31:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

10/14/2016 09:31:46: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:46: Starting minibatch loop.
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.17832527 * 2560; err = 0.35468750 * 2560; time = 0.0240s; samplesPerSecond = 106458.2
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.14753838 * 2560; err = 0.35859375 * 2560; time = 0.0219s; samplesPerSecond = 117162.5
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15549850 * 2560; err = 0.34726563 * 2560; time = 0.0217s; samplesPerSecond = 117760.7
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.14482193 * 2560; err = 0.34804687 * 2560; time = 0.0216s; samplesPerSecond = 118513.0
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.14781761 * 2560; err = 0.36250000 * 2560; time = 0.0216s; samplesPerSecond = 118250.3
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.15032234 * 2560; err = 0.34179688 * 2560; time = 0.0216s; samplesPerSecond = 118617.4
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.09860153 * 2560; err = 0.33984375 * 2560; time = 0.0216s; samplesPerSecond = 118573.4
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.15725021 * 2560; err = 0.35585937 * 2560; time = 0.0216s; samplesPerSecond = 118414.4
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.16588898 * 2560; err = 0.36250000 * 2560; time = 0.0216s; samplesPerSecond = 118573.4
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12342911 * 2560; err = 0.34414062 * 2560; time = 0.0216s; samplesPerSecond = 118600.9
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.12388916 * 2560; err = 0.34492187 * 2560; time = 0.0216s; samplesPerSecond = 118430.8
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18532639 * 2560; err = 0.35937500 * 2560; time = 0.0216s; samplesPerSecond = 118441.8
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.13089142 * 2560; err = 0.33750000 * 2560; time = 0.0216s; samplesPerSecond = 118732.9
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.17003326 * 2560; err = 0.35468750 * 2560; time = 0.0216s; samplesPerSecond = 118540.5
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.11926270 * 2560; err = 0.34804687 * 2560; time = 0.0216s; samplesPerSecond = 118573.4
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.09435272 * 2560; err = 0.33984375 * 2560; time = 0.0216s; samplesPerSecond = 118397.9
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.10923157 * 2560; err = 0.33789063 * 2560; time = 0.0216s; samplesPerSecond = 118622.9
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.11402588 * 2560; err = 0.33085938 * 2560; time = 0.0216s; samplesPerSecond = 118688.9
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.10265350 * 2560; err = 0.33828125 * 2560; time = 0.0216s; samplesPerSecond = 118727.4
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.05749359 * 2560; err = 0.32656250 * 2560; time = 0.0214s; samplesPerSecond = 119391.8
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.10532532 * 2560; err = 0.34023437 * 2560; time = 0.0214s; samplesPerSecond = 119615.0
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13354645 * 2560; err = 0.34023437 * 2560; time = 0.0214s; samplesPerSecond = 119598.2
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.12023163 * 2560; err = 0.34960938 * 2560; time = 0.0213s; samplesPerSecond = 119973.8
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10714111 * 2560; err = 0.33476563 * 2560; time = 0.0214s; samplesPerSecond = 119575.9
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09808960 * 2560; err = 0.33984375 * 2560; time = 0.0213s; samplesPerSecond = 119917.6
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.04961853 * 2560; err = 0.32187500 * 2560; time = 0.0214s; samplesPerSecond = 119715.7
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.05262756 * 2560; err = 0.33515625 * 2560; time = 0.0214s; samplesPerSecond = 119531.2
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.03559570 * 2560; err = 0.32265625 * 2560; time = 0.0213s; samplesPerSecond = 120266.8
10/14/2016 09:31:46:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.06228638 * 2560; err = 0.32734375 * 2560; time = 0.0213s; samplesPerSecond = 120182.2
10/14/2016 09:31:47:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.11060791 * 2560; err = 0.34023437 * 2560; time = 0.0214s; samplesPerSecond = 119676.5
10/14/2016 09:31:47:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08368530 * 2560; err = 0.33867188 * 2560; time = 0.0214s; samplesPerSecond = 119839.0
10/14/2016 09:31:47:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.04422913 * 2560; err = 0.31757812 * 2560; time = 0.0208s; samplesPerSecond = 123124.3
10/14/2016 09:31:47: Finished Epoch[ 2 of 2]: [Training] ce = 1.11498871 * 81920; err = 0.34191895 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.693525s
10/14/2016 09:31:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

10/14/2016 09:31:47: Action "train" complete.


10/14/2016 09:31:47: ##############################################################################
10/14/2016 09:31:47: #                                                                            #
10/14/2016 09:31:47: # addLayer3 command (edit action)                                            #
10/14/2016 09:31:47: #                                                                            #
10/14/2016 09:31:47: ##############################################################################


10/14/2016 09:31:47: Action "edit" complete.


10/14/2016 09:31:47: ##############################################################################
10/14/2016 09:31:47: #                                                                            #
10/14/2016 09:31:47: # speechTrain command (train action)                                         #
10/14/2016 09:31:47: #                                                                            #
10/14/2016 09:31:47: ##############################################################################

10/14/2016 09:31:47: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
10/14/2016 09:31:48: 
Model has 29 nodes. Using GPU 0.

10/14/2016 09:31:48: Training criterion:   ce = CrossEntropyWithSoftmax
10/14/2016 09:31:48: Evaluation criterion: err = ClassificationError

10/14/2016 09:31:48: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

10/14/2016 09:31:48: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
10/14/2016 09:31:48: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:48: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:48: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:48: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:48: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:48: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
10/14/2016 09:31:48: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

10/14/2016 09:31:48: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

10/14/2016 09:31:48: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

10/14/2016 09:31:48: Starting minibatch loop.
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.09989014 * 2560; err = 0.82539063 * 2560; time = 0.0357s; samplesPerSecond = 71668.5
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.56160202 * 2560; err = 0.63437500 * 2560; time = 0.0256s; samplesPerSecond = 99968.8
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03064728 * 2560; err = 0.54335937 * 2560; time = 0.0255s; samplesPerSecond = 100530.1
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.73696213 * 2560; err = 0.47773437 * 2560; time = 0.0255s; samplesPerSecond = 100569.6
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.54395218 * 2560; err = 0.43632813 * 2560; time = 0.0255s; samplesPerSecond = 100530.1
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.44518509 * 2560; err = 0.41171875 * 2560; time = 0.0257s; samplesPerSecond = 99579.9
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.36156158 * 2560; err = 0.40859375 * 2560; time = 0.0255s; samplesPerSecond = 100364.6
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.35925751 * 2560; err = 0.40195313 * 2560; time = 0.0255s; samplesPerSecond = 100337.1
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.34173279 * 2560; err = 0.39062500 * 2560; time = 0.0255s; samplesPerSecond = 100518.3
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30521545 * 2560; err = 0.37773438 * 2560; time = 0.0255s; samplesPerSecond = 100526.2
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.30856018 * 2560; err = 0.38710937 * 2560; time = 0.0254s; samplesPerSecond = 100680.4
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.23465576 * 2560; err = 0.36875000 * 2560; time = 0.0259s; samplesPerSecond = 99025.2
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.21390839 * 2560; err = 0.35625000 * 2560; time = 0.0252s; samplesPerSecond = 101394.2
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.24229126 * 2560; err = 0.37226562 * 2560; time = 0.0253s; samplesPerSecond = 101317.9
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.23405151 * 2560; err = 0.37187500 * 2560; time = 0.0252s; samplesPerSecond = 101394.2
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.19202881 * 2560; err = 0.35000000 * 2560; time = 0.0253s; samplesPerSecond = 101261.8
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.21569824 * 2560; err = 0.36445312 * 2560; time = 0.0253s; samplesPerSecond = 101054.0
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.24724121 * 2560; err = 0.37109375 * 2560; time = 0.0261s; samplesPerSecond = 98189.6
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.27052612 * 2560; err = 0.38710937 * 2560; time = 0.0252s; samplesPerSecond = 101390.2
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.22104492 * 2560; err = 0.38007812 * 2560; time = 0.0252s; samplesPerSecond = 101390.2
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.17722778 * 2560; err = 0.35117188 * 2560; time = 0.0252s; samplesPerSecond = 101498.7
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.19718323 * 2560; err = 0.36875000 * 2560; time = 0.0253s; samplesPerSecond = 101237.8
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.21679382 * 2560; err = 0.35859375 * 2560; time = 0.0252s; samplesPerSecond = 101434.3
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.18633118 * 2560; err = 0.35781250 * 2560; time = 0.0252s; samplesPerSecond = 101534.9
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17235107 * 2560; err = 0.35664062 * 2560; time = 0.0252s; samplesPerSecond = 101450.4
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.12943115 * 2560; err = 0.35078125 * 2560; time = 0.0252s; samplesPerSecond = 101466.5
10/14/2016 09:31:48:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.18720093 * 2560; err = 0.36367187 * 2560; time = 0.0252s; samplesPerSecond = 101406.2
10/14/2016 09:31:49:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.13684082 * 2560; err = 0.35156250 * 2560; time = 0.0252s; samplesPerSecond = 101466.5
10/14/2016 09:31:49:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.12584839 * 2560; err = 0.33828125 * 2560; time = 0.0251s; samplesPerSecond = 101841.9
10/14/2016 09:31:49:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.10959778 * 2560; err = 0.33710937 * 2560; time = 0.0252s; samplesPerSecond = 101595.4
10/14/2016 09:31:49:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.13491211 * 2560; err = 0.33828125 * 2560; time = 0.0252s; samplesPerSecond = 101446.4
10/14/2016 09:31:49:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.12952271 * 2560; err = 0.34804687 * 2560; time = 0.0247s; samplesPerSecond = 103534.7
10/14/2016 09:31:49: Finished Epoch[ 1 of 4]: [Training] ce = 1.40841417 * 81920; err = 0.40117188 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.986151s
10/14/2016 09:31:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

10/14/2016 09:31:49: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:49: Starting minibatch loop.
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.19426661 * 5120; err = 0.36464844 * 5120; time = 0.0417s; samplesPerSecond = 122720.0
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.15754251 * 5120; err = 0.34804687 * 5120; time = 0.0310s; samplesPerSecond = 165214.6
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.10045757 * 5120; err = 0.33671875 * 5120; time = 0.0310s; samplesPerSecond = 165294.6
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10381279 * 5120; err = 0.34238281 * 5120; time = 0.0308s; samplesPerSecond = 166045.1
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.18317070 * 5120; err = 0.36523438 * 5120; time = 0.0308s; samplesPerSecond = 165985.9
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.16267395 * 5120; err = 0.35898438 * 5120; time = 0.0312s; samplesPerSecond = 164355.4
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.14521179 * 5120; err = 0.34531250 * 5120; time = 0.0313s; samplesPerSecond = 163635.8
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.10903397 * 5120; err = 0.34316406 * 5120; time = 0.0307s; samplesPerSecond = 166856.8
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.10861740 * 5120; err = 0.34199219 * 5120; time = 0.0307s; samplesPerSecond = 166715.5
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.05995026 * 5120; err = 0.32871094 * 5120; time = 0.0307s; samplesPerSecond = 166764.4
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.11063232 * 5120; err = 0.33867188 * 5120; time = 0.0306s; samplesPerSecond = 167080.0
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.14281464 * 5120; err = 0.35371094 * 5120; time = 0.0307s; samplesPerSecond = 166612.4
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.04878998 * 5120; err = 0.32011719 * 5120; time = 0.0307s; samplesPerSecond = 166579.9
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02525330 * 5120; err = 0.32265625 * 5120; time = 0.0307s; samplesPerSecond = 166927.5
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.07958527 * 5120; err = 0.32871094 * 5120; time = 0.0305s; samplesPerSecond = 167775.3
10/14/2016 09:31:49:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06008148 * 5120; err = 0.32226563 * 5120; time = 0.0306s; samplesPerSecond = 167336.7
10/14/2016 09:31:49: Finished Epoch[ 2 of 4]: [Training] ce = 1.11199341 * 81920; err = 0.34133301 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.50708s
10/14/2016 09:31:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

10/14/2016 09:31:49: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:49: Starting minibatch loop.
10/14/2016 09:31:49:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.12118511 * 5120; err = 0.34140625 * 5120; time = 0.0323s; samplesPerSecond = 158626.9
10/14/2016 09:31:49:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.08082790 * 5120; err = 0.33242187 * 5120; time = 0.0307s; samplesPerSecond = 166786.1
10/14/2016 09:31:49:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.07538490 * 5120; err = 0.33476563 * 5120; time = 0.0305s; samplesPerSecond = 167885.4
10/14/2016 09:31:49:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.08917313 * 5120; err = 0.33457031 * 5120; time = 0.0306s; samplesPerSecond = 167156.4
10/14/2016 09:31:49:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07542572 * 5120; err = 0.33632812 * 5120; time = 0.0306s; samplesPerSecond = 167380.4
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.05808182 * 5120; err = 0.33183594 * 5120; time = 0.0305s; samplesPerSecond = 167632.5
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.08808289 * 5120; err = 0.33398438 * 5120; time = 0.0307s; samplesPerSecond = 166932.9
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.08346863 * 5120; err = 0.32812500 * 5120; time = 0.0306s; samplesPerSecond = 167380.4
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.04576874 * 5120; err = 0.32187500 * 5120; time = 0.0306s; samplesPerSecond = 167429.7
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.05990982 * 5120; err = 0.32617188 * 5120; time = 0.0307s; samplesPerSecond = 166634.1
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.04123764 * 5120; err = 0.32363281 * 5120; time = 0.0308s; samplesPerSecond = 166352.6
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.08518143 * 5120; err = 0.33476563 * 5120; time = 0.0306s; samplesPerSecond = 167385.9
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.11212463 * 5120; err = 0.33457031 * 5120; time = 0.0306s; samplesPerSecond = 167391.4
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.05583191 * 5120; err = 0.32441406 * 5120; time = 0.0307s; samplesPerSecond = 166748.1
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.06386566 * 5120; err = 0.33710937 * 5120; time = 0.0306s; samplesPerSecond = 167544.7
10/14/2016 09:31:50:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.04508209 * 5120; err = 0.32656250 * 5120; time = 0.0306s; samplesPerSecond = 167511.9
10/14/2016 09:31:50: Finished Epoch[ 3 of 4]: [Training] ce = 1.07378950 * 81920; err = 0.33140869 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.494655s
10/14/2016 09:31:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

10/14/2016 09:31:50: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:50: Starting minibatch loop.
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.03368073 * 5120; err = 0.32460937 * 5120; time = 0.0322s; samplesPerSecond = 158976.6
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.03708301 * 4926; err = 0.31161186 * 4926; time = 0.0745s; samplesPerSecond = 66136.8
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02361641 * 5120; err = 0.32070312 * 5120; time = 0.0307s; samplesPerSecond = 166677.5
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.01664028 * 5120; err = 0.31718750 * 5120; time = 0.0306s; samplesPerSecond = 167572.2
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.00534554 * 5120; err = 0.31855469 * 5120; time = 0.0307s; samplesPerSecond = 166992.8
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99899979 * 5120; err = 0.31093750 * 5120; time = 0.0306s; samplesPerSecond = 167440.6
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 0.99219475 * 5120; err = 0.31132813 * 5120; time = 0.0306s; samplesPerSecond = 167402.3
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.02102280 * 5120; err = 0.32089844 * 5120; time = 0.0306s; samplesPerSecond = 167205.5
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99145279 * 5120; err = 0.31152344 * 5120; time = 0.0306s; samplesPerSecond = 167282.0
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.95891037 * 5120; err = 0.30878906 * 5120; time = 0.0305s; samplesPerSecond = 167813.8
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 0.99036713 * 5120; err = 0.30703125 * 5120; time = 0.0307s; samplesPerSecond = 166851.3
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.99520874 * 5120; err = 0.30664063 * 5120; time = 0.0305s; samplesPerSecond = 167736.9
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00657120 * 5120; err = 0.31464844 * 5120; time = 0.0306s; samplesPerSecond = 167298.4
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.99018097 * 5120; err = 0.31484375 * 5120; time = 0.0307s; samplesPerSecond = 166889.4
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.95191345 * 5120; err = 0.30195312 * 5120; time = 0.0306s; samplesPerSecond = 167287.5
10/14/2016 09:31:50:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97685089 * 5120; err = 0.30605469 * 5120; time = 0.0305s; samplesPerSecond = 167830.3
10/14/2016 09:31:50: Finished Epoch[ 4 of 4]: [Training] ce = 0.99912224 * 81920; err = 0.31293945 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.540628s
10/14/2016 09:31:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech'

10/14/2016 09:31:51: Action "train" complete.


10/14/2016 09:31:51: ##############################################################################
10/14/2016 09:31:51: #                                                                            #
10/14/2016 09:31:51: # replaceCriterionNode command (edit action)                                 #
10/14/2016 09:31:51: #                                                                            #
10/14/2016 09:31:51: ##############################################################################


10/14/2016 09:31:51: Action "edit" complete.


10/14/2016 09:31:51: ##############################################################################
10/14/2016 09:31:51: #                                                                            #
10/14/2016 09:31:51: # sequenceTrain command (train action)                                       #
10/14/2016 09:31:51: #                                                                            #
10/14/2016 09:31:51: ##############################################################################

10/14/2016 09:31:51: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu\TestData\CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
10/14/2016 09:31:51: 
Model has 29 nodes. Using GPU 0.

10/14/2016 09:31:51: Training criterion:   ce = SequenceWithSoftmax
10/14/2016 09:31:51: Evaluation criterion: err = ClassificationError

10/14/2016 09:31:51: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

10/14/2016 09:31:51: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
10/14/2016 09:31:51: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:51: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:51: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:51: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:51: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:51: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
10/14/2016 09:31:51: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

10/14/2016 09:31:51: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-010
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

10/14/2016 09:31:51: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

10/14/2016 09:31:58: Starting minibatch loop.
dengamma value 1.010813
dengamma value 1.053567
dengamma value 1.069922
dengamma value 1.061326
dengamma value 1.058624
dengamma value 1.089351
dengamma value 0.976123
dengamma value 1.191611
dengamma value 1.011987
dengamma value 1.100422
dengamma value 1.032246
dengamma value 1.146917
dengamma value 1.041547
dengamma value 1.028939
dengamma value 1.106203
dengamma value 1.034048
dengamma value 1.124099
dengamma value 1.034000
dengamma value 1.056743
dengamma value 1.064363
dengamma value 0.996911
10/14/2016 09:32:01:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08330144 * 4628; err = 0.32713915 * 4628; time = 2.3200s; samplesPerSecond = 1994.9
dengamma value 1.098945
dengamma value 1.041185
dengamma value 1.109455
dengamma value 0.954272
dengamma value 1.115065
dengamma value 1.103072
dengamma value 1.057688
dengamma value 1.060260
dengamma value 0.978515
dengamma value 1.037171
dengamma value 0.999333
dengamma value 1.059275
dengamma value 1.039979
dengamma value 1.021931
dengamma value 1.139701
dengamma value 1.163029
dengamma value 1.135458
dengamma value 1.078447
dengamma value 1.099056
dengamma value 1.074452
dengamma value 1.081227
dengamma value 1.071118
10/14/2016 09:32:01:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08227256 * 5946; err = 0.31214262 * 5946; time = 0.6255s; samplesPerSecond = 9506.6
dengamma value 1.040578
dengamma value 1.102001
dengamma value 1.090209
dengamma value 1.133649
dengamma value 1.070618
dengamma value 1.050511
dengamma value 1.095551
dengamma value 1.104608
dengamma value 1.022729
dengamma value 1.077977
dengamma value 1.007506
dengamma value 1.079278
dengamma value 1.081541
dengamma value 1.115979
dengamma value 1.055023
dengamma value 1.072198
dengamma value 1.040951
dengamma value 0.981575
dengamma value 1.074111
dengamma value 1.110206
dengamma value 1.090361
dengamma value 1.071237
10/14/2016 09:32:02:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08325995 * 5916; err = 0.32285328 * 5916; time = 0.5297s; samplesPerSecond = 11169.5
dengamma value 1.025129
dengamma value 1.045618
dengamma value 1.039598
dengamma value 1.127857
dengamma value 1.103988
dengamma value 1.025685
dengamma value 1.076572
dengamma value 1.098188
dengamma value 1.104591
dengamma value 1.152648
dengamma value 1.044990
dengamma value 1.002877
dengamma value 1.102133
dengamma value 1.101007
dengamma value 0.955680
dengamma value 1.001784
dengamma value 1.065788
dengamma value 1.057847
dengamma value 1.041478
dengamma value 1.020996
dengamma value 1.087384
dengamma value 1.060113
10/14/2016 09:32:02:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08002894 * 6386; err = 0.33275916 * 6386; time = 0.5602s; samplesPerSecond = 11398.8
dengamma value 1.039200
dengamma value 1.076213
dengamma value 1.071171
dengamma value 1.130312
dengamma value 1.075025
dengamma value 1.095827
dengamma value 1.079816
dengamma value 1.093307
dengamma value 1.166855
dengamma value 1.048873
dengamma value 1.070442
dengamma value 1.042621
dengamma value 1.086037
dengamma value 1.045325
dengamma value 1.102499
dengamma value 1.117923
dengamma value 1.052263
dengamma value 1.035316
dengamma value 1.047596
dengamma value 0.981591
dengamma value 1.098449
dengamma value 1.150105
dengamma value 1.052417
10/14/2016 09:32:03:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08173488 * 6734; err = 0.29863380 * 6734; time = 0.6025s; samplesPerSecond = 11176.2
dengamma value 1.083423
dengamma value 1.126978
dengamma value 1.068590
dengamma value 1.086825
dengamma value 1.031178
dengamma value 0.980600
dengamma value 1.056211
dengamma value 1.121540
dengamma value 1.083726
dengamma value 1.058316
dengamma value 1.092545
dengamma value 1.031263
dengamma value 1.076191
dengamma value 0.977289
dengamma value 1.100631
dengamma value 1.043826
dengamma value 1.027584
dengamma value 1.126640
dengamma value 1.055547
dengamma value 1.073397
dengamma value 1.128533
dengamma value 1.076845
dengamma value 1.076031
dengamma value 0.973450
10/14/2016 09:32:04:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08484418 * 6202; err = 0.31264108 * 6202; time = 0.5576s; samplesPerSecond = 11123.3
dengamma value 1.127066
dengamma value 1.108877
dengamma value 1.051886
dengamma value 1.059551
dengamma value 1.149944
dengamma value 1.022880
dengamma value 1.104704
dengamma value 1.094137
dengamma value 1.058856
dengamma value 1.103320
dengamma value 1.102342
dengamma value 1.074327
dengamma value 1.108630
dengamma value 1.001979
dengamma value 0.945554
dengamma value 1.119570
dengamma value 1.085589
dengamma value 1.034662
dengamma value 1.065413
dengamma value 1.042782
dengamma value 1.071397
dengamma value 1.086801
dengamma value 1.050305
dengamma value 1.016537
10/14/2016 09:32:04:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07935476 * 6362; err = 0.32552656 * 6362; time = 0.5826s; samplesPerSecond = 10919.2
dengamma value 1.066737
dengamma value 1.082108
dengamma value 1.113538
dengamma value 1.029295
dengamma value 1.055601
dengamma value 1.096592
dengamma value 1.026282
dengamma value 1.037690
dengamma value 1.019558
dengamma value 1.127336
dengamma value 1.113253
dengamma value 1.057405
dengamma value 1.061114
dengamma value 1.053717
dengamma value 1.059038
dengamma value 1.096533
dengamma value 1.111271
dengamma value 1.134057
dengamma value 1.051571
dengamma value 1.091531
dengamma value 1.064877
10/14/2016 09:32:05:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.07491748 * 5608; err = 0.31669044 * 5608; time = 0.4999s; samplesPerSecond = 11218.7
dengamma value 1.060376
dengamma value 1.036571
dengamma value 1.059261
dengamma value 1.015821
dengamma value 1.098202
dengamma value 1.026236
dengamma value 1.102474
dengamma value 0.990043
dengamma value 1.107676
dengamma value 1.090494
dengamma value 1.041305
dengamma value 1.127041
dengamma value 1.111564
dengamma value 1.041030
dengamma value 1.059116
dengamma value 1.010456
dengamma value 1.050917
dengamma value 1.027517
dengamma value 1.092520
dengamma value 1.080199
dengamma value 1.099829
dengamma value 1.043464
dengamma value 1.014769
10/14/2016 09:32:05:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08121071 * 6594; err = 0.33166515 * 6594; time = 0.6223s; samplesPerSecond = 10596.4
dengamma value 1.021212
dengamma value 0.880379
dengamma value 1.149701
dengamma value 1.007930
dengamma value 1.108681
dengamma value 1.038727
dengamma value 1.096226
dengamma value 1.096317
dengamma value 1.114097
dengamma value 1.105358
dengamma value 1.074976
dengamma value 1.063048
dengamma value 1.085815
dengamma value 1.072817
dengamma value 1.139287
dengamma value 1.028657
dengamma value 1.117363
dengamma value 1.129794
dengamma value 1.051710
dengamma value 1.063165
dengamma value 1.071447
dengamma value 1.001418
dengamma value 1.106344
10/14/2016 09:32:06:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.07953215 * 6364; err = 0.31992458 * 6364; time = 0.6143s; samplesPerSecond = 10359.6
dengamma value 1.056535
dengamma value 1.043476
dengamma value 0.985332
dengamma value 1.057976
dengamma value 1.048038
dengamma value 1.131044
dengamma value 1.126577
dengamma value 1.075958
dengamma value 1.041575
dengamma value 1.136670
dengamma value 1.071087
dengamma value 1.156986
dengamma value 1.085340
dengamma value 1.003388
dengamma value 1.114456
dengamma value 1.053213
dengamma value 1.147603
dengamma value 1.083957
dengamma value 1.140444
dengamma value 1.136609
dengamma value 1.091818
dengamma value 1.055380
dengamma value 1.038826
dengamma value 1.112391
dengamma value 1.037130
dengamma value 0.996455
dengamma value 0.999691
10/14/2016 09:32:06:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08586847 * 6536; err = 0.31777846 * 6536; time = 0.5971s; samplesPerSecond = 10946.7
dengamma value 1.083794
dengamma value 1.054279
dengamma value 1.043891
dengamma value 1.071441
dengamma value 1.095727
dengamma value 1.049900
dengamma value 1.085945
dengamma value 1.067041
dengamma value 1.085870
dengamma value 1.026142
dengamma value 1.073640
dengamma value 1.097352
dengamma value 1.030699
dengamma value 0.934228
dengamma value 1.098489
dengamma value 1.053208
dengamma value 1.053343
dengamma value 1.014596
dengamma value 1.040647
dengamma value 1.018947
dengamma value 1.027664
10/14/2016 09:32:07:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08312107 * 6208; err = 0.31153351 * 6208; time = 0.5820s; samplesPerSecond = 10665.8
dengamma value 1.081401
dengamma value 1.072634
dengamma value 1.112671
dengamma value 1.067306
dengamma value 0.940397
dengamma value 1.044162
dengamma value 1.073388
dengamma value 1.093748
dengamma value 1.081216
dengamma value 1.047346
dengamma value 1.054239
dengamma value 1.122179
dengamma value 1.022712
dengamma value 1.178763
dengamma value 1.024520
dengamma value 1.088092
dengamma value 1.082920
dengamma value 1.078428
dengamma value 1.064357
dengamma value 1.080103
dengamma value 1.131270
dengamma value 1.116761
10/14/2016 09:32:08:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08110810 * 6326; err = 0.29908315 * 6326; time = 0.5896s; samplesPerSecond = 10729.2
dengamma value 1.080030
dengamma value 1.067617
dengamma value 1.108808
dengamma value 1.133629
dengamma value 0.994182
dengamma value 1.026217
dengamma value 1.097145
10/14/2016 09:32:08: Finished Epoch[ 1 of 3]: [Training] ce = 0.08130301 * 81936; err = 0.31606376 * 81936; totalSamplesSeen = 81936; learningRatePerSample = 2e-006; epochTime=16.4619s
10/14/2016 09:32:08: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

10/14/2016 09:32:08: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81936), data subset 0 of 1, with 1 datapasses

10/14/2016 09:32:08: Starting minibatch loop.
dengamma value 1.142727
dengamma value 1.081761
dengamma value 1.144005
dengamma value 1.049049
dengamma value 1.114474
dengamma value 1.051579
dengamma value 1.099055
dengamma value 1.137667
dengamma value 1.039834
dengamma value 1.039117
dengamma value 1.016867
dengamma value 1.084239
dengamma value 1.074856
dengamma value 1.089988
dengamma value 1.047050
dengamma value 1.011463
dengamma value 1.055807
dengamma value 1.100829
dengamma value 1.057685
dengamma value 1.070029
dengamma value 1.080165
dengamma value 1.128044
dengamma value 1.033077
dengamma value 1.033358
10/14/2016 09:32:09:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08333955 * 6182; err = 0.30087350 * 6182; time = 0.6279s; samplesPerSecond = 9845.7
dengamma value 1.043181
dengamma value 0.998904
dengamma value 1.277540
dengamma value 1.028480
dengamma value 1.085627
dengamma value 1.116363
dengamma value 1.098548
dengamma value 1.029273
dengamma value 1.045316
dengamma value 1.076029
dengamma value 1.038003
dengamma value 1.111350
dengamma value 1.128664
dengamma value 1.028735
dengamma value 1.027722
dengamma value 1.083059
dengamma value 1.026847
dengamma value 1.110027
dengamma value 1.043039
dengamma value 1.024069
dengamma value 1.041890
dengamma value 1.108358
10/14/2016 09:32:09:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08415022 * 5736; err = 0.28765690 * 5736; time = 0.5560s; samplesPerSecond = 10317.0
dengamma value 1.007215
dengamma value 1.110158
dengamma value 1.078000
dengamma value 1.079723
dengamma value 1.052228
dengamma value 1.158622
dengamma value 1.017692
dengamma value 1.124232
dengamma value 1.045670
dengamma value 1.046793
dengamma value 1.044627
dengamma value 1.047853
dengamma value 1.108116
dengamma value 1.179472
dengamma value 1.061911
dengamma value 1.163078
dengamma value 1.106670
dengamma value 1.060826
dengamma value 1.066276
dengamma value 1.094044
dengamma value 0.966373
dengamma value 0.959180
dengamma value 1.062876
10/14/2016 09:32:10:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08088687 * 6244; err = 0.30733504 * 6244; time = 0.5797s; samplesPerSecond = 10770.4
dengamma value 1.097019
dengamma value 1.110132
dengamma value 1.086533
dengamma value 1.051383
dengamma value 1.154094
dengamma value 1.083670
dengamma value 1.070526
dengamma value 1.042010
dengamma value 1.071656
dengamma value 1.010815
dengamma value 1.090738
dengamma value 1.122010
dengamma value 1.112890
dengamma value 1.124769
dengamma value 1.006035
dengamma value 1.126522
dengamma value 1.018507
dengamma value 1.015308
dengamma value 1.075688
dengamma value 1.090868
dengamma value 1.026000
dengamma value 1.059661
dengamma value 1.166139
dengamma value 1.073558
dengamma value 1.049236
10/14/2016 09:32:10:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08479231 * 6280; err = 0.31114650 * 6280; time = 0.5635s; samplesPerSecond = 11145.1
dengamma value 1.007964
dengamma value 1.070611
dengamma value 1.074382
dengamma value 1.080781
dengamma value 1.060500
dengamma value 1.071068
dengamma value 1.060052
dengamma value 1.047931
dengamma value 1.108786
dengamma value 1.062774
dengamma value 1.064598
dengamma value 1.038360
dengamma value 1.110943
dengamma value 1.059820
dengamma value 1.104559
dengamma value 1.084428
dengamma value 1.140410
dengamma value 1.085541
dengamma value 1.085620
dengamma value 1.056026
dengamma value 1.102340
dengamma value 1.079971
dengamma value 1.094004
dengamma value 1.077265
dengamma value 1.090572
dengamma value 1.101897
10/14/2016 09:32:11:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.07748323 * 7428; err = 0.30196554 * 7428; time = 0.7010s; samplesPerSecond = 10596.5
dengamma value 1.133202
dengamma value 1.075958
dengamma value 1.046372
dengamma value 1.129961
dengamma value 1.047182
dengamma value 1.029604
dengamma value 1.034183
dengamma value 1.086760
dengamma value 1.060813
dengamma value 1.057019
dengamma value 1.030997
dengamma value 1.046501
dengamma value 1.031295
dengamma value 1.138860
dengamma value 1.082792
dengamma value 1.076027
dengamma value 1.085985
dengamma value 0.972163
dengamma value 1.051432
dengamma value 1.068238
dengamma value 1.114450
dengamma value 1.013615
dengamma value 1.056237
10/14/2016 09:32:12:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08131551 * 6994; err = 0.31998856 * 6994; time = 0.5981s; samplesPerSecond = 11693.4
dengamma value 1.107592
dengamma value 1.074164
dengamma value 1.168248
dengamma value 1.020719
dengamma value 1.049899
dengamma value 1.122754
dengamma value 0.970135
dengamma value 1.129856
dengamma value 1.173341
dengamma value 1.060533
dengamma value 1.146421
dengamma value 1.111626
dengamma value 1.053436
dengamma value 1.026882
dengamma value 1.064592
dengamma value 1.080580
dengamma value 1.042032
dengamma value 1.035876
dengamma value 1.086503
dengamma value 1.086144
dengamma value 1.068495
dengamma value 1.144640
dengamma value 1.068926
dengamma value 1.091454
10/14/2016 09:32:12:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07691641 * 6572; err = 0.30477785 * 6572; time = 0.6209s; samplesPerSecond = 10584.8
dengamma value 1.091597
dengamma value 1.015069
dengamma value 1.078114
dengamma value 1.077965
dengamma value 1.067830
dengamma value 1.114765
dengamma value 1.184889
dengamma value 1.065097
dengamma value 1.068501
dengamma value 1.052224
dengamma value 0.999700
dengamma value 1.033992
dengamma value 1.012802
dengamma value 1.163340
dengamma value 1.077011
dengamma value 0.937565
dengamma value 1.007302
dengamma value 1.032539
dengamma value 1.069993
dengamma value 1.075935
dengamma value 1.206704
dengamma value 1.013961
10/14/2016 09:32:13:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08812470 * 5506; err = 0.32618961 * 5506; time = 0.5105s; samplesPerSecond = 10785.2
dengamma value 0.996695
dengamma value 1.065765
dengamma value 1.006928
dengamma value 1.075976
dengamma value 1.116437
dengamma value 1.113536
dengamma value 1.124672
dengamma value 1.072168
dengamma value 1.035176
dengamma value 1.008360
dengamma value 1.086930
dengamma value 0.954409
dengamma value 1.071499
dengamma value 1.024350
dengamma value 1.061722
dengamma value 1.109754
dengamma value 1.112504
dengamma value 1.080005
dengamma value 1.099348
dengamma value 1.004377
dengamma value 0.994480
10/14/2016 09:32:13:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08545876 * 5628; err = 0.33333333 * 5628; time = 0.5272s; samplesPerSecond = 10675.2
dengamma value 1.034617
dengamma value 1.123616
dengamma value 1.071118
dengamma value 1.085905
dengamma value 1.078446
dengamma value 0.976321
dengamma value 1.028754
dengamma value 1.004763
dengamma value 1.095321
dengamma value 1.049105
dengamma value 1.160841
dengamma value 1.085499
dengamma value 1.076978
dengamma value 1.067231
dengamma value 1.013989
dengamma value 1.038417
dengamma value 1.040735
dengamma value 1.055441
dengamma value 1.057952
dengamma value 1.137059
dengamma value 1.016247
dengamma value 1.026864
dengamma value 1.051071
dengamma value 0.985296
10/14/2016 09:32:14:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08228672 * 6032; err = 0.32708886 * 6032; time = 0.5464s; samplesPerSecond = 11039.9
dengamma value 1.036069
dengamma value 1.052771
dengamma value 1.057070
dengamma value 1.083562
dengamma value 1.061932
dengamma value 1.108845
dengamma value 1.074544
dengamma value 0.961218
dengamma value 1.119431
dengamma value 1.129746
dengamma value 1.032365
dengamma value 0.964541
dengamma value 1.053785
dengamma value 1.130472
dengamma value 1.084118
dengamma value 0.998337
dengamma value 1.155273
dengamma value 1.042959
dengamma value 1.100230
dengamma value 1.020966
10/14/2016 09:32:14:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08817523 * 4790; err = 0.33528184 * 4790; time = 0.4700s; samplesPerSecond = 10191.1
dengamma value 1.010051
dengamma value 0.962545
dengamma value 1.057832
dengamma value 1.057640
dengamma value 1.070267
dengamma value 1.012649
dengamma value 1.008626
dengamma value 1.084981
dengamma value 1.069008
dengamma value 0.953263
dengamma value 1.122590
dengamma value 1.053536
dengamma value 1.074027
dengamma value 1.009590
dengamma value 1.124196
dengamma value 1.061358
dengamma value 1.121049
dengamma value 1.163172
dengamma value 0.956156
dengamma value 1.141843
dengamma value 1.033437
dengamma value 1.033382
10/14/2016 09:32:15:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08578007 * 5986; err = 0.34363515 * 5986; time = 0.5476s; samplesPerSecond = 10931.0
dengamma value 1.017944
dengamma value 1.002557
dengamma value 1.048798
dengamma value 1.081997
dengamma value 1.024737
dengamma value 1.208782
dengamma value 1.095272
dengamma value 1.102356
dengamma value 1.068024
dengamma value 1.074346
dengamma value 1.088912
dengamma value 1.082522
dengamma value 0.995117
dengamma value 0.989362
dengamma value 1.024624
dengamma value 1.072063
dengamma value 1.046036
dengamma value 1.044180
dengamma value 1.115042
dengamma value 1.042134
dengamma value 1.104190
dengamma value 1.051856
dengamma value 1.083797
dengamma value 0.986825
10/14/2016 09:32:15:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08624520 * 7022; err = 0.31415551 * 7022; time = 0.6259s; samplesPerSecond = 11218.7
dengamma value 1.028699
dengamma value 1.092125
dengamma value 1.177922
dengamma value 1.072124
dengamma value 1.039946
dengamma value 1.076855
dengamma value 1.003565
dengamma value 1.076847
dengamma value 1.076847
10/14/2016 09:32:16: Finished Epoch[ 2 of 3]: [Training] ce = 0.08318149 * 82462; err = 0.31597584 * 82462; totalSamplesSeen = 164398; learningRatePerSample = 2e-006; epochTime=7.67366s
10/14/2016 09:32:16: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

10/14/2016 09:32:16: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 164102), data subset 0 of 1, with 1 datapasses

10/14/2016 09:32:16: Starting minibatch loop.
dengamma value 1.087636
dengamma value 1.096740
dengamma value 1.082391
dengamma value 1.101840
dengamma value 1.075501
dengamma value 1.054471
dengamma value 1.147974
dengamma value 1.031040
dengamma value 1.110178
dengamma value 0.981965
dengamma value 1.113325
dengamma value 1.070686
dengamma value 1.062902
dengamma value 1.096790
dengamma value 1.067317
dengamma value 1.054973
dengamma value 1.101891
dengamma value 1.010577
dengamma value 1.090699
dengamma value 1.091403
dengamma value 1.042045
dengamma value 1.061682
dengamma value 1.035023
dengamma value 1.034002
10/14/2016 09:32:16:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08375071 * 6292; err = 0.29577241 * 6292; time = 0.5648s; samplesPerSecond = 11139.9
dengamma value 1.154305
dengamma value 1.028805
dengamma value 0.983355
dengamma value 1.093973
dengamma value 1.080800
dengamma value 1.023480
dengamma value 1.044427
dengamma value 1.124571
dengamma value 1.030553
dengamma value 0.972422
dengamma value 0.951375
dengamma value 1.096771
dengamma value 1.058601
dengamma value 1.061875
dengamma value 1.027806
dengamma value 1.061978
dengamma value 1.009969
dengamma value 1.071149
dengamma value 1.100611
dengamma value 1.030946
dengamma value 1.063625
dengamma value 1.021002
10/14/2016 09:32:17:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.07982852 * 6596; err = 0.32731959 * 6596; time = 0.5928s; samplesPerSecond = 11126.1
dengamma value 1.077732
dengamma value 1.003030
dengamma value 1.093154
dengamma value 1.114959
dengamma value 1.068342
dengamma value 1.154573
dengamma value 1.026770
dengamma value 1.076325
dengamma value 1.050099
dengamma value 1.056673
dengamma value 1.095218
dengamma value 1.048864
dengamma value 1.021095
dengamma value 1.027027
dengamma value 1.115761
dengamma value 0.945114
dengamma value 1.046601
dengamma value 1.027408
dengamma value 1.022318
dengamma value 1.164948
dengamma value 1.069227
dengamma value 1.191568
10/14/2016 09:32:17:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08667350 * 5666; err = 0.29315214 * 5666; time = 0.5366s; samplesPerSecond = 10559.0
dengamma value 1.127089
dengamma value 1.021296
dengamma value 1.057385
dengamma value 1.089277
dengamma value 1.074904
dengamma value 1.073336
dengamma value 1.100413
dengamma value 1.064172
dengamma value 1.088663
dengamma value 1.072180
dengamma value 1.098026
dengamma value 1.048377
dengamma value 0.996858
dengamma value 1.127211
dengamma value 1.119129
dengamma value 1.030978
dengamma value 1.081222
dengamma value 1.035273
dengamma value 1.088873
dengamma value 1.033398
dengamma value 1.082120
dengamma value 1.030010
10/14/2016 09:32:18:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08123945 * 6626; err = 0.28373076 * 6626; time = 0.6129s; samplesPerSecond = 10811.4
dengamma value 1.088522
dengamma value 1.035731
dengamma value 1.022585
dengamma value 1.086574
dengamma value 1.118783
dengamma value 1.149721
dengamma value 1.092877
dengamma value 1.096528
dengamma value 1.025384
dengamma value 1.080530
dengamma value 1.138051
dengamma value 1.066387
dengamma value 1.036808
dengamma value 1.061539
dengamma value 1.022443
dengamma value 1.058962
dengamma value 1.076586
dengamma value 1.056594
dengamma value 1.105661
dengamma value 1.100929
dengamma value 1.070995
dengamma value 1.068775
dengamma value 1.061413
dengamma value 1.054328
10/14/2016 09:32:19:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08163307 * 5652; err = 0.30697098 * 5652; time = 0.5587s; samplesPerSecond = 10116.0
dengamma value 1.086107
dengamma value 1.041128
dengamma value 0.997412
dengamma value 1.044336
dengamma value 1.028712
dengamma value 1.148658
dengamma value 1.040816
dengamma value 1.045247
dengamma value 1.103276
dengamma value 1.016635
dengamma value 1.020373
dengamma value 1.049750
dengamma value 1.069377
dengamma value 1.064447
dengamma value 1.082492
dengamma value 1.032318
dengamma value 1.002113
dengamma value 1.036118
dengamma value 1.096767
dengamma value 1.038854
dengamma value 1.049953
10/14/2016 09:32:19:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08630923 * 6588; err = 0.33378871 * 6588; time = 0.5903s; samplesPerSecond = 11160.8
dengamma value 1.066441
dengamma value 1.093958
dengamma value 1.033323
dengamma value 0.981316
dengamma value 1.147939
dengamma value 1.061524
dengamma value 1.075187
dengamma value 1.032098
dengamma value 1.005410
dengamma value 1.094402
dengamma value 1.084178
dengamma value 1.017585
dengamma value 1.021937
dengamma value 1.109318
dengamma value 1.130673
dengamma value 1.051587
dengamma value 1.040534
dengamma value 1.073914
dengamma value 1.091924
dengamma value 1.049826
dengamma value 1.019380
10/14/2016 09:32:20:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08640931 * 6328; err = 0.30372946 * 6328; time = 0.5963s; samplesPerSecond = 10612.7
dengamma value 1.064719
dengamma value 1.093539
dengamma value 1.002399
dengamma value 1.094119
dengamma value 1.118071
dengamma value 1.065102
dengamma value 1.083048
dengamma value 1.106819
dengamma value 1.045471
dengamma value 0.986268
dengamma value 1.050041
dengamma value 1.030450
dengamma value 1.016237
dengamma value 1.095763
dengamma value 1.042887
dengamma value 1.079248
dengamma value 1.072767
dengamma value 1.195247
dengamma value 1.084564
dengamma value 1.056453
dengamma value 1.064537
dengamma value 1.100874
dengamma value 1.027473
dengamma value 1.096298
dengamma value 1.070845
10/14/2016 09:32:20:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08253282 * 6980; err = 0.28810888 * 6980; time = 0.6309s; samplesPerSecond = 11064.2
dengamma value 1.044561
dengamma value 0.973102
dengamma value 0.946300
dengamma value 1.126348
dengamma value 1.120933
dengamma value 1.017880
dengamma value 1.261465
dengamma value 1.100053
dengamma value 1.057651
dengamma value 1.110499
dengamma value 0.974991
dengamma value 1.068561
dengamma value 1.055017
dengamma value 1.007612
dengamma value 1.120328
dengamma value 1.056563
dengamma value 0.997949
dengamma value 1.272062
dengamma value 1.181020
dengamma value 1.040958
dengamma value 1.127123
dengamma value 0.979521
dengamma value 1.018474
10/14/2016 09:32:21:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08026136 * 6774; err = 0.31148509 * 6774; time = 0.5639s; samplesPerSecond = 12012.9
dengamma value 0.989752
dengamma value 1.074276
dengamma value 1.113957
dengamma value 1.017564
dengamma value 0.926127
dengamma value 1.067556
dengamma value 1.035497
dengamma value 1.065197
dengamma value 0.930131
dengamma value 1.063483
dengamma value 1.005306
dengamma value 1.087335
dengamma value 1.020724
dengamma value 0.977606
dengamma value 1.060993
dengamma value 0.929103
dengamma value 1.048094
dengamma value 1.005116
dengamma value 1.067375
dengamma value 1.064348
dengamma value 1.096758
dengamma value 1.078146
10/14/2016 09:32:22:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08897619 * 6146; err = 0.35356329 * 6146; time = 0.5692s; samplesPerSecond = 10797.1
dengamma value 1.009819
dengamma value 1.119422
dengamma value 1.049283
dengamma value 1.142937
dengamma value 0.951330
dengamma value 1.077497
dengamma value 1.063639
dengamma value 1.140839
dengamma value 1.102733
dengamma value 1.080079
dengamma value 1.035346
dengamma value 1.006653
dengamma value 1.168069
dengamma value 1.055353
dengamma value 1.111938
dengamma value 1.060447
dengamma value 1.082436
dengamma value 1.091862
dengamma value 1.007270
dengamma value 1.137129
dengamma value 1.056713
dengamma value 1.076516
10/14/2016 09:32:22:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08237849 * 5366; err = 0.30413716 * 5366; time = 0.5212s; samplesPerSecond = 10296.4
dengamma value 1.054579
dengamma value 1.043681
dengamma value 1.085655
dengamma value 1.058035
dengamma value 1.056141
dengamma value 1.009498
dengamma value 1.118719
dengamma value 1.059527
dengamma value 1.017717
dengamma value 1.025216
dengamma value 1.025224
dengamma value 1.062736
dengamma value 1.052254
dengamma value 1.032643
dengamma value 1.088685
dengamma value 1.082686
dengamma value 1.106165
dengamma value 1.097797
dengamma value 1.052919
dengamma value 0.983814
dengamma value 1.035006
dengamma value 1.116974
dengamma value 1.140775
dengamma value 1.090025
dengamma value 1.084324
10/14/2016 09:32:23:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08116467 * 6220; err = 0.31752412 * 6220; time = 0.5620s; samplesPerSecond = 11068.2
dengamma value 1.077858
dengamma value 1.049408
dengamma value 1.105668
dengamma value 1.075972
dengamma value 1.028771
dengamma value 1.065883
dengamma value 1.068645
dengamma value 1.100384
dengamma value 1.077524
dengamma value 1.080811
dengamma value 1.036224
dengamma value 1.059269
dengamma value 1.024829
dengamma value 1.085790
dengamma value 1.154435
dengamma value 1.110502
dengamma value 1.056073
dengamma value 0.991725
dengamma value 1.076609
dengamma value 1.027388
dengamma value 1.076504
dengamma value 1.090849
dengamma value 1.134935
10/14/2016 09:32:23:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08474558 * 6564; err = 0.29692261 * 6564; time = 0.5857s; samplesPerSecond = 11206.7
10/14/2016 09:32:23: Finished Epoch[ 3 of 3]: [Training] ce = 0.08349178 * 81798; err = 0.30889508 * 81798; totalSamplesSeen = 246196; learningRatePerSample = 2e-006; epochTime=7.4882s
10/14/2016 09:32:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

10/14/2016 09:32:23: Action "train" complete.

10/14/2016 09:32:23: __COMPLETED__