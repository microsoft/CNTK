CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on dphaim-26-new at 2016/12/15 08:28:56

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData
12/15/2016 08:28:58: -------------------------------------------------------------------
12/15/2016 08:28:58: Build info: 

12/15/2016 08:28:58: 		Built time: Dec 15 2016 06:29:34
12/15/2016 08:28:58: 		Last modified date: Wed Dec 14 12:53:20 2016
12/15/2016 08:28:58: 		Build type: Release
12/15/2016 08:28:58: 		Build target: GPU
12/15/2016 08:28:58: 		With 1bit-SGD: no
12/15/2016 08:28:58: 		With ASGD: yes
12/15/2016 08:28:58: 		Math lib: mkl
12/15/2016 08:28:58: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
12/15/2016 08:28:58: 		CUB_PATH: c:\src\cub-1.4.1
12/15/2016 08:28:58: 		CUDNN_PATH: C:\local\cudnn-8.0-windows10-x64-v5.1
12/15/2016 08:28:58: 		Build Branch: HEAD
12/15/2016 08:28:58: 		Build SHA1: 5f1fabfe95e68af0787193f8849159f824d914d5 (modified)
12/15/2016 08:28:58: 		Built by svcphil on liana-08-w
12/15/2016 08:28:58: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
12/15/2016 08:28:58: -------------------------------------------------------------------
12/15/2016 08:29:00: -------------------------------------------------------------------
12/15/2016 08:29:00: GPU info:

12/15/2016 08:29:00: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:29:00: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:29:00: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:29:00: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:29:00: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
        labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying"
            transpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
12/15/2016 08:29:00: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
12/15/2016 08:29:00: precision = "float"

12/15/2016 08:29:00: ##############################################################################
12/15/2016 08:29:00: #                                                                            #
12/15/2016 08:29:00: # dptPre1 command (train action)                                             #
12/15/2016 08:29:00: #                                                                            #
12/15/2016 08:29:00: ##############################################################################

12/15/2016 08:29:00: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/15/2016 08:29:01: 
Model has 19 nodes. Using GPU 0.

12/15/2016 08:29:01: Training criterion:   ce = CrossEntropyWithSoftmax
12/15/2016 08:29:01: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }


12/15/2016 08:29:01: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/15/2016 08:29:01: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/15/2016 08:29:01: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:01: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/15/2016 08:29:01: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/15/2016 08:29:01: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/15/2016 08:29:01: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/15/2016 08:29:01: Starting minibatch loop.
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.89978218 * 2560; err = 0.84375000 * 2560; time = 0.2526s; samplesPerSecond = 10133.8
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.96755714 * 2560; err = 0.72031250 * 2560; time = 0.0177s; samplesPerSecond = 144649.1
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.55723495 * 2560; err = 0.65859375 * 2560; time = 0.0179s; samplesPerSecond = 143288.9
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.29642715 * 2560; err = 0.61992187 * 2560; time = 0.0176s; samplesPerSecond = 145429.8
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 2.02396469 * 2560; err = 0.55117187 * 2560; time = 0.0176s; samplesPerSecond = 145314.2
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87309265 * 2560; err = 0.51484375 * 2560; time = 0.0177s; samplesPerSecond = 144952.2
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.78157196 * 2560; err = 0.50507813 * 2560; time = 0.0175s; samplesPerSecond = 145960.4
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.75391235 * 2560; err = 0.50781250 * 2560; time = 0.0177s; samplesPerSecond = 144714.5
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66460266 * 2560; err = 0.45742187 * 2560; time = 0.0177s; samplesPerSecond = 144771.8
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62184448 * 2560; err = 0.47968750 * 2560; time = 0.0177s; samplesPerSecond = 144600.1
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.65328217 * 2560; err = 0.47265625 * 2560; time = 0.0175s; samplesPerSecond = 146319.2
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.50686798 * 2560; err = 0.44921875 * 2560; time = 0.0174s; samplesPerSecond = 147406.0
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.46723938 * 2560; err = 0.42304687 * 2560; time = 0.0175s; samplesPerSecond = 146152.1
12/15/2016 08:29:01:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.49163513 * 2560; err = 0.44140625 * 2560; time = 0.0174s; samplesPerSecond = 147380.5
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46437683 * 2560; err = 0.43398437 * 2560; time = 0.0175s; samplesPerSecond = 146027.0
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43047180 * 2560; err = 0.43867187 * 2560; time = 0.0175s; samplesPerSecond = 146344.3
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.42106018 * 2560; err = 0.41992188 * 2560; time = 0.0175s; samplesPerSecond = 146135.4
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.46538086 * 2560; err = 0.42421875 * 2560; time = 0.0176s; samplesPerSecond = 145240.0
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.47427673 * 2560; err = 0.44062500 * 2560; time = 0.0176s; samplesPerSecond = 145454.5
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42846985 * 2560; err = 0.44023438 * 2560; time = 0.0177s; samplesPerSecond = 144698.2
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.34077454 * 2560; err = 0.41171875 * 2560; time = 0.0177s; samplesPerSecond = 144290.4
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.39475098 * 2560; err = 0.42734375 * 2560; time = 0.0176s; samplesPerSecond = 145075.4
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.40151062 * 2560; err = 0.41250000 * 2560; time = 0.0177s; samplesPerSecond = 144469.5
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.39343872 * 2560; err = 0.42734375 * 2560; time = 0.0177s; samplesPerSecond = 144878.3
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.32482300 * 2560; err = 0.40195313 * 2560; time = 0.0176s; samplesPerSecond = 145380.2
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.27031250 * 2560; err = 0.39843750 * 2560; time = 0.0175s; samplesPerSecond = 146052.0
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.32369690 * 2560; err = 0.39296875 * 2560; time = 0.0175s; samplesPerSecond = 146010.4
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25391541 * 2560; err = 0.38281250 * 2560; time = 0.0177s; samplesPerSecond = 144322.9
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.23369446 * 2560; err = 0.36953125 * 2560; time = 0.0176s; samplesPerSecond = 145363.7
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20872803 * 2560; err = 0.36015625 * 2560; time = 0.0178s; samplesPerSecond = 143787.9
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23682861 * 2560; err = 0.36757812 * 2560; time = 0.0177s; samplesPerSecond = 145026.1
12/15/2016 08:29:02:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.22942505 * 2560; err = 0.37460938 * 2560; time = 0.0173s; samplesPerSecond = 147610.0
12/15/2016 08:29:02: Finished Epoch[ 1 of 2]: [Training] ce = 1.65171719 * 81920; err = 0.46779785 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.962387s
12/15/2016 08:29:02: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

12/15/2016 08:29:02: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/15/2016 08:29:02: Starting minibatch loop.
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.21853390 * 2560; err = 0.37031250 * 2560; time = 0.0195s; samplesPerSecond = 131558.7
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18339520 * 2560; err = 0.36640625 * 2560; time = 0.0181s; samplesPerSecond = 141679.1
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.17222099 * 2560; err = 0.35859375 * 2560; time = 0.0192s; samplesPerSecond = 133257.0
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.20084305 * 2560; err = 0.35742188 * 2560; time = 0.0182s; samplesPerSecond = 140327.8
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.19529877 * 2560; err = 0.37773438 * 2560; time = 0.0178s; samplesPerSecond = 144192.9
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.16530914 * 2560; err = 0.34570313 * 2560; time = 0.0181s; samplesPerSecond = 141671.3
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.13811340 * 2560; err = 0.34843750 * 2560; time = 0.0177s; samplesPerSecond = 144502.1
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.19432220 * 2560; err = 0.37265625 * 2560; time = 0.0175s; samplesPerSecond = 146052.0
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.24415894 * 2560; err = 0.37929687 * 2560; time = 0.0175s; samplesPerSecond = 146210.5
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18925095 * 2560; err = 0.36523438 * 2560; time = 0.0174s; samplesPerSecond = 146763.7
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.16683502 * 2560; err = 0.35859375 * 2560; time = 0.0175s; samplesPerSecond = 146654.4
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.24675751 * 2560; err = 0.38125000 * 2560; time = 0.0174s; samplesPerSecond = 146881.6
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.19025574 * 2560; err = 0.35195312 * 2560; time = 0.0173s; samplesPerSecond = 147575.9
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.22029724 * 2560; err = 0.37382813 * 2560; time = 0.0178s; samplesPerSecond = 143731.4
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.20153046 * 2560; err = 0.37343750 * 2560; time = 0.0178s; samplesPerSecond = 144095.5
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.14394226 * 2560; err = 0.34101562 * 2560; time = 0.0179s; samplesPerSecond = 143409.3
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.14187469 * 2560; err = 0.35742188 * 2560; time = 0.0177s; samplesPerSecond = 144436.9
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.17012939 * 2560; err = 0.34687500 * 2560; time = 0.0177s; samplesPerSecond = 144706.3
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.15014648 * 2560; err = 0.35546875 * 2560; time = 0.0177s; samplesPerSecond = 144518.5
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08505096 * 2560; err = 0.33359375 * 2560; time = 0.0177s; samplesPerSecond = 144812.8
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.14442139 * 2560; err = 0.34726563 * 2560; time = 0.0178s; samplesPerSecond = 144030.6
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.17172089 * 2560; err = 0.36093750 * 2560; time = 0.0177s; samplesPerSecond = 144861.9
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.19044189 * 2560; err = 0.37382813 * 2560; time = 0.0176s; samplesPerSecond = 145388.5
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.14433289 * 2560; err = 0.34453125 * 2560; time = 0.0178s; samplesPerSecond = 143876.8
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.14347839 * 2560; err = 0.35039063 * 2560; time = 0.0177s; samplesPerSecond = 144339.2
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07991028 * 2560; err = 0.32812500 * 2560; time = 0.0178s; samplesPerSecond = 144087.4
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.09500122 * 2560; err = 0.34335938 * 2560; time = 0.0178s; samplesPerSecond = 143521.9
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.06157837 * 2560; err = 0.33085938 * 2560; time = 0.0179s; samplesPerSecond = 143168.7
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09024658 * 2560; err = 0.33476563 * 2560; time = 0.0179s; samplesPerSecond = 143032.7
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.14956360 * 2560; err = 0.35742188 * 2560; time = 0.0178s; samplesPerSecond = 144136.0
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.11126099 * 2560; err = 0.34609375 * 2560; time = 0.0177s; samplesPerSecond = 144771.8
12/15/2016 08:29:02:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07835693 * 2560; err = 0.32343750 * 2560; time = 0.0174s; samplesPerSecond = 147109.5
12/15/2016 08:29:02: Finished Epoch[ 2 of 2]: [Training] ce = 1.15870562 * 81920; err = 0.35488281 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.573351s
12/15/2016 08:29:02: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

12/15/2016 08:29:02: Action "train" complete.


12/15/2016 08:29:02: ##############################################################################
12/15/2016 08:29:02: #                                                                            #
12/15/2016 08:29:02: # addLayer2 command (edit action)                                            #
12/15/2016 08:29:02: #                                                                            #
12/15/2016 08:29:02: ##############################################################################


12/15/2016 08:29:03: Action "edit" complete.


12/15/2016 08:29:03: ##############################################################################
12/15/2016 08:29:03: #                                                                            #
12/15/2016 08:29:03: # dptPre2 command (train action)                                             #
12/15/2016 08:29:03: #                                                                            #
12/15/2016 08:29:03: ##############################################################################

12/15/2016 08:29:03: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/15/2016 08:29:03: 
Model has 24 nodes. Using GPU 0.

12/15/2016 08:29:03: Training criterion:   ce = CrossEntropyWithSoftmax
12/15/2016 08:29:03: Evaluation criterion: err = ClassificationError

12/15/2016 08:29:03: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/15/2016 08:29:03: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/15/2016 08:29:03: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:03: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:29:03: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:03: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/15/2016 08:29:03: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/15/2016 08:29:03: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/15/2016 08:29:03: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/15/2016 08:29:03: Starting minibatch loop.
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 4.74167099 * 2560; err = 0.81054688 * 2560; time = 0.0306s; samplesPerSecond = 83728.5
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.84300308 * 2560; err = 0.69531250 * 2560; time = 0.0220s; samplesPerSecond = 116549.1
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.27835464 * 2560; err = 0.59335938 * 2560; time = 0.0219s; samplesPerSecond = 116644.6
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.94081573 * 2560; err = 0.52343750 * 2560; time = 0.0219s; samplesPerSecond = 116820.3
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.72623672 * 2560; err = 0.47890625 * 2560; time = 0.0221s; samplesPerSecond = 115774.2
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.62105103 * 2560; err = 0.47070313 * 2560; time = 0.0222s; samplesPerSecond = 115336.1
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.51758118 * 2560; err = 0.44609375 * 2560; time = 0.0223s; samplesPerSecond = 114690.2
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.50083008 * 2560; err = 0.44023438 * 2560; time = 0.0223s; samplesPerSecond = 114973.5
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.46038666 * 2560; err = 0.41679688 * 2560; time = 0.0221s; samplesPerSecond = 115669.6
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.41371765 * 2560; err = 0.41250000 * 2560; time = 0.0220s; samplesPerSecond = 116522.5
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41839752 * 2560; err = 0.41132812 * 2560; time = 0.0221s; samplesPerSecond = 116089.2
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.34823303 * 2560; err = 0.39921875 * 2560; time = 0.0220s; samplesPerSecond = 116194.6
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.32336731 * 2560; err = 0.39257813 * 2560; time = 0.0221s; samplesPerSecond = 116094.5
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33528748 * 2560; err = 0.39765625 * 2560; time = 0.0222s; samplesPerSecond = 115346.5
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.33034973 * 2560; err = 0.39609375 * 2560; time = 0.0221s; samplesPerSecond = 115931.5
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28290405 * 2560; err = 0.39062500 * 2560; time = 0.0222s; samplesPerSecond = 115549.5
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.29310608 * 2560; err = 0.38515625 * 2560; time = 0.0220s; samplesPerSecond = 116226.3
12/15/2016 08:29:03:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.29662476 * 2560; err = 0.39023438 * 2560; time = 0.0220s; samplesPerSecond = 116353.1
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.33261414 * 2560; err = 0.40078125 * 2560; time = 0.0221s; samplesPerSecond = 115763.8
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32491455 * 2560; err = 0.41210938 * 2560; time = 0.0221s; samplesPerSecond = 115659.2
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.23887329 * 2560; err = 0.37304688 * 2560; time = 0.0221s; samplesPerSecond = 115910.5
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.27495728 * 2560; err = 0.39453125 * 2560; time = 0.0221s; samplesPerSecond = 115627.8
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.26325378 * 2560; err = 0.37070313 * 2560; time = 0.0220s; samplesPerSecond = 116443.0
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.24714355 * 2560; err = 0.37148437 * 2560; time = 0.0221s; samplesPerSecond = 115648.7
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.21944275 * 2560; err = 0.36796875 * 2560; time = 0.0220s; samplesPerSecond = 116533.1
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19143677 * 2560; err = 0.36914063 * 2560; time = 0.0219s; samplesPerSecond = 117044.6
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.24004211 * 2560; err = 0.36484375 * 2560; time = 0.0220s; samplesPerSecond = 116252.7
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.18594666 * 2560; err = 0.35781250 * 2560; time = 0.0219s; samplesPerSecond = 116911.0
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.16903687 * 2560; err = 0.35117188 * 2560; time = 0.0219s; samplesPerSecond = 116650.0
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.14319458 * 2560; err = 0.33906250 * 2560; time = 0.0221s; samplesPerSecond = 115748.1
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.17464294 * 2560; err = 0.35117188 * 2560; time = 0.0221s; samplesPerSecond = 115591.3
12/15/2016 08:29:04:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.19253845 * 2560; err = 0.37187500 * 2560; time = 0.0217s; samplesPerSecond = 117739.0
12/15/2016 08:29:04: Finished Epoch[ 1 of 2]: [Training] ce = 1.52718611 * 81920; err = 0.42645264 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.876866s
12/15/2016 08:29:04: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

12/15/2016 08:29:04: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/15/2016 08:29:04: Starting minibatch loop.
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.18524780 * 2560; err = 0.35585937 * 2560; time = 0.0238s; samplesPerSecond = 107662.5
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.15788822 * 2560; err = 0.35703125 * 2560; time = 0.0222s; samplesPerSecond = 115216.7
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15483952 * 2560; err = 0.34453125 * 2560; time = 0.0221s; samplesPerSecond = 115795.2
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.13996239 * 2560; err = 0.34765625 * 2560; time = 0.0221s; samplesPerSecond = 115669.6
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.14662666 * 2560; err = 0.36679688 * 2560; time = 0.0221s; samplesPerSecond = 115915.8
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.14488792 * 2560; err = 0.33789063 * 2560; time = 0.0220s; samplesPerSecond = 116226.3
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.10152817 * 2560; err = 0.34218750 * 2560; time = 0.0220s; samplesPerSecond = 116305.5
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.15620499 * 2560; err = 0.35703125 * 2560; time = 0.0222s; samplesPerSecond = 115466.1
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.16887283 * 2560; err = 0.36171875 * 2560; time = 0.0220s; samplesPerSecond = 116168.3
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.11664963 * 2560; err = 0.34218750 * 2560; time = 0.0221s; samplesPerSecond = 115910.5
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.11689453 * 2560; err = 0.34492187 * 2560; time = 0.0220s; samplesPerSecond = 116189.4
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19347076 * 2560; err = 0.36523438 * 2560; time = 0.0221s; samplesPerSecond = 115648.7
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.13292542 * 2560; err = 0.33945313 * 2560; time = 0.0222s; samplesPerSecond = 115575.6
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16542816 * 2560; err = 0.35703125 * 2560; time = 0.0221s; samplesPerSecond = 116026.1
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.12298584 * 2560; err = 0.34804687 * 2560; time = 0.0220s; samplesPerSecond = 116163.0
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.09707184 * 2560; err = 0.33945313 * 2560; time = 0.0220s; samplesPerSecond = 116363.6
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.10823212 * 2560; err = 0.33710937 * 2560; time = 0.0219s; samplesPerSecond = 116959.1
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.10896149 * 2560; err = 0.33203125 * 2560; time = 0.0220s; samplesPerSecond = 116226.3
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.10190125 * 2560; err = 0.33710937 * 2560; time = 0.0222s; samplesPerSecond = 115107.9
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.05974274 * 2560; err = 0.33203125 * 2560; time = 0.0223s; samplesPerSecond = 114597.8
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.10639954 * 2560; err = 0.34453125 * 2560; time = 0.0224s; samplesPerSecond = 114531.1
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13493958 * 2560; err = 0.35117188 * 2560; time = 0.0222s; samplesPerSecond = 115466.1
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.12500610 * 2560; err = 0.34414062 * 2560; time = 0.0224s; samplesPerSecond = 114428.8
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10846252 * 2560; err = 0.34023437 * 2560; time = 0.0221s; samplesPerSecond = 116026.1
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09664307 * 2560; err = 0.34179688 * 2560; time = 0.0220s; samplesPerSecond = 116310.8
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.05256653 * 2560; err = 0.32656250 * 2560; time = 0.0221s; samplesPerSecond = 116099.8
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.05011597 * 2560; err = 0.33515625 * 2560; time = 0.0221s; samplesPerSecond = 115601.7
12/15/2016 08:29:04:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.03956299 * 2560; err = 0.32460937 * 2560; time = 0.0221s; samplesPerSecond = 116036.6
12/15/2016 08:29:05:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.05979309 * 2560; err = 0.32617188 * 2560; time = 0.0220s; samplesPerSecond = 116215.7
12/15/2016 08:29:05:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.11582336 * 2560; err = 0.34140625 * 2560; time = 0.0221s; samplesPerSecond = 116047.1
12/15/2016 08:29:05:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08835449 * 2560; err = 0.33007813 * 2560; time = 0.0221s; samplesPerSecond = 116015.6
12/15/2016 08:29:05:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.04839172 * 2560; err = 0.32617188 * 2560; time = 0.0216s; samplesPerSecond = 118617.4
12/15/2016 08:29:05: Finished Epoch[ 2 of 2]: [Training] ce = 1.11582441 * 81920; err = 0.34304199 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.711371s
12/15/2016 08:29:05: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

12/15/2016 08:29:05: Action "train" complete.


12/15/2016 08:29:05: ##############################################################################
12/15/2016 08:29:05: #                                                                            #
12/15/2016 08:29:05: # addLayer3 command (edit action)                                            #
12/15/2016 08:29:05: #                                                                            #
12/15/2016 08:29:05: ##############################################################################


12/15/2016 08:29:05: Action "edit" complete.


12/15/2016 08:29:05: ##############################################################################
12/15/2016 08:29:05: #                                                                            #
12/15/2016 08:29:05: # speechTrain command (train action)                                         #
12/15/2016 08:29:05: #                                                                            #
12/15/2016 08:29:05: ##############################################################################

12/15/2016 08:29:05: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/15/2016 08:29:06: 
Model has 29 nodes. Using GPU 0.

12/15/2016 08:29:06: Training criterion:   ce = CrossEntropyWithSoftmax
12/15/2016 08:29:06: Evaluation criterion: err = ClassificationError

12/15/2016 08:29:06: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

12/15/2016 08:29:06: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/15/2016 08:29:06: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:06: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:29:06: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:06: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:29:06: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:06: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/15/2016 08:29:06: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/15/2016 08:29:06: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/15/2016 08:29:06: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/15/2016 08:29:06: Starting minibatch loop.
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.09883881 * 2560; err = 0.82031250 * 2560; time = 0.0440s; samplesPerSecond = 58195.0
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.57322998 * 2560; err = 0.63984375 * 2560; time = 0.0317s; samplesPerSecond = 80647.7
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03002777 * 2560; err = 0.54179687 * 2560; time = 0.0316s; samplesPerSecond = 80966.5
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.73531723 * 2560; err = 0.47421875 * 2560; time = 0.0316s; samplesPerSecond = 80964.0
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.54839096 * 2560; err = 0.44062500 * 2560; time = 0.0316s; samplesPerSecond = 81061.4
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.44536438 * 2560; err = 0.41250000 * 2560; time = 0.0315s; samplesPerSecond = 81396.5
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.36092682 * 2560; err = 0.40390625 * 2560; time = 0.0316s; samplesPerSecond = 81130.8
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.35942230 * 2560; err = 0.39570312 * 2560; time = 0.0316s; samplesPerSecond = 81087.1
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.34109039 * 2560; err = 0.38789062 * 2560; time = 0.0299s; samplesPerSecond = 85561.5
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30646057 * 2560; err = 0.38203125 * 2560; time = 0.0291s; samplesPerSecond = 88033.0
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31617279 * 2560; err = 0.38789062 * 2560; time = 0.0291s; samplesPerSecond = 88081.5
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.23955231 * 2560; err = 0.36718750 * 2560; time = 0.0290s; samplesPerSecond = 88227.2
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.21489868 * 2560; err = 0.35351563 * 2560; time = 0.0290s; samplesPerSecond = 88294.1
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.24303131 * 2560; err = 0.36914063 * 2560; time = 0.0290s; samplesPerSecond = 88379.5
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.23680115 * 2560; err = 0.37460938 * 2560; time = 0.0289s; samplesPerSecond = 88443.6
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.19860382 * 2560; err = 0.35351563 * 2560; time = 0.0289s; samplesPerSecond = 88627.3
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.21908875 * 2560; err = 0.36718750 * 2560; time = 0.0289s; samplesPerSecond = 88615.0
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.25010681 * 2560; err = 0.37304688 * 2560; time = 0.0289s; samplesPerSecond = 88612.0
12/15/2016 08:29:06:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.27134705 * 2560; err = 0.38398437 * 2560; time = 0.0284s; samplesPerSecond = 90118.6
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.22826843 * 2560; err = 0.39062500 * 2560; time = 0.0270s; samplesPerSecond = 94878.1
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.17830505 * 2560; err = 0.35585937 * 2560; time = 0.0270s; samplesPerSecond = 94688.6
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.20061646 * 2560; err = 0.36914063 * 2560; time = 0.0269s; samplesPerSecond = 95170.8
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.21882324 * 2560; err = 0.35976562 * 2560; time = 0.0270s; samplesPerSecond = 94867.5
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.18892212 * 2560; err = 0.35664062 * 2560; time = 0.0270s; samplesPerSecond = 94906.2
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17613525 * 2560; err = 0.35664062 * 2560; time = 0.0272s; samplesPerSecond = 94027.8
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.12889709 * 2560; err = 0.35468750 * 2560; time = 0.0269s; samplesPerSecond = 95117.8
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.19678345 * 2560; err = 0.36015625 * 2560; time = 0.0270s; samplesPerSecond = 94716.6
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.13889160 * 2560; err = 0.35312500 * 2560; time = 0.0269s; samplesPerSecond = 95199.1
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.12339172 * 2560; err = 0.33593750 * 2560; time = 0.0270s; samplesPerSecond = 94818.3
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.10182190 * 2560; err = 0.33828125 * 2560; time = 0.0268s; samplesPerSecond = 95380.0
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12782288 * 2560; err = 0.33789063 * 2560; time = 0.0253s; samplesPerSecond = 101018.1
12/15/2016 08:29:07:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.13245239 * 2560; err = 0.34921875 * 2560; time = 0.0249s; samplesPerSecond = 102770.0
12/15/2016 08:29:07: Finished Epoch[ 1 of 4]: [Training] ce = 1.41030636 * 81920; err = 0.40146484 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=1.16022s
12/15/2016 08:29:07: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

12/15/2016 08:29:07: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/15/2016 08:29:07: Starting minibatch loop.
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.20105247 * 5120; err = 0.35957031 * 5120; time = 0.0434s; samplesPerSecond = 117893.6
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.14062042 * 5120; err = 0.33886719 * 5120; time = 0.0312s; samplesPerSecond = 164081.5
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.10435333 * 5120; err = 0.33710937 * 5120; time = 0.0308s; samplesPerSecond = 166109.7
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10075417 * 5120; err = 0.34433594 * 5120; time = 0.0309s; samplesPerSecond = 165561.8
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16076813 * 5120; err = 0.35859375 * 5120; time = 0.0311s; samplesPerSecond = 164572.0
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.16044693 * 5120; err = 0.35429688 * 5120; time = 0.0316s; samplesPerSecond = 161856.3
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.14450684 * 5120; err = 0.34218750 * 5120; time = 0.0310s; samplesPerSecond = 165315.9
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.09959564 * 5120; err = 0.34355469 * 5120; time = 0.0309s; samplesPerSecond = 165615.4
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.13638000 * 5120; err = 0.35136719 * 5120; time = 0.0311s; samplesPerSecond = 164768.0
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.08415527 * 5120; err = 0.33125000 * 5120; time = 0.0314s; samplesPerSecond = 163067.7
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.10513916 * 5120; err = 0.33906250 * 5120; time = 0.0315s; samplesPerSecond = 162503.6
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.11582870 * 5120; err = 0.34472656 * 5120; time = 0.0312s; samplesPerSecond = 163855.7
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05081482 * 5120; err = 0.32285156 * 5120; time = 0.0310s; samplesPerSecond = 165108.0
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02892609 * 5120; err = 0.32265625 * 5120; time = 0.0313s; samplesPerSecond = 163813.8
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08521881 * 5120; err = 0.33359375 * 5120; time = 0.0311s; samplesPerSecond = 164852.9
12/15/2016 08:29:07:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06631470 * 5120; err = 0.32285156 * 5120; time = 0.0304s; samplesPerSecond = 168177.6
12/15/2016 08:29:07: Finished Epoch[ 2 of 4]: [Training] ce = 1.11155472 * 81920; err = 0.34042969 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.513255s
12/15/2016 08:29:08: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

12/15/2016 08:29:08: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

12/15/2016 08:29:08: Starting minibatch loop.
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.12035828 * 5120; err = 0.33808594 * 5120; time = 0.0322s; samplesPerSecond = 159184.2
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.08019066 * 5120; err = 0.33613281 * 5120; time = 0.0309s; samplesPerSecond = 165604.7
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08200569 * 5120; err = 0.33710937 * 5120; time = 0.0310s; samplesPerSecond = 165187.9
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10718307 * 5120; err = 0.34023437 * 5120; time = 0.0309s; samplesPerSecond = 165781.6
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07951164 * 5120; err = 0.33535156 * 5120; time = 0.0309s; samplesPerSecond = 165722.6
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.05355492 * 5120; err = 0.32597656 * 5120; time = 0.0308s; samplesPerSecond = 166201.4
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06127243 * 5120; err = 0.32597656 * 5120; time = 0.0309s; samplesPerSecond = 165626.1
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07337036 * 5120; err = 0.32832031 * 5120; time = 0.0310s; samplesPerSecond = 165182.6
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.03899231 * 5120; err = 0.32187500 * 5120; time = 0.0310s; samplesPerSecond = 165332.0
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.05433731 * 5120; err = 0.32421875 * 5120; time = 0.0311s; samplesPerSecond = 164746.8
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.04803772 * 5120; err = 0.32246094 * 5120; time = 0.0309s; samplesPerSecond = 165444.1
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.08577728 * 5120; err = 0.34277344 * 5120; time = 0.0310s; samplesPerSecond = 165390.7
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.10846710 * 5120; err = 0.33183594 * 5120; time = 0.0311s; samplesPerSecond = 164725.6
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.05836334 * 5120; err = 0.32089844 * 5120; time = 0.0315s; samplesPerSecond = 162694.6
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.05460358 * 5120; err = 0.33105469 * 5120; time = 0.0307s; samplesPerSecond = 166585.3
12/15/2016 08:29:08:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.04181213 * 5120; err = 0.32617188 * 5120; time = 0.0303s; samplesPerSecond = 168976.9
12/15/2016 08:29:08: Finished Epoch[ 3 of 4]: [Training] ce = 1.07173986 * 81920; err = 0.33052979 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.499185s
12/15/2016 08:29:08: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

12/15/2016 08:29:08: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

12/15/2016 08:29:08: Starting minibatch loop.
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.03390188 * 5120; err = 0.32187500 * 5120; time = 0.0328s; samplesPerSecond = 155954.9
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.03852396 * 4926; err = 0.31526594 * 4926; time = 0.0758s; samplesPerSecond = 64982.5
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.00715580 * 5120; err = 0.31796875 * 5120; time = 0.0313s; samplesPerSecond = 163374.7
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.00949211 * 5120; err = 0.31992188 * 5120; time = 0.0310s; samplesPerSecond = 165326.6
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 0.99561920 * 5120; err = 0.31171875 * 5120; time = 0.0309s; samplesPerSecond = 165813.8
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00287132 * 5120; err = 0.31484375 * 5120; time = 0.0310s; samplesPerSecond = 165214.6
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 0.99213638 * 5120; err = 0.30214844 * 5120; time = 0.0310s; samplesPerSecond = 165412.1
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.01515121 * 5120; err = 0.31757812 * 5120; time = 0.0309s; samplesPerSecond = 165438.8
12/15/2016 08:29:08:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99261093 * 5120; err = 0.30917969 * 5120; time = 0.0309s; samplesPerSecond = 165524.4
12/15/2016 08:29:09:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.97133331 * 5120; err = 0.31054688 * 5120; time = 0.0309s; samplesPerSecond = 165583.3
12/15/2016 08:29:09:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 0.98741531 * 5120; err = 0.30839844 * 5120; time = 0.0308s; samplesPerSecond = 166325.6
12/15/2016 08:29:09:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.99450150 * 5120; err = 0.30800781 * 5120; time = 0.0307s; samplesPerSecond = 166639.5
12/15/2016 08:29:09:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00091553 * 5120; err = 0.30898437 * 5120; time = 0.0307s; samplesPerSecond = 166634.1
12/15/2016 08:29:09:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.97703552 * 5120; err = 0.30683594 * 5120; time = 0.0307s; samplesPerSecond = 166634.1
12/15/2016 08:29:09:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.93543549 * 5120; err = 0.29824219 * 5120; time = 0.0313s; samplesPerSecond = 163808.5
12/15/2016 08:29:09:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97297211 * 5120; err = 0.30429688 * 5120; time = 0.0307s; samplesPerSecond = 166558.2
12/15/2016 08:29:09: Finished Epoch[ 4 of 4]: [Training] ce = 0.99517956 * 81920; err = 0.31094971 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.546954s
12/15/2016 08:29:09: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech'

12/15/2016 08:29:09: Action "train" complete.


12/15/2016 08:29:09: ##############################################################################
12/15/2016 08:29:09: #                                                                            #
12/15/2016 08:29:09: # replaceCriterionNode command (edit action)                                 #
12/15/2016 08:29:09: #                                                                            #
12/15/2016 08:29:09: ##############################################################################


12/15/2016 08:29:09: Action "edit" complete.


12/15/2016 08:29:09: ##############################################################################
12/15/2016 08:29:09: #                                                                            #
12/15/2016 08:29:09: # sequenceTrain command (train action)                                       #
12/15/2016 08:29:09: #                                                                            #
12/15/2016 08:29:09: ##############################################################################

12/15/2016 08:29:09: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu\TestData\CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
12/15/2016 08:29:10: 
Model has 29 nodes. Using GPU 0.

12/15/2016 08:29:10: Training criterion:   ce = SequenceWithSoftmax
12/15/2016 08:29:10: Evaluation criterion: err = ClassificationError

12/15/2016 08:29:10: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

12/15/2016 08:29:10: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/15/2016 08:29:10: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:10: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:29:10: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:10: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:29:10: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:29:10: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/15/2016 08:29:10: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/15/2016 08:29:10: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-010
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

12/15/2016 08:29:10: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/15/2016 08:29:17: Starting minibatch loop.
dengamma value 1.018244
dengamma value 1.054675
dengamma value 1.074819
dengamma value 1.064547
dengamma value 1.067486
dengamma value 1.105522
dengamma value 0.977820
dengamma value 1.194798
dengamma value 1.017469
dengamma value 1.106882
dengamma value 1.031883
dengamma value 1.152337
dengamma value 1.049235
dengamma value 1.024297
dengamma value 1.107913
dengamma value 1.031237
dengamma value 1.117306
dengamma value 1.038063
dengamma value 1.058686
dengamma value 1.058911
dengamma value 1.000544
12/15/2016 08:29:19:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08408287 * 4628; err = 0.33146067 * 4628; time = 2.3538s; samplesPerSecond = 1966.2
dengamma value 1.102830
dengamma value 1.038706
dengamma value 1.118447
dengamma value 0.959611
dengamma value 1.126940
dengamma value 1.105626
dengamma value 1.063953
dengamma value 1.068995
dengamma value 0.984464
dengamma value 1.043641
dengamma value 1.010103
dengamma value 1.062429
dengamma value 1.042592
dengamma value 1.027040
dengamma value 1.144248
dengamma value 1.171111
dengamma value 1.140285
dengamma value 1.079819
dengamma value 1.115921
dengamma value 1.076322
dengamma value 1.088631
dengamma value 1.081052
12/15/2016 08:29:20:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08232441 * 5946; err = 0.31315170 * 5946; time = 0.6515s; samplesPerSecond = 9126.5
dengamma value 1.046788
dengamma value 1.108406
dengamma value 1.096271
dengamma value 1.135374
dengamma value 1.071471
dengamma value 1.062697
dengamma value 1.097505
dengamma value 1.107006
dengamma value 1.026202
dengamma value 1.078646
dengamma value 1.013913
dengamma value 1.077880
dengamma value 1.078731
dengamma value 1.124053
dengamma value 1.061216
dengamma value 1.075155
dengamma value 1.046904
dengamma value 0.988090
dengamma value 1.081479
dengamma value 1.115638
dengamma value 1.094946
dengamma value 1.076471
12/15/2016 08:29:20:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08376621 * 5916; err = 0.32403651 * 5916; time = 0.5970s; samplesPerSecond = 9909.6
dengamma value 1.024548
dengamma value 1.047511
dengamma value 1.041524
dengamma value 1.137186
dengamma value 1.104863
dengamma value 1.035010
dengamma value 1.084050
dengamma value 1.105248
dengamma value 1.106479
dengamma value 1.161050
dengamma value 1.054518
dengamma value 1.007265
dengamma value 1.107339
dengamma value 1.112591
dengamma value 0.950099
dengamma value 1.011899
dengamma value 1.071695
dengamma value 1.062175
dengamma value 1.044814
dengamma value 1.018995
dengamma value 1.095460
dengamma value 1.073376
12/15/2016 08:29:21:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08025817 * 6386; err = 0.32947072 * 6386; time = 0.6273s; samplesPerSecond = 10180.6
dengamma value 1.044378
dengamma value 1.083695
dengamma value 1.075362
dengamma value 1.127366
dengamma value 1.081958
dengamma value 1.103210
dengamma value 1.084509
dengamma value 1.095316
dengamma value 1.173612
dengamma value 1.060373
dengamma value 1.082699
dengamma value 1.046336
dengamma value 1.093552
dengamma value 1.048264
dengamma value 1.109601
dengamma value 1.125223
dengamma value 1.052911
dengamma value 1.040133
dengamma value 1.055259
dengamma value 0.988017
dengamma value 1.103789
dengamma value 1.165368
dengamma value 1.055686
12/15/2016 08:29:21:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08187659 * 6734; err = 0.29581230 * 6734; time = 0.6580s; samplesPerSecond = 10233.7
dengamma value 1.088038
dengamma value 1.127336
dengamma value 1.078051
dengamma value 1.094395
dengamma value 1.039800
dengamma value 0.990507
dengamma value 1.065936
dengamma value 1.126821
dengamma value 1.087375
dengamma value 1.056771
dengamma value 1.097724
dengamma value 1.033527
dengamma value 1.084542
dengamma value 0.983820
dengamma value 1.107373
dengamma value 1.047426
dengamma value 1.034155
dengamma value 1.141293
dengamma value 1.066307
dengamma value 1.076243
dengamma value 1.134380
dengamma value 1.073682
dengamma value 1.079007
dengamma value 0.979878
12/15/2016 08:29:22:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08548949 * 6202; err = 0.31409223 * 6202; time = 0.5820s; samplesPerSecond = 10656.6
dengamma value 1.129627
dengamma value 1.110994
dengamma value 1.059747
dengamma value 1.062095
dengamma value 1.152112
dengamma value 1.033736
dengamma value 1.110210
dengamma value 1.097902
dengamma value 1.063220
dengamma value 1.111680
dengamma value 1.108287
dengamma value 1.079266
dengamma value 1.110608
dengamma value 1.010746
dengamma value 0.953161
dengamma value 1.129591
dengamma value 1.088841
dengamma value 1.032469
dengamma value 1.066154
dengamma value 1.043133
dengamma value 1.071585
dengamma value 1.096228
dengamma value 1.055553
dengamma value 1.017836
12/15/2016 08:29:23:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08027219 * 6362; err = 0.31986797 * 6362; time = 0.5918s; samplesPerSecond = 10750.3
dengamma value 1.076993
dengamma value 1.086235
dengamma value 1.122678
dengamma value 1.033734
dengamma value 1.063240
dengamma value 1.101795
dengamma value 1.030007
dengamma value 1.040029
dengamma value 1.026286
dengamma value 1.134625
dengamma value 1.115102
dengamma value 1.050001
dengamma value 1.063581
dengamma value 1.069772
dengamma value 1.063847
dengamma value 1.102745
dengamma value 1.121613
dengamma value 1.137498
dengamma value 1.056815
dengamma value 1.095439
dengamma value 1.068626
12/15/2016 08:29:23:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.07506710 * 5608; err = 0.32471469 * 5608; time = 0.5033s; samplesPerSecond = 11142.5
dengamma value 1.066322
dengamma value 1.047410
dengamma value 1.062264
dengamma value 1.016632
dengamma value 1.096004
dengamma value 1.031493
dengamma value 1.106665
dengamma value 0.993220
dengamma value 1.110627
dengamma value 1.095481
dengamma value 1.046925
dengamma value 1.117958
dengamma value 1.109956
dengamma value 1.044942
dengamma value 1.064652
dengamma value 1.020967
dengamma value 1.052344
dengamma value 1.031910
dengamma value 1.095509
dengamma value 1.083885
dengamma value 1.110995
dengamma value 1.049869
dengamma value 1.016282
12/15/2016 08:29:24:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08184254 * 6594; err = 0.33500152 * 6594; time = 0.6319s; samplesPerSecond = 10435.1
dengamma value 1.022956
dengamma value 0.882555
dengamma value 1.153609
dengamma value 1.016037
dengamma value 1.123434
dengamma value 1.045451
dengamma value 1.096786
dengamma value 1.102373
dengamma value 1.113371
dengamma value 1.114171
dengamma value 1.081186
dengamma value 1.070550
dengamma value 1.091953
dengamma value 1.080379
dengamma value 1.144489
dengamma value 1.036543
dengamma value 1.124244
dengamma value 1.136956
dengamma value 1.056402
dengamma value 1.067521
dengamma value 1.074208
dengamma value 1.006966
dengamma value 1.111260
12/15/2016 08:29:24:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08005534 * 6364; err = 0.31285355 * 6364; time = 0.6209s; samplesPerSecond = 10249.8
dengamma value 1.065405
dengamma value 1.051239
dengamma value 0.994896
dengamma value 1.061812
dengamma value 1.053229
dengamma value 1.144456
dengamma value 1.132612
dengamma value 1.078085
dengamma value 1.048426
dengamma value 1.143194
dengamma value 1.076260
dengamma value 1.163339
dengamma value 1.098771
dengamma value 1.008245
dengamma value 1.122606
dengamma value 1.056073
dengamma value 1.155770
dengamma value 1.092417
dengamma value 1.148046
dengamma value 1.142789
dengamma value 1.092340
dengamma value 1.053116
dengamma value 1.046732
dengamma value 1.115999
dengamma value 1.049864
dengamma value 1.002852
dengamma value 1.010600
12/15/2016 08:29:25:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08598449 * 6536; err = 0.31533048 * 6536; time = 0.6044s; samplesPerSecond = 10813.2
dengamma value 1.085726
dengamma value 1.059181
dengamma value 1.055134
dengamma value 1.076407
dengamma value 1.099468
dengamma value 1.050823
dengamma value 1.087317
dengamma value 1.073496
dengamma value 1.096072
dengamma value 1.032853
dengamma value 1.079216
dengamma value 1.104478
dengamma value 1.035479
dengamma value 0.938556
dengamma value 1.106820
dengamma value 1.053933
dengamma value 1.064715
dengamma value 1.019852
dengamma value 1.043713
dengamma value 1.025967
dengamma value 1.037465
12/15/2016 08:29:26:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08295755 * 6208; err = 0.31749356 * 6208; time = 0.5899s; samplesPerSecond = 10523.4
dengamma value 1.093030
dengamma value 1.077599
dengamma value 1.115802
dengamma value 1.065852
dengamma value 0.947104
dengamma value 1.050804
dengamma value 1.077133
dengamma value 1.099401
dengamma value 1.087252
dengamma value 1.054500
dengamma value 1.061231
dengamma value 1.131706
dengamma value 1.026717
dengamma value 1.189655
dengamma value 1.027170
dengamma value 1.098630
dengamma value 1.096405
dengamma value 1.087166
dengamma value 1.075980
dengamma value 1.089172
dengamma value 1.141748
dengamma value 1.124649
12/15/2016 08:29:26:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08151333 * 6326; err = 0.29781853 * 6326; time = 0.5983s; samplesPerSecond = 10573.8
dengamma value 1.088702
dengamma value 1.072725
dengamma value 1.117399
dengamma value 1.141005
dengamma value 1.001158
dengamma value 1.028170
dengamma value 1.105767
12/15/2016 08:29:26: Finished Epoch[ 1 of 3]: [Training] ce = 0.08166789 * 81936; err = 0.31586848 * 81936; totalSamplesSeen = 81936; learningRatePerSample = 2e-006; epochTime=16.8048s
12/15/2016 08:29:26: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

12/15/2016 08:29:26: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81936), data subset 0 of 1, with 1 datapasses

12/15/2016 08:29:26: Starting minibatch loop.
dengamma value 1.150782
dengamma value 1.084117
dengamma value 1.160693
dengamma value 1.051462
dengamma value 1.116598
dengamma value 1.055419
dengamma value 1.092123
dengamma value 1.140551
dengamma value 1.046113
dengamma value 1.031960
dengamma value 1.020904
dengamma value 1.093788
dengamma value 1.087077
dengamma value 1.096171
dengamma value 1.045277
dengamma value 1.021766
dengamma value 1.052977
dengamma value 1.109195
dengamma value 1.055721
dengamma value 1.070095
dengamma value 1.091292
dengamma value 1.137460
dengamma value 1.040277
dengamma value 1.042987
12/15/2016 08:29:27:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08409153 * 6182; err = 0.29715302 * 6182; time = 0.6363s; samplesPerSecond = 9715.3
dengamma value 1.051468
dengamma value 0.999711
dengamma value 1.295670
dengamma value 1.037517
dengamma value 1.096218
dengamma value 1.119158
dengamma value 1.103662
dengamma value 1.037124
dengamma value 1.049736
dengamma value 1.087737
dengamma value 1.042910
dengamma value 1.122480
dengamma value 1.134581
dengamma value 1.034264
dengamma value 1.040570
dengamma value 1.088067
dengamma value 1.027532
dengamma value 1.116617
dengamma value 1.041081
dengamma value 1.026612
dengamma value 1.053961
dengamma value 1.115865
12/15/2016 08:29:28:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08497774 * 5736; err = 0.28591353 * 5736; time = 0.5621s; samplesPerSecond = 10205.3
dengamma value 1.010795
dengamma value 1.117192
dengamma value 1.086663
dengamma value 1.087707
dengamma value 1.056852
dengamma value 1.170870
dengamma value 1.023524
dengamma value 1.130908
dengamma value 1.056020
dengamma value 1.055911
dengamma value 1.047534
dengamma value 1.053224
dengamma value 1.112792
dengamma value 1.186345
dengamma value 1.069796
dengamma value 1.172271
dengamma value 1.110771
dengamma value 1.074462
dengamma value 1.078473
dengamma value 1.102063
dengamma value 0.975685
dengamma value 0.969797
dengamma value 1.063358
12/15/2016 08:29:28:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08118323 * 6244; err = 0.30301089 * 6244; time = 0.5884s; samplesPerSecond = 10611.4
dengamma value 1.105784
dengamma value 1.113826
dengamma value 1.079317
dengamma value 1.056808
dengamma value 1.159087
dengamma value 1.092059
dengamma value 1.076038
dengamma value 1.046463
dengamma value 1.059696
dengamma value 1.019351
dengamma value 1.093165
dengamma value 1.130745
dengamma value 1.121548
dengamma value 1.129657
dengamma value 1.015749
dengamma value 1.131145
dengamma value 1.023237
dengamma value 1.020426
dengamma value 1.084243
dengamma value 1.095305
dengamma value 1.027022
dengamma value 1.068120
dengamma value 1.167741
dengamma value 1.082768
dengamma value 1.056869
12/15/2016 08:29:29:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08559945 * 6280; err = 0.30987261 * 6280; time = 0.5711s; samplesPerSecond = 10995.8
dengamma value 1.017392
dengamma value 1.081221
dengamma value 1.077927
dengamma value 1.082202
dengamma value 1.063442
dengamma value 1.073346
dengamma value 1.070843
dengamma value 1.059524
dengamma value 1.112940
dengamma value 1.072711
dengamma value 1.074320
dengamma value 1.046132
dengamma value 1.120545
dengamma value 1.061872
dengamma value 1.105004
dengamma value 1.090297
dengamma value 1.144268
dengamma value 1.095317
dengamma value 1.090082
dengamma value 1.065249
dengamma value 1.104514
dengamma value 1.088320
dengamma value 1.101410
dengamma value 1.089516
dengamma value 1.098704
dengamma value 1.107598
12/15/2016 08:29:30:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.07759386 * 7428; err = 0.30061928 * 7428; time = 0.7130s; samplesPerSecond = 10417.6
dengamma value 1.134670
dengamma value 1.082089
dengamma value 1.048946
dengamma value 1.135837
dengamma value 1.050132
dengamma value 1.034074
dengamma value 1.040695
dengamma value 1.092780
dengamma value 1.067742
dengamma value 1.062919
dengamma value 1.039040
dengamma value 1.057282
dengamma value 1.028091
dengamma value 1.140414
dengamma value 1.091239
dengamma value 1.080126
dengamma value 1.092795
dengamma value 0.978353
dengamma value 1.055143
dengamma value 1.074772
dengamma value 1.119510
dengamma value 1.021551
dengamma value 1.061895
12/15/2016 08:29:30:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08149036 * 6994; err = 0.32041750 * 6994; time = 0.6109s; samplesPerSecond = 11447.8
dengamma value 1.118367
dengamma value 1.081979
dengamma value 1.175150
dengamma value 1.022372
dengamma value 1.053430
dengamma value 1.127259
dengamma value 0.977490
dengamma value 1.141616
dengamma value 1.182777
dengamma value 1.064982
dengamma value 1.152275
dengamma value 1.109854
dengamma value 1.058587
dengamma value 1.030619
dengamma value 1.077744
dengamma value 1.078244
dengamma value 1.049306
dengamma value 1.042347
dengamma value 1.100878
dengamma value 1.090770
dengamma value 1.067824
dengamma value 1.155571
dengamma value 1.078269
dengamma value 1.088296
12/15/2016 08:29:31:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07698179 * 6572; err = 0.30584297 * 6572; time = 0.6265s; samplesPerSecond = 10490.3
dengamma value 1.093594
dengamma value 1.013656
dengamma value 1.087007
dengamma value 1.089498
dengamma value 1.074495
dengamma value 1.117296
dengamma value 1.200993
dengamma value 1.076084
dengamma value 1.070517
dengamma value 1.064054
dengamma value 1.003884
dengamma value 1.045064
dengamma value 1.019404
dengamma value 1.172201
dengamma value 1.081120
dengamma value 0.941563
dengamma value 1.008990
dengamma value 1.036987
dengamma value 1.076393
dengamma value 1.089481
dengamma value 1.216563
dengamma value 1.013347
12/15/2016 08:29:31:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08826969 * 5506; err = 0.32364693 * 5506; time = 0.5148s; samplesPerSecond = 10695.2
dengamma value 1.003312
dengamma value 1.076374
dengamma value 1.009626
dengamma value 1.088102
dengamma value 1.121727
dengamma value 1.119405
dengamma value 1.131505
dengamma value 1.076863
dengamma value 1.039925
dengamma value 1.013473
dengamma value 1.089782
dengamma value 0.960494
dengamma value 1.075394
dengamma value 1.031012
dengamma value 1.071185
dengamma value 1.117562
dengamma value 1.120235
dengamma value 1.081075
dengamma value 1.105257
dengamma value 1.008454
dengamma value 0.998531
12/15/2016 08:29:32:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08593394 * 5628; err = 0.33777541 * 5628; time = 0.5251s; samplesPerSecond = 10718.1
dengamma value 1.035405
dengamma value 1.123441
dengamma value 1.076034
dengamma value 1.093190
dengamma value 1.086913
dengamma value 0.985012
dengamma value 1.036915
dengamma value 1.004166
dengamma value 1.103941
dengamma value 1.056707
dengamma value 1.170805
dengamma value 1.094038
dengamma value 1.077565
dengamma value 1.077852
dengamma value 1.017089
dengamma value 1.039058
dengamma value 1.044801
dengamma value 1.060837
dengamma value 1.054807
dengamma value 1.131299
dengamma value 1.020129
dengamma value 1.030997
dengamma value 1.053488
dengamma value 0.991559
12/15/2016 08:29:32:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08234468 * 6032; err = 0.33007294 * 6032; time = 0.5446s; samplesPerSecond = 11076.7
dengamma value 1.037343
dengamma value 1.056369
dengamma value 1.068246
dengamma value 1.085957
dengamma value 1.064372
dengamma value 1.114897
dengamma value 1.085924
dengamma value 0.962258
dengamma value 1.124781
dengamma value 1.133768
dengamma value 1.036815
dengamma value 0.967017
dengamma value 1.054217
dengamma value 1.139675
dengamma value 1.091516
dengamma value 0.994863
dengamma value 1.153313
dengamma value 1.052652
dengamma value 1.102079
dengamma value 1.027608
12/15/2016 08:29:33:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08816178 * 4790; err = 0.32964509 * 4790; time = 0.4620s; samplesPerSecond = 10367.4
dengamma value 1.015855
dengamma value 0.968632
dengamma value 1.050943
dengamma value 1.064630
dengamma value 1.082701
dengamma value 1.020425
dengamma value 1.011100
dengamma value 1.093998
dengamma value 1.073254
dengamma value 0.962609
dengamma value 1.126199
dengamma value 1.058246
dengamma value 1.081458
dengamma value 1.016927
dengamma value 1.129523
dengamma value 1.069275
dengamma value 1.133306
dengamma value 1.171201
dengamma value 0.962987
dengamma value 1.145127
dengamma value 1.034817
dengamma value 1.040967
12/15/2016 08:29:33:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08567378 * 5986; err = 0.34396926 * 5986; time = 0.5380s; samplesPerSecond = 11127.3
dengamma value 1.023926
dengamma value 1.009922
dengamma value 1.059804
dengamma value 1.090217
dengamma value 1.028770
dengamma value 1.218336
dengamma value 1.106914
dengamma value 1.115102
dengamma value 1.076270
dengamma value 1.079668
dengamma value 1.096508
dengamma value 1.088603
dengamma value 0.999240
dengamma value 0.993835
dengamma value 1.029776
dengamma value 1.077333
dengamma value 1.049450
dengamma value 1.052151
dengamma value 1.124674
dengamma value 1.040892
dengamma value 1.109055
dengamma value 1.051901
dengamma value 1.095508
dengamma value 0.996864
12/15/2016 08:29:34:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08666325 * 7022; err = 0.31486756 * 7022; time = 0.6140s; samplesPerSecond = 11435.8
dengamma value 1.030574
dengamma value 1.096729
dengamma value 1.191708
dengamma value 1.074767
dengamma value 1.048072
dengamma value 1.081857
dengamma value 1.009774
dengamma value 1.081853
dengamma value 1.081853
12/15/2016 08:29:34: Finished Epoch[ 2 of 3]: [Training] ce = 0.08348054 * 82462; err = 0.31540588 * 82462; totalSamplesSeen = 164398; learningRatePerSample = 2e-006; epochTime=7.70361s
12/15/2016 08:29:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

12/15/2016 08:29:34: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 164102), data subset 0 of 1, with 1 datapasses

12/15/2016 08:29:34: Starting minibatch loop.
dengamma value 1.089624
dengamma value 1.105586
dengamma value 1.084437
dengamma value 1.104178
dengamma value 1.072037
dengamma value 1.069971
dengamma value 1.155542
dengamma value 1.034500
dengamma value 1.118246
dengamma value 0.983955
dengamma value 1.113556
dengamma value 1.073012
dengamma value 1.066501
dengamma value 1.104030
dengamma value 1.077437
dengamma value 1.064413
dengamma value 1.106104
dengamma value 1.013723
dengamma value 1.090325
dengamma value 1.099150
dengamma value 1.048222
dengamma value 1.066392
dengamma value 1.042483
dengamma value 1.032185
12/15/2016 08:29:35:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08375882 * 6292; err = 0.29640814 * 6292; time = 0.5716s; samplesPerSecond = 11008.2
dengamma value 1.160934
dengamma value 1.034237
dengamma value 0.990282
dengamma value 1.095793
dengamma value 1.081534
dengamma value 1.023932
dengamma value 1.047106
dengamma value 1.137081
dengamma value 1.041847
dengamma value 0.980121
dengamma value 0.957173
dengamma value 1.100887
dengamma value 1.065302
dengamma value 1.067494
dengamma value 1.027303
dengamma value 1.066311
dengamma value 1.021595
dengamma value 1.074477
dengamma value 1.111626
dengamma value 1.037971
dengamma value 1.069401
dengamma value 1.028945
12/15/2016 08:29:35:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08027829 * 6596; err = 0.32868405 * 6596; time = 0.6035s; samplesPerSecond = 10929.8
dengamma value 1.088750
dengamma value 1.008458
dengamma value 1.101040
dengamma value 1.119327
dengamma value 1.068696
dengamma value 1.161123
dengamma value 1.032850
dengamma value 1.082983
dengamma value 1.057937
dengamma value 1.062384
dengamma value 1.106970
dengamma value 1.062699
dengamma value 1.028115
dengamma value 1.038343
dengamma value 1.129269
dengamma value 0.952811
dengamma value 1.054110
dengamma value 1.033374
dengamma value 1.029764
dengamma value 1.174079
dengamma value 1.073154
dengamma value 1.203313
12/15/2016 08:29:36:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08629871 * 5666; err = 0.30074126 * 5666; time = 0.5438s; samplesPerSecond = 10420.2
dengamma value 1.130487
dengamma value 1.024747
dengamma value 1.061534
dengamma value 1.094625
dengamma value 1.079427
dengamma value 1.077169
dengamma value 1.105139
dengamma value 1.071630
dengamma value 1.098369
dengamma value 1.082015
dengamma value 1.102373
dengamma value 1.056006
dengamma value 1.003652
dengamma value 1.134334
dengamma value 1.118100
dengamma value 1.044148
dengamma value 1.085953
dengamma value 1.044736
dengamma value 1.096175
dengamma value 1.040087
dengamma value 1.091430
dengamma value 1.031705
12/15/2016 08:29:37:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08112167 * 6626; err = 0.28720193 * 6626; time = 0.6216s; samplesPerSecond = 10659.6
dengamma value 1.091139
dengamma value 1.041630
dengamma value 1.030816
dengamma value 1.092472
dengamma value 1.131168
dengamma value 1.154823
dengamma value 1.096113
dengamma value 1.096293
dengamma value 1.029214
dengamma value 1.084814
dengamma value 1.144704
dengamma value 1.074456
dengamma value 1.045082
dengamma value 1.064559
dengamma value 1.028077
dengamma value 1.065403
dengamma value 1.085748
dengamma value 1.062858
dengamma value 1.108800
dengamma value 1.105401
dengamma value 1.071299
dengamma value 1.083226
dengamma value 1.064244
dengamma value 1.055714
12/15/2016 08:29:37:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08215980 * 5652; err = 0.30590941 * 5652; time = 0.5671s; samplesPerSecond = 9967.1
dengamma value 1.093683
dengamma value 1.043029
dengamma value 0.998884
dengamma value 1.051845
dengamma value 1.033730
dengamma value 1.153375
dengamma value 1.050045
dengamma value 1.045298
dengamma value 1.111270
dengamma value 1.023204
dengamma value 1.022438
dengamma value 1.055214
dengamma value 1.070049
dengamma value 1.070792
dengamma value 1.094849
dengamma value 1.043172
dengamma value 1.009321
dengamma value 1.037956
dengamma value 1.103703
dengamma value 1.044189
dengamma value 1.055503
12/15/2016 08:29:38:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08656390 * 6588; err = 0.34395871 * 6588; time = 0.5991s; samplesPerSecond = 10996.0
dengamma value 1.073673
dengamma value 1.096601
dengamma value 1.041155
dengamma value 0.986929
dengamma value 1.155175
dengamma value 1.067884
dengamma value 1.076922
dengamma value 1.035702
dengamma value 1.007830
dengamma value 1.093380
dengamma value 1.087902
dengamma value 1.024117
dengamma value 1.038409
dengamma value 1.124315
dengamma value 1.140124
dengamma value 1.053114
dengamma value 1.041876
dengamma value 1.081442
dengamma value 1.103719
dengamma value 1.062596
dengamma value 1.026821
12/15/2016 08:29:38:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08654349 * 6328; err = 0.30831226 * 6328; time = 0.6049s; samplesPerSecond = 10461.1
dengamma value 1.069731
dengamma value 1.104001
dengamma value 1.009234
dengamma value 1.103003
dengamma value 1.121808
dengamma value 1.072609
dengamma value 1.089752
dengamma value 1.112743
dengamma value 1.050067
dengamma value 0.990503
dengamma value 1.060536
dengamma value 1.035210
dengamma value 1.020352
dengamma value 1.106489
dengamma value 1.050728
dengamma value 1.083387
dengamma value 1.073433
dengamma value 1.196301
dengamma value 1.091270
dengamma value 1.062741
dengamma value 1.065283
dengamma value 1.108682
dengamma value 1.041275
dengamma value 1.105519
dengamma value 1.080000
12/15/2016 08:29:39:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08283314 * 6980; err = 0.28710602 * 6980; time = 0.6395s; samplesPerSecond = 10915.4
dengamma value 1.057307
dengamma value 0.978166
dengamma value 0.955435
dengamma value 1.137618
dengamma value 1.131176
dengamma value 1.023009
dengamma value 1.271235
dengamma value 1.108752
dengamma value 1.065951
dengamma value 1.117579
dengamma value 0.980412
dengamma value 1.074655
dengamma value 1.059473
dengamma value 1.013131
dengamma value 1.123365
dengamma value 1.058819
dengamma value 1.008071
dengamma value 1.272964
dengamma value 1.189753
dengamma value 1.045101
dengamma value 1.133020
dengamma value 0.977555
dengamma value 1.025691
12/15/2016 08:29:40:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.07988509 * 6774; err = 0.31355182 * 6774; time = 0.5698s; samplesPerSecond = 11889.1
dengamma value 0.986610
dengamma value 1.076873
dengamma value 1.125757
dengamma value 1.028680
dengamma value 0.933211
dengamma value 1.072107
dengamma value 1.043299
dengamma value 1.062961
dengamma value 0.933620
dengamma value 1.074421
dengamma value 1.012053
dengamma value 1.089357
dengamma value 1.027431
dengamma value 0.981654
dengamma value 1.069125
dengamma value 0.933358
dengamma value 1.052127
dengamma value 1.004358
dengamma value 1.073174
dengamma value 1.073461
dengamma value 1.100131
dengamma value 1.086084
12/15/2016 08:29:40:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08889205 * 6146; err = 0.35535308 * 6146; time = 0.5758s; samplesPerSecond = 10674.6
dengamma value 1.023205
dengamma value 1.119241
dengamma value 1.059870
dengamma value 1.147533
dengamma value 0.958733
dengamma value 1.083095
dengamma value 1.071960
dengamma value 1.147989
dengamma value 1.102544
dengamma value 1.084094
dengamma value 1.037369
dengamma value 1.017444
dengamma value 1.174865
dengamma value 1.064153
dengamma value 1.119070
dengamma value 1.064131
dengamma value 1.087913
dengamma value 1.109102
dengamma value 1.013208
dengamma value 1.142014
dengamma value 1.062458
dengamma value 1.079948
12/15/2016 08:29:41:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08259042 * 5366; err = 0.30059635 * 5366; time = 0.5261s; samplesPerSecond = 10200.1
dengamma value 1.060856
dengamma value 1.049614
dengamma value 1.092956
dengamma value 1.065587
dengamma value 1.062127
dengamma value 1.010274
dengamma value 1.128625
dengamma value 1.068910
dengamma value 1.025339
dengamma value 1.031902
dengamma value 1.028412
dengamma value 1.061972
dengamma value 1.060266
dengamma value 1.040959
dengamma value 1.091078
dengamma value 1.087396
dengamma value 1.110806
dengamma value 1.099914
dengamma value 1.058292
dengamma value 0.989568
dengamma value 1.037671
dengamma value 1.133282
dengamma value 1.155070
dengamma value 1.098460
dengamma value 1.090119
12/15/2016 08:29:41:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08095680 * 6220; err = 0.32395498 * 6220; time = 0.5675s; samplesPerSecond = 10959.9
dengamma value 1.083226
dengamma value 1.056861
dengamma value 1.113076
dengamma value 1.079789
dengamma value 1.034739
dengamma value 1.069542
dengamma value 1.077972
dengamma value 1.107195
dengamma value 1.085268
dengamma value 1.087336
dengamma value 1.047744
dengamma value 1.073712
dengamma value 1.034079
dengamma value 1.090702
dengamma value 1.151654
dengamma value 1.109933
dengamma value 1.058051
dengamma value 1.000397
dengamma value 1.084082
dengamma value 1.030934
dengamma value 1.081563
dengamma value 1.097703
dengamma value 1.137838
12/15/2016 08:29:42:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08458952 * 6564; err = 0.30103595 * 6564; time = 0.5908s; samplesPerSecond = 11110.6
12/15/2016 08:29:42: Finished Epoch[ 3 of 3]: [Training] ce = 0.08353418 * 81798; err = 0.31176801 * 81798; totalSamplesSeen = 246196; learningRatePerSample = 2e-006; epochTime=7.58353s
12/15/2016 08:29:42: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

12/15/2016 08:29:42: Action "train" complete.

12/15/2016 08:29:42: __COMPLETED__
