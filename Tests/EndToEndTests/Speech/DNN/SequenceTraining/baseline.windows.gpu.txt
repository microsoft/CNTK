CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3530 @ 2.80GHz
    Hardware threads: 4
    Total Memory: 12580404 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-SlaveTest/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta3.0+ (HEAD 73542d, Nov 22 2016 13:21:29) on cntk-muc00 at 2016/11/24 05:51:26

C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData
11/24/2016 05:51:27: -------------------------------------------------------------------
11/24/2016 05:51:27: Build info: 

11/24/2016 05:51:27: 		Built time: Nov 22 2016 13:21:29
11/24/2016 05:51:27: 		Last modified date: Tue Nov 22 13:07:57 2016
11/24/2016 05:51:27: 		Build type: Release
11/24/2016 05:51:27: 		Build target: GPU
11/24/2016 05:51:27: 		With 1bit-SGD: no
11/24/2016 05:51:27: 		With ASGD: yes
11/24/2016 05:51:27: 		Math lib: mkl
11/24/2016 05:51:27: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
11/24/2016 05:51:27: 		CUB_PATH: c:\src\cub-1.4.1
11/24/2016 05:51:27: 		CUDNN_PATH: C:\local\cudnn-8.0-windows10-x64-v5.1
11/24/2016 05:51:27: 		Build Branch: HEAD
11/24/2016 05:51:27: 		Build SHA1: 73542d173d5c829ef744eb26cba06230dfbe1983 (modified)
11/24/2016 05:51:27: 		Built by svcphil on Philly-Pool1
11/24/2016 05:51:27: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
11/24/2016 05:51:27: -------------------------------------------------------------------
11/24/2016 05:51:27: -------------------------------------------------------------------
11/24/2016 05:51:27: GPU info:

11/24/2016 05:51:27: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
11/24/2016 05:51:27: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
        labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying"
            transpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
11/24/2016 05:51:27: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
11/24/2016 05:51:27: precision = "float"

11/24/2016 05:51:27: ##############################################################################
11/24/2016 05:51:27: #                                                                            #
11/24/2016 05:51:27: # dptPre1 command (train action)                                             #
11/24/2016 05:51:27: #                                                                            #
11/24/2016 05:51:27: ##############################################################################

11/24/2016 05:51:27: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 05:51:27: 
Model has 19 nodes. Using GPU 0.

11/24/2016 05:51:27: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 05:51:27: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }


11/24/2016 05:51:27: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

11/24/2016 05:51:27: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 05:51:27: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:27: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 05:51:27: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 05:51:27: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 05:51:27: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 05:51:27: Starting minibatch loop.
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.89978256 * 2560; err = 0.84375000 * 2560; time = 0.2327s; samplesPerSecond = 11003.6
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.96755676 * 2560; err = 0.72031250 * 2560; time = 0.0116s; samplesPerSecond = 220975.4
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.55723495 * 2560; err = 0.65859375 * 2560; time = 0.0115s; samplesPerSecond = 222512.0
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.29642715 * 2560; err = 0.61992187 * 2560; time = 0.0115s; samplesPerSecond = 223249.3
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 2.02396469 * 2560; err = 0.55117187 * 2560; time = 0.0119s; samplesPerSecond = 214243.9
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87309265 * 2560; err = 0.51484375 * 2560; time = 0.0116s; samplesPerSecond = 220044.7
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.78157196 * 2560; err = 0.50507813 * 2560; time = 0.0115s; samplesPerSecond = 223346.7
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.75391235 * 2560; err = 0.50781250 * 2560; time = 0.0117s; samplesPerSecond = 218132.2
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66460266 * 2560; err = 0.45742187 * 2560; time = 0.0118s; samplesPerSecond = 216655.4
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62184296 * 2560; err = 0.47968750 * 2560; time = 0.0115s; samplesPerSecond = 222183.6
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.65328217 * 2560; err = 0.47265625 * 2560; time = 0.0115s; samplesPerSecond = 222183.6
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.50686646 * 2560; err = 0.44921875 * 2560; time = 0.0116s; samplesPerSecond = 221395.8
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.46723938 * 2560; err = 0.42304687 * 2560; time = 0.0116s; samplesPerSecond = 220442.6
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.49163513 * 2560; err = 0.44140625 * 2560; time = 0.0118s; samplesPerSecond = 216472.2
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46437683 * 2560; err = 0.43398437 * 2560; time = 0.0117s; samplesPerSecond = 218243.8
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43047791 * 2560; err = 0.43867187 * 2560; time = 0.0120s; samplesPerSecond = 213903.7
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.42104797 * 2560; err = 0.41992188 * 2560; time = 0.0118s; samplesPerSecond = 217151.6
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.46536865 * 2560; err = 0.42421875 * 2560; time = 0.0117s; samplesPerSecond = 218430.0
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.47427673 * 2560; err = 0.44062500 * 2560; time = 0.0117s; samplesPerSecond = 218803.4
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42848816 * 2560; err = 0.44062500 * 2560; time = 0.0117s; samplesPerSecond = 218132.2
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.34078674 * 2560; err = 0.41171875 * 2560; time = 0.0119s; samplesPerSecond = 214909.3
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.39474792 * 2560; err = 0.42773438 * 2560; time = 0.0115s; samplesPerSecond = 222957.7
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.40156250 * 2560; err = 0.41250000 * 2560; time = 0.0116s; samplesPerSecond = 221089.9
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.39350586 * 2560; err = 0.42734375 * 2560; time = 0.0118s; samplesPerSecond = 216472.2
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.32500916 * 2560; err = 0.40156250 * 2560; time = 0.0115s; samplesPerSecond = 223483.2
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.27034607 * 2560; err = 0.39804688 * 2560; time = 0.0114s; samplesPerSecond = 223854.5
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.32393494 * 2560; err = 0.39375000 * 2560; time = 0.0115s; samplesPerSecond = 223580.8
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25440979 * 2560; err = 0.38437500 * 2560; time = 0.0116s; samplesPerSecond = 220784.8
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.23372498 * 2560; err = 0.37148437 * 2560; time = 0.0117s; samplesPerSecond = 219234.4
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20885620 * 2560; err = 0.35976562 * 2560; time = 0.0115s; samplesPerSecond = 223580.8
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23717957 * 2560; err = 0.36953125 * 2560; time = 0.0114s; samplesPerSecond = 224325.3
11/24/2016 05:51:28:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.23036499 * 2560; err = 0.37382813 * 2560; time = 0.0114s; samplesPerSecond = 225015.4
11/24/2016 05:51:28: Finished Epoch[ 1 of 2]: [Training] ce = 1.65179615 * 81920; err = 0.46795654 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.736819s
11/24/2016 05:51:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

11/24/2016 05:51:28: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:28: Starting minibatch loop.
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.21826115 * 2560; err = 0.37031250 * 2560; time = 0.0126s; samplesPerSecond = 203271.4
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18394604 * 2560; err = 0.36640625 * 2560; time = 0.0120s; samplesPerSecond = 212659.9
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.17353325 * 2560; err = 0.35976562 * 2560; time = 0.0117s; samplesPerSecond = 218318.3
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.20286140 * 2560; err = 0.35859375 * 2560; time = 0.0115s; samplesPerSecond = 223405.2
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.19606552 * 2560; err = 0.37812500 * 2560; time = 0.0115s; samplesPerSecond = 223171.5
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.16461716 * 2560; err = 0.34375000 * 2560; time = 0.0117s; samplesPerSecond = 218616.6
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.13763046 * 2560; err = 0.34765625 * 2560; time = 0.0116s; samplesPerSecond = 220271.9
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.19578094 * 2560; err = 0.37226562 * 2560; time = 0.0118s; samplesPerSecond = 216380.7
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.24385757 * 2560; err = 0.38046875 * 2560; time = 0.0115s; samplesPerSecond = 223152.0
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18975372 * 2560; err = 0.36093750 * 2560; time = 0.0114s; samplesPerSecond = 223698.0
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.16871262 * 2560; err = 0.35625000 * 2560; time = 0.0114s; samplesPerSecond = 223600.3
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.24394531 * 2560; err = 0.37929687 * 2560; time = 0.0115s; samplesPerSecond = 222280.1
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.18284454 * 2560; err = 0.34921875 * 2560; time = 0.0115s; samplesPerSecond = 222376.7
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.21535187 * 2560; err = 0.36875000 * 2560; time = 0.0116s; samplesPerSecond = 221013.6
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.19859619 * 2560; err = 0.37187500 * 2560; time = 0.0118s; samplesPerSecond = 216637.0
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.14699402 * 2560; err = 0.34648438 * 2560; time = 0.0117s; samplesPerSecond = 218766.0
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.14664307 * 2560; err = 0.35859375 * 2560; time = 0.0116s; samplesPerSecond = 220442.6
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.17961731 * 2560; err = 0.35234375 * 2560; time = 0.0117s; samplesPerSecond = 217965.1
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14800873 * 2560; err = 0.35234375 * 2560; time = 0.0116s; samplesPerSecond = 221645.0
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08513489 * 2560; err = 0.33320312 * 2560; time = 0.0115s; samplesPerSecond = 223561.3
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.14455261 * 2560; err = 0.34726563 * 2560; time = 0.0117s; samplesPerSecond = 219290.7
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.16282043 * 2560; err = 0.35703125 * 2560; time = 0.0117s; samplesPerSecond = 218934.4
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.19267578 * 2560; err = 0.37265625 * 2560; time = 0.0118s; samplesPerSecond = 217170.0
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.15575562 * 2560; err = 0.34882812 * 2560; time = 0.0116s; samplesPerSecond = 219742.5
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.15968018 * 2560; err = 0.35351563 * 2560; time = 0.0116s; samplesPerSecond = 221338.4
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08686829 * 2560; err = 0.33007813 * 2560; time = 0.0114s; samplesPerSecond = 223737.1
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.10071411 * 2560; err = 0.34804687 * 2560; time = 0.0114s; samplesPerSecond = 223698.0
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.06582336 * 2560; err = 0.33945313 * 2560; time = 0.0115s; samplesPerSecond = 223229.9
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09620972 * 2560; err = 0.33085938 * 2560; time = 0.0116s; samplesPerSecond = 219912.4
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.15163269 * 2560; err = 0.35195312 * 2560; time = 0.0116s; samplesPerSecond = 221128.1
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.10898132 * 2560; err = 0.34296875 * 2560; time = 0.0116s; samplesPerSecond = 219836.8
11/24/2016 05:51:28:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06808777 * 2560; err = 0.32304688 * 2560; time = 0.0116s; samplesPerSecond = 220271.9
11/24/2016 05:51:28: Finished Epoch[ 2 of 2]: [Training] ce = 1.15987368 * 81920; err = 0.35476074 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.375505s
11/24/2016 05:51:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

11/24/2016 05:51:29: Action "train" complete.


11/24/2016 05:51:29: ##############################################################################
11/24/2016 05:51:29: #                                                                            #
11/24/2016 05:51:29: # addLayer2 command (edit action)                                            #
11/24/2016 05:51:29: #                                                                            #
11/24/2016 05:51:29: ##############################################################################


11/24/2016 05:51:29: Action "edit" complete.


11/24/2016 05:51:29: ##############################################################################
11/24/2016 05:51:29: #                                                                            #
11/24/2016 05:51:29: # dptPre2 command (train action)                                             #
11/24/2016 05:51:29: #                                                                            #
11/24/2016 05:51:29: ##############################################################################

11/24/2016 05:51:29: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 05:51:29: 
Model has 24 nodes. Using GPU 0.

11/24/2016 05:51:29: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 05:51:29: Evaluation criterion: err = ClassificationError

11/24/2016 05:51:29: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

11/24/2016 05:51:29: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 05:51:29: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:29: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:29: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:29: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 05:51:29: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 05:51:29: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 05:51:29: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 05:51:29: Starting minibatch loop.
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 4.35297356 * 2560; err = 0.80507812 * 2560; time = 0.0211s; samplesPerSecond = 121154.8
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.79278145 * 2560; err = 0.68007812 * 2560; time = 0.0169s; samplesPerSecond = 151461.4
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.22797165 * 2560; err = 0.59687500 * 2560; time = 0.0169s; samplesPerSecond = 151919.8
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.89317703 * 2560; err = 0.50937500 * 2560; time = 0.0169s; samplesPerSecond = 151748.7
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.68641968 * 2560; err = 0.47343750 * 2560; time = 0.0169s; samplesPerSecond = 151766.7
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.58091736 * 2560; err = 0.45585938 * 2560; time = 0.0169s; samplesPerSecond = 151703.7
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.48223877 * 2560; err = 0.43203125 * 2560; time = 0.0169s; samplesPerSecond = 151452.4
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.48543396 * 2560; err = 0.43203125 * 2560; time = 0.0169s; samplesPerSecond = 151802.7
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.45170441 * 2560; err = 0.41914062 * 2560; time = 0.0169s; samplesPerSecond = 151497.2
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.41144409 * 2560; err = 0.40625000 * 2560; time = 0.0169s; samplesPerSecond = 151425.5
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41792297 * 2560; err = 0.41640625 * 2560; time = 0.0169s; samplesPerSecond = 151193.0
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.33702698 * 2560; err = 0.39648438 * 2560; time = 0.0169s; samplesPerSecond = 151802.7
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.31339722 * 2560; err = 0.38281250 * 2560; time = 0.0168s; samplesPerSecond = 151946.8
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.32979889 * 2560; err = 0.39531250 * 2560; time = 0.0169s; samplesPerSecond = 151345.0
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.31671143 * 2560; err = 0.38867188 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.26952820 * 2560; err = 0.38359375 * 2560; time = 0.0169s; samplesPerSecond = 151291.3
11/24/2016 05:51:29:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.29362488 * 2560; err = 0.38593750 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.32294312 * 2560; err = 0.38945313 * 2560; time = 0.0169s; samplesPerSecond = 151569.0
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.33757629 * 2560; err = 0.40859375 * 2560; time = 0.0169s; samplesPerSecond = 151847.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.31420593 * 2560; err = 0.41601563 * 2560; time = 0.0169s; samplesPerSecond = 151703.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.23244324 * 2560; err = 0.37851563 * 2560; time = 0.0169s; samplesPerSecond = 151820.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.26672058 * 2560; err = 0.38671875 * 2560; time = 0.0169s; samplesPerSecond = 151694.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.26799927 * 2560; err = 0.37734375 * 2560; time = 0.0169s; samplesPerSecond = 151730.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.23920288 * 2560; err = 0.36875000 * 2560; time = 0.0169s; samplesPerSecond = 151892.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.21632996 * 2560; err = 0.36953125 * 2560; time = 0.0169s; samplesPerSecond = 151712.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.18666687 * 2560; err = 0.36406250 * 2560; time = 0.0169s; samplesPerSecond = 151255.5
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.24128113 * 2560; err = 0.36640625 * 2560; time = 0.0169s; samplesPerSecond = 151264.5
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.18781738 * 2560; err = 0.36601563 * 2560; time = 0.0169s; samplesPerSecond = 151721.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.16813354 * 2560; err = 0.34960938 * 2560; time = 0.0169s; samplesPerSecond = 151784.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.14536438 * 2560; err = 0.34375000 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.17401123 * 2560; err = 0.34843750 * 2560; time = 0.0169s; samplesPerSecond = 151649.8
11/24/2016 05:51:30:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.18512573 * 2560; err = 0.36640625 * 2560; time = 0.0169s; samplesPerSecond = 151613.9
11/24/2016 05:51:30: Finished Epoch[ 1 of 2]: [Training] ce = 1.50402794 * 81920; err = 0.42371826 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.690968s
11/24/2016 05:51:30: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

11/24/2016 05:51:30: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:30: Starting minibatch loop.
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.17943249 * 2560; err = 0.34960938 * 2560; time = 0.0178s; samplesPerSecond = 143973.9
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.14734955 * 2560; err = 0.35312500 * 2560; time = 0.0169s; samplesPerSecond = 151649.8
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15603657 * 2560; err = 0.35117188 * 2560; time = 0.0169s; samplesPerSecond = 151586.9
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.14244919 * 2560; err = 0.34531250 * 2560; time = 0.0169s; samplesPerSecond = 151604.9
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.14663010 * 2560; err = 0.36132813 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.14568787 * 2560; err = 0.33710937 * 2560; time = 0.0169s; samplesPerSecond = 151793.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.09567490 * 2560; err = 0.33867188 * 2560; time = 0.0169s; samplesPerSecond = 151712.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.15968857 * 2560; err = 0.35859375 * 2560; time = 0.0169s; samplesPerSecond = 151578.0
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.16455688 * 2560; err = 0.36132813 * 2560; time = 0.0169s; samplesPerSecond = 151694.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12126999 * 2560; err = 0.34062500 * 2560; time = 0.0169s; samplesPerSecond = 151730.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.12287445 * 2560; err = 0.34843750 * 2560; time = 0.0169s; samplesPerSecond = 151658.8
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18522873 * 2560; err = 0.35976562 * 2560; time = 0.0169s; samplesPerSecond = 151757.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.13055420 * 2560; err = 0.33828125 * 2560; time = 0.0168s; samplesPerSecond = 152010.0
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.17141113 * 2560; err = 0.35820313 * 2560; time = 0.0169s; samplesPerSecond = 151694.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.12022705 * 2560; err = 0.34492187 * 2560; time = 0.0169s; samplesPerSecond = 151694.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.09330750 * 2560; err = 0.33632812 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.10945435 * 2560; err = 0.34492187 * 2560; time = 0.0169s; samplesPerSecond = 151694.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.12213135 * 2560; err = 0.33359375 * 2560; time = 0.0169s; samplesPerSecond = 151802.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.10285187 * 2560; err = 0.33671875 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.06152496 * 2560; err = 0.33203125 * 2560; time = 0.0169s; samplesPerSecond = 151542.1
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.10955505 * 2560; err = 0.33984375 * 2560; time = 0.0169s; samplesPerSecond = 151640.8
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13198547 * 2560; err = 0.34023437 * 2560; time = 0.0169s; samplesPerSecond = 151676.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.12280273 * 2560; err = 0.34179688 * 2560; time = 0.0169s; samplesPerSecond = 151721.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.11058960 * 2560; err = 0.33242187 * 2560; time = 0.0169s; samplesPerSecond = 151649.8
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09971924 * 2560; err = 0.33828125 * 2560; time = 0.0169s; samplesPerSecond = 151865.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.05331116 * 2560; err = 0.32968750 * 2560; time = 0.0169s; samplesPerSecond = 151721.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.05122681 * 2560; err = 0.33437500 * 2560; time = 0.0169s; samplesPerSecond = 151766.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.03399353 * 2560; err = 0.31914063 * 2560; time = 0.0169s; samplesPerSecond = 151542.1
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.05401917 * 2560; err = 0.32421875 * 2560; time = 0.0169s; samplesPerSecond = 151586.9
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.10884705 * 2560; err = 0.34335938 * 2560; time = 0.0169s; samplesPerSecond = 151766.7
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08281250 * 2560; err = 0.33437500 * 2560; time = 0.0169s; samplesPerSecond = 151640.8
11/24/2016 05:51:30:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.04478760 * 2560; err = 0.32031250 * 2560; time = 0.0169s; samplesPerSecond = 151622.8
11/24/2016 05:51:30: Finished Epoch[ 2 of 2]: [Training] ce = 1.11506224 * 81920; err = 0.34150391 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.543974s
11/24/2016 05:51:30: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

11/24/2016 05:51:30: Action "train" complete.


11/24/2016 05:51:30: ##############################################################################
11/24/2016 05:51:30: #                                                                            #
11/24/2016 05:51:30: # addLayer3 command (edit action)                                            #
11/24/2016 05:51:30: #                                                                            #
11/24/2016 05:51:30: ##############################################################################


11/24/2016 05:51:31: Action "edit" complete.


11/24/2016 05:51:31: ##############################################################################
11/24/2016 05:51:31: #                                                                            #
11/24/2016 05:51:31: # speechTrain command (train action)                                         #
11/24/2016 05:51:31: #                                                                            #
11/24/2016 05:51:31: ##############################################################################

11/24/2016 05:51:31: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 05:51:31: 
Model has 29 nodes. Using GPU 0.

11/24/2016 05:51:31: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 05:51:31: Evaluation criterion: err = ClassificationError

11/24/2016 05:51:31: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

11/24/2016 05:51:31: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 05:51:31: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:31: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:31: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:31: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:31: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:31: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 05:51:31: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 05:51:31: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 05:51:31: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 05:51:31: Starting minibatch loop.
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.13822479 * 2560; err = 0.82539063 * 2560; time = 0.0275s; samplesPerSecond = 93111.2
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.55949097 * 2560; err = 0.62968750 * 2560; time = 0.0227s; samplesPerSecond = 112879.8
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03831863 * 2560; err = 0.54296875 * 2560; time = 0.0227s; samplesPerSecond = 112581.9
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.73823318 * 2560; err = 0.47812500 * 2560; time = 0.0227s; samplesPerSecond = 112705.8
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.54281845 * 2560; err = 0.43906250 * 2560; time = 0.0227s; samplesPerSecond = 112586.9
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.44529800 * 2560; err = 0.41718750 * 2560; time = 0.0228s; samplesPerSecond = 112364.5
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.36146088 * 2560; err = 0.40937500 * 2560; time = 0.0227s; samplesPerSecond = 112949.5
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.36031494 * 2560; err = 0.39843750 * 2560; time = 0.0227s; samplesPerSecond = 112879.8
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.34325104 * 2560; err = 0.38906250 * 2560; time = 0.0227s; samplesPerSecond = 112626.5
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30486298 * 2560; err = 0.37968750 * 2560; time = 0.0228s; samplesPerSecond = 112458.3
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.30955048 * 2560; err = 0.38789062 * 2560; time = 0.0226s; samplesPerSecond = 113069.2
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.23771362 * 2560; err = 0.37148437 * 2560; time = 0.0227s; samplesPerSecond = 112969.4
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.21626434 * 2560; err = 0.35742188 * 2560; time = 0.0227s; samplesPerSecond = 112785.3
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.23931732 * 2560; err = 0.36914063 * 2560; time = 0.0227s; samplesPerSecond = 112844.9
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.23382874 * 2560; err = 0.37109375 * 2560; time = 0.0227s; samplesPerSecond = 112825.0
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.19437866 * 2560; err = 0.35312500 * 2560; time = 0.0227s; samplesPerSecond = 112785.3
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.21520996 * 2560; err = 0.36445312 * 2560; time = 0.0227s; samplesPerSecond = 112904.6
11/24/2016 05:51:31:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.24609985 * 2560; err = 0.36953125 * 2560; time = 0.0227s; samplesPerSecond = 112879.8
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.26908569 * 2560; err = 0.38242188 * 2560; time = 0.0227s; samplesPerSecond = 112939.5
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.22153931 * 2560; err = 0.38242188 * 2560; time = 0.0227s; samplesPerSecond = 112780.3
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.17947388 * 2560; err = 0.35390625 * 2560; time = 0.0227s; samplesPerSecond = 112750.5
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.20200500 * 2560; err = 0.37148437 * 2560; time = 0.0227s; samplesPerSecond = 112755.5
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.21993408 * 2560; err = 0.36210938 * 2560; time = 0.0227s; samplesPerSecond = 112859.9
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.18955078 * 2560; err = 0.35859375 * 2560; time = 0.0227s; samplesPerSecond = 112884.7
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17432251 * 2560; err = 0.35625000 * 2560; time = 0.0227s; samplesPerSecond = 112661.2
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.12846069 * 2560; err = 0.35000000 * 2560; time = 0.0227s; samplesPerSecond = 113024.3
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.19460449 * 2560; err = 0.35781250 * 2560; time = 0.0227s; samplesPerSecond = 112745.5
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.13890076 * 2560; err = 0.35156250 * 2560; time = 0.0227s; samplesPerSecond = 112785.3
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.12744446 * 2560; err = 0.34062500 * 2560; time = 0.0227s; samplesPerSecond = 112899.7
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.10971680 * 2560; err = 0.33984375 * 2560; time = 0.0226s; samplesPerSecond = 113039.3
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.13348999 * 2560; err = 0.34257813 * 2560; time = 0.0227s; samplesPerSecond = 112710.8
11/24/2016 05:51:32:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.12946472 * 2560; err = 0.34921875 * 2560; time = 0.0228s; samplesPerSecond = 112502.7
11/24/2016 05:51:32: Finished Epoch[ 1 of 4]: [Training] ce = 1.41070719 * 81920; err = 0.40162354 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.87512s
11/24/2016 05:51:32: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

11/24/2016 05:51:32: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:32: Starting minibatch loop.
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.20551834 * 5120; err = 0.36816406 * 5120; time = 0.0380s; samplesPerSecond = 134690.8
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.16181965 * 5120; err = 0.34804687 * 5120; time = 0.0330s; samplesPerSecond = 155113.9
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.10130672 * 5120; err = 0.33535156 * 5120; time = 0.0329s; samplesPerSecond = 155424.7
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10210381 * 5120; err = 0.34140625 * 5120; time = 0.0329s; samplesPerSecond = 155807.8
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.17025757 * 5120; err = 0.36035156 * 5120; time = 0.0328s; samplesPerSecond = 156159.5
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.15351219 * 5120; err = 0.35371094 * 5120; time = 0.0328s; samplesPerSecond = 156040.5
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.14052505 * 5120; err = 0.34355469 * 5120; time = 0.0328s; samplesPerSecond = 155912.2
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.11847076 * 5120; err = 0.34628906 * 5120; time = 0.0328s; samplesPerSecond = 156312.0
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.11398239 * 5120; err = 0.34257813 * 5120; time = 0.0328s; samplesPerSecond = 156292.9
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06153030 * 5120; err = 0.33085938 * 5120; time = 0.0327s; samplesPerSecond = 156474.4
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.11382904 * 5120; err = 0.34179688 * 5120; time = 0.0328s; samplesPerSecond = 155988.2
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.14130249 * 5120; err = 0.35136719 * 5120; time = 0.0328s; samplesPerSecond = 156064.3
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05320435 * 5120; err = 0.32636719 * 5120; time = 0.0328s; samplesPerSecond = 156078.5
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02661438 * 5120; err = 0.32226563 * 5120; time = 0.0327s; samplesPerSecond = 156355.0
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08014221 * 5120; err = 0.33105469 * 5120; time = 0.0328s; samplesPerSecond = 156121.4
11/24/2016 05:51:32:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05691986 * 5120; err = 0.32480469 * 5120; time = 0.0328s; samplesPerSecond = 156149.9
11/24/2016 05:51:32: Finished Epoch[ 2 of 4]: [Training] ce = 1.11256495 * 81920; err = 0.34174805 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.533317s
11/24/2016 05:51:32: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

11/24/2016 05:51:33: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:33: Starting minibatch loop.
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.12661972 * 5120; err = 0.34375000 * 5120; time = 0.0334s; samplesPerSecond = 153408.2
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.07772541 * 5120; err = 0.33222656 * 5120; time = 0.0328s; samplesPerSecond = 156207.1
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.06582432 * 5120; err = 0.32871094 * 5120; time = 0.0328s; samplesPerSecond = 155964.4
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.08506088 * 5120; err = 0.33828125 * 5120; time = 0.0328s; samplesPerSecond = 156240.5
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07473717 * 5120; err = 0.33242187 * 5120; time = 0.0328s; samplesPerSecond = 156240.5
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.05632477 * 5120; err = 0.33535156 * 5120; time = 0.0328s; samplesPerSecond = 156207.1
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.09331055 * 5120; err = 0.33320312 * 5120; time = 0.0328s; samplesPerSecond = 156278.6
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.09819107 * 5120; err = 0.33242187 * 5120; time = 0.0327s; samplesPerSecond = 156421.9
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.06145096 * 5120; err = 0.33066406 * 5120; time = 0.0328s; samplesPerSecond = 156335.9
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06447296 * 5120; err = 0.32871094 * 5120; time = 0.0327s; samplesPerSecond = 156460.1
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.04175034 * 5120; err = 0.32539062 * 5120; time = 0.0327s; samplesPerSecond = 156359.7
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07516785 * 5120; err = 0.33242187 * 5120; time = 0.0327s; samplesPerSecond = 156417.1
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.10691376 * 5120; err = 0.33027344 * 5120; time = 0.0327s; samplesPerSecond = 156378.9
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.05968170 * 5120; err = 0.32421875 * 5120; time = 0.0328s; samplesPerSecond = 156269.1
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.06469574 * 5120; err = 0.33789063 * 5120; time = 0.0328s; samplesPerSecond = 156254.8
11/24/2016 05:51:33:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.04725037 * 5120; err = 0.33144531 * 5120; time = 0.0328s; samplesPerSecond = 156297.7
11/24/2016 05:51:33: Finished Epoch[ 3 of 4]: [Training] ce = 1.07494860 * 81920; err = 0.33233643 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.527613s
11/24/2016 05:51:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

11/24/2016 05:51:33: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:33: Starting minibatch loop.
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.03825827 * 5120; err = 0.32324219 * 5120; time = 0.0334s; samplesPerSecond = 153408.2
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.03995689 * 4926; err = 0.31668697 * 4926; time = 0.0694s; samplesPerSecond = 70954.3
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02281990 * 5120; err = 0.32363281 * 5120; time = 0.0328s; samplesPerSecond = 156102.3
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.01672840 * 5120; err = 0.31640625 * 5120; time = 0.0328s; samplesPerSecond = 156064.3
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.00018463 * 5120; err = 0.31796875 * 5120; time = 0.0328s; samplesPerSecond = 156278.6
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00074234 * 5120; err = 0.31210938 * 5120; time = 0.0328s; samplesPerSecond = 156316.8
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 0.98887520 * 5120; err = 0.30585937 * 5120; time = 0.0328s; samplesPerSecond = 156273.8
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.01920166 * 5120; err = 0.32109375 * 5120; time = 0.0329s; samplesPerSecond = 155627.8
11/24/2016 05:51:33:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99688110 * 5120; err = 0.31503906 * 5120; time = 0.0329s; samplesPerSecond = 155841.0
11/24/2016 05:51:34:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.97588196 * 5120; err = 0.31289062 * 5120; time = 0.0328s; samplesPerSecond = 156021.5
11/24/2016 05:51:34:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 0.99557800 * 5120; err = 0.30625000 * 5120; time = 0.0329s; samplesPerSecond = 155717.8
11/24/2016 05:51:34:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.99837418 * 5120; err = 0.30429688 * 5120; time = 0.0328s; samplesPerSecond = 156226.2
11/24/2016 05:51:34:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00913620 * 5120; err = 0.31445313 * 5120; time = 0.0328s; samplesPerSecond = 156245.2
11/24/2016 05:51:34:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.98607788 * 5120; err = 0.30625000 * 5120; time = 0.0328s; samplesPerSecond = 156197.6
11/24/2016 05:51:34:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.95079041 * 5120; err = 0.29589844 * 5120; time = 0.0328s; samplesPerSecond = 156259.5
11/24/2016 05:51:34:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97977753 * 5120; err = 0.30761719 * 5120; time = 0.0328s; samplesPerSecond = 156064.3
11/24/2016 05:51:34: Finished Epoch[ 4 of 4]: [Training] ce = 1.00093651 * 81920; err = 0.31246338 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.567066s
11/24/2016 05:51:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech'

11/24/2016 05:51:34: Action "train" complete.


11/24/2016 05:51:34: ##############################################################################
11/24/2016 05:51:34: #                                                                            #
11/24/2016 05:51:34: # replaceCriterionNode command (edit action)                                 #
11/24/2016 05:51:34: #                                                                            #
11/24/2016 05:51:34: ##############################################################################


11/24/2016 05:51:34: Action "edit" complete.


11/24/2016 05:51:34: ##############################################################################
11/24/2016 05:51:34: #                                                                            #
11/24/2016 05:51:34: # sequenceTrain command (train action)                                       #
11/24/2016 05:51:34: #                                                                            #
11/24/2016 05:51:34: ##############################################################################

11/24/2016 05:51:34: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu\TestData\CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
11/24/2016 05:51:35: 
Model has 29 nodes. Using GPU 0.

11/24/2016 05:51:35: Training criterion:   ce = SequenceWithSoftmax
11/24/2016 05:51:35: Evaluation criterion: err = ClassificationError

11/24/2016 05:51:35: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

11/24/2016 05:51:35: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 05:51:35: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:35: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:35: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:35: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:35: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:35: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 05:51:35: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 05:51:35: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-010
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

11/24/2016 05:51:35: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 05:51:43: Starting minibatch loop.
dengamma value 1.001789
dengamma value 1.046103
dengamma value 1.066235
dengamma value 1.058501
dengamma value 1.054282
dengamma value 1.081927
dengamma value 0.962321
dengamma value 1.192817
dengamma value 1.010820
dengamma value 1.096595
dengamma value 1.032700
dengamma value 1.136578
dengamma value 1.045068
dengamma value 1.023533
dengamma value 1.101341
dengamma value 1.033235
dengamma value 1.107651
dengamma value 1.032180
dengamma value 1.057213
dengamma value 1.052624
dengamma value 0.992501
11/24/2016 05:51:46:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08349998 * 4628; err = 0.33059637 * 4628; time = 2.8650s; samplesPerSecond = 1615.4
dengamma value 1.103028
dengamma value 1.036764
dengamma value 1.100651
dengamma value 0.949968
dengamma value 1.114181
dengamma value 1.093506
dengamma value 1.054571
dengamma value 1.057771
dengamma value 0.985081
dengamma value 1.035001
dengamma value 0.990666
dengamma value 1.058520
dengamma value 1.032938
dengamma value 1.019900
dengamma value 1.130534
dengamma value 1.155994
dengamma value 1.129197
dengamma value 1.085386
dengamma value 1.097783
dengamma value 1.069798
dengamma value 1.080026
dengamma value 1.067988
11/24/2016 05:51:47:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08278332 * 5946; err = 0.30760175 * 5946; time = 0.9860s; samplesPerSecond = 6030.4
dengamma value 1.038181
dengamma value 1.102444
dengamma value 1.090990
dengamma value 1.131415
dengamma value 1.059998
dengamma value 1.048366
dengamma value 1.094464
dengamma value 1.103676
dengamma value 1.021067
dengamma value 1.070171
dengamma value 1.004520
dengamma value 1.072360
dengamma value 1.079522
dengamma value 1.114562
dengamma value 1.055148
dengamma value 1.066818
dengamma value 1.035007
dengamma value 0.981645
dengamma value 1.076961
dengamma value 1.105860
dengamma value 1.080845
dengamma value 1.070048
11/24/2016 05:51:48:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08414630 * 5916; err = 0.32352941 * 5916; time = 0.8803s; samplesPerSecond = 6720.3
dengamma value 1.025992
dengamma value 1.040869
dengamma value 1.035353
dengamma value 1.126384
dengamma value 1.100646
dengamma value 1.025893
dengamma value 1.069349
dengamma value 1.095163
dengamma value 1.101373
dengamma value 1.145394
dengamma value 1.040230
dengamma value 0.999097
dengamma value 1.099520
dengamma value 1.097798
dengamma value 0.955191
dengamma value 1.004414
dengamma value 1.068393
dengamma value 1.056871
dengamma value 1.036725
dengamma value 1.020537
dengamma value 1.085684
dengamma value 1.051455
11/24/2016 05:51:49:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08100246 * 6386; err = 0.32445976 * 6386; time = 0.9386s; samplesPerSecond = 6804.0
dengamma value 1.037321
dengamma value 1.074729
dengamma value 1.061118
dengamma value 1.131311
dengamma value 1.068609
dengamma value 1.098983
dengamma value 1.078355
dengamma value 1.092612
dengamma value 1.164741
dengamma value 1.040135
dengamma value 1.069529
dengamma value 1.040972
dengamma value 1.083975
dengamma value 1.042458
dengamma value 1.100387
dengamma value 1.114388
dengamma value 1.048888
dengamma value 1.037523
dengamma value 1.037771
dengamma value 0.974699
dengamma value 1.101628
dengamma value 1.146818
dengamma value 1.048774
11/24/2016 05:51:50:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08275976 * 6734; err = 0.28927829 * 6734; time = 1.0163s; samplesPerSecond = 6625.8
dengamma value 1.076210
dengamma value 1.118100
dengamma value 1.059530
dengamma value 1.085561
dengamma value 1.028712
dengamma value 0.981575
dengamma value 1.055524
dengamma value 1.118188
dengamma value 1.084563
dengamma value 1.056682
dengamma value 1.090217
dengamma value 1.029226
dengamma value 1.069669
dengamma value 0.971849
dengamma value 1.096284
dengamma value 1.043900
dengamma value 1.021812
dengamma value 1.121020
dengamma value 1.050638
dengamma value 1.069355
dengamma value 1.123681
dengamma value 1.063472
dengamma value 1.074820
dengamma value 0.973168
11/24/2016 05:51:51:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08558330 * 6202; err = 0.31376975 * 6202; time = 0.9232s; samplesPerSecond = 6717.9
dengamma value 1.126277
dengamma value 1.109510
dengamma value 1.050797
dengamma value 1.057729
dengamma value 1.139780
dengamma value 1.013761
dengamma value 1.100083
dengamma value 1.090876
dengamma value 1.060692
dengamma value 1.094872
dengamma value 1.092657
dengamma value 1.067255
dengamma value 1.101505
dengamma value 0.997991
dengamma value 0.937640
dengamma value 1.116270
dengamma value 1.083460
dengamma value 1.030041
dengamma value 1.061332
dengamma value 1.042972
dengamma value 1.073277
dengamma value 1.086112
dengamma value 1.051231
dengamma value 1.012984
11/24/2016 05:51:52:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08051356 * 6362; err = 0.32143980 * 6362; time = 0.9846s; samplesPerSecond = 6461.6
dengamma value 1.068911
dengamma value 1.076013
dengamma value 1.111403
dengamma value 1.023743
dengamma value 1.055027
dengamma value 1.090766
dengamma value 1.019594
dengamma value 1.032323
dengamma value 1.016784
dengamma value 1.127077
dengamma value 1.111130
dengamma value 1.054326
dengamma value 1.053589
dengamma value 1.053899
dengamma value 1.052360
dengamma value 1.086669
dengamma value 1.103392
dengamma value 1.128125
dengamma value 1.044551
dengamma value 1.079893
dengamma value 1.054332
11/24/2016 05:51:53:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.07602682 * 5608; err = 0.31508559 * 5608; time = 0.8346s; samplesPerSecond = 6719.4
dengamma value 1.056254
dengamma value 1.037437
dengamma value 1.058650
dengamma value 1.008595
dengamma value 1.081512
dengamma value 1.025969
dengamma value 1.095446
dengamma value 0.992611
dengamma value 1.105144
dengamma value 1.092495
dengamma value 1.040508
dengamma value 1.122757
dengamma value 1.109257
dengamma value 1.033985
dengamma value 1.055500
dengamma value 1.007981
dengamma value 1.045888
dengamma value 1.024794
dengamma value 1.088387
dengamma value 1.071645
dengamma value 1.094680
dengamma value 1.043026
dengamma value 1.014498
11/24/2016 05:51:54:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08226158 * 6594; err = 0.33030027 * 6594; time = 1.0389s; samplesPerSecond = 6346.8
dengamma value 1.019845
dengamma value 0.882733
dengamma value 1.147536
dengamma value 1.003418
dengamma value 1.102949
dengamma value 1.032970
dengamma value 1.092903
dengamma value 1.091507
dengamma value 1.114255
dengamma value 1.096574
dengamma value 1.066187
dengamma value 1.054825
dengamma value 1.084607
dengamma value 1.069651
dengamma value 1.139587
dengamma value 1.023527
dengamma value 1.097427
dengamma value 1.126171
dengamma value 1.048791
dengamma value 1.060946
dengamma value 1.072694
dengamma value 0.998535
dengamma value 1.103585
11/24/2016 05:51:55:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08032342 * 6364; err = 0.31882464 * 6364; time = 1.0513s; samplesPerSecond = 6053.2
dengamma value 1.054305
dengamma value 1.035389
dengamma value 0.981138
dengamma value 1.052572
dengamma value 1.050499
dengamma value 1.130930
dengamma value 1.126263
dengamma value 1.073395
dengamma value 1.041747
dengamma value 1.135342
dengamma value 1.070312
dengamma value 1.155222
dengamma value 1.083846
dengamma value 1.002990
dengamma value 1.107359
dengamma value 1.053807
dengamma value 1.150873
dengamma value 1.084736
dengamma value 1.136049
dengamma value 1.138033
dengamma value 1.078185
dengamma value 1.056611
dengamma value 1.036215
dengamma value 1.105968
dengamma value 1.031480
dengamma value 0.994343
dengamma value 1.001032
11/24/2016 05:51:56:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08647031 * 6536; err = 0.31777846 * 6536; time = 0.9957s; samplesPerSecond = 6564.0
dengamma value 1.078778
dengamma value 1.049558
dengamma value 1.040334
dengamma value 1.067532
dengamma value 1.090041
dengamma value 1.048200
dengamma value 1.079197
dengamma value 1.061228
dengamma value 1.071122
dengamma value 1.025066
dengamma value 1.078113
dengamma value 1.093986
dengamma value 1.035336
dengamma value 0.932626
dengamma value 1.093424
dengamma value 1.053064
dengamma value 1.059779
dengamma value 1.008007
dengamma value 1.044616
dengamma value 1.018627
dengamma value 1.025965
11/24/2016 05:51:57:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08349366 * 6208; err = 0.31411082 * 6208; time = 1.0024s; samplesPerSecond = 6193.0
dengamma value 1.080428
dengamma value 1.065874
dengamma value 1.105914
dengamma value 1.066889
dengamma value 0.939629
dengamma value 1.039080
dengamma value 1.079313
dengamma value 1.091565
dengamma value 1.075301
dengamma value 1.035830
dengamma value 1.054108
dengamma value 1.120248
dengamma value 1.016701
dengamma value 1.177360
dengamma value 1.022460
dengamma value 1.085595
dengamma value 1.076425
dengamma value 1.072483
dengamma value 1.066963
dengamma value 1.076953
dengamma value 1.129427
dengamma value 1.119120
11/24/2016 05:51:58:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08191717 * 6326; err = 0.29386658 * 6326; time = 1.0109s; samplesPerSecond = 6258.0
dengamma value 1.073903
dengamma value 1.064017
dengamma value 1.105885
dengamma value 1.132498
dengamma value 0.988838
dengamma value 1.021531
dengamma value 1.096566
11/24/2016 05:51:58: Finished Epoch[ 1 of 3]: [Training] ce = 0.08210146 * 81936; err = 0.31365944 * 81936; totalSamplesSeen = 81936; learningRatePerSample = 2e-006; epochTime=23.4357s
11/24/2016 05:51:58: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

11/24/2016 05:51:58: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81936), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:58: Starting minibatch loop.
dengamma value 1.144788
dengamma value 1.067668
dengamma value 1.133582
dengamma value 1.047666
dengamma value 1.108951
dengamma value 1.051985
dengamma value 1.091162
dengamma value 1.133974
dengamma value 1.040092
dengamma value 1.045998
dengamma value 1.017054
dengamma value 1.080515
dengamma value 1.073922
dengamma value 1.085375
dengamma value 1.048284
dengamma value 1.008541
dengamma value 1.047478
dengamma value 1.097217
dengamma value 1.054430
dengamma value 1.067713
dengamma value 1.079077
dengamma value 1.126367
dengamma value 1.031468
dengamma value 1.040363
11/24/2016 05:51:59:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08394856 * 6182; err = 0.29715302 * 6182; time = 1.0744s; samplesPerSecond = 5754.0
dengamma value 1.039743
dengamma value 0.994095
dengamma value 1.271343
dengamma value 1.029025
dengamma value 1.082137
dengamma value 1.117012
dengamma value 1.094594
dengamma value 1.030560
dengamma value 1.041076
dengamma value 1.073651
dengamma value 1.037978
dengamma value 1.112773
dengamma value 1.128788
dengamma value 1.032214
dengamma value 1.028924
dengamma value 1.083076
dengamma value 1.019573
dengamma value 1.113091
dengamma value 1.040580
dengamma value 1.022642
dengamma value 1.036811
dengamma value 1.102996
11/24/2016 05:52:00:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08473918 * 5736; err = 0.28940028 * 5736; time = 0.9410s; samplesPerSecond = 6095.8
dengamma value 1.011202
dengamma value 1.100711
dengamma value 1.075193
dengamma value 1.074049
dengamma value 1.048571
dengamma value 1.160061
dengamma value 1.020202
dengamma value 1.119933
dengamma value 1.044584
dengamma value 1.047515
dengamma value 1.040145
dengamma value 1.052449
dengamma value 1.102338
dengamma value 1.169540
dengamma value 1.056408
dengamma value 1.160019
dengamma value 1.103474
dengamma value 1.061084
dengamma value 1.066689
dengamma value 1.090963
dengamma value 0.967020
dengamma value 0.955270
dengamma value 1.058014
11/24/2016 05:52:01:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08161773 * 6244; err = 0.30333120 * 6244; time = 0.9845s; samplesPerSecond = 6342.3
dengamma value 1.087335
dengamma value 1.109639
dengamma value 1.087609
dengamma value 1.050816
dengamma value 1.151471
dengamma value 1.084097
dengamma value 1.066436
dengamma value 1.035792
dengamma value 1.076042
dengamma value 1.012970
dengamma value 1.087685
dengamma value 1.118430
dengamma value 1.110162
dengamma value 1.123442
dengamma value 1.007924
dengamma value 1.121956
dengamma value 1.018405
dengamma value 1.014825
dengamma value 1.068963
dengamma value 1.087287
dengamma value 1.022505
dengamma value 1.059226
dengamma value 1.164692
dengamma value 1.075470
dengamma value 1.046580
11/24/2016 05:52:02:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08591266 * 6280; err = 0.30668790 * 6280; time = 0.9466s; samplesPerSecond = 6634.6
dengamma value 1.011824
dengamma value 1.074268
dengamma value 1.075781
dengamma value 1.071877
dengamma value 1.058875
dengamma value 1.067985
dengamma value 1.057309
dengamma value 1.047082
dengamma value 1.108367
dengamma value 1.065033
dengamma value 1.061061
dengamma value 1.037591
dengamma value 1.111267
dengamma value 1.056545
dengamma value 1.101371
dengamma value 1.082386
dengamma value 1.138838
dengamma value 1.078568
dengamma value 1.085110
dengamma value 1.058575
dengamma value 1.096085
dengamma value 1.069447
dengamma value 1.085847
dengamma value 1.076495
dengamma value 1.087442
dengamma value 1.098921
11/24/2016 05:52:03:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.07806406 * 7428; err = 0.29483037 * 7428; time = 1.2128s; samplesPerSecond = 6124.7
dengamma value 1.129033
dengamma value 1.083035
dengamma value 1.044120
dengamma value 1.129306
dengamma value 1.041943
dengamma value 1.025041
dengamma value 1.033512
dengamma value 1.082857
dengamma value 1.060189
dengamma value 1.051552
dengamma value 1.031050
dengamma value 1.040581
dengamma value 1.026000
dengamma value 1.142609
dengamma value 1.082639
dengamma value 1.076994
dengamma value 1.084207
dengamma value 0.968924
dengamma value 1.047756
dengamma value 1.062654
dengamma value 1.112579
dengamma value 1.013362
dengamma value 1.056691
11/24/2016 05:52:04:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08174993 * 6994; err = 0.32098942 * 6994; time = 1.0258s; samplesPerSecond = 6818.0
dengamma value 1.104948
dengamma value 1.076387
dengamma value 1.164586
dengamma value 1.020876
dengamma value 1.047547
dengamma value 1.122460
dengamma value 0.969923
dengamma value 1.129578
dengamma value 1.165495
dengamma value 1.063070
dengamma value 1.142918
dengamma value 1.115485
dengamma value 1.042462
dengamma value 1.021439
dengamma value 1.066489
dengamma value 1.075629
dengamma value 1.047002
dengamma value 1.031252
dengamma value 1.089244
dengamma value 1.079581
dengamma value 1.063712
dengamma value 1.140261
dengamma value 1.065048
dengamma value 1.089694
11/24/2016 05:52:05:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07756833 * 6572; err = 0.30234327 * 6572; time = 1.0580s; samplesPerSecond = 6211.6
dengamma value 1.078434
dengamma value 1.014461
dengamma value 1.072225
dengamma value 1.079522
dengamma value 1.062720
dengamma value 1.118930
dengamma value 1.183187
dengamma value 1.064484
dengamma value 1.064534
dengamma value 1.053123
dengamma value 0.999522
dengamma value 1.034234
dengamma value 1.016161
dengamma value 1.158228
dengamma value 1.072633
dengamma value 0.940745
dengamma value 0.999668
dengamma value 1.030136
dengamma value 1.068105
dengamma value 1.078899
dengamma value 1.193323
dengamma value 1.010362
11/24/2016 05:52:06:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08826415 * 5506; err = 0.32891391 * 5506; time = 0.8439s; samplesPerSecond = 6524.3
dengamma value 0.995239
dengamma value 1.066258
dengamma value 1.008997
dengamma value 1.068584
dengamma value 1.115299
dengamma value 1.118109
dengamma value 1.122865
dengamma value 1.076676
dengamma value 1.031365
dengamma value 1.008796
dengamma value 1.086724
dengamma value 0.953431
dengamma value 1.069936
dengamma value 1.028596
dengamma value 1.063139
dengamma value 1.111163
dengamma value 1.113988
dengamma value 1.076633
dengamma value 1.098310
dengamma value 0.998565
dengamma value 0.995780
11/24/2016 05:52:07:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08586054 * 5628; err = 0.33120114 * 5628; time = 0.8695s; samplesPerSecond = 6472.7
dengamma value 1.030636
dengamma value 1.122158
dengamma value 1.071000
dengamma value 1.082131
dengamma value 1.078288
dengamma value 0.976728
dengamma value 1.034194
dengamma value 1.001687
dengamma value 1.092763
dengamma value 1.050236
dengamma value 1.156707
dengamma value 1.080040
dengamma value 1.082430
dengamma value 1.063162
dengamma value 1.018260
dengamma value 1.037647
dengamma value 1.038236
dengamma value 1.054992
dengamma value 1.053724
dengamma value 1.136263
dengamma value 1.011648
dengamma value 1.026312
dengamma value 1.046644
dengamma value 0.980904
11/24/2016 05:52:08:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08256543 * 6032; err = 0.32609416 * 6032; time = 0.8928s; samplesPerSecond = 6756.4
dengamma value 1.036405
dengamma value 1.052698
dengamma value 1.054865
dengamma value 1.080565
dengamma value 1.059186
dengamma value 1.107809
dengamma value 1.076557
dengamma value 0.963312
dengamma value 1.116781
dengamma value 1.130446
dengamma value 1.030180
dengamma value 0.968487
dengamma value 1.055465
dengamma value 1.133598
dengamma value 1.081955
dengamma value 0.986750
dengamma value 1.145767
dengamma value 1.041663
dengamma value 1.096804
dengamma value 1.014415
11/24/2016 05:52:09:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08855271 * 4790; err = 0.32964509 * 4790; time = 0.7542s; samplesPerSecond = 6350.8
dengamma value 1.009262
dengamma value 0.960464
dengamma value 1.057838
dengamma value 1.057408
dengamma value 1.068856
dengamma value 1.011671
dengamma value 1.006617
dengamma value 1.084475
dengamma value 1.066719
dengamma value 0.953276
dengamma value 1.113813
dengamma value 1.049543
dengamma value 1.064398
dengamma value 1.011656
dengamma value 1.124873
dengamma value 1.058611
dengamma value 1.117174
dengamma value 1.163091
dengamma value 0.953690
dengamma value 1.141115
dengamma value 1.032477
dengamma value 1.034117
11/24/2016 05:52:10:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08604860 * 5986; err = 0.34330104 * 5986; time = 0.8870s; samplesPerSecond = 6748.8
dengamma value 1.023001
dengamma value 1.002941
dengamma value 1.047033
dengamma value 1.081415
dengamma value 1.025410
dengamma value 1.197755
dengamma value 1.088493
dengamma value 1.105166
dengamma value 1.066182
dengamma value 1.070647
dengamma value 1.088689
dengamma value 1.077664
dengamma value 0.993398
dengamma value 0.988926
dengamma value 1.024617
dengamma value 1.072682
dengamma value 1.043573
dengamma value 1.043180
dengamma value 1.110051
dengamma value 1.038232
dengamma value 1.100638
dengamma value 1.052356
dengamma value 1.076558
dengamma value 0.981333
11/24/2016 05:52:11:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08672339 * 7022; err = 0.31543720 * 7022; time = 1.0302s; samplesPerSecond = 6816.3
dengamma value 1.025593
dengamma value 1.095874
dengamma value 1.175655
dengamma value 1.072353
dengamma value 1.035818
dengamma value 1.073142
dengamma value 1.006410
dengamma value 1.073130
dengamma value 1.073130
11/24/2016 05:52:11: Finished Epoch[ 2 of 3]: [Training] ce = 0.08368858 * 82462; err = 0.31396279 * 82462; totalSamplesSeen = 164398; learningRatePerSample = 2e-006; epochTime=12.8467s
11/24/2016 05:52:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

11/24/2016 05:52:11: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 164102), data subset 0 of 1, with 1 datapasses

11/24/2016 05:52:11: Starting minibatch loop.
dengamma value 1.093325
dengamma value 1.093290
dengamma value 1.078079
dengamma value 1.101315
dengamma value 1.062543
dengamma value 1.048869
dengamma value 1.144281
dengamma value 1.031190
dengamma value 1.109625
dengamma value 0.980896
dengamma value 1.110815
dengamma value 1.069864
dengamma value 1.063919
dengamma value 1.094402
dengamma value 1.065247
dengamma value 1.055912
dengamma value 1.096847
dengamma value 1.007792
dengamma value 1.096083
dengamma value 1.091273
dengamma value 1.038316
dengamma value 1.055802
dengamma value 1.038140
dengamma value 1.038473
11/24/2016 05:52:12:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08372720 * 6292; err = 0.29513668 * 6292; time = 0.9456s; samplesPerSecond = 6654.3
dengamma value 1.154513
dengamma value 1.029643
dengamma value 0.982874
dengamma value 1.089715
dengamma value 1.078008
dengamma value 1.017680
dengamma value 1.043414
dengamma value 1.126086
dengamma value 1.030913
dengamma value 0.968231
dengamma value 0.960794
dengamma value 1.091606
dengamma value 1.058386
dengamma value 1.062539
dengamma value 1.024998
dengamma value 1.063282
dengamma value 1.004053
dengamma value 1.066975
dengamma value 1.092495
dengamma value 1.025583
dengamma value 1.070193
dengamma value 1.020889
11/24/2016 05:52:13:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.07971280 * 6596; err = 0.33217101 * 6596; time = 1.0191s; samplesPerSecond = 6472.1
dengamma value 1.074300
dengamma value 1.000704
dengamma value 1.089941
dengamma value 1.114393
dengamma value 1.063478
dengamma value 1.150361
dengamma value 1.021944
dengamma value 1.074172
dengamma value 1.050505
dengamma value 1.055580
dengamma value 1.096195
dengamma value 1.050428
dengamma value 1.017433
dengamma value 1.025604
dengamma value 1.115736
dengamma value 0.948157
dengamma value 1.042625
dengamma value 1.028026
dengamma value 1.021894
dengamma value 1.167727
dengamma value 1.071504
dengamma value 1.184830
11/24/2016 05:52:14:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08684471 * 5666; err = 0.29085775 * 5666; time = 0.9025s; samplesPerSecond = 6278.2
dengamma value 1.124766
dengamma value 1.021517
dengamma value 1.057101
dengamma value 1.080541
dengamma value 1.071841
dengamma value 1.070481
dengamma value 1.099237
dengamma value 1.066131
dengamma value 1.087266
dengamma value 1.073005
dengamma value 1.096354
dengamma value 1.040918
dengamma value 0.994948
dengamma value 1.127304
dengamma value 1.118610
dengamma value 1.032991
dengamma value 1.076252
dengamma value 1.031770
dengamma value 1.083275
dengamma value 1.025399
dengamma value 1.080415
dengamma value 1.026206
11/24/2016 05:52:15:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08171786 * 6626; err = 0.28146695 * 6626; time = 1.0556s; samplesPerSecond = 6276.9
dengamma value 1.084985
dengamma value 1.038321
dengamma value 1.019886
dengamma value 1.085216
dengamma value 1.113452
dengamma value 1.145861
dengamma value 1.076982
dengamma value 1.097638
dengamma value 1.020262
dengamma value 1.080939
dengamma value 1.136270
dengamma value 1.071480
dengamma value 1.031346
dengamma value 1.066578
dengamma value 1.019942
dengamma value 1.056769
dengamma value 1.076691
dengamma value 1.059788
dengamma value 1.104866
dengamma value 1.099456
dengamma value 1.065104
dengamma value 1.070282
dengamma value 1.060589
dengamma value 1.051952
11/24/2016 05:52:16:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08171929 * 5652; err = 0.30661713 * 5652; time = 0.9429s; samplesPerSecond = 5994.3
dengamma value 1.085475
dengamma value 1.041727
dengamma value 0.999519
dengamma value 1.044009
dengamma value 1.030048
dengamma value 1.145261
dengamma value 1.039033
dengamma value 1.043872
dengamma value 1.096938
dengamma value 1.016520
dengamma value 1.018497
dengamma value 1.053764
dengamma value 1.069873
dengamma value 1.061719
dengamma value 1.079761
dengamma value 1.029372
dengamma value 1.003244
dengamma value 1.035332
dengamma value 1.089386
dengamma value 1.036093
dengamma value 1.049912
11/24/2016 05:52:17:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08664254 * 6588; err = 0.33591378 * 6588; time = 1.0164s; samplesPerSecond = 6481.6
dengamma value 1.062761
dengamma value 1.088534
dengamma value 1.030429
dengamma value 0.978924
dengamma value 1.144138
dengamma value 1.065584
dengamma value 1.074983
dengamma value 1.028052
dengamma value 1.004280
dengamma value 1.085115
dengamma value 1.078701
dengamma value 1.021154
dengamma value 1.025216
dengamma value 1.113527
dengamma value 1.131221
dengamma value 1.050445
dengamma value 1.036988
dengamma value 1.077845
dengamma value 1.094059
dengamma value 1.055228
dengamma value 1.019418
11/24/2016 05:52:18:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08665410 * 6328; err = 0.30041087 * 6328; time = 1.0243s; samplesPerSecond = 6178.0
dengamma value 1.065151
dengamma value 1.092482
dengamma value 1.000608
dengamma value 1.094549
dengamma value 1.119028
dengamma value 1.066092
dengamma value 1.083037
dengamma value 1.104295
dengamma value 1.052824
dengamma value 0.985415
dengamma value 1.048441
dengamma value 1.025753
dengamma value 1.019787
dengamma value 1.096436
dengamma value 1.042069
dengamma value 1.075620
dengamma value 1.069405
dengamma value 1.185225
dengamma value 1.085977
dengamma value 1.055246
dengamma value 1.062520
dengamma value 1.103389
dengamma value 1.028822
dengamma value 1.090527
dengamma value 1.064958
11/24/2016 05:52:19:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08280250 * 6980; err = 0.28696275 * 6980; time = 1.0783s; samplesPerSecond = 6473.5
dengamma value 1.041103
dengamma value 0.970241
dengamma value 0.945343
dengamma value 1.122680
dengamma value 1.120082
dengamma value 1.016399
dengamma value 1.256791
dengamma value 1.098080
dengamma value 1.059433
dengamma value 1.111956
dengamma value 0.975359
dengamma value 1.068666
dengamma value 1.054015
dengamma value 1.003948
dengamma value 1.119815
dengamma value 1.054965
dengamma value 0.999153
dengamma value 1.265836
dengamma value 1.184139
dengamma value 1.041464
dengamma value 1.127826
dengamma value 0.972101
dengamma value 1.020741
11/24/2016 05:52:20:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08057347 * 6774; err = 0.31030410 * 6774; time = 0.9516s; samplesPerSecond = 7118.2
dengamma value 0.984444
dengamma value 1.075092
dengamma value 1.110428
dengamma value 1.017753
dengamma value 0.926113
dengamma value 1.068063
dengamma value 1.035198
dengamma value 1.049943
dengamma value 0.927311
dengamma value 1.063838
dengamma value 1.004998
dengamma value 1.083997
dengamma value 1.016184
dengamma value 0.978279
dengamma value 1.061870
dengamma value 0.923002
dengamma value 1.047923
dengamma value 1.007333
dengamma value 1.063524
dengamma value 1.062727
dengamma value 1.095547
dengamma value 1.078367
11/24/2016 05:52:21:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08922414 * 6146; err = 0.35551578 * 6146; time = 0.9760s; samplesPerSecond = 6297.1
dengamma value 1.003198
dengamma value 1.121018
dengamma value 1.050772
dengamma value 1.141898
dengamma value 0.952279
dengamma value 1.080954
dengamma value 1.062003
dengamma value 1.134550
dengamma value 1.107400
dengamma value 1.079618
dengamma value 1.036801
dengamma value 1.007516
dengamma value 1.164952
dengamma value 1.057983
dengamma value 1.111117
dengamma value 1.062356
dengamma value 1.082772
dengamma value 1.090492
dengamma value 1.006457
dengamma value 1.133521
dengamma value 1.057975
dengamma value 1.079631
11/24/2016 05:52:22:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08236220 * 5366; err = 0.30357808 * 5366; time = 0.8760s; samplesPerSecond = 6125.6
dengamma value 1.052223
dengamma value 1.047077
dengamma value 1.082992
dengamma value 1.060814
dengamma value 1.058900
dengamma value 1.005897
dengamma value 1.115806
dengamma value 1.060509
dengamma value 1.007156
dengamma value 1.021254
dengamma value 1.018205
dengamma value 1.060350
dengamma value 1.052215
dengamma value 1.030463
dengamma value 1.088068
dengamma value 1.083264
dengamma value 1.105645
dengamma value 1.103729
dengamma value 1.053346
dengamma value 0.976522
dengamma value 1.023172
dengamma value 1.113141
dengamma value 1.135918
dengamma value 1.095686
dengamma value 1.077372
11/24/2016 05:52:23:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08146509 * 6220; err = 0.31623794 * 6220; time = 0.9434s; samplesPerSecond = 6593.4
dengamma value 1.071231
dengamma value 1.043554
dengamma value 1.104420
dengamma value 1.079753
dengamma value 1.025009
dengamma value 1.062639
dengamma value 1.069930
dengamma value 1.099450
dengamma value 1.078811
dengamma value 1.074026
dengamma value 1.038141
dengamma value 1.049004
dengamma value 1.023503
dengamma value 1.085062
dengamma value 1.152116
dengamma value 1.111020
dengamma value 1.051507
dengamma value 0.984069
dengamma value 1.078883
dengamma value 1.030281
dengamma value 1.072279
dengamma value 1.095373
dengamma value 1.132264
11/24/2016 05:52:24:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08534619 * 6564; err = 0.29418038 * 6564; time = 0.9968s; samplesPerSecond = 6585.4
11/24/2016 05:52:24: Finished Epoch[ 3 of 3]: [Training] ce = 0.08372046 * 81798; err = 0.30838162 * 81798; totalSamplesSeen = 246196; learningRatePerSample = 2e-006; epochTime=12.7306s
11/24/2016 05:52:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

11/24/2016 05:52:24: Action "train" complete.

11/24/2016 05:52:24: __COMPLETED__