CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3530 @ 2.80GHz
    Hardware threads: 4
    Total Memory: 12580404 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-SlaveTest/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta6.0+ (HEAD 6f1527, Dec 16 2016 04:56:11) on cntk-muc00 at 2016/12/16 06:06:45

C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/cntk_sequence.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData
12/16/2016 06:06:46: -------------------------------------------------------------------
12/16/2016 06:06:46: Build info: 

12/16/2016 06:06:46: 		Built time: Dec 16 2016 04:56:11
12/16/2016 06:06:46: 		Last modified date: Thu Dec 15 15:24:22 2016
12/16/2016 06:06:46: 		Build type: Release
12/16/2016 06:06:46: 		Build target: GPU
12/16/2016 06:06:46: 		With 1bit-SGD: no
12/16/2016 06:06:46: 		With ASGD: yes
12/16/2016 06:06:46: 		Math lib: mkl
12/16/2016 06:06:46: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
12/16/2016 06:06:46: 		CUB_PATH: c:\src\cub-1.4.1
12/16/2016 06:06:46: 		CUDNN_PATH: C:\local\cudnn-8.0-windows10-x64-v5.1
12/16/2016 06:06:46: 		Build Branch: HEAD
12/16/2016 06:06:46: 		Build SHA1: 6f15279421b79cbe94481fb1b652411e51114d51 (modified)
12/16/2016 06:06:46: 		Built by svcphil on Philly-Pool1
12/16/2016 06:06:46: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
12/16/2016 06:06:46: -------------------------------------------------------------------
12/16/2016 06:06:46: -------------------------------------------------------------------
12/16/2016 06:06:46: GPU info:

12/16/2016 06:06:46: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
12/16/2016 06:06:46: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
        labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf"
            labelMappingFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying"
            transpFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
12/16/2016 06:06:46: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
12/16/2016 06:06:46: precision = "float"

12/16/2016 06:06:46: ##############################################################################
12/16/2016 06:06:46: #                                                                            #
12/16/2016 06:06:46: # dptPre1 command (train action)                                             #
12/16/2016 06:06:46: #                                                                            #
12/16/2016 06:06:46: ##############################################################################

12/16/2016 06:06:46: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/16/2016 06:06:47: 
Model has 19 nodes. Using GPU 0.

12/16/2016 06:06:47: Training criterion:   ce = CrossEntropyWithSoftmax
12/16/2016 06:06:47: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }


12/16/2016 06:06:47: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/16/2016 06:06:47: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/16/2016 06:06:47: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:47: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/16/2016 06:06:47: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/16/2016 06:06:47: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/16/2016 06:06:47: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/16/2016 06:06:47: Starting minibatch loop.
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.89978256 * 2560; err = 0.84375000 * 2560; time = 0.4028s; samplesPerSecond = 6354.9
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.96755676 * 2560; err = 0.72031250 * 2560; time = 0.0111s; samplesPerSecond = 231318.3
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.55723495 * 2560; err = 0.65859375 * 2560; time = 0.0110s; samplesPerSecond = 233108.7
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.29642715 * 2560; err = 0.61992187 * 2560; time = 0.0110s; samplesPerSecond = 233598.0
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 2.02396469 * 2560; err = 0.55117187 * 2560; time = 0.0110s; samplesPerSecond = 233661.9
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87309265 * 2560; err = 0.51484375 * 2560; time = 0.0110s; samplesPerSecond = 233640.6
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.78157196 * 2560; err = 0.50507813 * 2560; time = 0.0110s; samplesPerSecond = 233790.0
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.75391235 * 2560; err = 0.50781250 * 2560; time = 0.0112s; samplesPerSecond = 227616.3
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66460266 * 2560; err = 0.45742187 * 2560; time = 0.0111s; samplesPerSecond = 230174.4
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62184296 * 2560; err = 0.47968750 * 2560; time = 0.0111s; samplesPerSecond = 229781.9
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.65328217 * 2560; err = 0.47265625 * 2560; time = 0.0111s; samplesPerSecond = 229658.2
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.50686646 * 2560; err = 0.44921875 * 2560; time = 0.0111s; samplesPerSecond = 230859.4
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.46723938 * 2560; err = 0.42304687 * 2560; time = 0.0111s; samplesPerSecond = 231088.6
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.49163513 * 2560; err = 0.44140625 * 2560; time = 0.0110s; samplesPerSecond = 233640.6
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46437683 * 2560; err = 0.43398437 * 2560; time = 0.0110s; samplesPerSecond = 233640.6
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43047791 * 2560; err = 0.43867187 * 2560; time = 0.0111s; samplesPerSecond = 230506.0
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.42104797 * 2560; err = 0.41992188 * 2560; time = 0.0110s; samplesPerSecond = 232241.7
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.46536865 * 2560; err = 0.42421875 * 2560; time = 0.0112s; samplesPerSecond = 228001.4
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.47427673 * 2560; err = 0.44062500 * 2560; time = 0.0113s; samplesPerSecond = 226970.5
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42848816 * 2560; err = 0.44062500 * 2560; time = 0.0110s; samplesPerSecond = 233023.8
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.34078674 * 2560; err = 0.41171875 * 2560; time = 0.0109s; samplesPerSecond = 234905.5
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.39474792 * 2560; err = 0.42773438 * 2560; time = 0.0109s; samplesPerSecond = 234754.7
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.40156250 * 2560; err = 0.41250000 * 2560; time = 0.0109s; samplesPerSecond = 235078.1
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.39350586 * 2560; err = 0.42734375 * 2560; time = 0.0109s; samplesPerSecond = 234110.7
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.32500916 * 2560; err = 0.40156250 * 2560; time = 0.0109s; samplesPerSecond = 233832.7
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.27034607 * 2560; err = 0.39804688 * 2560; time = 0.0109s; samplesPerSecond = 234110.7
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.32393494 * 2560; err = 0.39375000 * 2560; time = 0.0109s; samplesPerSecond = 233896.8
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25440979 * 2560; err = 0.38437500 * 2560; time = 0.0109s; samplesPerSecond = 234496.7
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.23372498 * 2560; err = 0.37148437 * 2560; time = 0.0109s; samplesPerSecond = 234475.2
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20885620 * 2560; err = 0.35976562 * 2560; time = 0.0109s; samplesPerSecond = 234410.8
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23717957 * 2560; err = 0.36953125 * 2560; time = 0.0109s; samplesPerSecond = 234582.6
12/16/2016 06:06:47:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.23036499 * 2560; err = 0.37382813 * 2560; time = 0.0108s; samplesPerSecond = 237080.9
12/16/2016 06:06:47: Finished Epoch[ 1 of 2]: [Training] ce = 1.65179615 * 81920; err = 0.46795654 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.884601s
12/16/2016 06:06:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

12/16/2016 06:06:48: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/16/2016 06:06:48: Starting minibatch loop.
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.21826115 * 2560; err = 0.37031250 * 2560; time = 0.0118s; samplesPerSecond = 216399.0
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18394604 * 2560; err = 0.36640625 * 2560; time = 0.0110s; samplesPerSecond = 232262.7
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.17353325 * 2560; err = 0.35976562 * 2560; time = 0.0113s; samplesPerSecond = 225849.1
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.20286140 * 2560; err = 0.35859375 * 2560; time = 0.0112s; samplesPerSecond = 227636.5
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.19606552 * 2560; err = 0.37812500 * 2560; time = 0.0113s; samplesPerSecond = 227555.6
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.16461716 * 2560; err = 0.34375000 * 2560; time = 0.0112s; samplesPerSecond = 229514.1
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.13763046 * 2560; err = 0.34765625 * 2560; time = 0.0113s; samplesPerSecond = 227555.6
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.19578094 * 2560; err = 0.37226562 * 2560; time = 0.0113s; samplesPerSecond = 226468.5
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.24385757 * 2560; err = 0.38046875 * 2560; time = 0.0112s; samplesPerSecond = 227940.5
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18975372 * 2560; err = 0.36093750 * 2560; time = 0.0111s; samplesPerSecond = 231674.2
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.16871262 * 2560; err = 0.35625000 * 2560; time = 0.0115s; samplesPerSecond = 222841.2
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.24394531 * 2560; err = 0.37929687 * 2560; time = 0.0112s; samplesPerSecond = 228062.4
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.18284454 * 2560; err = 0.34921875 * 2560; time = 0.0112s; samplesPerSecond = 229226.4
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.21535187 * 2560; err = 0.36875000 * 2560; time = 0.0111s; samplesPerSecond = 231632.3
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.19859619 * 2560; err = 0.37187500 * 2560; time = 0.0109s; samplesPerSecond = 234346.4
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.14699402 * 2560; err = 0.34648438 * 2560; time = 0.0109s; samplesPerSecond = 234196.3
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.14664307 * 2560; err = 0.35859375 * 2560; time = 0.0109s; samplesPerSecond = 234518.1
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.17961731 * 2560; err = 0.35234375 * 2560; time = 0.0109s; samplesPerSecond = 234217.7
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14800873 * 2560; err = 0.35234375 * 2560; time = 0.0109s; samplesPerSecond = 234089.2
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08513489 * 2560; err = 0.33320312 * 2560; time = 0.0109s; samplesPerSecond = 234346.4
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.14455261 * 2560; err = 0.34726563 * 2560; time = 0.0109s; samplesPerSecond = 234110.7
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.16282043 * 2560; err = 0.35703125 * 2560; time = 0.0110s; samplesPerSecond = 233768.6
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.19267578 * 2560; err = 0.37265625 * 2560; time = 0.0109s; samplesPerSecond = 234346.4
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.15575562 * 2560; err = 0.34882812 * 2560; time = 0.0110s; samplesPerSecond = 233747.3
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.15968018 * 2560; err = 0.35351563 * 2560; time = 0.0111s; samplesPerSecond = 229761.3
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08686829 * 2560; err = 0.33007813 * 2560; time = 0.0111s; samplesPerSecond = 230776.2
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.10071411 * 2560; err = 0.34804687 * 2560; time = 0.0111s; samplesPerSecond = 230880.2
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.06582336 * 2560; err = 0.33945313 * 2560; time = 0.0109s; samplesPerSecond = 234303.5
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09620972 * 2560; err = 0.33085938 * 2560; time = 0.0110s; samplesPerSecond = 233747.3
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.15163269 * 2560; err = 0.35195312 * 2560; time = 0.0109s; samplesPerSecond = 234282.1
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.10898132 * 2560; err = 0.34296875 * 2560; time = 0.0109s; samplesPerSecond = 234067.8
12/16/2016 06:06:48:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06808777 * 2560; err = 0.32304688 * 2560; time = 0.0108s; samplesPerSecond = 237168.8
12/16/2016 06:06:48: Finished Epoch[ 2 of 2]: [Training] ce = 1.15987368 * 81920; err = 0.35476074 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.357876s
12/16/2016 06:06:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

12/16/2016 06:06:48: Action "train" complete.


12/16/2016 06:06:48: ##############################################################################
12/16/2016 06:06:48: #                                                                            #
12/16/2016 06:06:48: # addLayer2 command (edit action)                                            #
12/16/2016 06:06:48: #                                                                            #
12/16/2016 06:06:48: ##############################################################################


12/16/2016 06:06:48: Action "edit" complete.


12/16/2016 06:06:48: ##############################################################################
12/16/2016 06:06:48: #                                                                            #
12/16/2016 06:06:48: # dptPre2 command (train action)                                             #
12/16/2016 06:06:48: #                                                                            #
12/16/2016 06:06:48: ##############################################################################

12/16/2016 06:06:48: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/16/2016 06:06:49: 
Model has 24 nodes. Using GPU 0.

12/16/2016 06:06:49: Training criterion:   ce = CrossEntropyWithSoftmax
12/16/2016 06:06:49: Evaluation criterion: err = ClassificationError

12/16/2016 06:06:49: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/16/2016 06:06:49: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/16/2016 06:06:49: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:49: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/16/2016 06:06:49: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:49: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/16/2016 06:06:49: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/16/2016 06:06:49: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/16/2016 06:06:49: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/16/2016 06:06:49: Starting minibatch loop.
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 4.68514633 * 2560; err = 0.80507812 * 2560; time = 0.0191s; samplesPerSecond = 134115.7
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.83540878 * 2560; err = 0.69765625 * 2560; time = 0.0154s; samplesPerSecond = 166309.4
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.27396317 * 2560; err = 0.59335938 * 2560; time = 0.0154s; samplesPerSecond = 166612.4
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.93453598 * 2560; err = 0.52070313 * 2560; time = 0.0154s; samplesPerSecond = 166514.9
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.72010651 * 2560; err = 0.47890625 * 2560; time = 0.0154s; samplesPerSecond = 166569.1
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.61654205 * 2560; err = 0.47070313 * 2560; time = 0.0154s; samplesPerSecond = 166634.1
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.51410522 * 2560; err = 0.44140625 * 2560; time = 0.0154s; samplesPerSecond = 166223.0
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.49882050 * 2560; err = 0.43671875 * 2560; time = 0.0154s; samplesPerSecond = 166590.7
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.45906067 * 2560; err = 0.41835937 * 2560; time = 0.0154s; samplesPerSecond = 166439.1
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.41359100 * 2560; err = 0.40937500 * 2560; time = 0.0154s; samplesPerSecond = 166493.2
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41605682 * 2560; err = 0.41093750 * 2560; time = 0.0154s; samplesPerSecond = 166623.3
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.34621582 * 2560; err = 0.39531250 * 2560; time = 0.0154s; samplesPerSecond = 166536.6
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.32200775 * 2560; err = 0.39257813 * 2560; time = 0.0154s; samplesPerSecond = 165985.9
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33358612 * 2560; err = 0.39609375 * 2560; time = 0.0159s; samplesPerSecond = 160562.0
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.32798462 * 2560; err = 0.39023438 * 2560; time = 0.0154s; samplesPerSecond = 165760.2
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28152161 * 2560; err = 0.38906250 * 2560; time = 0.0154s; samplesPerSecond = 166082.8
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.29407654 * 2560; err = 0.38476563 * 2560; time = 0.0155s; samplesPerSecond = 165108.0
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.29927979 * 2560; err = 0.39023438 * 2560; time = 0.0154s; samplesPerSecond = 165856.8
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.33316956 * 2560; err = 0.40546875 * 2560; time = 0.0154s; samplesPerSecond = 166050.5
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32376099 * 2560; err = 0.41406250 * 2560; time = 0.0154s; samplesPerSecond = 166439.1
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.23729553 * 2560; err = 0.37539062 * 2560; time = 0.0154s; samplesPerSecond = 166385.0
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.27207336 * 2560; err = 0.38906250 * 2560; time = 0.0154s; samplesPerSecond = 166590.7
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.26402893 * 2560; err = 0.37695313 * 2560; time = 0.0154s; samplesPerSecond = 166720.9
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.24779053 * 2560; err = 0.36992188 * 2560; time = 0.0154s; samplesPerSecond = 166525.7
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.21864014 * 2560; err = 0.36757812 * 2560; time = 0.0154s; samplesPerSecond = 166050.5
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19121704 * 2560; err = 0.37070313 * 2560; time = 0.0154s; samplesPerSecond = 166028.9
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.23925476 * 2560; err = 0.36835937 * 2560; time = 0.0154s; samplesPerSecond = 166212.2
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.18916016 * 2560; err = 0.36406250 * 2560; time = 0.0154s; samplesPerSecond = 166363.4
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.17012329 * 2560; err = 0.35351563 * 2560; time = 0.0154s; samplesPerSecond = 166277.0
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.14500122 * 2560; err = 0.33984375 * 2560; time = 0.0154s; samplesPerSecond = 166385.0
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.17140808 * 2560; err = 0.35000000 * 2560; time = 0.0154s; samplesPerSecond = 166363.4
12/16/2016 06:06:49:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.18915710 * 2560; err = 0.36992188 * 2560; time = 0.0154s; samplesPerSecond = 166449.9
12/16/2016 06:06:49: Finished Epoch[ 1 of 2]: [Training] ce = 1.52387781 * 81920; err = 0.42613525 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.637725s
12/16/2016 06:06:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

12/16/2016 06:06:49: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/16/2016 06:06:49: Starting minibatch loop.
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.18371334 * 2560; err = 0.35312500 * 2560; time = 0.0161s; samplesPerSecond = 159134.7
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.15387115 * 2560; err = 0.35195312 * 2560; time = 0.0154s; samplesPerSecond = 165975.1
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15634022 * 2560; err = 0.35078125 * 2560; time = 0.0154s; samplesPerSecond = 166147.5
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.13972702 * 2560; err = 0.34531250 * 2560; time = 0.0154s; samplesPerSecond = 166136.7
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.14528008 * 2560; err = 0.36445312 * 2560; time = 0.0154s; samplesPerSecond = 165953.6
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.14011345 * 2560; err = 0.33476563 * 2560; time = 0.0154s; samplesPerSecond = 166471.6
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.09710693 * 2560; err = 0.33671875 * 2560; time = 0.0154s; samplesPerSecond = 166514.9
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.15687256 * 2560; err = 0.35546875 * 2560; time = 0.0154s; samplesPerSecond = 166601.6
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.16989441 * 2560; err = 0.35898438 * 2560; time = 0.0154s; samplesPerSecond = 166309.4
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.12214737 * 2560; err = 0.34804687 * 2560; time = 0.0154s; samplesPerSecond = 166428.3
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.12149048 * 2560; err = 0.34687500 * 2560; time = 0.0154s; samplesPerSecond = 166179.8
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19465485 * 2560; err = 0.36406250 * 2560; time = 0.0154s; samplesPerSecond = 166417.5
12/16/2016 06:06:49:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.13471985 * 2560; err = 0.34140625 * 2560; time = 0.0154s; samplesPerSecond = 166612.4
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16473541 * 2560; err = 0.36054687 * 2560; time = 0.0154s; samplesPerSecond = 166277.0
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.12361755 * 2560; err = 0.35000000 * 2560; time = 0.0154s; samplesPerSecond = 166439.1
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.09654999 * 2560; err = 0.34101562 * 2560; time = 0.0154s; samplesPerSecond = 166439.1
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.10468903 * 2560; err = 0.33945313 * 2560; time = 0.0154s; samplesPerSecond = 165964.3
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.11432037 * 2560; err = 0.33007813 * 2560; time = 0.0154s; samplesPerSecond = 166449.9
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.10250244 * 2560; err = 0.33906250 * 2560; time = 0.0154s; samplesPerSecond = 166547.4
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.06273804 * 2560; err = 0.32578125 * 2560; time = 0.0154s; samplesPerSecond = 166612.4
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.10996704 * 2560; err = 0.33750000 * 2560; time = 0.0154s; samplesPerSecond = 166710.1
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13582306 * 2560; err = 0.35078125 * 2560; time = 0.0154s; samplesPerSecond = 166720.9
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.12325439 * 2560; err = 0.34257813 * 2560; time = 0.0154s; samplesPerSecond = 166341.8
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10882263 * 2560; err = 0.34023437 * 2560; time = 0.0154s; samplesPerSecond = 166590.7
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09274902 * 2560; err = 0.33789063 * 2560; time = 0.0154s; samplesPerSecond = 166233.8
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.04688721 * 2560; err = 0.31914063 * 2560; time = 0.0155s; samplesPerSecond = 165214.6
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.04932556 * 2560; err = 0.33515625 * 2560; time = 0.0154s; samplesPerSecond = 165803.1
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.03842468 * 2560; err = 0.31992188 * 2560; time = 0.0155s; samplesPerSecond = 165118.7
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.06117859 * 2560; err = 0.33046875 * 2560; time = 0.0154s; samplesPerSecond = 165770.9
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.11318054 * 2560; err = 0.34492187 * 2560; time = 0.0154s; samplesPerSecond = 166039.7
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08679199 * 2560; err = 0.33515625 * 2560; time = 0.0154s; samplesPerSecond = 165770.9
12/16/2016 06:06:50:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.04743347 * 2560; err = 0.32773438 * 2560; time = 0.0154s; samplesPerSecond = 166764.4
12/16/2016 06:06:50: Finished Epoch[ 2 of 2]: [Training] ce = 1.11559134 * 81920; err = 0.34248047 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.49665s
12/16/2016 06:06:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

12/16/2016 06:06:50: Action "train" complete.


12/16/2016 06:06:50: ##############################################################################
12/16/2016 06:06:50: #                                                                            #
12/16/2016 06:06:50: # addLayer3 command (edit action)                                            #
12/16/2016 06:06:50: #                                                                            #
12/16/2016 06:06:50: ##############################################################################


12/16/2016 06:06:50: Action "edit" complete.


12/16/2016 06:06:50: ##############################################################################
12/16/2016 06:06:50: #                                                                            #
12/16/2016 06:06:50: # speechTrain command (train action)                                         #
12/16/2016 06:06:50: #                                                                            #
12/16/2016 06:06:50: ##############################################################################

12/16/2016 06:06:50: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/16/2016 06:06:50: 
Model has 29 nodes. Using GPU 0.

12/16/2016 06:06:50: Training criterion:   ce = CrossEntropyWithSoftmax
12/16/2016 06:06:50: Evaluation criterion: err = ClassificationError

12/16/2016 06:06:50: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

12/16/2016 06:06:50: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/16/2016 06:06:50: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:50: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/16/2016 06:06:50: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:50: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/16/2016 06:06:50: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:50: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/16/2016 06:06:50: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/16/2016 06:06:50: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/16/2016 06:06:50: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/16/2016 06:06:51: Starting minibatch loop.
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.09347076 * 2560; err = 0.82734375 * 2560; time = 0.0251s; samplesPerSecond = 102134.5
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.57447586 * 2560; err = 0.64023438 * 2560; time = 0.0205s; samplesPerSecond = 124671.3
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03476105 * 2560; err = 0.54375000 * 2560; time = 0.0205s; samplesPerSecond = 124750.3
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.73747635 * 2560; err = 0.47617188 * 2560; time = 0.0205s; samplesPerSecond = 124574.2
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.55056915 * 2560; err = 0.43750000 * 2560; time = 0.0205s; samplesPerSecond = 124604.5
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.44497986 * 2560; err = 0.41054687 * 2560; time = 0.0206s; samplesPerSecond = 124073.1
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.36142731 * 2560; err = 0.40546875 * 2560; time = 0.0206s; samplesPerSecond = 124513.6
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.35946808 * 2560; err = 0.39531250 * 2560; time = 0.0205s; samplesPerSecond = 124780.7
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.34237213 * 2560; err = 0.39570312 * 2560; time = 0.0205s; samplesPerSecond = 124841.5
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.30687866 * 2560; err = 0.37929687 * 2560; time = 0.0205s; samplesPerSecond = 124640.9
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31363678 * 2560; err = 0.38750000 * 2560; time = 0.0206s; samplesPerSecond = 124489.4
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.24034119 * 2560; err = 0.37109375 * 2560; time = 0.0205s; samplesPerSecond = 124634.9
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.21518860 * 2560; err = 0.35937500 * 2560; time = 0.0206s; samplesPerSecond = 124543.9
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.24078827 * 2560; err = 0.36914063 * 2560; time = 0.0205s; samplesPerSecond = 124683.4
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.23589020 * 2560; err = 0.37265625 * 2560; time = 0.0206s; samplesPerSecond = 124568.1
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.20203857 * 2560; err = 0.35351563 * 2560; time = 0.0205s; samplesPerSecond = 124677.3
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.22040405 * 2560; err = 0.36328125 * 2560; time = 0.0205s; samplesPerSecond = 124610.6
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.25242310 * 2560; err = 0.38046875 * 2560; time = 0.0205s; samplesPerSecond = 124640.9
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.27484131 * 2560; err = 0.38554688 * 2560; time = 0.0205s; samplesPerSecond = 124786.7
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.22908630 * 2560; err = 0.38554688 * 2560; time = 0.0206s; samplesPerSecond = 124568.1
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.18030090 * 2560; err = 0.36093750 * 2560; time = 0.0205s; samplesPerSecond = 124689.5
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.19837036 * 2560; err = 0.36757812 * 2560; time = 0.0205s; samplesPerSecond = 124580.3
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.22071533 * 2560; err = 0.36406250 * 2560; time = 0.0206s; samplesPerSecond = 124434.9
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.19018860 * 2560; err = 0.35351563 * 2560; time = 0.0205s; samplesPerSecond = 124586.3
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17300720 * 2560; err = 0.35742188 * 2560; time = 0.0205s; samplesPerSecond = 124616.7
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.12558594 * 2560; err = 0.35351563 * 2560; time = 0.0205s; samplesPerSecond = 124780.7
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.19316711 * 2560; err = 0.35898438 * 2560; time = 0.0205s; samplesPerSecond = 124750.3
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.13930359 * 2560; err = 0.35195312 * 2560; time = 0.0206s; samplesPerSecond = 124519.7
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.12437134 * 2560; err = 0.33515625 * 2560; time = 0.0205s; samplesPerSecond = 124884.1
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.10540161 * 2560; err = 0.34101562 * 2560; time = 0.0205s; samplesPerSecond = 124707.7
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12473755 * 2560; err = 0.33515625 * 2560; time = 0.0205s; samplesPerSecond = 124713.8
12/16/2016 06:06:51:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.13026428 * 2560; err = 0.34765625 * 2560; time = 0.0205s; samplesPerSecond = 124634.9
12/16/2016 06:06:51: Finished Epoch[ 1 of 4]: [Training] ce = 1.41049786 * 81920; err = 0.40207520 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.80798s
12/16/2016 06:06:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

12/16/2016 06:06:51: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/16/2016 06:06:51: Starting minibatch loop.
12/16/2016 06:06:51:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.21424761 * 5120; err = 0.36523438 * 5120; time = 0.0351s; samplesPerSecond = 145844.0
12/16/2016 06:06:51:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.14997759 * 5120; err = 0.34570313 * 5120; time = 0.0298s; samplesPerSecond = 171599.0
12/16/2016 06:06:51:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.10502491 * 5120; err = 0.33886719 * 5120; time = 0.0299s; samplesPerSecond = 171220.3
12/16/2016 06:06:51:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10657425 * 5120; err = 0.34101562 * 5120; time = 0.0299s; samplesPerSecond = 171237.5
12/16/2016 06:06:51:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16255760 * 5120; err = 0.36328125 * 5120; time = 0.0299s; samplesPerSecond = 171375.0
12/16/2016 06:06:51:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.15796585 * 5120; err = 0.35898438 * 5120; time = 0.0298s; samplesPerSecond = 171794.8
12/16/2016 06:06:51:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.13883362 * 5120; err = 0.34492187 * 5120; time = 0.0298s; samplesPerSecond = 171581.8
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.10509262 * 5120; err = 0.34648438 * 5120; time = 0.0298s; samplesPerSecond = 171708.4
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.11047897 * 5120; err = 0.34062500 * 5120; time = 0.0298s; samplesPerSecond = 171840.9
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06133652 * 5120; err = 0.32734375 * 5120; time = 0.0298s; samplesPerSecond = 171535.8
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.10699844 * 5120; err = 0.33867188 * 5120; time = 0.0298s; samplesPerSecond = 171696.8
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.13975754 * 5120; err = 0.35292969 * 5120; time = 0.0298s; samplesPerSecond = 171875.5
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.04995117 * 5120; err = 0.32480469 * 5120; time = 0.0299s; samplesPerSecond = 171357.8
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.02763824 * 5120; err = 0.32285156 * 5120; time = 0.0299s; samplesPerSecond = 171524.3
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08706665 * 5120; err = 0.32988281 * 5120; time = 0.0300s; samplesPerSecond = 170905.9
12/16/2016 06:06:52:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06690369 * 5120; err = 0.32167969 * 5120; time = 0.0298s; samplesPerSecond = 171547.3
12/16/2016 06:06:52: Finished Epoch[ 2 of 4]: [Training] ce = 1.11190033 * 81920; err = 0.34145508 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.486349s
12/16/2016 06:06:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

12/16/2016 06:06:52: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

12/16/2016 06:06:52: Starting minibatch loop.
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.12241631 * 5120; err = 0.34179688 * 5120; time = 0.0308s; samplesPerSecond = 166320.2
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.08498535 * 5120; err = 0.33613281 * 5120; time = 0.0299s; samplesPerSecond = 171415.2
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.09316635 * 5120; err = 0.33828125 * 5120; time = 0.0298s; samplesPerSecond = 171599.0
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.10422935 * 5120; err = 0.33828125 * 5120; time = 0.0299s; samplesPerSecond = 171501.3
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07953568 * 5120; err = 0.33261719 * 5120; time = 0.0298s; samplesPerSecond = 171570.3
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.05399170 * 5120; err = 0.33085938 * 5120; time = 0.0298s; samplesPerSecond = 171587.5
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06956406 * 5120; err = 0.32539062 * 5120; time = 0.0299s; samplesPerSecond = 171512.8
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07985764 * 5120; err = 0.32792969 * 5120; time = 0.0298s; samplesPerSecond = 171731.4
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.05197220 * 5120; err = 0.32617188 * 5120; time = 0.0298s; samplesPerSecond = 171748.7
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.05977478 * 5120; err = 0.33046875 * 5120; time = 0.0298s; samplesPerSecond = 171679.6
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.04717255 * 5120; err = 0.32792969 * 5120; time = 0.0298s; samplesPerSecond = 171714.1
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.08563995 * 5120; err = 0.33964844 * 5120; time = 0.0298s; samplesPerSecond = 171673.8
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.10514679 * 5120; err = 0.32910156 * 5120; time = 0.0298s; samplesPerSecond = 171668.1
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.06171722 * 5120; err = 0.32109375 * 5120; time = 0.0298s; samplesPerSecond = 171645.0
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.05704346 * 5120; err = 0.33281250 * 5120; time = 0.0298s; samplesPerSecond = 171604.8
12/16/2016 06:06:52:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.04391479 * 5120; err = 0.32871094 * 5120; time = 0.0298s; samplesPerSecond = 171673.8
12/16/2016 06:06:52: Finished Epoch[ 3 of 4]: [Training] ce = 1.07500801 * 81920; err = 0.33170166 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.481206s
12/16/2016 06:06:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

12/16/2016 06:06:52: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

12/16/2016 06:06:52: Starting minibatch loop.
12/16/2016 06:06:52:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.03005266 * 5120; err = 0.32695313 * 5120; time = 0.0304s; samplesPerSecond = 168526.4
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.04017556 * 4926; err = 0.31303289 * 4926; time = 0.0681s; samplesPerSecond = 72370.9
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02174778 * 5120; err = 0.32285156 * 5120; time = 0.0298s; samplesPerSecond = 171587.5
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.01952095 * 5120; err = 0.31582031 * 5120; time = 0.0298s; samplesPerSecond = 171719.9
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.00513458 * 5120; err = 0.31972656 * 5120; time = 0.0298s; samplesPerSecond = 171530.0
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99812813 * 5120; err = 0.31367187 * 5120; time = 0.0298s; samplesPerSecond = 171587.5
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 0.99019432 * 5120; err = 0.30546875 * 5120; time = 0.0298s; samplesPerSecond = 171668.1
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.01111908 * 5120; err = 0.31445313 * 5120; time = 0.0298s; samplesPerSecond = 171708.4
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99833145 * 5120; err = 0.31289062 * 5120; time = 0.0298s; samplesPerSecond = 171633.5
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.96827850 * 5120; err = 0.31464844 * 5120; time = 0.0298s; samplesPerSecond = 171806.3
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 0.99143982 * 5120; err = 0.30781250 * 5120; time = 0.0298s; samplesPerSecond = 171570.3
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.00068130 * 5120; err = 0.31035156 * 5120; time = 0.0303s; samplesPerSecond = 169189.1
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00592957 * 5120; err = 0.31328125 * 5120; time = 0.0300s; samplesPerSecond = 170422.4
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.98450165 * 5120; err = 0.30976562 * 5120; time = 0.0300s; samplesPerSecond = 170535.9
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.93657532 * 5120; err = 0.29726562 * 5120; time = 0.0300s; samplesPerSecond = 170746.3
12/16/2016 06:06:53:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96798401 * 5120; err = 0.30292969 * 5120; time = 0.0300s; samplesPerSecond = 170643.9
12/16/2016 06:06:53: Finished Epoch[ 4 of 4]: [Training] ce = 0.99785318 * 81920; err = 0.31252441 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.522278s
12/16/2016 06:06:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech'

12/16/2016 06:06:53: Action "train" complete.


12/16/2016 06:06:53: ##############################################################################
12/16/2016 06:06:53: #                                                                            #
12/16/2016 06:06:53: # replaceCriterionNode command (edit action)                                 #
12/16/2016 06:06:53: #                                                                            #
12/16/2016 06:06:53: ##############################################################################


12/16/2016 06:06:53: Action "edit" complete.


12/16/2016 06:06:53: ##############################################################################
12/16/2016 06:06:53: #                                                                            #
12/16/2016 06:06:53: # sequenceTrain command (train action)                                       #
12/16/2016 06:06:53: #                                                                            #
12/16/2016 06:06:53: ##############################################################################

12/16/2016 06:06:53: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/model.overalltying', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list', 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/state.list
htkmlfreader: reading MLF file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu\TestData\CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
12/16/2016 06:06:54: 
Model has 29 nodes. Using GPU 0.

12/16/2016 06:06:54: Training criterion:   ce = SequenceWithSoftmax
12/16/2016 06:06:54: Evaluation criterion: err = ClassificationError

12/16/2016 06:06:54: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

12/16/2016 06:06:54: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/16/2016 06:06:54: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:54: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/16/2016 06:06:54: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:54: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/16/2016 06:06:54: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/16/2016 06:06:54: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/16/2016 06:06:54: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/16/2016 06:06:54: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-010
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

12/16/2016 06:06:54: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/16/2016 06:07:01: Starting minibatch loop.
dengamma value 1.013698
dengamma value 1.049159
dengamma value 1.070227
dengamma value 1.063804
dengamma value 1.059820
dengamma value 1.097746
dengamma value 0.963255
dengamma value 1.198104
dengamma value 1.017893
dengamma value 1.107183
dengamma value 1.035339
dengamma value 1.149233
dengamma value 1.049182
dengamma value 1.023314
dengamma value 1.106992
dengamma value 1.035802
dengamma value 1.124624
dengamma value 1.038131
dengamma value 1.057013
dengamma value 1.056830
dengamma value 0.998212
12/16/2016 06:07:03:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08307556 * 4628; err = 0.33318928 * 4628; time = 2.6015s; samplesPerSecond = 1779.0
dengamma value 1.097027
dengamma value 1.037025
dengamma value 1.112173
dengamma value 0.954260
dengamma value 1.120938
dengamma value 1.107617
dengamma value 1.063092
dengamma value 1.060568
dengamma value 0.980109
dengamma value 1.042329
dengamma value 1.002867
dengamma value 1.055401
dengamma value 1.040418
dengamma value 1.021522
dengamma value 1.148695
dengamma value 1.169876
dengamma value 1.140047
dengamma value 1.083306
dengamma value 1.104912
dengamma value 1.075253
dengamma value 1.083956
dengamma value 1.077059
12/16/2016 06:07:04:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08167187 * 5946; err = 0.31432896 * 5946; time = 0.9822s; samplesPerSecond = 6053.9
dengamma value 1.038795
dengamma value 1.104225
dengamma value 1.095914
dengamma value 1.130726
dengamma value 1.069469
dengamma value 1.056703
dengamma value 1.098395
dengamma value 1.104856
dengamma value 1.022483
dengamma value 1.076521
dengamma value 1.007273
dengamma value 1.074368
dengamma value 1.080310
dengamma value 1.121480
dengamma value 1.054229
dengamma value 1.065950
dengamma value 1.043711
dengamma value 0.984074
dengamma value 1.084396
dengamma value 1.113504
dengamma value 1.086690
dengamma value 1.075008
12/16/2016 06:07:05:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08283125 * 5916; err = 0.32724814 * 5916; time = 0.8769s; samplesPerSecond = 6746.6
dengamma value 1.023911
dengamma value 1.040957
dengamma value 1.038658
dengamma value 1.134274
dengamma value 1.101505
dengamma value 1.028362
dengamma value 1.083775
dengamma value 1.104205
dengamma value 1.100733
dengamma value 1.157921
dengamma value 1.046630
dengamma value 1.003405
dengamma value 1.106272
dengamma value 1.107699
dengamma value 0.952141
dengamma value 1.005500
dengamma value 1.071254
dengamma value 1.062009
dengamma value 1.047743
dengamma value 1.017346
dengamma value 1.090642
dengamma value 1.067565
12/16/2016 06:07:06:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.07967380 * 6386; err = 0.32759161 * 6386; time = 0.9339s; samplesPerSecond = 6837.9
dengamma value 1.043108
dengamma value 1.080916
dengamma value 1.071508
dengamma value 1.127803
dengamma value 1.078172
dengamma value 1.100926
dengamma value 1.086778
dengamma value 1.096610
dengamma value 1.169886
dengamma value 1.046452
dengamma value 1.080651
dengamma value 1.046261
dengamma value 1.088444
dengamma value 1.043683
dengamma value 1.107498
dengamma value 1.121672
dengamma value 1.046750
dengamma value 1.035661
dengamma value 1.048700
dengamma value 0.985445
dengamma value 1.105091
dengamma value 1.154226
dengamma value 1.054531
12/16/2016 06:07:07:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08091057 * 6734; err = 0.30264330 * 6734; time = 1.0119s; samplesPerSecond = 6654.6
dengamma value 1.086073
dengamma value 1.124065
dengamma value 1.073615
dengamma value 1.086503
dengamma value 1.035832
dengamma value 0.987107
dengamma value 1.062404
dengamma value 1.125456
dengamma value 1.082792
dengamma value 1.055782
dengamma value 1.090676
dengamma value 1.031398
dengamma value 1.077657
dengamma value 0.975112
dengamma value 1.101320
dengamma value 1.043464
dengamma value 1.033121
dengamma value 1.136664
dengamma value 1.067075
dengamma value 1.072709
dengamma value 1.127434
dengamma value 1.066778
dengamma value 1.079165
dengamma value 0.974364
12/16/2016 06:07:08:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08461941 * 6202; err = 0.31651080 * 6202; time = 0.9197s; samplesPerSecond = 6743.9
dengamma value 1.129934
dengamma value 1.106571
dengamma value 1.056297
dengamma value 1.059466
dengamma value 1.146020
dengamma value 1.025292
dengamma value 1.107965
dengamma value 1.093934
dengamma value 1.061969
dengamma value 1.098801
dengamma value 1.101506
dengamma value 1.077579
dengamma value 1.106306
dengamma value 1.004038
dengamma value 0.949963
dengamma value 1.123815
dengamma value 1.083327
dengamma value 1.027165
dengamma value 1.067223
dengamma value 1.042702
dengamma value 1.074382
dengamma value 1.093028
dengamma value 1.051964
dengamma value 1.014042
12/16/2016 06:07:09:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07926189 * 6362; err = 0.33024206 * 6362; time = 0.9717s; samplesPerSecond = 6547.0
dengamma value 1.077030
dengamma value 1.080405
dengamma value 1.118982
dengamma value 1.029288
dengamma value 1.058463
dengamma value 1.101013
dengamma value 1.020428
dengamma value 1.036320
dengamma value 1.020777
dengamma value 1.128641
dengamma value 1.121888
dengamma value 1.049921
dengamma value 1.061449
dengamma value 1.059581
dengamma value 1.054011
dengamma value 1.098880
dengamma value 1.116273
dengamma value 1.141112
dengamma value 1.049009
dengamma value 1.092923
dengamma value 1.067351
12/16/2016 06:07:10:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.07338959 * 5608; err = 0.32275321 * 5608; time = 0.8211s; samplesPerSecond = 6829.8
dengamma value 1.062212
dengamma value 1.042746
dengamma value 1.062760
dengamma value 1.009867
dengamma value 1.086363
dengamma value 1.026902
dengamma value 1.103406
dengamma value 0.992357
dengamma value 1.109645
dengamma value 1.097232
dengamma value 1.047754
dengamma value 1.119728
dengamma value 1.107015
dengamma value 1.038601
dengamma value 1.055615
dengamma value 1.020338
dengamma value 1.048647
dengamma value 1.028872
dengamma value 1.093726
dengamma value 1.076599
dengamma value 1.105503
dengamma value 1.042579
dengamma value 1.015710
12/16/2016 06:07:11:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08062542 * 6594; err = 0.33742796 * 6594; time = 1.0233s; samplesPerSecond = 6444.1
dengamma value 1.022639
dengamma value 0.879085
dengamma value 1.156954
dengamma value 1.011943
dengamma value 1.115340
dengamma value 1.039790
dengamma value 1.098528
dengamma value 1.100507
dengamma value 1.111651
dengamma value 1.107393
dengamma value 1.074092
dengamma value 1.061694
dengamma value 1.085015
dengamma value 1.078665
dengamma value 1.141901
dengamma value 1.031900
dengamma value 1.113112
dengamma value 1.130357
dengamma value 1.053180
dengamma value 1.065676
dengamma value 1.073630
dengamma value 1.004978
dengamma value 1.108612
12/16/2016 06:07:12:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.07932514 * 6364; err = 0.31741043 * 6364; time = 1.0369s; samplesPerSecond = 6137.6
dengamma value 1.060328
dengamma value 1.041925
dengamma value 0.985633
dengamma value 1.060947
dengamma value 1.051926
dengamma value 1.141933
dengamma value 1.132435
dengamma value 1.075780
dengamma value 1.046517
dengamma value 1.144617
dengamma value 1.074856
dengamma value 1.156399
dengamma value 1.092101
dengamma value 0.998989
dengamma value 1.113441
dengamma value 1.053138
dengamma value 1.155597
dengamma value 1.089154
dengamma value 1.139063
dengamma value 1.142676
dengamma value 1.084686
dengamma value 1.055062
dengamma value 1.042349
dengamma value 1.109849
dengamma value 1.045001
dengamma value 0.998186
dengamma value 1.005263
12/16/2016 06:07:13:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08483117 * 6536; err = 0.32053244 * 6536; time = 0.9812s; samplesPerSecond = 6661.4
dengamma value 1.084720
dengamma value 1.059186
dengamma value 1.046268
dengamma value 1.069014
dengamma value 1.096144
dengamma value 1.049244
dengamma value 1.085412
dengamma value 1.065760
dengamma value 1.089457
dengamma value 1.020782
dengamma value 1.080231
dengamma value 1.102623
dengamma value 1.029863
dengamma value 0.934754
dengamma value 1.106073
dengamma value 1.053426
dengamma value 1.067965
dengamma value 1.013588
dengamma value 1.040881
dengamma value 1.018005
dengamma value 1.032843
12/16/2016 06:07:14:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08267739 * 6208; err = 0.31846005 * 6208; time = 0.9858s; samplesPerSecond = 6297.2
dengamma value 1.085942
dengamma value 1.073564
dengamma value 1.106399
dengamma value 1.069899
dengamma value 0.944912
dengamma value 1.048471
dengamma value 1.074981
dengamma value 1.097235
dengamma value 1.084364
dengamma value 1.042913
dengamma value 1.060335
dengamma value 1.128005
dengamma value 1.024119
dengamma value 1.190238
dengamma value 1.027430
dengamma value 1.088637
dengamma value 1.082798
dengamma value 1.080262
dengamma value 1.069500
dengamma value 1.081476
dengamma value 1.143735
dengamma value 1.123673
12/16/2016 06:07:15:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08045379 * 6326; err = 0.29892507 * 6326; time = 0.9957s; samplesPerSecond = 6353.2
dengamma value 1.089143
dengamma value 1.070564
dengamma value 1.106279
dengamma value 1.137484
dengamma value 0.993643
dengamma value 1.028767
dengamma value 1.098955
12/16/2016 06:07:15: Finished Epoch[ 1 of 3]: [Training] ce = 0.08075110 * 81936; err = 0.31894405 * 81936; totalSamplesSeen = 81936; learningRatePerSample = 2e-006; epochTime=21.2828s
12/16/2016 06:07:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

12/16/2016 06:07:15: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81936), data subset 0 of 1, with 1 datapasses

12/16/2016 06:07:15: Starting minibatch loop.
dengamma value 1.145906
dengamma value 1.080357
dengamma value 1.149736
dengamma value 1.049997
dengamma value 1.111646
dengamma value 1.052975
dengamma value 1.089404
dengamma value 1.143738
dengamma value 1.043324
dengamma value 1.029783
dengamma value 1.016871
dengamma value 1.089215
dengamma value 1.076265
dengamma value 1.093923
dengamma value 1.044791
dengamma value 1.020125
dengamma value 1.056467
dengamma value 1.108409
dengamma value 1.057475
dengamma value 1.069001
dengamma value 1.081168
dengamma value 1.131012
dengamma value 1.035830
dengamma value 1.039459
12/16/2016 06:07:16:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08307970 * 6182; err = 0.30637334 * 6182; time = 1.0571s; samplesPerSecond = 5847.9
dengamma value 1.045155
dengamma value 0.998067
dengamma value 1.289365
dengamma value 1.033868
dengamma value 1.092783
dengamma value 1.119573
dengamma value 1.098048
dengamma value 1.035654
dengamma value 1.043805
dengamma value 1.086280
dengamma value 1.037740
dengamma value 1.117945
dengamma value 1.134873
dengamma value 1.028858
dengamma value 1.031485
dengamma value 1.084655
dengamma value 1.026738
dengamma value 1.111964
dengamma value 1.038040
dengamma value 1.021737
dengamma value 1.050137
dengamma value 1.113166
12/16/2016 06:07:17:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08400597 * 5736; err = 0.28626220 * 5736; time = 0.9254s; samplesPerSecond = 6198.4
dengamma value 1.008289
dengamma value 1.109700
dengamma value 1.077175
dengamma value 1.081680
dengamma value 1.055023
dengamma value 1.165126
dengamma value 1.021026
dengamma value 1.129057
dengamma value 1.050032
dengamma value 1.045817
dengamma value 1.042651
dengamma value 1.053389
dengamma value 1.105091
dengamma value 1.175931
dengamma value 1.065119
dengamma value 1.168127
dengamma value 1.104079
dengamma value 1.069164
dengamma value 1.070395
dengamma value 1.097639
dengamma value 0.974669
dengamma value 0.970781
dengamma value 1.053570
12/16/2016 06:07:18:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08036293 * 6244; err = 0.31165919 * 6244; time = 0.9694s; samplesPerSecond = 6441.1
dengamma value 1.102059
dengamma value 1.111039
dengamma value 1.076042
dengamma value 1.054273
dengamma value 1.155097
dengamma value 1.083462
dengamma value 1.075422
dengamma value 1.044182
dengamma value 1.062736
dengamma value 1.014664
dengamma value 1.088157
dengamma value 1.126523
dengamma value 1.118790
dengamma value 1.129303
dengamma value 1.013076
dengamma value 1.129322
dengamma value 1.013985
dengamma value 1.015005
dengamma value 1.075354
dengamma value 1.090989
dengamma value 1.027171
dengamma value 1.061360
dengamma value 1.170461
dengamma value 1.074235
dengamma value 1.048625
12/16/2016 06:07:19:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08498230 * 6280; err = 0.31162420 * 6280; time = 0.9329s; samplesPerSecond = 6731.4
dengamma value 1.011474
dengamma value 1.080414
dengamma value 1.075262
dengamma value 1.084531
dengamma value 1.061243
dengamma value 1.066724
dengamma value 1.065026
dengamma value 1.051012
dengamma value 1.107365
dengamma value 1.068085
dengamma value 1.066638
dengamma value 1.040850
dengamma value 1.114224
dengamma value 1.055724
dengamma value 1.102578
dengamma value 1.084468
dengamma value 1.142223
dengamma value 1.086677
dengamma value 1.089740
dengamma value 1.059384
dengamma value 1.101177
dengamma value 1.080403
dengamma value 1.100520
dengamma value 1.089005
dengamma value 1.089593
dengamma value 1.101075
12/16/2016 06:07:20:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.07673638 * 7428; err = 0.30358104 * 7428; time = 1.1960s; samplesPerSecond = 6210.6
dengamma value 1.133177
dengamma value 1.082510
dengamma value 1.043806
dengamma value 1.125152
dengamma value 1.049063
dengamma value 1.033853
dengamma value 1.038948
dengamma value 1.086023
dengamma value 1.061776
dengamma value 1.062581
dengamma value 1.035546
dengamma value 1.050793
dengamma value 1.028746
dengamma value 1.149934
dengamma value 1.090942
dengamma value 1.076455
dengamma value 1.086142
dengamma value 0.975598
dengamma value 1.051069
dengamma value 1.069312
dengamma value 1.117282
dengamma value 1.016940
dengamma value 1.060124
12/16/2016 06:07:21:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08035019 * 6994; err = 0.32313411 * 6994; time = 1.0097s; samplesPerSecond = 6927.0
dengamma value 1.115350
dengamma value 1.076818
dengamma value 1.173008
dengamma value 1.015323
dengamma value 1.050525
dengamma value 1.126346
dengamma value 0.973230
dengamma value 1.137645
dengamma value 1.171155
dengamma value 1.064698
dengamma value 1.150983
dengamma value 1.108554
dengamma value 1.056138
dengamma value 1.025348
dengamma value 1.074977
dengamma value 1.081217
dengamma value 1.044567
dengamma value 1.035260
dengamma value 1.089761
dengamma value 1.084391
dengamma value 1.062234
dengamma value 1.143951
dengamma value 1.077124
dengamma value 1.090446
12/16/2016 06:07:22:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07649934 * 6572; err = 0.30523433 * 6572; time = 1.0410s; samplesPerSecond = 6313.0
dengamma value 1.082757
dengamma value 1.013328
dengamma value 1.079252
dengamma value 1.087431
dengamma value 1.068285
dengamma value 1.115707
dengamma value 1.189853
dengamma value 1.069129
dengamma value 1.066429
dengamma value 1.059628
dengamma value 0.998192
dengamma value 1.041181
dengamma value 1.015502
dengamma value 1.167340
dengamma value 1.081678
dengamma value 0.936377
dengamma value 1.006003
dengamma value 1.036481
dengamma value 1.072469
dengamma value 1.077091
dengamma value 1.209142
dengamma value 1.011108
12/16/2016 06:07:23:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08788677 * 5506; err = 0.33290955 * 5506; time = 0.8312s; samplesPerSecond = 6624.4
dengamma value 1.000503
dengamma value 1.068714
dengamma value 1.009847
dengamma value 1.077441
dengamma value 1.118232
dengamma value 1.125831
dengamma value 1.127592
dengamma value 1.076902
dengamma value 1.037190
dengamma value 1.010546
dengamma value 1.090102
dengamma value 0.957581
dengamma value 1.070256
dengamma value 1.028928
dengamma value 1.065352
dengamma value 1.114618
dengamma value 1.116112
dengamma value 1.081327
dengamma value 1.098738
dengamma value 1.003801
dengamma value 0.990440
12/16/2016 06:07:24:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08560747 * 5628; err = 0.33742004 * 5628; time = 0.8566s; samplesPerSecond = 6570.4
dengamma value 1.028531
dengamma value 1.120517
dengamma value 1.071053
dengamma value 1.092126
dengamma value 1.081780
dengamma value 0.980315
dengamma value 1.033717
dengamma value 0.999283
dengamma value 1.100157
dengamma value 1.052575
dengamma value 1.165893
dengamma value 1.089106
dengamma value 1.071835
dengamma value 1.069244
dengamma value 1.016049
dengamma value 1.036170
dengamma value 1.035570
dengamma value 1.055093
dengamma value 1.052065
dengamma value 1.133057
dengamma value 1.017714
dengamma value 1.028762
dengamma value 1.050858
dengamma value 0.987378
12/16/2016 06:07:25:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08145158 * 6032; err = 0.33007294 * 6032; time = 0.8906s; samplesPerSecond = 6772.8
dengamma value 1.032495
dengamma value 1.055208
dengamma value 1.064087
dengamma value 1.088079
dengamma value 1.068233
dengamma value 1.113858
dengamma value 1.082619
dengamma value 0.959145
dengamma value 1.121953
dengamma value 1.132174
dengamma value 1.031471
dengamma value 0.965017
dengamma value 1.053959
dengamma value 1.138541
dengamma value 1.080704
dengamma value 0.992228
dengamma value 1.145745
dengamma value 1.045457
dengamma value 1.103696
dengamma value 1.019998
12/16/2016 06:07:26:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08826576 * 4790; err = 0.33340292 * 4790; time = 0.7534s; samplesPerSecond = 6358.1
dengamma value 1.012768
dengamma value 0.962347
dengamma value 1.051301
dengamma value 1.064123
dengamma value 1.073205
dengamma value 1.014143
dengamma value 1.007877
dengamma value 1.089876
dengamma value 1.065116
dengamma value 0.956802
dengamma value 1.126392
dengamma value 1.054480
dengamma value 1.078638
dengamma value 1.012063
dengamma value 1.131434
dengamma value 1.064807
dengamma value 1.124030
dengamma value 1.167600
dengamma value 0.958289
dengamma value 1.141690
dengamma value 1.031972
dengamma value 1.040617
12/16/2016 06:07:26:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08503876 * 5986; err = 0.34597394 * 5986; time = 0.8857s; samplesPerSecond = 6758.2
dengamma value 1.020285
dengamma value 1.008043
dengamma value 1.051871
dengamma value 1.085856
dengamma value 1.025729
dengamma value 1.210589
dengamma value 1.099521
dengamma value 1.116068
dengamma value 1.071087
dengamma value 1.075062
dengamma value 1.094922
dengamma value 1.084342
dengamma value 1.003141
dengamma value 0.991373
dengamma value 1.028755
dengamma value 1.079003
dengamma value 1.048411
dengamma value 1.047721
dengamma value 1.115266
dengamma value 1.043912
dengamma value 1.103542
dengamma value 1.050581
dengamma value 1.089208
dengamma value 0.995582
12/16/2016 06:07:28:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08579078 * 7022; err = 0.31500997 * 7022; time = 1.0279s; samplesPerSecond = 6831.4
dengamma value 1.027157
dengamma value 1.093782
dengamma value 1.179593
dengamma value 1.072612
dengamma value 1.045802
dengamma value 1.077005
dengamma value 1.005874
dengamma value 1.076960
dengamma value 1.076960
12/16/2016 06:07:28: Finished Epoch[ 2 of 3]: [Training] ce = 0.08278591 * 82462; err = 0.31819505 * 82462; totalSamplesSeen = 164398; learningRatePerSample = 2e-006; epochTime=12.7002s
12/16/2016 06:07:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

12/16/2016 06:07:28: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 164102), data subset 0 of 1, with 1 datapasses

12/16/2016 06:07:28: Starting minibatch loop.
dengamma value 1.094257
dengamma value 1.102062
dengamma value 1.081177
dengamma value 1.100395
dengamma value 1.061081
dengamma value 1.063386
dengamma value 1.150884
dengamma value 1.034091
dengamma value 1.115455
dengamma value 0.982793
dengamma value 1.111336
dengamma value 1.074570
dengamma value 1.065254
dengamma value 1.096414
dengamma value 1.071166
dengamma value 1.058043
dengamma value 1.100203
dengamma value 1.007771
dengamma value 1.091540
dengamma value 1.091436
dengamma value 1.045764
dengamma value 1.063837
dengamma value 1.036036
dengamma value 1.027664
12/16/2016 06:07:29:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08356751 * 6292; err = 0.29624921 * 6292; time = 0.9429s; samplesPerSecond = 6673.0
dengamma value 1.159272
dengamma value 1.028950
dengamma value 0.984374
dengamma value 1.092846
dengamma value 1.074898
dengamma value 1.023272
dengamma value 1.043823
dengamma value 1.132337
dengamma value 1.036878
dengamma value 0.975124
dengamma value 0.953517
dengamma value 1.095065
dengamma value 1.058997
dengamma value 1.062142
dengamma value 1.025603
dengamma value 1.066708
dengamma value 1.016941
dengamma value 1.071405
dengamma value 1.104881
dengamma value 1.030151
dengamma value 1.062236
dengamma value 1.024593
12/16/2016 06:07:30:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.07963704 * 6596; err = 0.32625834 * 6596; time = 1.0153s; samplesPerSecond = 6496.6
dengamma value 1.077953
dengamma value 1.000460
dengamma value 1.098812
dengamma value 1.108836
dengamma value 1.064734
dengamma value 1.157504
dengamma value 1.031443
dengamma value 1.083789
dengamma value 1.049388
dengamma value 1.058531
dengamma value 1.099133
dengamma value 1.058104
dengamma value 1.020120
dengamma value 1.026473
dengamma value 1.121934
dengamma value 0.953552
dengamma value 1.052115
dengamma value 1.028406
dengamma value 1.023963
dengamma value 1.172603
dengamma value 1.073595
dengamma value 1.194452
12/16/2016 06:07:31:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.08627499 * 5666; err = 0.30321214 * 5666; time = 0.8959s; samplesPerSecond = 6324.0
dengamma value 1.125180
dengamma value 1.021984
dengamma value 1.056525
dengamma value 1.086749
dengamma value 1.077339
dengamma value 1.075381
dengamma value 1.100065
dengamma value 1.069280
dengamma value 1.089559
dengamma value 1.072618
dengamma value 1.098640
dengamma value 1.048133
dengamma value 1.000392
dengamma value 1.134041
dengamma value 1.118823
dengamma value 1.037378
dengamma value 1.086336
dengamma value 1.038469
dengamma value 1.088293
dengamma value 1.033011
dengamma value 1.083628
dengamma value 1.026360
12/16/2016 06:07:32:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08080075 * 6626; err = 0.28267431 * 6626; time = 1.0521s; samplesPerSecond = 6298.0
dengamma value 1.088573
dengamma value 1.044449
dengamma value 1.027173
dengamma value 1.090129
dengamma value 1.120368
dengamma value 1.147278
dengamma value 1.083638
dengamma value 1.092870
dengamma value 1.025071
dengamma value 1.081031
dengamma value 1.141421
dengamma value 1.073277
dengamma value 1.039767
dengamma value 1.062510
dengamma value 1.026026
dengamma value 1.059701
dengamma value 1.083481
dengamma value 1.060832
dengamma value 1.098279
dengamma value 1.100028
dengamma value 1.065087
dengamma value 1.079258
dengamma value 1.060304
dengamma value 1.047367
12/16/2016 06:07:33:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08112687 * 5652; err = 0.30856334 * 5652; time = 0.9395s; samplesPerSecond = 6015.9
dengamma value 1.091380
dengamma value 1.036402
dengamma value 0.996221
dengamma value 1.048045
dengamma value 1.027794
dengamma value 1.149046
dengamma value 1.041971
dengamma value 1.037577
dengamma value 1.101327
dengamma value 1.019907
dengamma value 1.021820
dengamma value 1.051421
dengamma value 1.070772
dengamma value 1.065110
dengamma value 1.083851
dengamma value 1.036018
dengamma value 1.004711
dengamma value 1.034939
dengamma value 1.095362
dengamma value 1.039635
dengamma value 1.052324
12/16/2016 06:07:34:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08572660 * 6588; err = 0.34699454 * 6588; time = 1.0129s; samplesPerSecond = 6504.3
dengamma value 1.067064
dengamma value 1.092245
dengamma value 1.035354
dengamma value 0.981503
dengamma value 1.148080
dengamma value 1.063695
dengamma value 1.073133
dengamma value 1.033304
dengamma value 1.001487
dengamma value 1.092797
dengamma value 1.081619
dengamma value 1.027799
dengamma value 1.031052
dengamma value 1.115343
dengamma value 1.135718
dengamma value 1.048797
dengamma value 1.040561
dengamma value 1.072954
dengamma value 1.103663
dengamma value 1.053970
dengamma value 1.023996
12/16/2016 06:07:35:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08608905 * 6328; err = 0.30420354 * 6328; time = 1.0197s; samplesPerSecond = 6205.6
dengamma value 1.064634
dengamma value 1.094232
dengamma value 1.007796
dengamma value 1.096441
dengamma value 1.118480
dengamma value 1.067216
dengamma value 1.081035
dengamma value 1.109912
dengamma value 1.051612
dengamma value 0.985897
dengamma value 1.056359
dengamma value 1.029954
dengamma value 1.015264
dengamma value 1.096703
dengamma value 1.047377
dengamma value 1.082201
dengamma value 1.071790
dengamma value 1.189235
dengamma value 1.088779
dengamma value 1.061259
dengamma value 1.062058
dengamma value 1.106991
dengamma value 1.030827
dengamma value 1.096883
dengamma value 1.072904
12/16/2016 06:07:36:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08242390 * 6980; err = 0.29355301 * 6980; time = 1.0752s; samplesPerSecond = 6491.6
dengamma value 1.052002
dengamma value 0.966952
dengamma value 0.951479
dengamma value 1.126456
dengamma value 1.121790
dengamma value 1.021532
dengamma value 1.264478
dengamma value 1.101973
dengamma value 1.064094
dengamma value 1.111367
dengamma value 0.972630
dengamma value 1.069454
dengamma value 1.056461
dengamma value 1.009102
dengamma value 1.121732
dengamma value 1.058861
dengamma value 1.002585
dengamma value 1.268169
dengamma value 1.190584
dengamma value 1.043439
dengamma value 1.124923
dengamma value 0.976121
dengamma value 1.018061
12/16/2016 06:07:37:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.07960260 * 6774; err = 0.31133747 * 6774; time = 0.9468s; samplesPerSecond = 7154.7
dengamma value 0.982952
dengamma value 1.077285
dengamma value 1.117000
dengamma value 1.021331
dengamma value 0.931373
dengamma value 1.067899
dengamma value 1.038277
dengamma value 1.053572
dengamma value 0.931092
dengamma value 1.067171
dengamma value 1.007461
dengamma value 1.083722
dengamma value 1.020488
dengamma value 0.977499
dengamma value 1.063165
dengamma value 0.932086
dengamma value 1.046781
dengamma value 1.006671
dengamma value 1.068047
dengamma value 1.064650
dengamma value 1.093474
dengamma value 1.083852
12/16/2016 06:07:38:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08893782 * 6146; err = 0.35421412 * 6146; time = 0.9711s; samplesPerSecond = 6328.6
dengamma value 1.014958
dengamma value 1.122368
dengamma value 1.052796
dengamma value 1.138400
dengamma value 0.955175
dengamma value 1.079987
dengamma value 1.069644
dengamma value 1.146236
dengamma value 1.098763
dengamma value 1.085548
dengamma value 1.032241
dengamma value 1.014208
dengamma value 1.170872
dengamma value 1.058026
dengamma value 1.112741
dengamma value 1.060730
dengamma value 1.086144
dengamma value 1.098638
dengamma value 1.005505
dengamma value 1.139421
dengamma value 1.064179
dengamma value 1.076283
12/16/2016 06:07:39:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08227812 * 5366; err = 0.30711890 * 5366; time = 0.8717s; samplesPerSecond = 6155.8
dengamma value 1.056133
dengamma value 1.044819
dengamma value 1.088580
dengamma value 1.060605
dengamma value 1.061721
dengamma value 1.003517
dengamma value 1.124267
dengamma value 1.064163
dengamma value 1.015164
dengamma value 1.024272
dengamma value 1.019151
dengamma value 1.061932
dengamma value 1.055812
dengamma value 1.035816
dengamma value 1.091788
dengamma value 1.083389
dengamma value 1.103485
dengamma value 1.102843
dengamma value 1.057135
dengamma value 0.984333
dengamma value 1.028692
dengamma value 1.119783
dengamma value 1.146684
dengamma value 1.090720
dengamma value 1.084957
12/16/2016 06:07:40:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08069641 * 6220; err = 0.31977492 * 6220; time = 0.9383s; samplesPerSecond = 6628.8
dengamma value 1.076388
dengamma value 1.048437
dengamma value 1.106987
dengamma value 1.077891
dengamma value 1.030010
dengamma value 1.063213
dengamma value 1.070726
dengamma value 1.103263
dengamma value 1.081655
dengamma value 1.080728
dengamma value 1.041698
dengamma value 1.062252
dengamma value 1.029934
dengamma value 1.089464
dengamma value 1.144604
dengamma value 1.108966
dengamma value 1.054422
dengamma value 0.988430
dengamma value 1.080805
dengamma value 1.032188
dengamma value 1.072561
dengamma value 1.092934
dengamma value 1.131961
12/16/2016 06:07:41:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08462203 * 6564; err = 0.29875076 * 6564; time = 0.9916s; samplesPerSecond = 6619.6
12/16/2016 06:07:41: Finished Epoch[ 3 of 3]: [Training] ce = 0.08317359 * 81798; err = 0.31168244 * 81798; totalSamplesSeen = 246196; learningRatePerSample = 2e-006; epochTime=12.6753s
12/16/2016 06:07:41: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161216060627.127385\Speech\DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

12/16/2016 06:07:41: Action "train" complete.

12/16/2016 06:07:41: __COMPLETED__