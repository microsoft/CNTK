CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining OutputDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta6.0+ (HEAD bf0ca9, Dec 20 2016 11:40:12) on localhost at 2016/12/20 16:01:44

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining  OutputDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
12/20/2016 16:01:46: -------------------------------------------------------------------
12/20/2016 16:01:46: Build info: 

12/20/2016 16:01:46: 		Built time: Dec 20 2016 11:40:12
12/20/2016 16:01:46: 		Last modified date: Tue Dec 20 11:38:27 2016
12/20/2016 16:01:46: 		Build type: release
12/20/2016 16:01:46: 		Build target: GPU
12/20/2016 16:01:46: 		With ASGD: yes
12/20/2016 16:01:46: 		Math lib: mkl
12/20/2016 16:01:46: 		CUDA_PATH: /usr/local/cuda-8.0
12/20/2016 16:01:46: 		CUB_PATH: /usr/local/cub-1.4.1
12/20/2016 16:01:46: 		CUDNN_PATH: /usr/local
12/20/2016 16:01:46: 		Build Branch: HEAD
12/20/2016 16:01:46: 		Build SHA1: bf0ca998cd077aa28c04371fd2093770e819ffd0
12/20/2016 16:01:46: 		Built by Source/CNTK/buildinfo.h$$0 on b4b39bc07965
12/20/2016 16:01:46: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
12/20/2016 16:01:46: -------------------------------------------------------------------
12/20/2016 16:01:47: -------------------------------------------------------------------
12/20/2016 16:01:47: GPU info:

12/20/2016 16:01:47: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:47: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:47: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:47: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
12/20/2016 16:01:47: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:precision=float
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
        labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
12/20/2016 16:01:47: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
12/20/2016 16:01:47: precision = "float"

12/20/2016 16:01:47: ##############################################################################
12/20/2016 16:01:47: #                                                                            #
12/20/2016 16:01:47: # dptPre1 command (train action)                                             #
12/20/2016 16:01:47: #                                                                            #
12/20/2016 16:01:47: ##############################################################################

12/20/2016 16:01:47: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/20/2016 16:01:47: 
Model has 19 nodes. Using GPU 0.

12/20/2016 16:01:47: Training criterion:   ce = CrossEntropyWithSoftmax
12/20/2016 16:01:47: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }


12/20/2016 16:01:47: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/20/2016 16:01:47: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/20/2016 16:01:47: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:47: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/20/2016 16:01:47: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/20/2016 16:01:47: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/20/2016 16:01:47: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/20/2016 16:01:47: Starting minibatch loop.
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.77545433 * 2560; err = 0.83984375 * 2560; time = 0.1500s; samplesPerSecond = 17067.9
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.92129173 * 2560; err = 0.69921875 * 2560; time = 0.0092s; samplesPerSecond = 278533.3
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.54243622 * 2560; err = 0.64882812 * 2560; time = 0.0090s; samplesPerSecond = 283656.5
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.20117416 * 2560; err = 0.60156250 * 2560; time = 0.0090s; samplesPerSecond = 285746.2
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.98474121 * 2560; err = 0.55273438 * 2560; time = 0.0089s; samplesPerSecond = 286706.2
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87129364 * 2560; err = 0.51562500 * 2560; time = 0.0089s; samplesPerSecond = 288971.7
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.83400879 * 2560; err = 0.52812500 * 2560; time = 0.0089s; samplesPerSecond = 286963.3
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71646271 * 2560; err = 0.49335937 * 2560; time = 0.0090s; samplesPerSecond = 283908.2
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.66541901 * 2560; err = 0.46328125 * 2560; time = 0.0093s; samplesPerSecond = 275624.5
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.57725983 * 2560; err = 0.46054688 * 2560; time = 0.0091s; samplesPerSecond = 280855.7
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.61621094 * 2560; err = 0.45390625 * 2560; time = 0.0088s; samplesPerSecond = 291771.1
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.56063995 * 2560; err = 0.44140625 * 2560; time = 0.0087s; samplesPerSecond = 293342.5
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.52853241 * 2560; err = 0.44492188 * 2560; time = 0.0090s; samplesPerSecond = 283091.9
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53460999 * 2560; err = 0.46210937 * 2560; time = 0.0090s; samplesPerSecond = 285969.6
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46377869 * 2560; err = 0.44140625 * 2560; time = 0.0090s; samplesPerSecond = 283248.5
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43344116 * 2560; err = 0.42617187 * 2560; time = 0.0091s; samplesPerSecond = 282311.4
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.43215027 * 2560; err = 0.42148438 * 2560; time = 0.0090s; samplesPerSecond = 284412.8
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.37987366 * 2560; err = 0.41250000 * 2560; time = 0.0089s; samplesPerSecond = 286481.6
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35841980 * 2560; err = 0.40039062 * 2560; time = 0.0091s; samplesPerSecond = 282685.5
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.44842224 * 2560; err = 0.42656250 * 2560; time = 0.0090s; samplesPerSecond = 284191.8
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.43927917 * 2560; err = 0.42539063 * 2560; time = 0.0090s; samplesPerSecond = 284286.5
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.41734009 * 2560; err = 0.42539063 * 2560; time = 0.0089s; samplesPerSecond = 286193.4
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.33211670 * 2560; err = 0.40468750 * 2560; time = 0.0089s; samplesPerSecond = 287253.1
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36109009 * 2560; err = 0.40429688 * 2560; time = 0.0090s; samplesPerSecond = 285395.8
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.30958252 * 2560; err = 0.39804688 * 2560; time = 0.0090s; samplesPerSecond = 284507.7
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25348511 * 2560; err = 0.36992188 * 2560; time = 0.0090s; samplesPerSecond = 285554.9
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.30338745 * 2560; err = 0.39570312 * 2560; time = 0.0091s; samplesPerSecond = 281783.2
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36117859 * 2560; err = 0.40859375 * 2560; time = 0.0089s; samplesPerSecond = 286225.4
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.29568787 * 2560; err = 0.39531250 * 2560; time = 0.0089s; samplesPerSecond = 287866.9
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.35455017 * 2560; err = 0.40859375 * 2560; time = 0.0090s; samplesPerSecond = 284792.5
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.32246399 * 2560; err = 0.39921875 * 2560; time = 0.0090s; samplesPerSecond = 284381.2
12/20/2016 16:01:47:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.27023926 * 2560; err = 0.38242188 * 2560; time = 0.0091s; samplesPerSecond = 282404.9
12/20/2016 16:01:47: Finished Epoch[ 1 of 2]: [Training] ce = 1.65206318 * 81920; err = 0.46723633 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.516067s
12/20/2016 16:01:47: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech.1'

12/20/2016 16:01:47: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:47: Starting minibatch loop.
12/20/2016 16:01:47:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.24553871 * 2560; err = 0.38984375 * 2560; time = 0.0104s; samplesPerSecond = 245375.3
12/20/2016 16:01:47:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23801517 * 2560; err = 0.36718750 * 2560; time = 0.0089s; samplesPerSecond = 287059.9
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.26358624 * 2560; err = 0.39218750 * 2560; time = 0.0087s; samplesPerSecond = 293915.0
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.26325531 * 2560; err = 0.38203125 * 2560; time = 0.0087s; samplesPerSecond = 295373.3
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.27975998 * 2560; err = 0.36562500 * 2560; time = 0.0086s; samplesPerSecond = 298646.8
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18315849 * 2560; err = 0.35195312 * 2560; time = 0.0086s; samplesPerSecond = 298298.8
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.19740906 * 2560; err = 0.37070313 * 2560; time = 0.0087s; samplesPerSecond = 294117.6
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.23275757 * 2560; err = 0.36835937 * 2560; time = 0.0090s; samplesPerSecond = 283782.3
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.27090912 * 2560; err = 0.38945313 * 2560; time = 0.0091s; samplesPerSecond = 281566.2
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.25143051 * 2560; err = 0.37500000 * 2560; time = 0.0091s; samplesPerSecond = 280486.5
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.21462936 * 2560; err = 0.37187500 * 2560; time = 0.0090s; samplesPerSecond = 285205.0
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19433441 * 2560; err = 0.36796875 * 2560; time = 0.0090s; samplesPerSecond = 283719.4
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16462097 * 2560; err = 0.36171875 * 2560; time = 0.0090s; samplesPerSecond = 284412.8
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16609802 * 2560; err = 0.36484375 * 2560; time = 0.0090s; samplesPerSecond = 283625.1
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.14834595 * 2560; err = 0.34492187 * 2560; time = 0.0090s; samplesPerSecond = 284318.1
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.11703033 * 2560; err = 0.34804687 * 2560; time = 0.0091s; samplesPerSecond = 282436.0
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.17735901 * 2560; err = 0.35703125 * 2560; time = 0.0091s; samplesPerSecond = 282404.9
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13435669 * 2560; err = 0.35664062 * 2560; time = 0.0091s; samplesPerSecond = 281938.3
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14561310 * 2560; err = 0.35039063 * 2560; time = 0.0091s; samplesPerSecond = 281721.1
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11020966 * 2560; err = 0.33281250 * 2560; time = 0.0090s; samplesPerSecond = 283625.1
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.16456146 * 2560; err = 0.35078125 * 2560; time = 0.0090s; samplesPerSecond = 285046.2
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.14552612 * 2560; err = 0.35742188 * 2560; time = 0.0089s; samplesPerSecond = 289102.2
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09541931 * 2560; err = 0.34492187 * 2560; time = 0.0086s; samplesPerSecond = 296536.5
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12883606 * 2560; err = 0.34218750 * 2560; time = 0.0086s; samplesPerSecond = 297951.6
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.08879089 * 2560; err = 0.33867188 * 2560; time = 0.0087s; samplesPerSecond = 294591.5
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08555603 * 2560; err = 0.32695313 * 2560; time = 0.0087s; samplesPerSecond = 294761.1
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.12885132 * 2560; err = 0.34492187 * 2560; time = 0.0086s; samplesPerSecond = 297052.7
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.12917175 * 2560; err = 0.34921875 * 2560; time = 0.0085s; samplesPerSecond = 301070.2
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.12189331 * 2560; err = 0.34570312 * 2560; time = 0.0086s; samplesPerSecond = 297121.6
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08549500 * 2560; err = 0.32773438 * 2560; time = 0.0088s; samplesPerSecond = 291704.6
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08267212 * 2560; err = 0.34023437 * 2560; time = 0.0086s; samplesPerSecond = 297294.2
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07620239 * 2560; err = 0.32578125 * 2560; time = 0.0082s; samplesPerSecond = 313687.0
12/20/2016 16:01:48: Finished Epoch[ 2 of 2]: [Training] ce = 1.16660604 * 81920; err = 0.35634766 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.287288s
12/20/2016 16:01:48: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech'

12/20/2016 16:01:48: Action "train" complete.


12/20/2016 16:01:48: ##############################################################################
12/20/2016 16:01:48: #                                                                            #
12/20/2016 16:01:48: # addLayer2 command (edit action)                                            #
12/20/2016 16:01:48: #                                                                            #
12/20/2016 16:01:48: ##############################################################################


12/20/2016 16:01:48: Action "edit" complete.


12/20/2016 16:01:48: ##############################################################################
12/20/2016 16:01:48: #                                                                            #
12/20/2016 16:01:48: # dptPre2 command (train action)                                             #
12/20/2016 16:01:48: #                                                                            #
12/20/2016 16:01:48: ##############################################################################

12/20/2016 16:01:48: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/20/2016 16:01:48: 
Model has 24 nodes. Using GPU 0.

12/20/2016 16:01:48: Training criterion:   ce = CrossEntropyWithSoftmax
12/20/2016 16:01:48: Evaluation criterion: err = ClassificationError

12/20/2016 16:01:48: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/20/2016 16:01:48: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/20/2016 16:01:48: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:48: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:48: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:48: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/20/2016 16:01:48: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/20/2016 16:01:48: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/20/2016 16:01:48: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/20/2016 16:01:48: Starting minibatch loop.
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.95234604 * 2560; err = 0.81796875 * 2560; time = 0.0135s; samplesPerSecond = 189826.5
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.60234833 * 2560; err = 0.63789063 * 2560; time = 0.0104s; samplesPerSecond = 245445.8
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.15345840 * 2560; err = 0.57734375 * 2560; time = 0.0104s; samplesPerSecond = 246889.8
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.80804749 * 2560; err = 0.50703125 * 2560; time = 0.0103s; samplesPerSecond = 248954.6
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.62714386 * 2560; err = 0.47343750 * 2560; time = 0.0103s; samplesPerSecond = 248302.6
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.58302765 * 2560; err = 0.45625000 * 2560; time = 0.0103s; samplesPerSecond = 247702.0
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57416840 * 2560; err = 0.46406250 * 2560; time = 0.0104s; samplesPerSecond = 245799.3
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.49049683 * 2560; err = 0.44609375 * 2560; time = 0.0104s; samplesPerSecond = 246699.4
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.43992004 * 2560; err = 0.41835937 * 2560; time = 0.0103s; samplesPerSecond = 247869.9
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.39899445 * 2560; err = 0.41093750 * 2560; time = 0.0104s; samplesPerSecond = 247199.7
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41018677 * 2560; err = 0.40273437 * 2560; time = 0.0117s; samplesPerSecond = 218299.7
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.35843353 * 2560; err = 0.39804688 * 2560; time = 0.0102s; samplesPerSecond = 251621.8
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.32144775 * 2560; err = 0.39375000 * 2560; time = 0.0101s; samplesPerSecond = 253339.9
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33142242 * 2560; err = 0.40546875 * 2560; time = 0.0100s; samplesPerSecond = 254827.8
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.27800751 * 2560; err = 0.37812500 * 2560; time = 0.0101s; samplesPerSecond = 254018.7
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28858032 * 2560; err = 0.39453125 * 2560; time = 0.0101s; samplesPerSecond = 252914.4
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.29140320 * 2560; err = 0.37968750 * 2560; time = 0.0101s; samplesPerSecond = 253039.4
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.27164612 * 2560; err = 0.39023438 * 2560; time = 0.0101s; samplesPerSecond = 253515.5
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29244080 * 2560; err = 0.38710937 * 2560; time = 0.0101s; samplesPerSecond = 252889.5
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32063599 * 2560; err = 0.39843750 * 2560; time = 0.0101s; samplesPerSecond = 253390.1
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.30206909 * 2560; err = 0.38476562 * 2560; time = 0.0101s; samplesPerSecond = 252515.3
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.31644287 * 2560; err = 0.39726563 * 2560; time = 0.0102s; samplesPerSecond = 250783.7
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.23897095 * 2560; err = 0.37187500 * 2560; time = 0.0101s; samplesPerSecond = 252415.7
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.26500854 * 2560; err = 0.38203125 * 2560; time = 0.0101s; samplesPerSecond = 252540.2
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.22773132 * 2560; err = 0.37265625 * 2560; time = 0.0102s; samplesPerSecond = 251993.3
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19237976 * 2560; err = 0.35507813 * 2560; time = 0.0101s; samplesPerSecond = 252864.5
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.20592957 * 2560; err = 0.36640625 * 2560; time = 0.0103s; samplesPerSecond = 248833.6
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.24901123 * 2560; err = 0.37304688 * 2560; time = 0.0102s; samplesPerSecond = 250122.1
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.17727051 * 2560; err = 0.34882812 * 2560; time = 0.0101s; samplesPerSecond = 252490.4
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.17915344 * 2560; err = 0.35585937 * 2560; time = 0.0101s; samplesPerSecond = 253264.7
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19775085 * 2560; err = 0.35703125 * 2560; time = 0.0101s; samplesPerSecond = 252390.8
12/20/2016 16:01:48:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.15687256 * 2560; err = 0.34179688 * 2560; time = 0.0102s; samplesPerSecond = 251720.7
12/20/2016 16:01:48: Finished Epoch[ 1 of 2]: [Training] ce = 1.48446083 * 81920; err = 0.42325439 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.417568s
12/20/2016 16:01:48: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.1'

12/20/2016 16:01:48: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:48: Starting minibatch loop.
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.16664762 * 2560; err = 0.36015625 * 2560; time = 0.0115s; samplesPerSecond = 222918.8
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18870573 * 2560; err = 0.35781250 * 2560; time = 0.0101s; samplesPerSecond = 252440.6
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.16170979 * 2560; err = 0.35625000 * 2560; time = 0.0101s; samplesPerSecond = 252864.5
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.15019836 * 2560; err = 0.35468750 * 2560; time = 0.0101s; samplesPerSecond = 253339.9
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.19214973 * 2560; err = 0.34375000 * 2560; time = 0.0101s; samplesPerSecond = 254245.7
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.13505058 * 2560; err = 0.35156250 * 2560; time = 0.0101s; samplesPerSecond = 254220.5
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14320984 * 2560; err = 0.35351562 * 2560; time = 0.0102s; samplesPerSecond = 251399.4
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17766495 * 2560; err = 0.36562500 * 2560; time = 0.0101s; samplesPerSecond = 252565.1
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.17257233 * 2560; err = 0.35937500 * 2560; time = 0.0101s; samplesPerSecond = 254271.0
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18593369 * 2560; err = 0.36210938 * 2560; time = 0.0101s; samplesPerSecond = 252341.1
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14418716 * 2560; err = 0.34921875 * 2560; time = 0.0106s; samplesPerSecond = 241122.7
12/20/2016 16:01:48:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13939972 * 2560; err = 0.34453125 * 2560; time = 0.0102s; samplesPerSecond = 251968.5
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.10048523 * 2560; err = 0.34375000 * 2560; time = 0.0101s; samplesPerSecond = 254245.7
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.12730865 * 2560; err = 0.34648438 * 2560; time = 0.0101s; samplesPerSecond = 254397.3
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.09852142 * 2560; err = 0.33828125 * 2560; time = 0.0101s; samplesPerSecond = 254018.7
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.07665100 * 2560; err = 0.33906250 * 2560; time = 0.0101s; samplesPerSecond = 252615.0
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.12044373 * 2560; err = 0.33828125 * 2560; time = 0.0101s; samplesPerSecond = 252839.5
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.07696075 * 2560; err = 0.33203125 * 2560; time = 0.0101s; samplesPerSecond = 253540.7
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11485443 * 2560; err = 0.34687500 * 2560; time = 0.0101s; samplesPerSecond = 254296.2
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08271027 * 2560; err = 0.32343750 * 2560; time = 0.0101s; samplesPerSecond = 254498.5
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.12734528 * 2560; err = 0.33164063 * 2560; time = 0.0101s; samplesPerSecond = 254726.4
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09645691 * 2560; err = 0.33906250 * 2560; time = 0.0101s; samplesPerSecond = 254018.7
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.04905548 * 2560; err = 0.32695313 * 2560; time = 0.0101s; samplesPerSecond = 254321.5
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.09844055 * 2560; err = 0.33906250 * 2560; time = 0.0101s; samplesPerSecond = 253892.7
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.09992371 * 2560; err = 0.34218750 * 2560; time = 0.0101s; samplesPerSecond = 253289.8
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07493591 * 2560; err = 0.33007812 * 2560; time = 0.0101s; samplesPerSecond = 254372.0
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.10963440 * 2560; err = 0.34218750 * 2560; time = 0.0101s; samplesPerSecond = 254574.4
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.08672485 * 2560; err = 0.33515625 * 2560; time = 0.0100s; samplesPerSecond = 255158.0
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.09848633 * 2560; err = 0.33789062 * 2560; time = 0.0101s; samplesPerSecond = 254372.0
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08891296 * 2560; err = 0.32343750 * 2560; time = 0.0101s; samplesPerSecond = 254498.5
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.07447510 * 2560; err = 0.33007812 * 2560; time = 0.0101s; samplesPerSecond = 252914.4
12/20/2016 16:01:49:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07217102 * 2560; err = 0.33632812 * 2560; time = 0.0101s; samplesPerSecond = 252989.4
12/20/2016 16:01:49: Finished Epoch[ 2 of 2]: [Training] ce = 1.11974773 * 81920; err = 0.34315186 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.328325s
12/20/2016 16:01:49: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech'

12/20/2016 16:01:49: Action "train" complete.


12/20/2016 16:01:49: ##############################################################################
12/20/2016 16:01:49: #                                                                            #
12/20/2016 16:01:49: # addLayer3 command (edit action)                                            #
12/20/2016 16:01:49: #                                                                            #
12/20/2016 16:01:49: ##############################################################################


12/20/2016 16:01:49: Action "edit" complete.


12/20/2016 16:01:49: ##############################################################################
12/20/2016 16:01:49: #                                                                            #
12/20/2016 16:01:49: # speechTrain command (train action)                                         #
12/20/2016 16:01:49: #                                                                            #
12/20/2016 16:01:49: ##############################################################################

12/20/2016 16:01:49: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/20/2016 16:01:49: 
Model has 29 nodes. Using GPU 0.

12/20/2016 16:01:49: Training criterion:   ce = CrossEntropyWithSoftmax
12/20/2016 16:01:49: Evaluation criterion: err = ClassificationError

12/20/2016 16:01:49: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

12/20/2016 16:01:49: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/20/2016 16:01:49: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:49: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:49: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:49: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/20/2016 16:01:49: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/20/2016 16:01:49: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/20/2016 16:01:49: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/20/2016 16:01:49: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/20/2016 16:01:49: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/20/2016 16:01:49: Starting minibatch loop.
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 4.04495506 * 2560; err = 0.84531250 * 2560; time = 0.0170s; samplesPerSecond = 150881.1
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.57063713 * 2560; err = 0.61523438 * 2560; time = 0.0136s; samplesPerSecond = 188637.5
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.05942078 * 2560; err = 0.56093750 * 2560; time = 0.0136s; samplesPerSecond = 188804.5
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.69141846 * 2560; err = 0.47031250 * 2560; time = 0.0136s; samplesPerSecond = 188027.9
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.51787796 * 2560; err = 0.44218750 * 2560; time = 0.0136s; samplesPerSecond = 187697.0
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.45984192 * 2560; err = 0.42070313 * 2560; time = 0.0135s; samplesPerSecond = 188985.7
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.46016541 * 2560; err = 0.42578125 * 2560; time = 0.0136s; samplesPerSecond = 188568.1
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.37518768 * 2560; err = 0.40390625 * 2560; time = 0.0136s; samplesPerSecond = 187903.7
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.33064575 * 2560; err = 0.38476562 * 2560; time = 0.0135s; samplesPerSecond = 189209.2
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.28854523 * 2560; err = 0.37734375 * 2560; time = 0.0136s; samplesPerSecond = 188651.4
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31856384 * 2560; err = 0.38203125 * 2560; time = 0.0136s; samplesPerSecond = 188069.4
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27931366 * 2560; err = 0.37148437 * 2560; time = 0.0135s; samplesPerSecond = 188971.7
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24598083 * 2560; err = 0.37382813 * 2560; time = 0.0136s; samplesPerSecond = 188540.3
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.26057587 * 2560; err = 0.38203125 * 2560; time = 0.0136s; samplesPerSecond = 188512.5
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.20037689 * 2560; err = 0.35742188 * 2560; time = 0.0136s; samplesPerSecond = 188069.4
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.22235413 * 2560; err = 0.37031250 * 2560; time = 0.0136s; samplesPerSecond = 188359.9
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.21270752 * 2560; err = 0.36328125 * 2560; time = 0.0136s; samplesPerSecond = 188097.0
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20062256 * 2560; err = 0.36640625 * 2560; time = 0.0136s; samplesPerSecond = 187738.3
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21882324 * 2560; err = 0.37226562 * 2560; time = 0.0136s; samplesPerSecond = 188110.8
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.25444336 * 2560; err = 0.37890625 * 2560; time = 0.0136s; samplesPerSecond = 187614.5
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.24527588 * 2560; err = 0.36523438 * 2560; time = 0.0137s; samplesPerSecond = 186656.9
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.24994202 * 2560; err = 0.38867188 * 2560; time = 0.0139s; samplesPerSecond = 184053.5
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.18169861 * 2560; err = 0.35117188 * 2560; time = 0.0138s; samplesPerSecond = 185372.9
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21201477 * 2560; err = 0.37265625 * 2560; time = 0.0138s; samplesPerSecond = 185198.6
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.17803345 * 2560; err = 0.35585937 * 2560; time = 0.0138s; samplesPerSecond = 185372.9
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.14755859 * 2560; err = 0.34570312 * 2560; time = 0.0138s; samplesPerSecond = 185857.4
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13581848 * 2560; err = 0.35585937 * 2560; time = 0.0137s; samplesPerSecond = 186195.4
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.19696655 * 2560; err = 0.36093750 * 2560; time = 0.0137s; samplesPerSecond = 186520.9
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.12962036 * 2560; err = 0.33710937 * 2560; time = 0.0137s; samplesPerSecond = 187298.8
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14494934 * 2560; err = 0.35195312 * 2560; time = 0.0137s; samplesPerSecond = 187107.1
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.15758972 * 2560; err = 0.34687500 * 2560; time = 0.0136s; samplesPerSecond = 188110.8
12/20/2016 16:01:49:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.11477661 * 2560; err = 0.34257813 * 2560; time = 0.0136s; samplesPerSecond = 187945.1
12/20/2016 16:01:49: Finished Epoch[ 1 of 4]: [Training] ce = 1.41583443 * 81920; err = 0.40434570 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.523357s
12/20/2016 16:01:49: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.1'

12/20/2016 16:01:49: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:49: Starting minibatch loop.
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.23277740 * 5120; err = 0.37402344 * 5120; time = 0.0258s; samplesPerSecond = 198326.6
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.34094334 * 5120; err = 0.39355469 * 5120; time = 0.0214s; samplesPerSecond = 239084.8
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.32344379 * 5120; err = 0.39804688 * 5120; time = 0.0213s; samplesPerSecond = 240217.7
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.16154022 * 5120; err = 0.35371094 * 5120; time = 0.0213s; samplesPerSecond = 240093.8
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16383133 * 5120; err = 0.34960938 * 5120; time = 0.0214s; samplesPerSecond = 239610.6
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.12472038 * 5120; err = 0.33984375 * 5120; time = 0.0214s; samplesPerSecond = 239745.3
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.09685593 * 5120; err = 0.33789062 * 5120; time = 0.0214s; samplesPerSecond = 239745.3
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.06717148 * 5120; err = 0.32890625 * 5120; time = 0.0213s; samplesPerSecond = 239925.0
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.09009476 * 5120; err = 0.33046875 * 5120; time = 0.0214s; samplesPerSecond = 239252.3
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.10942917 * 5120; err = 0.34824219 * 5120; time = 0.0215s; samplesPerSecond = 238605.6
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.09149475 * 5120; err = 0.32949219 * 5120; time = 0.0214s; samplesPerSecond = 239174.1
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07471619 * 5120; err = 0.33496094 * 5120; time = 0.0215s; samplesPerSecond = 237719.4
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.08045197 * 5120; err = 0.33378906 * 5120; time = 0.0215s; samplesPerSecond = 237863.0
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.18746948 * 5120; err = 0.36054687 * 5120; time = 0.0215s; samplesPerSecond = 238217.1
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08097229 * 5120; err = 0.33203125 * 5120; time = 0.0215s; samplesPerSecond = 237929.3
12/20/2016 16:01:50:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05254364 * 5120; err = 0.32460937 * 5120; time = 0.0215s; samplesPerSecond = 238416.8
12/20/2016 16:01:50: Finished Epoch[ 2 of 4]: [Training] ce = 1.14240351 * 81920; err = 0.34810791 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.350743s
12/20/2016 16:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.2'

12/20/2016 16:01:50: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:50: Starting minibatch loop.
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.07480564 * 5120; err = 0.33242187 * 5120; time = 0.0224s; samplesPerSecond = 228296.3
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.09418888 * 5120; err = 0.33535156 * 5120; time = 0.0215s; samplesPerSecond = 238017.8
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08832016 * 5120; err = 0.33691406 * 5120; time = 0.0215s; samplesPerSecond = 237874.0
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.04801941 * 5120; err = 0.32382813 * 5120; time = 0.0215s; samplesPerSecond = 238017.8
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07341309 * 5120; err = 0.32714844 * 5120; time = 0.0216s; samplesPerSecond = 237443.8
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.08500938 * 5120; err = 0.33398438 * 5120; time = 0.0215s; samplesPerSecond = 238161.7
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06951523 * 5120; err = 0.33125000 * 5120; time = 0.0216s; samplesPerSecond = 237520.9
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.08042984 * 5120; err = 0.34062500 * 5120; time = 0.0216s; samplesPerSecond = 237443.8
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.10114899 * 5120; err = 0.35390625 * 5120; time = 0.0215s; samplesPerSecond = 238217.1
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.01768875 * 5120; err = 0.31328125 * 5120; time = 0.0213s; samplesPerSecond = 239970.0
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03360672 * 5120; err = 0.32324219 * 5120; time = 0.0214s; samplesPerSecond = 239297.1
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.06860886 * 5120; err = 0.33789062 * 5120; time = 0.0214s; samplesPerSecond = 239588.2
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.06691895 * 5120; err = 0.33613281 * 5120; time = 0.0214s; samplesPerSecond = 238872.8
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.08316956 * 5120; err = 0.34160156 * 5120; time = 0.0215s; samplesPerSecond = 238073.1
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.01882782 * 5120; err = 0.31210938 * 5120; time = 0.0215s; samplesPerSecond = 238017.8
12/20/2016 16:01:50:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.03026886 * 5120; err = 0.32714844 * 5120; time = 0.0215s; samplesPerSecond = 237697.3
12/20/2016 16:01:50: Finished Epoch[ 3 of 4]: [Training] ce = 1.06462126 * 81920; err = 0.33167725 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.348228s
12/20/2016 16:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.3'

12/20/2016 16:01:50: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

12/20/2016 16:01:50: Starting minibatch loop.
12/20/2016 16:01:50:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02498760 * 5120; err = 0.32812500 * 5120; time = 0.0223s; samplesPerSecond = 229113.5
12/20/2016 16:01:50:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.00653004 * 4926; err = 0.31892002 * 4926; time = 0.0465s; samplesPerSecond = 106044.9
12/20/2016 16:01:50:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.01978836 * 5120; err = 0.31718750 * 5120; time = 0.0216s; samplesPerSecond = 237443.8
12/20/2016 16:01:50:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.03124619 * 5120; err = 0.32324219 * 5120; time = 0.0215s; samplesPerSecond = 238494.5
12/20/2016 16:01:50:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.02960358 * 5120; err = 0.31738281 * 5120; time = 0.0215s; samplesPerSecond = 238183.8
12/20/2016 16:01:50:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00228767 * 5120; err = 0.31523438 * 5120; time = 0.0215s; samplesPerSecond = 237995.6
12/20/2016 16:01:50:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01488953 * 5120; err = 0.32167969 * 5120; time = 0.0236s; samplesPerSecond = 216848.1
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.00438156 * 5120; err = 0.30585937 * 5120; time = 0.0293s; samplesPerSecond = 174648.7
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.98022079 * 5120; err = 0.32109375 * 5120; time = 0.0214s; samplesPerSecond = 238917.4
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98383560 * 5120; err = 0.30644531 * 5120; time = 0.0214s; samplesPerSecond = 239588.2
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03895187 * 5120; err = 0.32109375 * 5120; time = 0.0213s; samplesPerSecond = 239846.3
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.98408051 * 5120; err = 0.30019531 * 5120; time = 0.0213s; samplesPerSecond = 240646.7
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00010757 * 5120; err = 0.31171875 * 5120; time = 0.0212s; samplesPerSecond = 241111.4
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96877747 * 5120; err = 0.30097656 * 5120; time = 0.0213s; samplesPerSecond = 240737.3
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97649994 * 5120; err = 0.30332031 * 5120; time = 0.0214s; samplesPerSecond = 239779.0
12/20/2016 16:01:51:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96828461 * 5120; err = 0.30625000 * 5120; time = 0.0213s; samplesPerSecond = 239936.3
12/20/2016 16:01:51: Finished Epoch[ 4 of 4]: [Training] ce = 1.00239983 * 81920; err = 0.31373291 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.383333s
12/20/2016 16:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20161220160002.370246/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech'

12/20/2016 16:01:51: Action "train" complete.

12/20/2016 16:01:51: __COMPLETED__