CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 19 2016 15:29:02
		Last modified date: Thu Aug 18 15:17:07 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 9ad9bd04f89696255e558f3c8b774151021635f6
		Built by philly on 643085f7f8c2
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
08/19/2016 16:33:33: -------------------------------------------------------------------
08/19/2016 16:33:33: Build info: 

08/19/2016 16:33:33: 		Built time: Aug 19 2016 15:29:02
08/19/2016 16:33:33: 		Last modified date: Thu Aug 18 15:17:07 2016
08/19/2016 16:33:33: 		Build type: release
08/19/2016 16:33:33: 		Build target: GPU
08/19/2016 16:33:33: 		With 1bit-SGD: no
08/19/2016 16:33:33: 		Math lib: mkl
08/19/2016 16:33:33: 		CUDA_PATH: /usr/local/cuda-7.5
08/19/2016 16:33:33: 		CUB_PATH: /usr/local/cub-1.4.1
08/19/2016 16:33:33: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/19/2016 16:33:33: 		Build Branch: HEAD
08/19/2016 16:33:33: 		Build SHA1: 9ad9bd04f89696255e558f3c8b774151021635f6
08/19/2016 16:33:33: 		Built by philly on 643085f7f8c2
08/19/2016 16:33:33: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/19/2016 16:33:33: -------------------------------------------------------------------
08/19/2016 16:33:34: -------------------------------------------------------------------
08/19/2016 16:33:34: GPU info:

08/19/2016 16:33:34: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:34: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:34: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:34: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:34: -------------------------------------------------------------------

08/19/2016 16:33:34: Running on localhost at 2016/08/19 16:33:34
08/19/2016 16:33:34: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



08/19/2016 16:33:34: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/19/2016 16:33:34: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/19/2016 16:33:34: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/19/2016 16:33:34: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/19/2016 16:33:34: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/19/2016 16:33:34: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/19/2016 16:33:34: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/19/2016 16:33:34: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/19/2016 16:33:34: Commands: Simple_Demo Simple_Demo_Output
08/19/2016 16:33:34: Precision = "float"
08/19/2016 16:33:34: CNTKModelPath: /tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn
08/19/2016 16:33:34: CNTKCommandTrainInfo: Simple_Demo : 50
08/19/2016 16:33:34: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/19/2016 16:33:34: ##############################################################################
08/19/2016 16:33:34: #                                                                            #
08/19/2016 16:33:34: # Action "train"                                                             #
08/19/2016 16:33:34: #                                                                            #
08/19/2016 16:33:34: ##############################################################################

08/19/2016 16:33:34: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/19/2016 16:33:34: Creating virgin network.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, range=0.050000*1.000000, onCPU=false).
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/19/2016 16:33:34: Created model with 25 nodes on CPU.

08/19/2016 16:33:34: Training criterion node(s):
08/19/2016 16:33:34: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/19/2016 16:33:34: Evaluation criterion node(s):
08/19/2016 16:33:34: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }
	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }


08/19/2016 16:33:34: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/19/2016 16:33:34: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/19/2016 16:33:34: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/19/2016 16:33:34: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/19/2016 16:33:34: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/19/2016 16:33:34: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/19/2016 16:33:34: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


08/19/2016 16:33:34: Precomputing --> 3 PreCompute nodes found.

08/19/2016 16:33:34: 	MeanOfFeatures = Mean()
08/19/2016 16:33:34: 	InvStdOfFeatures = InvStdDev()
08/19/2016 16:33:34: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/19/2016 16:33:34: Precomputing --> Completed.


08/19/2016 16:33:34: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/19/2016 16:33:34: Starting minibatch loop.
08/19/2016 16:33:34:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.76787934 * 1280; EvalClassificationError = 0.50000000 * 1280; time = 0.0587s; samplesPerSecond = 21804.3
08/19/2016 16:33:34:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.72901568 * 1280; EvalClassificationError = 0.50468750 * 1280; time = 0.0391s; samplesPerSecond = 32774.3
08/19/2016 16:33:34:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.69672241 * 1280; EvalClassificationError = 0.49765625 * 1280; time = 0.0393s; samplesPerSecond = 32554.2
08/19/2016 16:33:34:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69961853 * 1280; EvalClassificationError = 0.46250000 * 1280; time = 0.0436s; samplesPerSecond = 29350.4
08/19/2016 16:33:34:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.69465542 * 1280; EvalClassificationError = 0.48515625 * 1280; time = 0.0627s; samplesPerSecond = 20406.2
08/19/2016 16:33:35:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.69459534 * 1280; EvalClassificationError = 0.41171875 * 1280; time = 0.0931s; samplesPerSecond = 13752.6
08/19/2016 16:33:35:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.65583420 * 1280; EvalClassificationError = 0.41796875 * 1280; time = 0.0386s; samplesPerSecond = 33129.7
08/19/2016 16:33:35: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.67760117 * 10000; EvalClassificationError = 0.43420000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.416737s
08/19/2016 16:33:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.1'

08/19/2016 16:33:35: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: samples [10000..20000] (first sequence at sample 10000), worker rank 0, total workers 1

08/19/2016 16:33:35: Starting minibatch loop.
08/19/2016 16:33:35:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17324982 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0435s; samplesPerSecond = 29392.9
08/19/2016 16:33:35:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20231733 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0537s; samplesPerSecond = 23838.3
08/19/2016 16:33:35:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.21851544 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0433s; samplesPerSecond = 29562.6
08/19/2016 16:33:35:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19079599 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0649s; samplesPerSecond = 19715.4
08/19/2016 16:33:35:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19158483 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0381s; samplesPerSecond = 33625.8
08/19/2016 16:33:35:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18068705 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0654s; samplesPerSecond = 19557.2
08/19/2016 16:33:35:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15414658 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0891s; samplesPerSecond = 14366.0
08/19/2016 16:33:35: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.18580663 * 10000; EvalClassificationError = 0.07910000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.439706s
08/19/2016 16:33:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.2'

08/19/2016 16:33:35: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: samples [20000..30000] (first sequence at sample 20000), worker rank 0, total workers 1

08/19/2016 16:33:35: Starting minibatch loop.
08/19/2016 16:33:35:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20254633 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0578s; samplesPerSecond = 22136.1
08/19/2016 16:33:35:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18272691 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0455s; samplesPerSecond = 28123.2
08/19/2016 16:33:35:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16485136 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0385s; samplesPerSecond = 33267.5
08/19/2016 16:33:35:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17932053 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0492s; samplesPerSecond = 26002.0
08/19/2016 16:33:35:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16228528 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0344s; samplesPerSecond = 37169.3
08/19/2016 16:33:35:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17208090 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0405s; samplesPerSecond = 31606.5
08/19/2016 16:33:35:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15790396 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0438s; samplesPerSecond = 29209.7
08/19/2016 16:33:35: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.17220917 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.346887s
08/19/2016 16:33:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.3'

08/19/2016 16:33:35: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: samples [30000..40000] (first sequence at sample 30000), worker rank 0, total workers 1

08/19/2016 16:33:35: Starting minibatch loop.
08/19/2016 16:33:35:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15375857 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0429s; samplesPerSecond = 29834.0
08/19/2016 16:33:35:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17569733 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0421s; samplesPerSecond = 30437.8
08/19/2016 16:33:36:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16692853 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0434s; samplesPerSecond = 29468.6
08/19/2016 16:33:36:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19348474 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0595s; samplesPerSecond = 21502.1
08/19/2016 16:33:36:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16766143 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0428s; samplesPerSecond = 29882.8
08/19/2016 16:33:36:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15068712 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0394s; samplesPerSecond = 32477.4
08/19/2016 16:33:36:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15202255 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0401s; samplesPerSecond = 31944.9
08/19/2016 16:33:36: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.16509663 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.379501s
08/19/2016 16:33:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.4'

08/19/2016 16:33:36: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: samples [40000..50000] (first sequence at sample 40000), worker rank 0, total workers 1

08/19/2016 16:33:36: Starting minibatch loop.
08/19/2016 16:33:36:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15456637 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0394s; samplesPerSecond = 32480.7
08/19/2016 16:33:36:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17114824 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0398s; samplesPerSecond = 32182.6
08/19/2016 16:33:36:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15907691 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0755s; samplesPerSecond = 16948.5
08/19/2016 16:33:36:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15822296 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0375s; samplesPerSecond = 34126.1
08/19/2016 16:33:36:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17749362 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.1001s; samplesPerSecond = 12792.7
08/19/2016 16:33:36:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17140379 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0398s; samplesPerSecond = 32167.3
08/19/2016 16:33:36:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17532120 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0565s; samplesPerSecond = 22663.3
08/19/2016 16:33:36: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16548112 * 10000; EvalClassificationError = 0.07580000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.470618s
08/19/2016 16:33:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.5'

08/19/2016 16:33:36: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: samples [50000..60000] (first sequence at sample 50000), worker rank 0, total workers 1

08/19/2016 16:33:36: Starting minibatch loop.
08/19/2016 16:33:36:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17227025 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0544s; samplesPerSecond = 23527.2
08/19/2016 16:33:36:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20439794 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0348s; samplesPerSecond = 36759.4
08/19/2016 16:33:36:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15904639 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0504s; samplesPerSecond = 25414.0
08/19/2016 16:33:36:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16456442 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0374s; samplesPerSecond = 34196.3
08/19/2016 16:33:36:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18057923 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0403s; samplesPerSecond = 31728.7
08/19/2016 16:33:37:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18235464 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0478s; samplesPerSecond = 26802.4
08/19/2016 16:33:37:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18240747 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0414s; samplesPerSecond = 30900.0
08/19/2016 16:33:37: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.17461414 * 10000; EvalClassificationError = 0.07850000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.344735s
08/19/2016 16:33:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.6'

08/19/2016 16:33:37: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: samples [60000..70000] (first sequence at sample 60000), worker rank 0, total workers 1

08/19/2016 16:33:37: Starting minibatch loop.
08/19/2016 16:33:37:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16127207 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0358s; samplesPerSecond = 35751.2
08/19/2016 16:33:37:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17270827 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0438s; samplesPerSecond = 29203.1
08/19/2016 16:33:37:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15257218 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0663s; samplesPerSecond = 19316.4
08/19/2016 16:33:37:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13763499 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0961s; samplesPerSecond = 13314.2
08/19/2016 16:33:37:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14628553 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0435s; samplesPerSecond = 29455.8
08/19/2016 16:33:37:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17638268 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0500s; samplesPerSecond = 25603.1
08/19/2016 16:33:37:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17476597 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0448s; samplesPerSecond = 28567.0
08/19/2016 16:33:37: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16351232 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.424642s
08/19/2016 16:33:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.7'

08/19/2016 16:33:37: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: samples [70000..80000] (first sequence at sample 70000), worker rank 0, total workers 1

08/19/2016 16:33:37: Starting minibatch loop.
08/19/2016 16:33:37:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16444731 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.1427s; samplesPerSecond = 8970.0
08/19/2016 16:33:37:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15843720 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0425s; samplesPerSecond = 30151.0
08/19/2016 16:33:37:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16285920 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0516s; samplesPerSecond = 24810.5
08/19/2016 16:33:37:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16373620 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0619s; samplesPerSecond = 20669.2
08/19/2016 16:33:37:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16341424 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0451s; samplesPerSecond = 28384.5
08/19/2016 16:33:37:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18029823 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0443s; samplesPerSecond = 28867.2
08/19/2016 16:33:37:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14125404 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0392s; samplesPerSecond = 32641.4
08/19/2016 16:33:37: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16305011 * 10000; EvalClassificationError = 0.07520000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.465877s
08/19/2016 16:33:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.8'

08/19/2016 16:33:37: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: samples [80000..90000] (first sequence at sample 80000), worker rank 0, total workers 1

08/19/2016 16:33:37: Starting minibatch loop.
08/19/2016 16:33:38:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18143573 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0431s; samplesPerSecond = 29681.8
08/19/2016 16:33:38:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18009186 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0428s; samplesPerSecond = 29903.0
08/19/2016 16:33:38:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17607355 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0435s; samplesPerSecond = 29457.1
08/19/2016 16:33:38:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17846341 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0417s; samplesPerSecond = 30710.9
08/19/2016 16:33:38:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16922579 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0429s; samplesPerSecond = 29863.3
08/19/2016 16:33:38:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15430441 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0416s; samplesPerSecond = 30775.9
08/19/2016 16:33:38:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15593309 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0447s; samplesPerSecond = 28610.4
08/19/2016 16:33:38: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.17140125 * 10000; EvalClassificationError = 0.07760000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.340354s
08/19/2016 16:33:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.9'

08/19/2016 16:33:38: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: samples [90000..100000] (first sequence at sample 90000), worker rank 0, total workers 1

08/19/2016 16:33:38: Starting minibatch loop.
08/19/2016 16:33:38:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17335187 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0440s; samplesPerSecond = 29118.0
08/19/2016 16:33:38:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15469073 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0585s; samplesPerSecond = 21893.1
08/19/2016 16:33:38:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17982941 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0498s; samplesPerSecond = 25705.4
08/19/2016 16:33:38:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16882930 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.1181s; samplesPerSecond = 10833.7
08/19/2016 16:33:38:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20348811 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0397s; samplesPerSecond = 32274.3
08/19/2016 16:33:38:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16315126 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0431s; samplesPerSecond = 29694.2
08/19/2016 16:33:38:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15775690 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0592s; samplesPerSecond = 21630.8
08/19/2016 16:33:38: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16880905 * 10000; EvalClassificationError = 0.07640000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.452982s
08/19/2016 16:33:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.10'

08/19/2016 16:33:38: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: samples [100000..110000] (first sequence at sample 100000), worker rank 0, total workers 1

08/19/2016 16:33:38: Starting minibatch loop.
08/19/2016 16:33:38:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17671552 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0351s; samplesPerSecond = 36461.0
08/19/2016 16:33:38:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16349590 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0486s; samplesPerSecond = 26312.0
08/19/2016 16:33:38:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17284467 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0727s; samplesPerSecond = 17615.3
08/19/2016 16:33:38:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16618638 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0601s; samplesPerSecond = 21284.0
08/19/2016 16:33:39:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15637784 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0474s; samplesPerSecond = 27005.4
08/19/2016 16:33:39:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15405140 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0399s; samplesPerSecond = 32105.9
08/19/2016 16:33:39:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16313572 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0462s; samplesPerSecond = 27690.0
08/19/2016 16:33:39: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.17006686 * 10000; EvalClassificationError = 0.07660000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.390663s
08/19/2016 16:33:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.11'

08/19/2016 16:33:39: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: samples [110000..120000] (first sequence at sample 110000), worker rank 0, total workers 1

08/19/2016 16:33:39: Starting minibatch loop.
08/19/2016 16:33:39:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16747355 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0456s; samplesPerSecond = 28054.2
08/19/2016 16:33:39:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16926193 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0624s; samplesPerSecond = 20521.7
08/19/2016 16:33:39:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17724948 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0426s; samplesPerSecond = 30063.2
08/19/2016 16:33:39:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16153197 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0421s; samplesPerSecond = 30427.7
08/19/2016 16:33:39:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15809436 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0427s; samplesPerSecond = 29952.0
08/19/2016 16:33:39:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16424351 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0852s; samplesPerSecond = 15022.1
08/19/2016 16:33:39:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14406033 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0919s; samplesPerSecond = 13933.2
08/19/2016 16:33:39: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16305160 * 10000; EvalClassificationError = 0.07630000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.453989s
08/19/2016 16:33:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.12'

08/19/2016 16:33:39: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: samples [120000..130000] (first sequence at sample 120000), worker rank 0, total workers 1

08/19/2016 16:33:39: Starting minibatch loop.
08/19/2016 16:33:39:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15032356 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0447s; samplesPerSecond = 28662.3
08/19/2016 16:33:39:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17721350 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0403s; samplesPerSecond = 31740.5
08/19/2016 16:33:39:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17323794 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0466s; samplesPerSecond = 27453.7
08/19/2016 16:33:39:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15412502 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0792s; samplesPerSecond = 16168.4
08/19/2016 16:33:39:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14742494 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0398s; samplesPerSecond = 32153.5
08/19/2016 16:33:39:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17056408 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0389s; samplesPerSecond = 32919.3
08/19/2016 16:33:39:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15463085 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0502s; samplesPerSecond = 25490.4
08/19/2016 16:33:40: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16187950 * 10000; EvalClassificationError = 0.07470000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.386627s
08/19/2016 16:33:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.13'

08/19/2016 16:33:40: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: samples [130000..140000] (first sequence at sample 130000), worker rank 0, total workers 1

08/19/2016 16:33:40: Starting minibatch loop.
08/19/2016 16:33:40:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20428095 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0453s; samplesPerSecond = 28246.1
08/19/2016 16:33:40:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20951290 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0439s; samplesPerSecond = 29163.8
08/19/2016 16:33:40:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17470493 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0449s; samplesPerSecond = 28539.6
08/19/2016 16:33:40:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20022807 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0454s; samplesPerSecond = 28222.4
08/19/2016 16:33:40:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19115624 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0485s; samplesPerSecond = 26407.5
08/19/2016 16:33:40:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16565647 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0449s; samplesPerSecond = 28492.6
08/19/2016 16:33:40:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15861502 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0439s; samplesPerSecond = 29179.1
08/19/2016 16:33:40: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.18525491 * 10000; EvalClassificationError = 0.08160000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.36439s
08/19/2016 16:33:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.14'

08/19/2016 16:33:40: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: samples [140000..150000] (first sequence at sample 140000), worker rank 0, total workers 1

08/19/2016 16:33:40: Starting minibatch loop.
08/19/2016 16:33:40:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17293936 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0454s; samplesPerSecond = 28185.8
08/19/2016 16:33:40:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14972342 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0977s; samplesPerSecond = 13098.5
08/19/2016 16:33:40:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17388477 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0687s; samplesPerSecond = 18627.1
08/19/2016 16:33:40:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16904759 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0413s; samplesPerSecond = 31013.8
08/19/2016 16:33:40:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16738758 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0449s; samplesPerSecond = 28527.5
08/19/2016 16:33:40:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16737280 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0754s; samplesPerSecond = 16986.7
08/19/2016 16:33:40:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15916157 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0436s; samplesPerSecond = 29390.2
08/19/2016 16:33:40: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16554252 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.458186s
08/19/2016 16:33:40: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.15'

08/19/2016 16:33:40: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: samples [150000..160000] (first sequence at sample 150000), worker rank 0, total workers 1

08/19/2016 16:33:40: Starting minibatch loop.
08/19/2016 16:33:40:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17063617 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0438s; samplesPerSecond = 29199.1
08/19/2016 16:33:40:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16444877 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0594s; samplesPerSecond = 21550.3
08/19/2016 16:33:40:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17523315 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0449s; samplesPerSecond = 28530.7
08/19/2016 16:33:41:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17308168 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0445s; samplesPerSecond = 28788.0
08/19/2016 16:33:41:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18644800 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0531s; samplesPerSecond = 24090.9
08/19/2016 16:33:41:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17276363 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0479s; samplesPerSecond = 26707.3
08/19/2016 16:33:41:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17704020 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0587s; samplesPerSecond = 21790.2
08/19/2016 16:33:41: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.17266418 * 10000; EvalClassificationError = 0.07770000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.39769s
08/19/2016 16:33:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.16'

08/19/2016 16:33:41: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: samples [160000..170000] (first sequence at sample 160000), worker rank 0, total workers 1

08/19/2016 16:33:41: Starting minibatch loop.
08/19/2016 16:33:41:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15754166 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0403s; samplesPerSecond = 31724.8
08/19/2016 16:33:41:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16700339 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0452s; samplesPerSecond = 28311.7
08/19/2016 16:33:41:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18876452 * 1280; EvalClassificationError = 0.09453125 * 1280; time = 0.0495s; samplesPerSecond = 25856.0
08/19/2016 16:33:41:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16264739 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0710s; samplesPerSecond = 18034.3
08/19/2016 16:33:41:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15761571 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0496s; samplesPerSecond = 25808.0
08/19/2016 16:33:41:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15861082 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0591s; samplesPerSecond = 21643.6
08/19/2016 16:33:41:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15868082 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0566s; samplesPerSecond = 22622.8
08/19/2016 16:33:41: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16474823 * 10000; EvalClassificationError = 0.07880000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.419028s
08/19/2016 16:33:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.17'

08/19/2016 16:33:41: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: samples [170000..180000] (first sequence at sample 170000), worker rank 0, total workers 1

08/19/2016 16:33:41: Starting minibatch loop.
08/19/2016 16:33:41:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15372934 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0452s; samplesPerSecond = 28325.5
08/19/2016 16:33:41:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16174209 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0395s; samplesPerSecond = 32396.0
08/19/2016 16:33:41:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16805203 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0453s; samplesPerSecond = 28244.8
08/19/2016 16:33:41:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15750542 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0430s; samplesPerSecond = 29770.9
08/19/2016 16:33:41:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14848328 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0414s; samplesPerSecond = 30900.7
08/19/2016 16:33:41:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15929041 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0445s; samplesPerSecond = 28781.5
08/19/2016 16:33:41:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15710382 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0417s; samplesPerSecond = 30719.0
08/19/2016 16:33:42: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15840825 * 10000; EvalClassificationError = 0.07410000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.376113s
08/19/2016 16:33:42: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.18'

08/19/2016 16:33:42: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: samples [180000..190000] (first sequence at sample 180000), worker rank 0, total workers 1

08/19/2016 16:33:42: Starting minibatch loop.
08/19/2016 16:33:42:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15729399 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0440s; samplesPerSecond = 29111.4
08/19/2016 16:33:42:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15066614 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0506s; samplesPerSecond = 25288.4
08/19/2016 16:33:42:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16931272 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0420s; samplesPerSecond = 30449.4
08/19/2016 16:33:42:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15056415 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0462s; samplesPerSecond = 27688.2
08/19/2016 16:33:42:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18283539 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0443s; samplesPerSecond = 28904.3
08/19/2016 16:33:42:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16821423 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0449s; samplesPerSecond = 28511.6
08/19/2016 16:33:42:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17998962 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0450s; samplesPerSecond = 28433.7
08/19/2016 16:33:42: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16611071 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.371354s
08/19/2016 16:33:42: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.19'

08/19/2016 16:33:42: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: samples [190000..200000] (first sequence at sample 190000), worker rank 0, total workers 1

08/19/2016 16:33:42: Starting minibatch loop.
08/19/2016 16:33:42:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16058819 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0376s; samplesPerSecond = 34072.5
08/19/2016 16:33:42:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15364983 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0450s; samplesPerSecond = 28413.5
08/19/2016 16:33:42:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15540876 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0440s; samplesPerSecond = 29094.2
08/19/2016 16:33:42:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16862626 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0587s; samplesPerSecond = 21795.0
08/19/2016 16:33:42:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15999017 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0399s; samplesPerSecond = 32093.9
08/19/2016 16:33:42:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15753341 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0701s; samplesPerSecond = 18260.7
08/19/2016 16:33:42:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16873493 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0622s; samplesPerSecond = 20566.2
08/19/2016 16:33:42: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.15916770 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.408026s
08/19/2016 16:33:42: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.20'

08/19/2016 16:33:42: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: samples [200000..210000] (first sequence at sample 200000), worker rank 0, total workers 1

08/19/2016 16:33:42: Starting minibatch loop.
08/19/2016 16:33:42:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16457530 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0508s; samplesPerSecond = 25219.2
08/19/2016 16:33:42:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14965640 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0440s; samplesPerSecond = 29118.7
08/19/2016 16:33:42:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15823958 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0444s; samplesPerSecond = 28834.7
08/19/2016 16:33:43:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14598188 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0501s; samplesPerSecond = 25526.5
08/19/2016 16:33:43:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16491947 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0357s; samplesPerSecond = 35867.4
08/19/2016 16:33:43:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17231421 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0414s; samplesPerSecond = 30929.1
08/19/2016 16:33:43:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16371145 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0396s; samplesPerSecond = 32358.4
08/19/2016 16:33:43: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16036292 * 10000; EvalClassificationError = 0.07640000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.350827s
08/19/2016 16:33:43: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.21'

08/19/2016 16:33:43: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: samples [210000..220000] (first sequence at sample 210000), worker rank 0, total workers 1

08/19/2016 16:33:43: Starting minibatch loop.
08/19/2016 16:33:43:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15611976 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0403s; samplesPerSecond = 31785.4
08/19/2016 16:33:43:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13785256 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0522s; samplesPerSecond = 24530.9
08/19/2016 16:33:43:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16535847 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0537s; samplesPerSecond = 23836.6
08/19/2016 16:33:43:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16503286 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0520s; samplesPerSecond = 24599.3
08/19/2016 16:33:43:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15546598 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0567s; samplesPerSecond = 22591.7
08/19/2016 16:33:43:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15233245 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0437s; samplesPerSecond = 29307.4
08/19/2016 16:33:43:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19573660 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0607s; samplesPerSecond = 21079.7
08/19/2016 16:33:43: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16261056 * 10000; EvalClassificationError = 0.07580000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.410668s
08/19/2016 16:33:43: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.22'

08/19/2016 16:33:43: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: samples [220000..230000] (first sequence at sample 220000), worker rank 0, total workers 1

08/19/2016 16:33:43: Starting minibatch loop.
08/19/2016 16:33:43:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16898190 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0442s; samplesPerSecond = 28978.3
08/19/2016 16:33:43:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17614695 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0676s; samplesPerSecond = 18933.0
08/19/2016 16:33:43:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16341064 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0477s; samplesPerSecond = 26836.6
08/19/2016 16:33:43:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16389289 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0610s; samplesPerSecond = 20981.2
08/19/2016 16:33:43:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15507503 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0439s; samplesPerSecond = 29128.6
08/19/2016 16:33:43:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16150293 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0402s; samplesPerSecond = 31841.6
08/19/2016 16:33:43:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15201712 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0481s; samplesPerSecond = 26610.7
08/19/2016 16:33:43: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16328608 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.389112s
08/19/2016 16:33:43: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.23'

08/19/2016 16:33:43: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: samples [230000..240000] (first sequence at sample 230000), worker rank 0, total workers 1

08/19/2016 16:33:43: Starting minibatch loop.
08/19/2016 16:33:44:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18361145 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0410s; samplesPerSecond = 31221.8
08/19/2016 16:33:44:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18937527 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0485s; samplesPerSecond = 26418.4
08/19/2016 16:33:44:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15248959 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0438s; samplesPerSecond = 29203.1
08/19/2016 16:33:44:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13488998 * 1280; EvalClassificationError = 0.05703125 * 1280; time = 0.0411s; samplesPerSecond = 31161.0
08/19/2016 16:33:44:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18253484 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0441s; samplesPerSecond = 29023.6
08/19/2016 16:33:44:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13559303 * 1280; EvalClassificationError = 0.05859375 * 1280; time = 0.0438s; samplesPerSecond = 29209.1
08/19/2016 16:33:44:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16215487 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0447s; samplesPerSecond = 28628.9
08/19/2016 16:33:44: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16349955 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.347812s
08/19/2016 16:33:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.24'

08/19/2016 16:33:44: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: samples [240000..250000] (first sequence at sample 240000), worker rank 0, total workers 1

08/19/2016 16:33:44: Starting minibatch loop.
08/19/2016 16:33:44:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14410827 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0508s; samplesPerSecond = 25200.3
08/19/2016 16:33:44:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17700346 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0444s; samplesPerSecond = 28821.0
08/19/2016 16:33:44:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14907322 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0867s; samplesPerSecond = 14762.2
08/19/2016 16:33:44:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16086659 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.2010s; samplesPerSecond = 6366.9
08/19/2016 16:33:44:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17219229 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0607s; samplesPerSecond = 21082.5
08/19/2016 16:33:44:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17564411 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0448s; samplesPerSecond = 28544.7
08/19/2016 16:33:44:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17609806 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0387s; samplesPerSecond = 33060.4
08/19/2016 16:33:44: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16392162 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.569993s
08/19/2016 16:33:44: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.25'

08/19/2016 16:33:44: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: samples [250000..260000] (first sequence at sample 250000), worker rank 0, total workers 1

08/19/2016 16:33:44: Starting minibatch loop.
08/19/2016 16:33:44:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14948863 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0455s; samplesPerSecond = 28155.4
08/19/2016 16:33:44:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18475274 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0448s; samplesPerSecond = 28565.1
08/19/2016 16:33:45:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16298697 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0433s; samplesPerSecond = 29585.8
08/19/2016 16:33:45:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14671764 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0407s; samplesPerSecond = 31455.8
08/19/2016 16:33:45:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16988983 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0463s; samplesPerSecond = 27670.9
08/19/2016 16:33:45:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12634602 * 1280; EvalClassificationError = 0.05156250 * 1280; time = 0.0407s; samplesPerSecond = 31441.9
08/19/2016 16:33:45:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16665201 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0436s; samplesPerSecond = 29336.3
08/19/2016 16:33:45: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15836490 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.369451s
08/19/2016 16:33:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.26'

08/19/2016 16:33:45: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: samples [260000..270000] (first sequence at sample 260000), worker rank 0, total workers 1

08/19/2016 16:33:45: Starting minibatch loop.
08/19/2016 16:33:45:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17074007 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0409s; samplesPerSecond = 31318.8
08/19/2016 16:33:45:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17057625 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0591s; samplesPerSecond = 21660.8
08/19/2016 16:33:45:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14733496 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0449s; samplesPerSecond = 28514.8
08/19/2016 16:33:45:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15325289 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0756s; samplesPerSecond = 16929.2
08/19/2016 16:33:45:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15593848 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0906s; samplesPerSecond = 14127.3
08/19/2016 16:33:45:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15706935 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0626s; samplesPerSecond = 20458.7
08/19/2016 16:33:45:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17286139 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0438s; samplesPerSecond = 29229.1
08/19/2016 16:33:45: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16107900 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.452862s
08/19/2016 16:33:45: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.27'

08/19/2016 16:33:45: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: samples [270000..280000] (first sequence at sample 270000), worker rank 0, total workers 1

08/19/2016 16:33:45: Starting minibatch loop.
08/19/2016 16:33:45:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16945839 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0386s; samplesPerSecond = 33135.7
08/19/2016 16:33:45:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18443933 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0352s; samplesPerSecond = 36326.5
08/19/2016 16:33:45:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16735659 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0467s; samplesPerSecond = 27394.3
08/19/2016 16:33:45:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15123658 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0396s; samplesPerSecond = 32355.9
08/19/2016 16:33:45:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14052629 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0440s; samplesPerSecond = 29098.2
08/19/2016 16:33:45:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15429277 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0608s; samplesPerSecond = 21068.2
08/19/2016 16:33:46:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16686220 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0448s; samplesPerSecond = 28554.2
08/19/2016 16:33:46: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16312493 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.357373s
08/19/2016 16:33:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.28'

08/19/2016 16:33:46: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: samples [280000..290000] (first sequence at sample 280000), worker rank 0, total workers 1

08/19/2016 16:33:46: Starting minibatch loop.
08/19/2016 16:33:46:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16114540 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0458s; samplesPerSecond = 27974.5
08/19/2016 16:33:46:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13027828 * 1280; EvalClassificationError = 0.05703125 * 1280; time = 0.0678s; samplesPerSecond = 18865.4
08/19/2016 16:33:46:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16984260 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0483s; samplesPerSecond = 26496.1
08/19/2016 16:33:46:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15046005 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0440s; samplesPerSecond = 29085.0
08/19/2016 16:33:46:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16504674 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0449s; samplesPerSecond = 28519.2
08/19/2016 16:33:46:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14679298 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0441s; samplesPerSecond = 29031.5
08/19/2016 16:33:46:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17150078 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0446s; samplesPerSecond = 28697.0
08/19/2016 16:33:46: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16135597 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.384222s
08/19/2016 16:33:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.29'

08/19/2016 16:33:46: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: samples [290000..300000] (first sequence at sample 290000), worker rank 0, total workers 1

08/19/2016 16:33:46: Starting minibatch loop.
08/19/2016 16:33:46:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16378831 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0333s; samplesPerSecond = 38450.0
08/19/2016 16:33:46:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15350198 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0452s; samplesPerSecond = 28325.5
08/19/2016 16:33:46:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16200159 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0929s; samplesPerSecond = 13780.6
08/19/2016 16:33:46:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17997231 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0383s; samplesPerSecond = 33414.3
08/19/2016 16:33:46:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17179413 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0411s; samplesPerSecond = 31123.9
08/19/2016 16:33:46:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16910982 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0394s; samplesPerSecond = 32462.6
08/19/2016 16:33:46:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17447052 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0668s; samplesPerSecond = 19151.9
08/19/2016 16:33:46: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16685386 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.403667s
08/19/2016 16:33:46: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.30'

08/19/2016 16:33:46: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: samples [300000..310000] (first sequence at sample 300000), worker rank 0, total workers 1

08/19/2016 16:33:46: Starting minibatch loop.
08/19/2016 16:33:46:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17310443 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0446s; samplesPerSecond = 28676.4
08/19/2016 16:33:46:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17225749 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0445s; samplesPerSecond = 28768.6
08/19/2016 16:33:46:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19278548 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0449s; samplesPerSecond = 28493.2
08/19/2016 16:33:47:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14848065 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0437s; samplesPerSecond = 29258.5
08/19/2016 16:33:47:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17797060 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0533s; samplesPerSecond = 24014.6
08/19/2016 16:33:47:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14993372 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0393s; samplesPerSecond = 32542.6
08/19/2016 16:33:47:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15609455 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0491s; samplesPerSecond = 26076.2
08/19/2016 16:33:47: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.16720491 * 10000; EvalClassificationError = 0.08070000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.362897s
08/19/2016 16:33:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.31'

08/19/2016 16:33:47: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: samples [310000..320000] (first sequence at sample 310000), worker rank 0, total workers 1

08/19/2016 16:33:47: Starting minibatch loop.
08/19/2016 16:33:47:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16825130 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0459s; samplesPerSecond = 27902.5
08/19/2016 16:33:47:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15172622 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0435s; samplesPerSecond = 29448.3
08/19/2016 16:33:47:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14193797 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0443s; samplesPerSecond = 28908.3
08/19/2016 16:33:47:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16006804 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0588s; samplesPerSecond = 21762.8
08/19/2016 16:33:47:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15443034 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0456s; samplesPerSecond = 28072.0
08/19/2016 16:33:47:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17014613 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0398s; samplesPerSecond = 32190.7
08/19/2016 16:33:47:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15410852 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0441s; samplesPerSecond = 29019.0
08/19/2016 16:33:47: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15899674 * 10000; EvalClassificationError = 0.07470000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.381376s
08/19/2016 16:33:47: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.32'

08/19/2016 16:33:47: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: samples [320000..330000] (first sequence at sample 320000), worker rank 0, total workers 1

08/19/2016 16:33:47: Starting minibatch loop.
08/19/2016 16:33:47:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16432745 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0593s; samplesPerSecond = 21569.2
08/19/2016 16:33:47:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17564254 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0710s; samplesPerSecond = 18027.2
08/19/2016 16:33:47:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15467417 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0860s; samplesPerSecond = 14892.4
08/19/2016 16:33:47:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15989146 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0787s; samplesPerSecond = 16267.0
08/19/2016 16:33:47:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14214611 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0411s; samplesPerSecond = 31108.7
08/19/2016 16:33:47:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15155435 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0486s; samplesPerSecond = 26329.3
08/19/2016 16:33:48:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17212152 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0456s; samplesPerSecond = 28100.4
08/19/2016 16:33:48: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15995261 * 10000; EvalClassificationError = 0.07600000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.480142s
08/19/2016 16:33:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.33'

08/19/2016 16:33:48: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: samples [330000..340000] (first sequence at sample 330000), worker rank 0, total workers 1

08/19/2016 16:33:48: Starting minibatch loop.
08/19/2016 16:33:48:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13921940 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0452s; samplesPerSecond = 28305.4
08/19/2016 16:33:48:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16276338 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0454s; samplesPerSecond = 28192.6
08/19/2016 16:33:48:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17090077 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0490s; samplesPerSecond = 26135.2
08/19/2016 16:33:48:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14848137 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0396s; samplesPerSecond = 32295.5
08/19/2016 16:33:48:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16527205 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0448s; samplesPerSecond = 28545.9
08/19/2016 16:33:48:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17159896 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0399s; samplesPerSecond = 32085.8
08/19/2016 16:33:48:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16636944 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0451s; samplesPerSecond = 28408.5
08/19/2016 16:33:48: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15936185 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.355095s
08/19/2016 16:33:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.34'

08/19/2016 16:33:48: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: samples [340000..350000] (first sequence at sample 340000), worker rank 0, total workers 1

08/19/2016 16:33:48: Starting minibatch loop.
08/19/2016 16:33:48:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16906831 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0683s; samplesPerSecond = 18738.1
08/19/2016 16:33:48:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14418762 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0615s; samplesPerSecond = 20807.3
08/19/2016 16:33:48:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15848703 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0401s; samplesPerSecond = 31958.5
08/19/2016 16:33:48:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16318016 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0458s; samplesPerSecond = 27934.2
08/19/2016 16:33:48:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15352073 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0570s; samplesPerSecond = 22452.2
08/19/2016 16:33:48:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14742355 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0429s; samplesPerSecond = 29822.2
08/19/2016 16:33:48:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16554461 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0484s; samplesPerSecond = 26450.7
08/19/2016 16:33:48: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15775419 * 10000; EvalClassificationError = 0.07640000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.405176s
08/19/2016 16:33:48: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.35'

08/19/2016 16:33:48: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: samples [350000..360000] (first sequence at sample 350000), worker rank 0, total workers 1

08/19/2016 16:33:48: Starting minibatch loop.
08/19/2016 16:33:48:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15373988 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0454s; samplesPerSecond = 28207.5
08/19/2016 16:33:48:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19182353 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0443s; samplesPerSecond = 28886.7
08/19/2016 16:33:48:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15158510 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0450s; samplesPerSecond = 28434.3
08/19/2016 16:33:49:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15708623 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0450s; samplesPerSecond = 28438.1
08/19/2016 16:33:49:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14619441 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0401s; samplesPerSecond = 31882.0
08/19/2016 16:33:49:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13910189 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0482s; samplesPerSecond = 26580.3
08/19/2016 16:33:49:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15226831 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0644s; samplesPerSecond = 19873.9
08/19/2016 16:33:49: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15698862 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.38524s
08/19/2016 16:33:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.36'

08/19/2016 16:33:49: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: samples [360000..370000] (first sequence at sample 360000), worker rank 0, total workers 1

08/19/2016 16:33:49: Starting minibatch loop.
08/19/2016 16:33:49:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17271135 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0555s; samplesPerSecond = 23079.7
08/19/2016 16:33:49:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15075927 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0450s; samplesPerSecond = 28435.6
08/19/2016 16:33:49:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15440285 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0438s; samplesPerSecond = 29204.4
08/19/2016 16:33:49:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12932644 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0451s; samplesPerSecond = 28351.8
08/19/2016 16:33:49:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16559262 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.1030s; samplesPerSecond = 12429.5
08/19/2016 16:33:49:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14702005 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.1667s; samplesPerSecond = 7677.6
08/19/2016 16:33:49:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16273041 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0541s; samplesPerSecond = 23656.4
08/19/2016 16:33:49: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15447838 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.557965s
08/19/2016 16:33:49: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.37'

08/19/2016 16:33:49: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: samples [370000..380000] (first sequence at sample 370000), worker rank 0, total workers 1

08/19/2016 16:33:49: Starting minibatch loop.
08/19/2016 16:33:49:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17086877 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0471s; samplesPerSecond = 27165.8
08/19/2016 16:33:49:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14715701 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0477s; samplesPerSecond = 26838.3
08/19/2016 16:33:49:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14940424 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0648s; samplesPerSecond = 19739.7
08/19/2016 16:33:50:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16454654 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0661s; samplesPerSecond = 19375.2
08/19/2016 16:33:50:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14210200 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0586s; samplesPerSecond = 21852.7
08/19/2016 16:33:50:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16033564 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0447s; samplesPerSecond = 28611.7
08/19/2016 16:33:50:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14252691 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0520s; samplesPerSecond = 24623.4
08/19/2016 16:33:50: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15447964 * 10000; EvalClassificationError = 0.07520000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.426241s
08/19/2016 16:33:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.38'

08/19/2016 16:33:50: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: samples [380000..390000] (first sequence at sample 380000), worker rank 0, total workers 1

08/19/2016 16:33:50: Starting minibatch loop.
08/19/2016 16:33:50:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15245643 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0407s; samplesPerSecond = 31445.8
08/19/2016 16:33:50:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14150627 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0449s; samplesPerSecond = 28483.7
08/19/2016 16:33:50:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15755618 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0436s; samplesPerSecond = 29380.7
08/19/2016 16:33:50:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15467634 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0610s; samplesPerSecond = 20985.7
08/19/2016 16:33:50:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15592103 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0455s; samplesPerSecond = 28105.3
08/19/2016 16:33:50:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17342634 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0487s; samplesPerSecond = 26284.4
08/19/2016 16:33:50:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17978611 * 1280; EvalClassificationError = 0.09375000 * 1280; time = 0.0887s; samplesPerSecond = 14436.4
08/19/2016 16:33:50: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15823718 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.414511s
08/19/2016 16:33:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.39'

08/19/2016 16:33:50: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: samples [390000..400000] (first sequence at sample 390000), worker rank 0, total workers 1

08/19/2016 16:33:50: Starting minibatch loop.
08/19/2016 16:33:50:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18975165 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0500s; samplesPerSecond = 25622.0
08/19/2016 16:33:50:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14647384 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0554s; samplesPerSecond = 23097.2
08/19/2016 16:33:50:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15599782 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0481s; samplesPerSecond = 26618.4
08/19/2016 16:33:50:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15626078 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0399s; samplesPerSecond = 32108.4
08/19/2016 16:33:50:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15985618 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0349s; samplesPerSecond = 36720.4
08/19/2016 16:33:50:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16492434 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0354s; samplesPerSecond = 36191.9
08/19/2016 16:33:50:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14662266 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0372s; samplesPerSecond = 34445.6
08/19/2016 16:33:50: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15780455 * 10000; EvalClassificationError = 0.07550000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.343746s
08/19/2016 16:33:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.40'

08/19/2016 16:33:50: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: samples [400000..410000] (first sequence at sample 400000), worker rank 0, total workers 1

08/19/2016 16:33:50: Starting minibatch loop.
08/19/2016 16:33:51:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16937313 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0415s; samplesPerSecond = 30875.4
08/19/2016 16:33:51:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13820338 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0444s; samplesPerSecond = 28850.3
08/19/2016 16:33:51:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15636759 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0401s; samplesPerSecond = 31893.2
08/19/2016 16:33:51:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15901370 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0451s; samplesPerSecond = 28403.4
08/19/2016 16:33:51:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15166659 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.1225s; samplesPerSecond = 10452.1
08/19/2016 16:33:51:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15241694 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0485s; samplesPerSecond = 26371.6
08/19/2016 16:33:51:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15653992 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0404s; samplesPerSecond = 31680.0
08/19/2016 16:33:51: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.15444568 * 10000; EvalClassificationError = 0.07310000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.427799s
08/19/2016 16:33:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.41'

08/19/2016 16:33:51: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: samples [410000..420000] (first sequence at sample 410000), worker rank 0, total workers 1

08/19/2016 16:33:51: Starting minibatch loop.
08/19/2016 16:33:51:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15034850 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.1892s; samplesPerSecond = 6766.8
08/19/2016 16:33:51:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14989810 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.1079s; samplesPerSecond = 11862.9
08/19/2016 16:33:51:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15917447 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0743s; samplesPerSecond = 17230.0
08/19/2016 16:33:52:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15578227 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0443s; samplesPerSecond = 28869.8
08/19/2016 16:33:52:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16280832 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.1208s; samplesPerSecond = 10596.0
08/19/2016 16:33:52:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16846328 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0603s; samplesPerSecond = 21212.1
08/19/2016 16:33:52:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17319460 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0566s; samplesPerSecond = 22614.4
08/19/2016 16:33:52: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15898715 * 10000; EvalClassificationError = 0.07500000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.692808s
08/19/2016 16:33:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.42'

08/19/2016 16:33:52: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: samples [420000..430000] (first sequence at sample 420000), worker rank 0, total workers 1

08/19/2016 16:33:52: Starting minibatch loop.
08/19/2016 16:33:52:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16630232 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0428s; samplesPerSecond = 29896.8
08/19/2016 16:33:52:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13294590 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0451s; samplesPerSecond = 28359.4
08/19/2016 16:33:52:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15917592 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0600s; samplesPerSecond = 21344.4
08/19/2016 16:33:52:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15790648 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0438s; samplesPerSecond = 29241.8
08/19/2016 16:33:52:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16472116 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0439s; samplesPerSecond = 29182.4
08/19/2016 16:33:52:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14034104 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0706s; samplesPerSecond = 18133.9
08/19/2016 16:33:52:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16955996 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0437s; samplesPerSecond = 29318.1
08/19/2016 16:33:52: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.15555939 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.417286s
08/19/2016 16:33:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.43'

08/19/2016 16:33:52: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: samples [430000..440000] (first sequence at sample 430000), worker rank 0, total workers 1

08/19/2016 16:33:52: Starting minibatch loop.
08/19/2016 16:33:52:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16926425 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0401s; samplesPerSecond = 31892.4
08/19/2016 16:33:52:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16363909 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0383s; samplesPerSecond = 33462.3
08/19/2016 16:33:52:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13639560 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0442s; samplesPerSecond = 28963.9
08/19/2016 16:33:52:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16664824 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0451s; samplesPerSecond = 28373.2
08/19/2016 16:33:52:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16281099 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0445s; samplesPerSecond = 28733.7
08/19/2016 16:33:52:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13564277 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0432s; samplesPerSecond = 29607.0
08/19/2016 16:33:53:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16526623 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0466s; samplesPerSecond = 27492.0
08/19/2016 16:33:53: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.15709543 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.347777s
08/19/2016 16:33:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.44'

08/19/2016 16:33:53: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: samples [440000..450000] (first sequence at sample 440000), worker rank 0, total workers 1

08/19/2016 16:33:53: Starting minibatch loop.
08/19/2016 16:33:53:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16758119 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0396s; samplesPerSecond = 32318.3
08/19/2016 16:33:53:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14725617 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0481s; samplesPerSecond = 26628.9
08/19/2016 16:33:53:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16129522 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0400s; samplesPerSecond = 31974.4
08/19/2016 16:33:53:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16227779 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0432s; samplesPerSecond = 29601.5
08/19/2016 16:33:53:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15812407 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0445s; samplesPerSecond = 28751.1
08/19/2016 16:33:53:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14453869 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0397s; samplesPerSecond = 32233.7
08/19/2016 16:33:53:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15846958 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0386s; samplesPerSecond = 33189.9
08/19/2016 16:33:53: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15527954 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.342744s
08/19/2016 16:33:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.45'

08/19/2016 16:33:53: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: samples [450000..460000] (first sequence at sample 450000), worker rank 0, total workers 1

08/19/2016 16:33:53: Starting minibatch loop.
08/19/2016 16:33:53:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13163282 * 1280; EvalClassificationError = 0.05625000 * 1280; time = 0.0668s; samplesPerSecond = 19166.6
08/19/2016 16:33:53:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17128526 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0369s; samplesPerSecond = 34679.9
08/19/2016 16:33:53:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15425169 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0332s; samplesPerSecond = 38555.4
08/19/2016 16:33:53:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15192246 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0518s; samplesPerSecond = 24708.5
08/19/2016 16:33:53:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16164589 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0447s; samplesPerSecond = 28609.7
08/19/2016 16:33:53:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16738510 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0713s; samplesPerSecond = 17963.1
08/19/2016 16:33:53:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16348057 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.1100s; samplesPerSecond = 11639.3
08/19/2016 16:33:53: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.15742212 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.453155s
08/19/2016 16:33:53: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.46'

08/19/2016 16:33:53: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: samples [460000..470000] (first sequence at sample 460000), worker rank 0, total workers 1

08/19/2016 16:33:53: Starting minibatch loop.
08/19/2016 16:33:53:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16164534 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0464s; samplesPerSecond = 27576.7
08/19/2016 16:33:53:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16455069 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0470s; samplesPerSecond = 27205.1
08/19/2016 16:33:53:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16870224 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0471s; samplesPerSecond = 27188.9
08/19/2016 16:33:54:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12883611 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0446s; samplesPerSecond = 28691.2
08/19/2016 16:33:54:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14594216 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0398s; samplesPerSecond = 32157.6
08/19/2016 16:33:54:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15981736 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0445s; samplesPerSecond = 28788.6
08/19/2016 16:33:54:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14501286 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0449s; samplesPerSecond = 28526.2
08/19/2016 16:33:54: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.15290609 * 10000; EvalClassificationError = 0.07500000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.352175s
08/19/2016 16:33:54: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.47'

08/19/2016 16:33:54: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: samples [470000..480000] (first sequence at sample 470000), worker rank 0, total workers 1

08/19/2016 16:33:54: Starting minibatch loop.
08/19/2016 16:33:54:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16257973 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0539s; samplesPerSecond = 23731.4
08/19/2016 16:33:54:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16322253 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0477s; samplesPerSecond = 26833.3
08/19/2016 16:33:54:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16032908 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0674s; samplesPerSecond = 18994.8
08/19/2016 16:33:54:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15169978 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0572s; samplesPerSecond = 22390.5
08/19/2016 16:33:54:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15752783 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0815s; samplesPerSecond = 15709.0
08/19/2016 16:33:54:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14941444 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0823s; samplesPerSecond = 15556.8
08/19/2016 16:33:54:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14432421 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0444s; samplesPerSecond = 28828.8
08/19/2016 16:33:54: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.15491810 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.518098s
08/19/2016 16:33:54: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.48'

08/19/2016 16:33:54: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: samples [480000..490000] (first sequence at sample 480000), worker rank 0, total workers 1

08/19/2016 16:33:54: Starting minibatch loop.
08/19/2016 16:33:54:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16991398 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0447s; samplesPerSecond = 28626.4
08/19/2016 16:33:54:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15043983 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0589s; samplesPerSecond = 21717.7
08/19/2016 16:33:54:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16458757 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0436s; samplesPerSecond = 29383.4
08/19/2016 16:33:54:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15567188 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0445s; samplesPerSecond = 28791.2
08/19/2016 16:33:54:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14840384 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0405s; samplesPerSecond = 31609.6
08/19/2016 16:33:55:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15142775 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0381s; samplesPerSecond = 33638.2
08/19/2016 16:33:55:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19236526 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0385s; samplesPerSecond = 33252.8
08/19/2016 16:33:55: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.16079437 * 10000; EvalClassificationError = 0.07610000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.348s
08/19/2016 16:33:55: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.49'

08/19/2016 16:33:55: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/19/2016 16:33:55: Starting minibatch loop.
08/19/2016 16:33:55:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15400996 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0431s; samplesPerSecond = 29665.3
08/19/2016 16:33:55:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14237223 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0753s; samplesPerSecond = 17000.0
08/19/2016 16:33:55:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15252090 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0438s; samplesPerSecond = 29248.5
08/19/2016 16:33:55:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16386971 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0404s; samplesPerSecond = 31709.1
08/19/2016 16:33:55:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14503131 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0441s; samplesPerSecond = 29049.3
08/19/2016 16:33:55:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16062880 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0451s; samplesPerSecond = 28352.5
08/19/2016 16:33:55:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15499449 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0440s; samplesPerSecond = 29077.7
08/19/2016 16:33:55: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15345079 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.412333s
08/19/2016 16:33:55: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn'
08/19/2016 16:33:55: CNTKCommandTrainEnd: Simple_Demo

08/19/2016 16:33:55: Action "train" complete.


08/19/2016 16:33:55: ##############################################################################
08/19/2016 16:33:55: #                                                                            #
08/19/2016 16:33:55: # Action "write"                                                             #
08/19/2016 16:33:55: #                                                                            #
08/19/2016 16:33:55: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/19/2016 16:33:55: Action "write" complete.

08/19/2016 16:33:55: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 19 2016 15:29:02
		Last modified date: Thu Aug 18 15:17:07 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 9ad9bd04f89696255e558f3c8b774151021635f6
		Built by philly on 643085f7f8c2
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
08/19/2016 16:33:55: -------------------------------------------------------------------
08/19/2016 16:33:55: Build info: 

08/19/2016 16:33:55: 		Built time: Aug 19 2016 15:29:02
08/19/2016 16:33:55: 		Last modified date: Thu Aug 18 15:17:07 2016
08/19/2016 16:33:55: 		Build type: release
08/19/2016 16:33:55: 		Build target: GPU
08/19/2016 16:33:55: 		With 1bit-SGD: no
08/19/2016 16:33:55: 		Math lib: mkl
08/19/2016 16:33:55: 		CUDA_PATH: /usr/local/cuda-7.5
08/19/2016 16:33:55: 		CUB_PATH: /usr/local/cub-1.4.1
08/19/2016 16:33:55: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/19/2016 16:33:55: 		Build Branch: HEAD
08/19/2016 16:33:55: 		Build SHA1: 9ad9bd04f89696255e558f3c8b774151021635f6
08/19/2016 16:33:55: 		Built by philly on 643085f7f8c2
08/19/2016 16:33:55: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/19/2016 16:33:55: -------------------------------------------------------------------
08/19/2016 16:33:56: -------------------------------------------------------------------
08/19/2016 16:33:56: GPU info:

08/19/2016 16:33:56: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:56: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:56: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:56: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/19/2016 16:33:56: -------------------------------------------------------------------

08/19/2016 16:33:56: Running on localhost at 2016/08/19 16:33:56
08/19/2016 16:33:56: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



08/19/2016 16:33:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/19/2016 16:33:56: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/19/2016 16:33:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/19/2016 16:33:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/19/2016 16:33:56: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/19/2016 16:33:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/19/2016 16:33:56: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/19/2016 16:33:56: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/19/2016 16:33:56: Commands: Simple_Demo Simple_Demo_Output
08/19/2016 16:33:56: Precision = "float"
08/19/2016 16:33:56: CNTKModelPath: /tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn
08/19/2016 16:33:56: CNTKCommandTrainInfo: Simple_Demo : 50
08/19/2016 16:33:56: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/19/2016 16:33:56: ##############################################################################
08/19/2016 16:33:56: #                                                                            #
08/19/2016 16:33:56: # Action "train"                                                             #
08/19/2016 16:33:56: #                                                                            #
08/19/2016 16:33:56: ##############################################################################

08/19/2016 16:33:56: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/19/2016 16:33:56: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/19/2016 16:33:56: Loaded model with 25 nodes on CPU.

08/19/2016 16:33:56: Training criterion node(s):
08/19/2016 16:33:56: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/19/2016 16:33:56: Evaluation criterion node(s):
08/19/2016 16:33:56: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }
	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }


08/19/2016 16:33:56: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/19/2016 16:33:56: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/19/2016 16:33:56: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/19/2016 16:33:56: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/19/2016 16:33:56: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/19/2016 16:33:56: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/19/2016 16:33:56: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

08/19/2016 16:33:56: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/19/2016 16:33:56: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/19/2016 16:33:56: Starting minibatch loop.
08/19/2016 16:33:56:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.15400996 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.2134s; samplesPerSecond = 5999.1
08/19/2016 16:33:56:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.14237223 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0578s; samplesPerSecond = 22140.7
08/19/2016 16:33:56:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15252090 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0453s; samplesPerSecond = 28233.0
08/19/2016 16:33:56:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.16386971 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0472s; samplesPerSecond = 27107.2
08/19/2016 16:33:56:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.14503131 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0461s; samplesPerSecond = 27748.9
08/19/2016 16:33:56:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.16062880 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0408s; samplesPerSecond = 31376.4
08/19/2016 16:33:57:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.15499449 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0453s; samplesPerSecond = 28269.2
08/19/2016 16:33:57: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15345079 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.547358s
08/19/2016 16:33:57: SGD: Saving checkpoint model '/tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/models/simple.dnn'
08/19/2016 16:33:57: CNTKCommandTrainEnd: Simple_Demo

08/19/2016 16:33:57: Action "train" complete.


08/19/2016 16:33:57: ##############################################################################
08/19/2016 16:33:57: #                                                                            #
08/19/2016 16:33:57: # Action "write"                                                             #
08/19/2016 16:33:57: #                                                                            #
08/19/2016 16:33:57: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160819162833.129025/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/19/2016 16:33:57: Action "write" complete.

08/19/2016 16:33:57: __COMPLETED__
