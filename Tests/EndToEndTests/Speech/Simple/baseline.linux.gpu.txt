CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 16 2016 09:41:56
		Last modified date: Fri Aug 12 07:32:43 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
		Built by philly on f67b30a647de
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
08/16/2016 10:01:48: -------------------------------------------------------------------
08/16/2016 10:01:48: Build info: 

08/16/2016 10:01:48: 		Built time: Aug 16 2016 09:41:56
08/16/2016 10:01:48: 		Last modified date: Fri Aug 12 07:32:43 2016
08/16/2016 10:01:48: 		Build type: release
08/16/2016 10:01:48: 		Build target: GPU
08/16/2016 10:01:48: 		With 1bit-SGD: no
08/16/2016 10:01:48: 		Math lib: mkl
08/16/2016 10:01:48: 		CUDA_PATH: /usr/local/cuda-7.5
08/16/2016 10:01:48: 		CUB_PATH: /usr/local/cub-1.4.1
08/16/2016 10:01:48: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/16/2016 10:01:48: 		Build Branch: HEAD
08/16/2016 10:01:48: 		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
08/16/2016 10:01:48: 		Built by philly on f67b30a647de
08/16/2016 10:01:48: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/16/2016 10:01:48: -------------------------------------------------------------------
08/16/2016 10:01:49: -------------------------------------------------------------------
08/16/2016 10:01:49: GPU info:

08/16/2016 10:01:49: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:49: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:49: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:49: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:49: -------------------------------------------------------------------

08/16/2016 10:01:49: Running on localhost at 2016/08/16 10:01:49
08/16/2016 10:01:49: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu  DeviceId=0  timestamping=true



08/16/2016 10:01:49: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/16/2016 10:01:49: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DeviceId=0
timestamping=true

08/16/2016 10:01:49: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/16/2016 10:01:49: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/16/2016 10:01:49: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DeviceId=0
timestamping=true

08/16/2016 10:01:49: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/16/2016 10:01:49: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/16/2016 10:01:49: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/16/2016 10:01:49: Commands: Simple_Demo Simple_Demo_Output
08/16/2016 10:01:49: Precision = "float"
08/16/2016 10:01:49: CNTKModelPath: /tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn
08/16/2016 10:01:49: CNTKCommandTrainInfo: Simple_Demo : 50
08/16/2016 10:01:49: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/16/2016 10:01:49: ##############################################################################
08/16/2016 10:01:49: #                                                                            #
08/16/2016 10:01:49: # Action "train"                                                             #
08/16/2016 10:01:49: #                                                                            #
08/16/2016 10:01:49: ##############################################################################

08/16/2016 10:01:49: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

08/16/2016 10:01:49: Creating virgin network.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, range=0.050000*1.000000, onCPU=false).
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/16/2016 10:01:49: Created model with 25 nodes on GPU 0.

08/16/2016 10:01:49: Training criterion node(s):
08/16/2016 10:01:49: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/16/2016 10:01:49: Evaluation criterion node(s):
08/16/2016 10:01:49: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }
	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }


08/16/2016 10:01:49: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/16/2016 10:01:49: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/16/2016 10:01:49: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/16/2016 10:01:49: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/16/2016 10:01:49: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/16/2016 10:01:49: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/16/2016 10:01:49: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


08/16/2016 10:01:49: Precomputing --> 3 PreCompute nodes found.

08/16/2016 10:01:49: 	MeanOfFeatures = Mean()
08/16/2016 10:01:49: 	InvStdOfFeatures = InvStdDev()
08/16/2016 10:01:49: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/16/2016 10:01:50: Precomputing --> Completed.


08/16/2016 10:01:50: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.84310608 * 1280; EvalClassificationError = 0.51718750 * 1280; time = 0.0075s; samplesPerSecond = 170416.7
08/16/2016 10:01:50:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.79649162 * 1280; EvalClassificationError = 0.51562500 * 1280; time = 0.0062s; samplesPerSecond = 204832.8
08/16/2016 10:01:50:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.72212505 * 1280; EvalClassificationError = 0.48515625 * 1280; time = 0.0062s; samplesPerSecond = 206252.0
08/16/2016 10:01:50:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71446991 * 1280; EvalClassificationError = 0.49765625 * 1280; time = 0.0064s; samplesPerSecond = 200815.8
08/16/2016 10:01:50:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.70253887 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0061s; samplesPerSecond = 208843.2
08/16/2016 10:01:50:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.70667038 * 1280; EvalClassificationError = 0.51718750 * 1280; time = 0.0061s; samplesPerSecond = 208707.0
08/16/2016 10:01:50:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.70342636 * 1280; EvalClassificationError = 0.50156250 * 1280; time = 0.0061s; samplesPerSecond = 208605.0
08/16/2016 10:01:50: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.73692178 * 10000; EvalClassificationError = 0.50500000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.052049s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.1'

08/16/2016 10:01:50: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70579815 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0071s; samplesPerSecond = 181508.8
08/16/2016 10:01:50:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74300938 * 1280; EvalClassificationError = 0.47968750 * 1280; time = 0.0066s; samplesPerSecond = 195151.7
08/16/2016 10:01:50:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.74903145 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0066s; samplesPerSecond = 193880.6
08/16/2016 10:01:50:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.74969635 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0066s; samplesPerSecond = 193998.2
08/16/2016 10:01:50:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.74229851 * 1280; EvalClassificationError = 0.50234375 * 1280; time = 0.0065s; samplesPerSecond = 197105.0
08/16/2016 10:01:50:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.72703133 * 1280; EvalClassificationError = 0.50546875 * 1280; time = 0.0069s; samplesPerSecond = 184331.8
08/16/2016 10:01:50:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.73382492 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0065s; samplesPerSecond = 195898.4
08/16/2016 10:01:50: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.73301997 * 10000; EvalClassificationError = 0.49860000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.053407s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.2'

08/16/2016 10:01:50: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.73711967 * 1280; EvalClassificationError = 0.50000000 * 1280; time = 0.0071s; samplesPerSecond = 179851.1
08/16/2016 10:01:50:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.73554993 * 1280; EvalClassificationError = 0.50625000 * 1280; time = 0.0067s; samplesPerSecond = 189939.2
08/16/2016 10:01:50:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.76822968 * 1280; EvalClassificationError = 0.52187500 * 1280; time = 0.0065s; samplesPerSecond = 197409.0
08/16/2016 10:01:50:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75786591 * 1280; EvalClassificationError = 0.50234375 * 1280; time = 0.0063s; samplesPerSecond = 202020.2
08/16/2016 10:01:50:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73280945 * 1280; EvalClassificationError = 0.50937500 * 1280; time = 0.0064s; samplesPerSecond = 199594.6
08/16/2016 10:01:50:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71082764 * 1280; EvalClassificationError = 0.48984375 * 1280; time = 0.0070s; samplesPerSecond = 182700.5
08/16/2016 10:01:50:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69263992 * 1280; EvalClassificationError = 0.50703125 * 1280; time = 0.0064s; samplesPerSecond = 199470.2
08/16/2016 10:01:50: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.72925479 * 10000; EvalClassificationError = 0.49610000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.053183s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.3'

08/16/2016 10:01:50: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69856057 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0066s; samplesPerSecond = 193587.4
08/16/2016 10:01:50:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.68708320 * 1280; EvalClassificationError = 0.47031250 * 1280; time = 0.0064s; samplesPerSecond = 200438.5
08/16/2016 10:01:50:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.44454384 * 1280; EvalClassificationError = 0.18593750 * 1280; time = 0.0063s; samplesPerSecond = 202339.6
08/16/2016 10:01:50:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20331936 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0065s; samplesPerSecond = 197836.2
08/16/2016 10:01:50:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16972294 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0063s; samplesPerSecond = 202435.6
08/16/2016 10:01:50:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16289215 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0065s; samplesPerSecond = 197744.5
08/16/2016 10:01:50:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16081238 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0064s; samplesPerSecond = 201447.9
08/16/2016 10:01:50: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.34526641 * 10000; EvalClassificationError = 0.19350000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.051481s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.4'

08/16/2016 10:01:50: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18459463 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0066s; samplesPerSecond = 194292.7
08/16/2016 10:01:50:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17662528 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0064s; samplesPerSecond = 201099.8
08/16/2016 10:01:50:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15586002 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0063s; samplesPerSecond = 201829.1
08/16/2016 10:01:50:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15864964 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0064s; samplesPerSecond = 200910.4
08/16/2016 10:01:50:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18221016 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0063s; samplesPerSecond = 202499.6
08/16/2016 10:01:50:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16875315 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0063s; samplesPerSecond = 201892.7
08/16/2016 10:01:50:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17399311 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0064s; samplesPerSecond = 201416.2
08/16/2016 10:01:50: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16924459 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.051314s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.5'

08/16/2016 10:01:50: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19218915 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0066s; samplesPerSecond = 194440.2
08/16/2016 10:01:50:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19492443 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0063s; samplesPerSecond = 202692.0
08/16/2016 10:01:50:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16309171 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0065s; samplesPerSecond = 198388.1
08/16/2016 10:01:50:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16469927 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0063s; samplesPerSecond = 203336.0
08/16/2016 10:01:50:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17971587 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0064s; samplesPerSecond = 200721.3
08/16/2016 10:01:50:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16465130 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0063s; samplesPerSecond = 202563.7
08/16/2016 10:01:50:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16045485 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0064s; samplesPerSecond = 200532.7
08/16/2016 10:01:50: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.17021433 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.051798s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.6'

08/16/2016 10:01:50: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15642909 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0065s; samplesPerSecond = 196379.3
08/16/2016 10:01:50:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16490401 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0064s; samplesPerSecond = 198511.2
08/16/2016 10:01:50:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15031970 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0063s; samplesPerSecond = 202115.9
08/16/2016 10:01:50:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13484669 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0064s; samplesPerSecond = 201068.2
08/16/2016 10:01:50:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14183764 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0064s; samplesPerSecond = 200689.9
08/16/2016 10:01:50:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17524877 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0064s; samplesPerSecond = 201447.9
08/16/2016 10:01:50:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16879549 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0063s; samplesPerSecond = 202916.9
08/16/2016 10:01:50: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16104001 * 10000; EvalClassificationError = 0.07610000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.051253s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.7'

08/16/2016 10:01:50: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19399148 * 1280; EvalClassificationError = 0.09375000 * 1280; time = 0.0069s; samplesPerSecond = 186154.7
08/16/2016 10:01:50:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18360873 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0063s; samplesPerSecond = 202788.3
08/16/2016 10:01:50:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18547022 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0062s; samplesPerSecond = 206785.1
08/16/2016 10:01:50:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17984591 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0062s; samplesPerSecond = 205490.4
08/16/2016 10:01:50:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17576346 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 209526.9
08/16/2016 10:01:50:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.20375605 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0061s; samplesPerSecond = 209355.6
08/16/2016 10:01:50:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15429964 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0061s; samplesPerSecond = 208673.0
08/16/2016 10:01:50: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.18108601 * 10000; EvalClassificationError = 0.08070000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.050602s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.8'

08/16/2016 10:01:50: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17657450 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0064s; samplesPerSecond = 201289.5
08/16/2016 10:01:50:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17487627 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 208605.0
08/16/2016 10:01:50:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17738194 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0061s; samplesPerSecond = 209424.1
08/16/2016 10:01:50:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17675438 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 208435.1
08/16/2016 10:01:50:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16243391 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0061s; samplesPerSecond = 209287.1
08/16/2016 10:01:50:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14487505 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0061s; samplesPerSecond = 210077.1
08/16/2016 10:01:50:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14202633 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0061s; samplesPerSecond = 209287.1
08/16/2016 10:01:50: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.16574330 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.049429s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.9'

08/16/2016 10:01:50: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16489167 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0063s; samplesPerSecond = 203854.1
08/16/2016 10:01:50:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14849167 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0062s; samplesPerSecond = 207489.1
08/16/2016 10:01:50:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16935616 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0061s; samplesPerSecond = 210907.9
08/16/2016 10:01:50:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15455165 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0063s; samplesPerSecond = 203174.6
08/16/2016 10:01:50:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.21274233 * 1280; EvalClassificationError = 0.09375000 * 1280; time = 0.0061s; samplesPerSecond = 209732.9
08/16/2016 10:01:50:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16063108 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0061s; samplesPerSecond = 211535.3
08/16/2016 10:01:50:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17145748 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0061s; samplesPerSecond = 210942.6
08/16/2016 10:01:50: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16641783 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.049482s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.10'

08/16/2016 10:01:50: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17450614 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0063s; samplesPerSecond = 202275.6
08/16/2016 10:01:50:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16514256 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0061s; samplesPerSecond = 209287.1
08/16/2016 10:01:50:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17608402 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0061s; samplesPerSecond = 210008.2
08/16/2016 10:01:50:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16732321 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0062s; samplesPerSecond = 205754.7
08/16/2016 10:01:50:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16031547 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0061s; samplesPerSecond = 209561.2
08/16/2016 10:01:50:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15653191 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0061s; samplesPerSecond = 209767.3
08/16/2016 10:01:50:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16287127 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 209973.8
08/16/2016 10:01:50: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.17136853 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.049438s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.11'

08/16/2016 10:01:50: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16789967 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0064s; samplesPerSecond = 200847.3
08/16/2016 10:01:50:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17225724 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0061s; samplesPerSecond = 208231.7
08/16/2016 10:01:50:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17605832 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0061s; samplesPerSecond = 209904.9
08/16/2016 10:01:50:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16139808 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0062s; samplesPerSecond = 205358.6
08/16/2016 10:01:50:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15683770 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0062s; samplesPerSecond = 207994.8
08/16/2016 10:01:50:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16268196 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 211430.5
08/16/2016 10:01:50:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14391632 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0061s; samplesPerSecond = 210907.9
08/16/2016 10:01:50: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16267987 * 10000; EvalClassificationError = 0.07550000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.049803s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.12'

08/16/2016 10:01:50: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14964317 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0064s; samplesPerSecond = 201543.1
08/16/2016 10:01:50:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17667559 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0061s; samplesPerSecond = 209116.2
08/16/2016 10:01:50:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17469652 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0061s; samplesPerSecond = 208333.3
08/16/2016 10:01:50:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15370793 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0062s; samplesPerSecond = 207354.6
08/16/2016 10:01:50:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14474144 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0061s; samplesPerSecond = 209458.4
08/16/2016 10:01:50:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16730952 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 209424.1
08/16/2016 10:01:50:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15163937 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0061s; samplesPerSecond = 210180.6
08/16/2016 10:01:50: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16008048 * 10000; EvalClassificationError = 0.07610000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.049536s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.13'

08/16/2016 10:01:50: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19452736 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0064s; samplesPerSecond = 200344.3
08/16/2016 10:01:50:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20183799 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0062s; samplesPerSecond = 206918.8
08/16/2016 10:01:50:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17685056 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 209732.9
08/16/2016 10:01:50:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20354209 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0063s; samplesPerSecond = 204669.0
08/16/2016 10:01:50:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18834009 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0061s; samplesPerSecond = 209595.5
08/16/2016 10:01:50:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16556721 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0061s; samplesPerSecond = 211395.5
08/16/2016 10:01:50:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15758457 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0061s; samplesPerSecond = 209595.5
08/16/2016 10:01:50: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.18295509 * 10000; EvalClassificationError = 0.08140000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.049546s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.14'

08/16/2016 10:01:50: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17045991 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0063s; samplesPerSecond = 202339.6
08/16/2016 10:01:50:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14826863 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0061s; samplesPerSecond = 211221.1
08/16/2016 10:01:50:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17499018 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 209458.4
08/16/2016 10:01:50:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17048912 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0062s; samplesPerSecond = 204931.2
08/16/2016 10:01:50:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16545115 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 208877.3
08/16/2016 10:01:50:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16484280 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0061s; samplesPerSecond = 210353.3
08/16/2016 10:01:50:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15723133 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0061s; samplesPerSecond = 209767.3
08/16/2016 10:01:50: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16392716 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.049491s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.15'

08/16/2016 10:01:50: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17300388 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0064s; samplesPerSecond = 201068.2
08/16/2016 10:01:50:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16495076 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0062s; samplesPerSecond = 207354.6
08/16/2016 10:01:50:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17640350 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 210942.6
08/16/2016 10:01:50:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17643890 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0062s; samplesPerSecond = 205161.1
08/16/2016 10:01:50:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18799286 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0061s; samplesPerSecond = 210249.7
08/16/2016 10:01:50:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17479095 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0061s; samplesPerSecond = 209801.7
08/16/2016 10:01:50:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17468281 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 210180.6
08/16/2016 10:01:50: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.17355865 * 10000; EvalClassificationError = 0.08010000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.049631s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.16'

08/16/2016 10:01:50: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15547787 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0063s; samplesPerSecond = 202595.8
08/16/2016 10:01:50:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16448799 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 210215.1
08/16/2016 10:01:50:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18492763 * 1280; EvalClassificationError = 0.09296875 * 1280; time = 0.0061s; samplesPerSecond = 208979.6
08/16/2016 10:01:50:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15973492 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0062s; samplesPerSecond = 207321.0
08/16/2016 10:01:50:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15464163 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 209939.3
08/16/2016 10:01:50:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15534620 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0061s; samplesPerSecond = 210249.7
08/16/2016 10:01:50:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15559587 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0062s; samplesPerSecond = 206952.3
08/16/2016 10:01:50: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16203708 * 10000; EvalClassificationError = 0.07860000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.049466s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.17'

08/16/2016 10:01:50: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15387502 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0064s; samplesPerSecond = 201289.5
08/16/2016 10:01:50:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15887523 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0061s; samplesPerSecond = 210215.1
08/16/2016 10:01:50:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16482134 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 210042.7
08/16/2016 10:01:50:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15368652 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0062s; samplesPerSecond = 206518.2
08/16/2016 10:01:50:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14909182 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0061s; samplesPerSecond = 209047.9
08/16/2016 10:01:50:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15584965 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 210422.5
08/16/2016 10:01:50:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15353718 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0061s; samplesPerSecond = 210146.1
08/16/2016 10:01:50: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15599124 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.049449s
08/16/2016 10:01:50: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.18'

08/16/2016 10:01:50: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

08/16/2016 10:01:50: Starting minibatch loop.
08/16/2016 10:01:50:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15185862 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0068s; samplesPerSecond = 187025.1
08/16/2016 10:01:50:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14511428 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0062s; samplesPerSecond = 208096.2
08/16/2016 10:01:50:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16339183 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0062s; samplesPerSecond = 207792.2
08/16/2016 10:01:51:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14803147 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0062s; samplesPerSecond = 205589.5
08/16/2016 10:01:51:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17850142 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0061s; samplesPerSecond = 209767.3
08/16/2016 10:01:51:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16295705 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0061s; samplesPerSecond = 210042.7
08/16/2016 10:01:51:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17260580 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0061s; samplesPerSecond = 210491.7
08/16/2016 10:01:51: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16107345 * 10000; EvalClassificationError = 0.07880000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.049963s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.19'

08/16/2016 10:01:51: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16136272 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0062s; samplesPerSecond = 204898.4
08/16/2016 10:01:51:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16000416 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0061s; samplesPerSecond = 209939.3
08/16/2016 10:01:51:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15729117 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0061s; samplesPerSecond = 208911.4
08/16/2016 10:01:51:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17018433 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0061s; samplesPerSecond = 208299.4
08/16/2016 10:01:51:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16124377 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0061s; samplesPerSecond = 209664.2
08/16/2016 10:01:51:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15530777 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0061s; samplesPerSecond = 209458.4
08/16/2016 10:01:51:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16405993 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 210422.5
08/16/2016 10:01:51: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.15965645 * 10000; EvalClassificationError = 0.07630000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.049324s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.20'

08/16/2016 10:01:51: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16149700 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0062s; samplesPerSecond = 205622.5
08/16/2016 10:01:51:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14376297 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0062s; samplesPerSecond = 207657.4
08/16/2016 10:01:51:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15459526 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0061s; samplesPerSecond = 208469.1
08/16/2016 10:01:51:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14109788 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0062s; samplesPerSecond = 207354.6
08/16/2016 10:01:51:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15918331 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0061s; samplesPerSecond = 210907.9
08/16/2016 10:01:51:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16574650 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0061s; samplesPerSecond = 209664.2
08/16/2016 10:01:51:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16026459 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0061s; samplesPerSecond = 209629.9
08/16/2016 10:01:51: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15594359 * 10000; EvalClassificationError = 0.07760000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.049412s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.21'

08/16/2016 10:01:51: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15156336 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0067s; samplesPerSecond = 191330.3
08/16/2016 10:01:51:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13561721 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0062s; samplesPerSecond = 205953.3
08/16/2016 10:01:51:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16119771 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0062s; samplesPerSecond = 207287.4
08/16/2016 10:01:51:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16036229 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0061s; samplesPerSecond = 208163.9
08/16/2016 10:01:51:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15335422 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0062s; samplesPerSecond = 207691.1
08/16/2016 10:01:51:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14870081 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0061s; samplesPerSecond = 209150.3
08/16/2016 10:01:51:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18252916 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0061s; samplesPerSecond = 210353.3
08/16/2016 10:01:51: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.15802612 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.050324s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.22'

08/16/2016 10:01:51: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17649695 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0064s; samplesPerSecond = 199906.3
08/16/2016 10:01:51:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17540611 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0060s; samplesPerSecond = 214190.1
08/16/2016 10:01:51:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15473452 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 208707.0
08/16/2016 10:01:51:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17021165 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0060s; samplesPerSecond = 213368.9
08/16/2016 10:01:51:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15742469 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0060s; samplesPerSecond = 213689.5
08/16/2016 10:01:51:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16152945 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0060s; samplesPerSecond = 214369.5
08/16/2016 10:01:51:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14951353 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0060s; samplesPerSecond = 212307.2
08/16/2016 10:01:51: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16317336 * 10000; EvalClassificationError = 0.07840000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.048786s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.23'

08/16/2016 10:01:51: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16322435 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0062s; samplesPerSecond = 207825.9
08/16/2016 10:01:51:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17743517 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0060s; samplesPerSecond = 214801.1
08/16/2016 10:01:51:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14414515 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0060s; samplesPerSecond = 214333.6
08/16/2016 10:01:51:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12805438 * 1280; EvalClassificationError = 0.05859375 * 1280; time = 0.0060s; samplesPerSecond = 214369.5
08/16/2016 10:01:51:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17812719 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0059s; samplesPerSecond = 215524.5
08/16/2016 10:01:51:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13290920 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0060s; samplesPerSecond = 213262.2
08/16/2016 10:01:51:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15600262 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0059s; samplesPerSecond = 216216.2
08/16/2016 10:01:51: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.15501090 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.048211s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.24'

08/16/2016 10:01:51: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13686550 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0062s; samplesPerSecond = 207994.8
08/16/2016 10:01:51:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17400646 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0061s; samplesPerSecond = 210180.6
08/16/2016 10:01:51:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14073536 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0060s; samplesPerSecond = 214513.2
08/16/2016 10:01:51:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15342216 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0060s; samplesPerSecond = 212025.8
08/16/2016 10:01:51:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16745076 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0060s; samplesPerSecond = 213333.3
08/16/2016 10:01:51:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16927581 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0061s; samplesPerSecond = 209973.8
08/16/2016 10:01:51:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17954512 * 1280; EvalClassificationError = 0.09765625 * 1280; time = 0.0061s; samplesPerSecond = 209424.1
08/16/2016 10:01:51: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16094979 * 10000; EvalClassificationError = 0.07980000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.051849s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.25'

08/16/2016 10:01:51: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15746422 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0066s; samplesPerSecond = 192945.4
08/16/2016 10:01:51:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19772153 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0063s; samplesPerSecond = 204342.3
08/16/2016 10:01:51:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16204095 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0062s; samplesPerSecond = 205128.2
08/16/2016 10:01:51:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14501700 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0061s; samplesPerSecond = 211570.2
08/16/2016 10:01:51:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16413703 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 210422.5
08/16/2016 10:01:51:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12358284 * 1280; EvalClassificationError = 0.05312500 * 1280; time = 0.0061s; samplesPerSecond = 208571.0
08/16/2016 10:01:51:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16245909 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0061s; samplesPerSecond = 209150.3
08/16/2016 10:01:51: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15827272 * 10000; EvalClassificationError = 0.07500000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.050058s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.26'

08/16/2016 10:01:51: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16253564 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0067s; samplesPerSecond = 190419.5
08/16/2016 10:01:51:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16306875 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0061s; samplesPerSecond = 208163.9
08/16/2016 10:01:51:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14200211 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0062s; samplesPerSecond = 207724.8
08/16/2016 10:01:51:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15200095 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0061s; samplesPerSecond = 208775.1
08/16/2016 10:01:51:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15755296 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 210664.9
08/16/2016 10:01:51:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15269809 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0060s; samplesPerSecond = 212272.0
08/16/2016 10:01:51:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16627932 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0061s; samplesPerSecond = 208265.5
08/16/2016 10:01:51: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15596610 * 10000; EvalClassificationError = 0.07630000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.049958s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.27'

08/16/2016 10:01:51: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15554501 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0063s; samplesPerSecond = 203465.3
08/16/2016 10:01:51:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16508816 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0061s; samplesPerSecond = 209150.3
08/16/2016 10:01:51:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16708326 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0063s; samplesPerSecond = 204081.6
08/16/2016 10:01:51:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14226341 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 209561.2
08/16/2016 10:01:51:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14113979 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0061s; samplesPerSecond = 208265.5
08/16/2016 10:01:51:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15288949 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0061s; samplesPerSecond = 210353.3
08/16/2016 10:01:51:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16410732 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0061s; samplesPerSecond = 210215.1
08/16/2016 10:01:51: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15700087 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.049632s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.28'

08/16/2016 10:01:51: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15318733 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0063s; samplesPerSecond = 202179.8
08/16/2016 10:01:51:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13557602 * 1280; EvalClassificationError = 0.05859375 * 1280; time = 0.0061s; samplesPerSecond = 208707.0
08/16/2016 10:01:51:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16530411 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0061s; samplesPerSecond = 208741.0
08/16/2016 10:01:51:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14492359 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0061s; samplesPerSecond = 209047.9
08/16/2016 10:01:51:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16227589 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0061s; samplesPerSecond = 210664.9
08/16/2016 10:01:51:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14070592 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0060s; samplesPerSecond = 211605.2
08/16/2016 10:01:51:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16054277 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 209664.2
08/16/2016 10:01:51: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15657330 * 10000; EvalClassificationError = 0.07700000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.049282s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.29'

08/16/2016 10:01:51: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15556115 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0063s; samplesPerSecond = 202084.0
08/16/2016 10:01:51:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14724370 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 210942.6
08/16/2016 10:01:51:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14685407 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0063s; samplesPerSecond = 203336.0
08/16/2016 10:01:51:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16360621 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0061s; samplesPerSecond = 209767.3
08/16/2016 10:01:51:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15780845 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0060s; samplesPerSecond = 211605.2
08/16/2016 10:01:51:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15691619 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0061s; samplesPerSecond = 208741.0
08/16/2016 10:01:51:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15916872 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0061s; samplesPerSecond = 211012.2
08/16/2016 10:01:51: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15400253 * 10000; EvalClassificationError = 0.07670000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.049361s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.30'

08/16/2016 10:01:51: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15854410 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0069s; samplesPerSecond = 185212.0
08/16/2016 10:01:51:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15420641 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0065s; samplesPerSecond = 197317.7
08/16/2016 10:01:51:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15646703 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0063s; samplesPerSecond = 203336.0
08/16/2016 10:01:51:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14557357 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0066s; samplesPerSecond = 194884.3
08/16/2016 10:01:51:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17078629 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0063s; samplesPerSecond = 202211.7
08/16/2016 10:01:51:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13947372 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0061s; samplesPerSecond = 209355.6
08/16/2016 10:01:51:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14868889 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0060s; samplesPerSecond = 211605.2
08/16/2016 10:01:51: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15281967 * 10000; EvalClassificationError = 0.07560000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.05115s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.31'

08/16/2016 10:01:51: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15335751 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0069s; samplesPerSecond = 185830.4
08/16/2016 10:01:51:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14308777 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0062s; samplesPerSecond = 204996.8
08/16/2016 10:01:51:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14223814 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0061s; samplesPerSecond = 209082.0
08/16/2016 10:01:51:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15188785 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0061s; samplesPerSecond = 209561.2
08/16/2016 10:01:51:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15086718 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0061s; samplesPerSecond = 210595.6
08/16/2016 10:01:51:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16064487 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0061s; samplesPerSecond = 208537.0
08/16/2016 10:01:51:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15454378 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0061s; samplesPerSecond = 210560.9
08/16/2016 10:01:51: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15326572 * 10000; EvalClassificationError = 0.07660000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.050038s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.32'

08/16/2016 10:01:51: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15866314 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0067s; samplesPerSecond = 191330.3
08/16/2016 10:01:51:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17100292 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0063s; samplesPerSecond = 204701.7
08/16/2016 10:01:51:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14906003 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0061s; samplesPerSecond = 209492.6
08/16/2016 10:01:51:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15649090 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 209321.3
08/16/2016 10:01:51:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13756232 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0061s; samplesPerSecond = 210769.0
08/16/2016 10:01:51:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14187331 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0060s; samplesPerSecond = 213226.7
08/16/2016 10:01:51:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16106300 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0060s; samplesPerSecond = 212978.4
08/16/2016 10:01:51: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15331483 * 10000; EvalClassificationError = 0.07750000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.049672s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.33'

08/16/2016 10:01:51: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14242122 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0062s; samplesPerSecond = 206385.0
08/16/2016 10:01:51:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15583344 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0061s; samplesPerSecond = 208945.5
08/16/2016 10:01:51:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15891840 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0060s; samplesPerSecond = 213333.3
08/16/2016 10:01:51:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14699554 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0060s; samplesPerSecond = 214369.5
08/16/2016 10:01:51:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15782819 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0060s; samplesPerSecond = 214261.8
08/16/2016 10:01:51:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15657229 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0061s; samplesPerSecond = 210630.2
08/16/2016 10:01:51:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15388899 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0060s; samplesPerSecond = 213868.0
08/16/2016 10:01:51: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15179636 * 10000; EvalClassificationError = 0.07640000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.048628s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.34'

08/16/2016 10:01:51: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15962774 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0069s; samplesPerSecond = 184252.2
08/16/2016 10:01:51:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14119731 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0067s; samplesPerSecond = 192249.9
08/16/2016 10:01:51:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14686043 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0067s; samplesPerSecond = 192048.0
08/16/2016 10:01:51:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14855204 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0066s; samplesPerSecond = 192684.0
08/16/2016 10:01:51:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14080853 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0067s; samplesPerSecond = 191875.3
08/16/2016 10:01:51:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14345264 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0068s; samplesPerSecond = 189321.1
08/16/2016 10:01:51:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15913496 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0067s; samplesPerSecond = 192452.3
08/16/2016 10:01:51: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.14921476 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.053914s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.35'

08/16/2016 10:01:51: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14721220 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0067s; samplesPerSecond = 191702.9
08/16/2016 10:01:51:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17289703 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0063s; samplesPerSecond = 204081.6
08/16/2016 10:01:51:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15483642 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0061s; samplesPerSecond = 208843.2
08/16/2016 10:01:51:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15603585 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0061s; samplesPerSecond = 211465.4
08/16/2016 10:01:51:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15346479 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0059s; samplesPerSecond = 215307.0
08/16/2016 10:01:51:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13617387 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0060s; samplesPerSecond = 214477.2
08/16/2016 10:01:51:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14273968 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0060s; samplesPerSecond = 212166.4
08/16/2016 10:01:51: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15350118 * 10000; EvalClassificationError = 0.07840000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.049445s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.36'

08/16/2016 10:01:51: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16883855 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0064s; samplesPerSecond = 201321.2
08/16/2016 10:01:51:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14396729 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0061s; samplesPerSecond = 209047.9
08/16/2016 10:01:51:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14920344 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0060s; samplesPerSecond = 214441.3
08/16/2016 10:01:51:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12402153 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0060s; samplesPerSecond = 214837.2
08/16/2016 10:01:51:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15503283 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0060s; samplesPerSecond = 213084.7
08/16/2016 10:01:51:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14398074 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0060s; samplesPerSecond = 212448.1
08/16/2016 10:01:51:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16336031 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0059s; samplesPerSecond = 215597.1
08/16/2016 10:01:51: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.14997814 * 10000; EvalClassificationError = 0.07470000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.048549s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.37'

08/16/2016 10:01:51: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16700895 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0062s; samplesPerSecond = 206119.2
08/16/2016 10:01:51:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14556196 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0061s; samplesPerSecond = 210664.9
08/16/2016 10:01:51:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13987446 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0060s; samplesPerSecond = 212483.4
08/16/2016 10:01:51:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15890779 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0060s; samplesPerSecond = 212659.9
08/16/2016 10:01:51:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13739614 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0060s; samplesPerSecond = 213618.2
08/16/2016 10:01:51:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15440755 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0060s; samplesPerSecond = 214441.3
08/16/2016 10:01:51:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13707781 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0060s; samplesPerSecond = 212978.4
08/16/2016 10:01:51: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.14876063 * 10000; EvalClassificationError = 0.07770000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.04859s
08/16/2016 10:01:51: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.38'

08/16/2016 10:01:51: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

08/16/2016 10:01:51: Starting minibatch loop.
08/16/2016 10:01:51:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14555572 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0062s; samplesPerSecond = 205721.6
08/16/2016 10:01:51:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13892103 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0061s; samplesPerSecond = 208571.0
08/16/2016 10:01:52:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14857798 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0061s; samplesPerSecond = 210630.2
08/16/2016 10:01:52:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14665322 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0060s; samplesPerSecond = 214693.1
08/16/2016 10:01:52:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15658579 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0060s; samplesPerSecond = 214441.3
08/16/2016 10:01:52:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17460589 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0059s; samplesPerSecond = 215488.2
08/16/2016 10:01:52:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18014584 * 1280; EvalClassificationError = 0.09609375 * 1280; time = 0.0059s; samplesPerSecond = 216216.2
08/16/2016 10:01:52: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15431099 * 10000; EvalClassificationError = 0.08030000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.048483s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.39'

08/16/2016 10:01:52: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18008713 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0063s; samplesPerSecond = 203530.0
08/16/2016 10:01:52:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14646364 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0061s; samplesPerSecond = 209150.3
08/16/2016 10:01:52:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15315385 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0060s; samplesPerSecond = 213226.7
08/16/2016 10:01:52:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15180483 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0060s; samplesPerSecond = 213832.3
08/16/2016 10:01:52:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15421243 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0060s; samplesPerSecond = 214046.8
08/16/2016 10:01:52:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15762272 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0059s; samplesPerSecond = 216033.8
08/16/2016 10:01:52:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14054337 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0060s; samplesPerSecond = 214190.1
08/16/2016 10:01:52: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15281458 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.048471s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.40'

08/16/2016 10:01:52: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16199740 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 210907.9
08/16/2016 10:01:52:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13060468 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0060s; samplesPerSecond = 213404.5
08/16/2016 10:01:52:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14528196 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0060s; samplesPerSecond = 214801.1
08/16/2016 10:01:52:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14745116 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0059s; samplesPerSecond = 216179.7
08/16/2016 10:01:52:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14677806 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0059s; samplesPerSecond = 216802.2
08/16/2016 10:01:52:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14226589 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0059s; samplesPerSecond = 216692.1
08/16/2016 10:01:52:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15018511 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0059s; samplesPerSecond = 217687.1
08/16/2016 10:01:52: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14561317 * 10000; EvalClassificationError = 0.07320000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.047989s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.41'

08/16/2016 10:01:52: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14121016 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0067s; samplesPerSecond = 192019.2
08/16/2016 10:01:52:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14013838 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0063s; samplesPerSecond = 204211.9
08/16/2016 10:01:52:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15148880 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0061s; samplesPerSecond = 209973.8
08/16/2016 10:01:52:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14152312 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0061s; samplesPerSecond = 210873.1
08/16/2016 10:01:52:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14899688 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0061s; samplesPerSecond = 210008.2
08/16/2016 10:01:52:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15725455 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0061s; samplesPerSecond = 211151.4
08/16/2016 10:01:52:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17800837 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0065s; samplesPerSecond = 197927.9
08/16/2016 10:01:52: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15123264 * 10000; EvalClassificationError = 0.07710000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.050356s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.42'

08/16/2016 10:01:52: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16342371 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0065s; samplesPerSecond = 195898.4
08/16/2016 10:01:52:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12180147 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0065s; samplesPerSecond = 197989.2
08/16/2016 10:01:52:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14622214 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0063s; samplesPerSecond = 202371.5
08/16/2016 10:01:52:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15369153 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0063s; samplesPerSecond = 204342.3
08/16/2016 10:01:52:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15860214 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0063s; samplesPerSecond = 204342.3
08/16/2016 10:01:52:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14122787 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0063s; samplesPerSecond = 204342.3
08/16/2016 10:01:52:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16564732 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0063s; samplesPerSecond = 201701.9
08/16/2016 10:01:52: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14938007 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.051064s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.43'

08/16/2016 10:01:52: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16123863 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0068s; samplesPerSecond = 189433.2
08/16/2016 10:01:52:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15577046 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0065s; samplesPerSecond = 197105.0
08/16/2016 10:01:52:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.12841337 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0063s; samplesPerSecond = 204081.6
08/16/2016 10:01:52:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14609427 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0063s; samplesPerSecond = 203724.3
08/16/2016 10:01:52:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15202394 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0063s; samplesPerSecond = 203400.6
08/16/2016 10:01:52:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13416452 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0062s; samplesPerSecond = 205424.5
08/16/2016 10:01:52:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15762548 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0063s; samplesPerSecond = 202627.8
08/16/2016 10:01:52: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.14863984 * 10000; EvalClassificationError = 0.07410000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.051358s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.44'

08/16/2016 10:01:52: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16425934 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0066s; samplesPerSecond = 194588.0
08/16/2016 10:01:52:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13906994 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0063s; samplesPerSecond = 202627.8
08/16/2016 10:01:52:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15275779 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0063s; samplesPerSecond = 203336.0
08/16/2016 10:01:52:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15256972 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0063s; samplesPerSecond = 203239.1
08/16/2016 10:01:52:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14671388 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0062s; samplesPerSecond = 205259.8
08/16/2016 10:01:52:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13406653 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0063s; samplesPerSecond = 203821.7
08/16/2016 10:01:52:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14873390 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0063s; samplesPerSecond = 203951.6
08/16/2016 10:01:52: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.14704158 * 10000; EvalClassificationError = 0.07600000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.05089s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.45'

08/16/2016 10:01:52: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12665194 * 1280; EvalClassificationError = 0.05703125 * 1280; time = 0.0066s; samplesPerSecond = 192655.0
08/16/2016 10:01:52:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16254121 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0061s; samplesPerSecond = 209698.6
08/16/2016 10:01:52:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14150271 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0061s; samplesPerSecond = 210803.7
08/16/2016 10:01:52:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13744431 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0062s; samplesPerSecond = 208062.4
08/16/2016 10:01:52:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14358287 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0062s; samplesPerSecond = 208062.4
08/16/2016 10:01:52:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14920034 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 209458.4
08/16/2016 10:01:52:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14926138 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 210042.7
08/16/2016 10:01:52: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14446512 * 10000; EvalClassificationError = 0.07150000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.049751s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.46'

08/16/2016 10:01:52: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14675944 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0063s; samplesPerSecond = 201797.3
08/16/2016 10:01:52:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14883988 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0061s; samplesPerSecond = 208197.8
08/16/2016 10:01:52:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15345011 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0061s; samplesPerSecond = 210526.3
08/16/2016 10:01:52:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11605964 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0061s; samplesPerSecond = 209184.5
08/16/2016 10:01:52:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13467174 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0061s; samplesPerSecond = 209458.4
08/16/2016 10:01:52:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14876428 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0062s; samplesPerSecond = 207489.1
08/16/2016 10:01:52:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13533363 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0061s; samplesPerSecond = 210699.6
08/16/2016 10:01:52: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14057228 * 10000; EvalClassificationError = 0.07400000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.049485s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.47'

08/16/2016 10:01:52: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14498210 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0065s; samplesPerSecond = 196802.0
08/16/2016 10:01:52:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14912119 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0061s; samplesPerSecond = 209252.9
08/16/2016 10:01:52:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14851689 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0062s; samplesPerSecond = 207489.1
08/16/2016 10:01:52:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13951344 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0062s; samplesPerSecond = 208062.4
08/16/2016 10:01:52:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13970771 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0061s; samplesPerSecond = 209870.5
08/16/2016 10:01:52:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13940897 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0061s; samplesPerSecond = 210838.4
08/16/2016 10:01:52:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.12628384 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0061s; samplesPerSecond = 210942.6
08/16/2016 10:01:52: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14128638 * 10000; EvalClassificationError = 0.07260000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.049638s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.48'

08/16/2016 10:01:52: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15530832 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0064s; samplesPerSecond = 200344.3
08/16/2016 10:01:52:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12999671 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0061s; samplesPerSecond = 209150.3
08/16/2016 10:01:52:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14699583 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0061s; samplesPerSecond = 210457.1
08/16/2016 10:01:52:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14356284 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0061s; samplesPerSecond = 211081.8
08/16/2016 10:01:52:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14086604 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0061s; samplesPerSecond = 210699.6
08/16/2016 10:01:52:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13911200 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0061s; samplesPerSecond = 210284.2
08/16/2016 10:01:52:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17052755 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0061s; samplesPerSecond = 208911.4
08/16/2016 10:01:52: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.14581655 * 10000; EvalClassificationError = 0.07380000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.049227s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.49'

08/16/2016 10:01:52: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/16/2016 10:01:52: Starting minibatch loop.
08/16/2016 10:01:52:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14376962 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0065s; samplesPerSecond = 197683.4
08/16/2016 10:01:52:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13468332 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0061s; samplesPerSecond = 209013.7
08/16/2016 10:01:52:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13613780 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0060s; samplesPerSecond = 211710.2
08/16/2016 10:01:52:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14630637 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0061s; samplesPerSecond = 210907.9
08/16/2016 10:01:52:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13355980 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0060s; samplesPerSecond = 212695.2
08/16/2016 10:01:52:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14160800 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 210249.7
08/16/2016 10:01:52:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14176855 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0060s; samplesPerSecond = 213262.2
08/16/2016 10:01:52: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.13893760 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.049194s
08/16/2016 10:01:52: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn'
08/16/2016 10:01:52: CNTKCommandTrainEnd: Simple_Demo

08/16/2016 10:01:52: Action "train" complete.


08/16/2016 10:01:52: ##############################################################################
08/16/2016 10:01:52: #                                                                            #
08/16/2016 10:01:52: # Action "write"                                                             #
08/16/2016 10:01:52: #                                                                            #
08/16/2016 10:01:52: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

08/16/2016 10:01:52: Action "write" complete.

08/16/2016 10:01:52: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 16 2016 09:41:56
		Last modified date: Fri Aug 12 07:32:43 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
		Built by philly on f67b30a647de
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
08/16/2016 10:01:54: -------------------------------------------------------------------
08/16/2016 10:01:54: Build info: 

08/16/2016 10:01:54: 		Built time: Aug 16 2016 09:41:56
08/16/2016 10:01:54: 		Last modified date: Fri Aug 12 07:32:43 2016
08/16/2016 10:01:54: 		Build type: release
08/16/2016 10:01:54: 		Build target: GPU
08/16/2016 10:01:54: 		With 1bit-SGD: no
08/16/2016 10:01:54: 		Math lib: mkl
08/16/2016 10:01:54: 		CUDA_PATH: /usr/local/cuda-7.5
08/16/2016 10:01:54: 		CUB_PATH: /usr/local/cub-1.4.1
08/16/2016 10:01:54: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/16/2016 10:01:54: 		Build Branch: HEAD
08/16/2016 10:01:54: 		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
08/16/2016 10:01:54: 		Built by philly on f67b30a647de
08/16/2016 10:01:54: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/16/2016 10:01:54: -------------------------------------------------------------------
08/16/2016 10:01:55: -------------------------------------------------------------------
08/16/2016 10:01:55: GPU info:

08/16/2016 10:01:55: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:55: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:55: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:55: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/16/2016 10:01:55: -------------------------------------------------------------------

08/16/2016 10:01:55: Running on localhost at 2016/08/16 10:01:55
08/16/2016 10:01:55: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu  DeviceId=0  timestamping=true  makeMode=true



08/16/2016 10:01:55: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/16/2016 10:01:55: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/16/2016 10:01:55: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/16/2016 10:01:55: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/16/2016 10:01:55: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/16/2016 10:01:55: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/16/2016 10:01:55: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/16/2016 10:01:55: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/16/2016 10:01:55: Commands: Simple_Demo Simple_Demo_Output
08/16/2016 10:01:55: Precision = "float"
08/16/2016 10:01:55: CNTKModelPath: /tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn
08/16/2016 10:01:55: CNTKCommandTrainInfo: Simple_Demo : 50
08/16/2016 10:01:55: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/16/2016 10:01:55: ##############################################################################
08/16/2016 10:01:55: #                                                                            #
08/16/2016 10:01:55: # Action "train"                                                             #
08/16/2016 10:01:55: #                                                                            #
08/16/2016 10:01:55: ##############################################################################

08/16/2016 10:01:55: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

08/16/2016 10:01:55: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/16/2016 10:01:55: Loaded model with 25 nodes on GPU 0.

08/16/2016 10:01:55: Training criterion node(s):
08/16/2016 10:01:55: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/16/2016 10:01:55: Evaluation criterion node(s):
08/16/2016 10:01:55: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }
	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }


08/16/2016 10:01:55: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/16/2016 10:01:55: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/16/2016 10:01:55: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/16/2016 10:01:55: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/16/2016 10:01:55: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/16/2016 10:01:55: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/16/2016 10:01:55: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

08/16/2016 10:01:55: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/16/2016 10:01:55: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/16/2016 10:01:55: Starting minibatch loop.
08/16/2016 10:01:55:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.14376962 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.1144s; samplesPerSecond = 11193.5
08/16/2016 10:01:55:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.13468332 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0062s; samplesPerSecond = 206818.5
08/16/2016 10:01:55:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.13613780 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0062s; samplesPerSecond = 207489.1
08/16/2016 10:01:55:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14630637 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0061s; samplesPerSecond = 208469.1
08/16/2016 10:01:55:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.13355980 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0062s; samplesPerSecond = 205358.6
08/16/2016 10:01:55:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14160800 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 208367.2
08/16/2016 10:01:55:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14176855 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0062s; samplesPerSecond = 206718.3
08/16/2016 10:01:55: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.13893760 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.159161s
08/16/2016 10:01:55: SGD: Saving checkpoint model '/tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/models/simple.dnn'
08/16/2016 10:01:55: CNTKCommandTrainEnd: Simple_Demo

08/16/2016 10:01:55: Action "train" complete.


08/16/2016 10:01:55: ##############################################################################
08/16/2016 10:01:55: #                                                                            #
08/16/2016 10:01:55: # Action "write"                                                             #
08/16/2016 10:01:55: #                                                                            #
08/16/2016 10:01:55: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160816095713.701165/Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

08/16/2016 10:01:55: Action "write" complete.

08/16/2016 10:01:55: __COMPLETED__