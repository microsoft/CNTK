CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3565 @ 3.20GHz
    Hardware threads: 8
    Total Memory: 12580436 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 16 2016 02:54:53
		Last modified date: Fri Aug 12 05:31:21 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
		Built by svcphil on Philly-Pool3
		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/16/2016 03:09:21: -------------------------------------------------------------------
08/16/2016 03:09:21: Build info: 

08/16/2016 03:09:21: 		Built time: Aug 16 2016 02:54:53
08/16/2016 03:09:21: 		Last modified date: Fri Aug 12 05:31:21 2016
08/16/2016 03:09:21: 		Build type: Release
08/16/2016 03:09:21: 		Build target: GPU
08/16/2016 03:09:21: 		With 1bit-SGD: no
08/16/2016 03:09:21: 		Math lib: mkl
08/16/2016 03:09:21: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/16/2016 03:09:21: 		CUB_PATH: c:\src\cub-1.4.1
08/16/2016 03:09:21: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/16/2016 03:09:21: 		Build Branch: HEAD
08/16/2016 03:09:21: 		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
08/16/2016 03:09:21: 		Built by svcphil on Philly-Pool3
08/16/2016 03:09:21: 		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/16/2016 03:09:21: -------------------------------------------------------------------
08/16/2016 03:09:22: -------------------------------------------------------------------
08/16/2016 03:09:22: GPU info:

08/16/2016 03:09:22: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/16/2016 03:09:22: -------------------------------------------------------------------

08/16/2016 03:09:22: Running on cntk-muc01 at 2016/08/16 03:09:22
08/16/2016 03:09:22: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu  DeviceId=0  timestamping=true



08/16/2016 03:09:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:09:22: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DeviceId=0
timestamping=true

08/16/2016 03:09:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:09:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:09:22: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DeviceId=0
timestamping=true

08/16/2016 03:09:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:09:22: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/16/2016 03:09:22: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/16/2016 03:09:22: Commands: Simple_Demo Simple_Demo_Output
08/16/2016 03:09:22: Precision = "float"
08/16/2016 03:09:22: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn
08/16/2016 03:09:22: CNTKCommandTrainInfo: Simple_Demo : 50
08/16/2016 03:09:22: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/16/2016 03:09:22: ##############################################################################
08/16/2016 03:09:22: #                                                                            #
08/16/2016 03:09:22: # Action "train"                                                             #
08/16/2016 03:09:22: #                                                                            #
08/16/2016 03:09:22: ##############################################################################

08/16/2016 03:09:22: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

08/16/2016 03:09:22: Creating virgin network.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, range=0.050000*1.000000, onCPU=false).
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/16/2016 03:09:22: Created model with 25 nodes on GPU 0.

08/16/2016 03:09:22: Training criterion node(s):
08/16/2016 03:09:22: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/16/2016 03:09:22: Evaluation criterion node(s):
08/16/2016 03:09:22: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }


08/16/2016 03:09:22: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/16/2016 03:09:22: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/16/2016 03:09:22: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/16/2016 03:09:22: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/16/2016 03:09:22: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/16/2016 03:09:22: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/16/2016 03:09:22: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


08/16/2016 03:09:22: Precomputing --> 3 PreCompute nodes found.

08/16/2016 03:09:22: 	MeanOfFeatures = Mean()
08/16/2016 03:09:22: 	InvStdOfFeatures = InvStdDev()
08/16/2016 03:09:22: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/16/2016 03:09:22: Precomputing --> Completed.


08/16/2016 03:09:22: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/16/2016 03:09:22: Starting minibatch loop.
08/16/2016 03:09:22:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.84310608 * 1280; EvalClassificationError = 0.51718750 * 1280; time = 0.0174s; samplesPerSecond = 73554.8
08/16/2016 03:09:22:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.79649162 * 1280; EvalClassificationError = 0.51562500 * 1280; time = 0.0164s; samplesPerSecond = 78239.6
08/16/2016 03:09:22:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.72212505 * 1280; EvalClassificationError = 0.48515625 * 1280; time = 0.0168s; samplesPerSecond = 76145.2
08/16/2016 03:09:22:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71446991 * 1280; EvalClassificationError = 0.49765625 * 1280; time = 0.0166s; samplesPerSecond = 77215.4
08/16/2016 03:09:22:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.70253887 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0166s; samplesPerSecond = 76909.2
08/16/2016 03:09:22:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.70667038 * 1280; EvalClassificationError = 0.51718750 * 1280; time = 0.0164s; samplesPerSecond = 78287.5
08/16/2016 03:09:22:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.70342636 * 1280; EvalClassificationError = 0.50156250 * 1280; time = 0.0167s; samplesPerSecond = 76550.4
08/16/2016 03:09:22: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.73692178 * 10000; EvalClassificationError = 0.50500000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.133816s
08/16/2016 03:09:22: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.1'

08/16/2016 03:09:22: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

08/16/2016 03:09:22: Starting minibatch loop.
08/16/2016 03:09:22:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70579815 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0170s; samplesPerSecond = 75179.1
08/16/2016 03:09:22:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74300938 * 1280; EvalClassificationError = 0.47968750 * 1280; time = 0.0172s; samplesPerSecond = 74492.2
08/16/2016 03:09:22:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.74903145 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0171s; samplesPerSecond = 75051.3
08/16/2016 03:09:22:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.74969635 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0171s; samplesPerSecond = 75024.9
08/16/2016 03:09:22:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.74229851 * 1280; EvalClassificationError = 0.50234375 * 1280; time = 0.0172s; samplesPerSecond = 74314.9
08/16/2016 03:09:22:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.72703133 * 1280; EvalClassificationError = 0.50546875 * 1280; time = 0.0170s; samplesPerSecond = 75285.3
08/16/2016 03:09:22:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.73382492 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0171s; samplesPerSecond = 75007.3
08/16/2016 03:09:22: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.73301997 * 10000; EvalClassificationError = 0.49860000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.135413s
08/16/2016 03:09:22: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.2'

08/16/2016 03:09:22: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

08/16/2016 03:09:22: Starting minibatch loop.
08/16/2016 03:09:22:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.73711967 * 1280; EvalClassificationError = 0.50000000 * 1280; time = 0.0168s; samplesPerSecond = 75991.5
08/16/2016 03:09:22:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.73554993 * 1280; EvalClassificationError = 0.50625000 * 1280; time = 0.0166s; samplesPerSecond = 77066.7
08/16/2016 03:09:22:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.76822968 * 1280; EvalClassificationError = 0.52187500 * 1280; time = 0.0168s; samplesPerSecond = 76285.8
08/16/2016 03:09:22:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75786591 * 1280; EvalClassificationError = 0.50234375 * 1280; time = 0.0164s; samplesPerSecond = 78115.5
08/16/2016 03:09:22:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73280945 * 1280; EvalClassificationError = 0.50937500 * 1280; time = 0.0163s; samplesPerSecond = 78316.2
08/16/2016 03:09:22:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71082764 * 1280; EvalClassificationError = 0.48984375 * 1280; time = 0.0164s; samplesPerSecond = 77934.7
08/16/2016 03:09:23:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69263992 * 1280; EvalClassificationError = 0.50703125 * 1280; time = 0.0164s; samplesPerSecond = 78244.4
08/16/2016 03:09:23: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.72925479 * 10000; EvalClassificationError = 0.49610000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.130945s
08/16/2016 03:09:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.3'

08/16/2016 03:09:23: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

08/16/2016 03:09:23: Starting minibatch loop.
08/16/2016 03:09:23:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69856057 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0167s; samplesPerSecond = 76628.4
08/16/2016 03:09:23:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.68708320 * 1280; EvalClassificationError = 0.47031250 * 1280; time = 0.0171s; samplesPerSecond = 74972.2
08/16/2016 03:09:23:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.44454384 * 1280; EvalClassificationError = 0.18593750 * 1280; time = 0.0174s; samplesPerSecond = 73546.3
08/16/2016 03:09:23:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20331936 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0170s; samplesPerSecond = 75135.0
08/16/2016 03:09:23:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16972294 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0170s; samplesPerSecond = 75360.6
08/16/2016 03:09:23:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16289215 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0180s; samplesPerSecond = 71079.5
08/16/2016 03:09:23:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16081238 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0173s; samplesPerSecond = 73903.0
08/16/2016 03:09:23: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.34526641 * 10000; EvalClassificationError = 0.19350000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.136331s
08/16/2016 03:09:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.4'

08/16/2016 03:09:23: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

08/16/2016 03:09:23: Starting minibatch loop.
08/16/2016 03:09:23:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18459458 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0174s; samplesPerSecond = 73398.7
08/16/2016 03:09:23:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17662528 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0171s; samplesPerSecond = 74788.2
08/16/2016 03:09:23:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15586007 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0174s; samplesPerSecond = 73652.1
08/16/2016 03:09:23:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15864964 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0172s; samplesPerSecond = 74561.7
08/16/2016 03:09:23:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18221016 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0176s; samplesPerSecond = 72913.7
08/16/2016 03:09:23:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16875296 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0171s; samplesPerSecond = 74941.5
08/16/2016 03:09:23:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17399311 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0171s; samplesPerSecond = 75042.5
08/16/2016 03:09:23: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16924456 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.136531s
08/16/2016 03:09:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.5'

08/16/2016 03:09:23: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

08/16/2016 03:09:23: Starting minibatch loop.
08/16/2016 03:09:23:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19218905 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0167s; samplesPerSecond = 76830.7
08/16/2016 03:09:23:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19492447 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0168s; samplesPerSecond = 76027.6
08/16/2016 03:09:23:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16309166 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0164s; samplesPerSecond = 78249.2
08/16/2016 03:09:23:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16469932 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0164s; samplesPerSecond = 78244.4
08/16/2016 03:09:23:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17971582 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0171s; samplesPerSecond = 75060.1
08/16/2016 03:09:23:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16465130 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0174s; samplesPerSecond = 73474.5
08/16/2016 03:09:23:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16045494 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0173s; samplesPerSecond = 74147.0
08/16/2016 03:09:23: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.17021433 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.133494s
08/16/2016 03:09:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.6'

08/16/2016 03:09:23: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

08/16/2016 03:09:23: Starting minibatch loop.
08/16/2016 03:09:23:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15642910 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0171s; samplesPerSecond = 74679.1
08/16/2016 03:09:23:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16490397 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0171s; samplesPerSecond = 74709.6
08/16/2016 03:09:23:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15031967 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0171s; samplesPerSecond = 74823.2
08/16/2016 03:09:23:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13484664 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0172s; samplesPerSecond = 74440.2
08/16/2016 03:09:23:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14183760 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0172s; samplesPerSecond = 74453.2
08/16/2016 03:09:23:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17524872 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0170s; samplesPerSecond = 75280.8
08/16/2016 03:09:23:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16879549 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0170s; samplesPerSecond = 75130.6
08/16/2016 03:09:23: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16103999 * 10000; EvalClassificationError = 0.07610000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.135686s
08/16/2016 03:09:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.7'

08/16/2016 03:09:23: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

08/16/2016 03:09:23: Starting minibatch loop.
08/16/2016 03:09:23:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19399147 * 1280; EvalClassificationError = 0.09375000 * 1280; time = 0.0175s; samplesPerSecond = 73335.6
08/16/2016 03:09:23:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18360868 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0170s; samplesPerSecond = 75502.9
08/16/2016 03:09:23:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18547025 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0173s; samplesPerSecond = 74056.9
08/16/2016 03:09:23:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17984595 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0170s; samplesPerSecond = 75227.7
08/16/2016 03:09:23:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17576346 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0169s; samplesPerSecond = 75534.0
08/16/2016 03:09:23:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.20375605 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0171s; samplesPerSecond = 75011.7
08/16/2016 03:09:23:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15429964 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0170s; samplesPerSecond = 75161.5
08/16/2016 03:09:23: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.18108601 * 10000; EvalClassificationError = 0.08070000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.135504s
08/16/2016 03:09:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.8'

08/16/2016 03:09:23: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

08/16/2016 03:09:23: Starting minibatch loop.
08/16/2016 03:09:23:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17657449 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0166s; samplesPerSecond = 76969.3
08/16/2016 03:09:23:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17487626 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0170s; samplesPerSecond = 75272.0
08/16/2016 03:09:23:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17738187 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0174s; samplesPerSecond = 73614.0
08/16/2016 03:09:23:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17675433 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0171s; samplesPerSecond = 75016.1
08/16/2016 03:09:23:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16243396 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0171s; samplesPerSecond = 75024.9
08/16/2016 03:09:23:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14487514 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0171s; samplesPerSecond = 74981.0
08/16/2016 03:09:23:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14202633 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0170s; samplesPerSecond = 75342.9
08/16/2016 03:09:23: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.16574330 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.134906s
08/16/2016 03:09:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.9'

08/16/2016 03:09:23: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

08/16/2016 03:09:23: Starting minibatch loop.
08/16/2016 03:09:23:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16489168 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0170s; samplesPerSecond = 75130.6
08/16/2016 03:09:23:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14849166 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0172s; samplesPerSecond = 74392.7
08/16/2016 03:09:23:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16935616 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0176s; samplesPerSecond = 72702.5
08/16/2016 03:09:23:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15455160 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0173s; samplesPerSecond = 74095.5
08/16/2016 03:09:23:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.21274228 * 1280; EvalClassificationError = 0.09375000 * 1280; time = 0.0172s; samplesPerSecond = 74211.5
08/16/2016 03:09:24:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16063108 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0173s; samplesPerSecond = 74091.2
08/16/2016 03:09:24:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17145748 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0171s; samplesPerSecond = 74858.2
08/16/2016 03:09:24: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16641782 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.136703s
08/16/2016 03:09:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.10'

08/16/2016 03:09:24: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

08/16/2016 03:09:24: Starting minibatch loop.
08/16/2016 03:09:24:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17450614 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0167s; samplesPerSecond = 76632.9
08/16/2016 03:09:24:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16514254 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0172s; samplesPerSecond = 74237.3
08/16/2016 03:09:24:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17608404 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0172s; samplesPerSecond = 74518.3
08/16/2016 03:09:24:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16732321 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0171s; samplesPerSecond = 74757.6
08/16/2016 03:09:24:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16031547 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0170s; samplesPerSecond = 75192.4
08/16/2016 03:09:24:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15653191 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0172s; samplesPerSecond = 74271.8
08/16/2016 03:09:24:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16287127 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0171s; samplesPerSecond = 75033.7
08/16/2016 03:09:24: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.17136853 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.135236s
08/16/2016 03:09:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.11'

08/16/2016 03:09:24: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

08/16/2016 03:09:24: Starting minibatch loop.
08/16/2016 03:09:24:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16789968 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0171s; samplesPerSecond = 74818.8
08/16/2016 03:09:24:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17225728 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0172s; samplesPerSecond = 74513.9
08/16/2016 03:09:24:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17605832 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0172s; samplesPerSecond = 74583.4
08/16/2016 03:09:24:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16139812 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0171s; samplesPerSecond = 74661.7
08/16/2016 03:09:24:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15683770 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0173s; samplesPerSecond = 74159.9
08/16/2016 03:09:24:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16268196 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0171s; samplesPerSecond = 74779.5
08/16/2016 03:09:24:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14391632 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0171s; samplesPerSecond = 74731.4
08/16/2016 03:09:24: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16267988 * 10000; EvalClassificationError = 0.07550000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.135809s
08/16/2016 03:09:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.12'

08/16/2016 03:09:24: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

08/16/2016 03:09:24: Starting minibatch loop.
08/16/2016 03:09:24:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14964318 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0174s; samplesPerSecond = 73550.5
08/16/2016 03:09:24:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17667563 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0168s; samplesPerSecond = 76294.9
08/16/2016 03:09:24:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17469652 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0173s; samplesPerSecond = 74159.9
08/16/2016 03:09:24:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15370793 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0171s; samplesPerSecond = 74775.1
08/16/2016 03:09:24:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14474139 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0173s; samplesPerSecond = 74117.0
08/16/2016 03:09:24:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16730952 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0173s; samplesPerSecond = 74168.5
08/16/2016 03:09:24:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15163946 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0171s; samplesPerSecond = 74727.1
08/16/2016 03:09:24: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16008049 * 10000; EvalClassificationError = 0.07610000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.135961s
08/16/2016 03:09:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.13'

08/16/2016 03:09:24: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

08/16/2016 03:09:24: Starting minibatch loop.
08/16/2016 03:09:24:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19452739 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0173s; samplesPerSecond = 73779.5
08/16/2016 03:09:24:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20183799 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0168s; samplesPerSecond = 76041.1
08/16/2016 03:09:24:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17685053 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0167s; samplesPerSecond = 76642.1
08/16/2016 03:09:24:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20354214 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0164s; samplesPerSecond = 78258.7
08/16/2016 03:09:24:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18834014 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0184s; samplesPerSecond = 69690.2
08/16/2016 03:09:24:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16556721 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0171s; samplesPerSecond = 74963.4
08/16/2016 03:09:24:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15758457 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0171s; samplesPerSecond = 74827.5
08/16/2016 03:09:24: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.18295510 * 10000; EvalClassificationError = 0.08140000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.135658s
08/16/2016 03:09:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.14'

08/16/2016 03:09:24: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

08/16/2016 03:09:24: Starting minibatch loop.
08/16/2016 03:09:24:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17045990 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0175s; samplesPerSecond = 73138.7
08/16/2016 03:09:24:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14826864 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0174s; samplesPerSecond = 73635.2
08/16/2016 03:09:24:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17499018 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0171s; samplesPerSecond = 74923.9
08/16/2016 03:09:24:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17048907 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0171s; samplesPerSecond = 75073.3
08/16/2016 03:09:24:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16545119 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0171s; samplesPerSecond = 74766.4
08/16/2016 03:09:24:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16484280 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0170s; samplesPerSecond = 75387.2
08/16/2016 03:09:24:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15723133 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0181s; samplesPerSecond = 70722.1
08/16/2016 03:09:24: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16392716 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.137118s
08/16/2016 03:09:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.15'

08/16/2016 03:09:24: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

08/16/2016 03:09:24: Starting minibatch loop.
08/16/2016 03:09:24:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17300390 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0172s; samplesPerSecond = 74526.9
08/16/2016 03:09:24:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16495074 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0173s; samplesPerSecond = 74138.4
08/16/2016 03:09:24:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17640350 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0172s; samplesPerSecond = 74422.9
08/16/2016 03:09:24:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17643890 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0172s; samplesPerSecond = 74440.2
08/16/2016 03:09:24:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18799286 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0170s; samplesPerSecond = 75090.9
08/16/2016 03:09:24:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17479095 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0175s; samplesPerSecond = 73318.8
08/16/2016 03:09:24:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17468281 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0172s; samplesPerSecond = 74509.6
08/16/2016 03:09:24: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.17355865 * 10000; EvalClassificationError = 0.08010000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.136346s
08/16/2016 03:09:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.16'

08/16/2016 03:09:24: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

08/16/2016 03:09:24: Starting minibatch loop.
08/16/2016 03:09:24:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15547787 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0176s; samplesPerSecond = 72648.8
08/16/2016 03:09:24:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16448799 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0172s; samplesPerSecond = 74435.9
08/16/2016 03:09:25:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18492768 * 1280; EvalClassificationError = 0.09296875 * 1280; time = 0.0172s; samplesPerSecond = 74371.0
08/16/2016 03:09:25:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15973492 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0170s; samplesPerSecond = 75117.4
08/16/2016 03:09:25:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15464168 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0172s; samplesPerSecond = 74353.8
08/16/2016 03:09:25:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15534620 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0172s; samplesPerSecond = 74631.2
08/16/2016 03:09:25:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15559587 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0173s; samplesPerSecond = 74155.6
08/16/2016 03:09:25: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16203710 * 10000; EvalClassificationError = 0.07860000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.136645s
08/16/2016 03:09:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.17'

08/16/2016 03:09:25: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

08/16/2016 03:09:25: Starting minibatch loop.
08/16/2016 03:09:25:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15387502 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0176s; samplesPerSecond = 72926.2
08/16/2016 03:09:25:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15887525 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0172s; samplesPerSecond = 74483.6
08/16/2016 03:09:25:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16482136 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0173s; samplesPerSecond = 73962.8
08/16/2016 03:09:25:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15368652 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0172s; samplesPerSecond = 74349.4
08/16/2016 03:09:25:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14909186 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0170s; samplesPerSecond = 75214.5
08/16/2016 03:09:25:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15584955 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0173s; samplesPerSecond = 74031.2
08/16/2016 03:09:25:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15353718 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0173s; samplesPerSecond = 74005.6
08/16/2016 03:09:25: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15599124 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.13675s
08/16/2016 03:09:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.18'

08/16/2016 03:09:25: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

08/16/2016 03:09:25: Starting minibatch loop.
08/16/2016 03:09:25:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15185862 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0177s; samplesPerSecond = 72418.7
08/16/2016 03:09:25:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14511428 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0172s; samplesPerSecond = 74500.9
08/16/2016 03:09:25:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16339183 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0171s; samplesPerSecond = 74972.2
08/16/2016 03:09:25:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14803152 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0171s; samplesPerSecond = 74884.5
08/16/2016 03:09:25:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17850142 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0173s; samplesPerSecond = 73984.2
08/16/2016 03:09:25:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16295710 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0171s; samplesPerSecond = 74644.3
08/16/2016 03:09:25:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17260590 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0171s; samplesPerSecond = 74818.8
08/16/2016 03:09:25: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16107349 * 10000; EvalClassificationError = 0.07880000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.136446s
08/16/2016 03:09:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.19'

08/16/2016 03:09:25: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

08/16/2016 03:09:25: Starting minibatch loop.
08/16/2016 03:09:25:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16136272 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0173s; samplesPerSecond = 74117.0
08/16/2016 03:09:25:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16000419 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0170s; samplesPerSecond = 75285.3
08/16/2016 03:09:25:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15729120 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0174s; samplesPerSecond = 73643.6
08/16/2016 03:09:25:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17018433 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0170s; samplesPerSecond = 75205.6
08/16/2016 03:09:25:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16124363 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0170s; samplesPerSecond = 75117.4
08/16/2016 03:09:25:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15530777 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0171s; samplesPerSecond = 74858.2
08/16/2016 03:09:25:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16406002 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0170s; samplesPerSecond = 75356.2
08/16/2016 03:09:25: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.15965645 * 10000; EvalClassificationError = 0.07630000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.135722s
08/16/2016 03:09:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.20'

08/16/2016 03:09:25: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

08/16/2016 03:09:25: Starting minibatch loop.
08/16/2016 03:09:25:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16149700 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0169s; samplesPerSecond = 75574.2
08/16/2016 03:09:25:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14376297 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0170s; samplesPerSecond = 75489.5
08/16/2016 03:09:25:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15459526 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0167s; samplesPerSecond = 76436.2
08/16/2016 03:09:25:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14109788 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0164s; samplesPerSecond = 78273.1
08/16/2016 03:09:25:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15918331 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0164s; samplesPerSecond = 78191.8
08/16/2016 03:09:25:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16574650 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0171s; samplesPerSecond = 74875.7
08/16/2016 03:09:25:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16026459 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0173s; samplesPerSecond = 74005.6
08/16/2016 03:09:25: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15594359 * 10000; EvalClassificationError = 0.07760000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.133458s
08/16/2016 03:09:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.21'

08/16/2016 03:09:25: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

08/16/2016 03:09:25: Starting minibatch loop.
08/16/2016 03:09:25:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15156336 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0173s; samplesPerSecond = 74155.6
08/16/2016 03:09:25:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13561723 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0171s; samplesPerSecond = 74888.8
08/16/2016 03:09:25:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16119769 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0174s; samplesPerSecond = 73669.1
08/16/2016 03:09:25:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16036229 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0172s; samplesPerSecond = 74526.9
08/16/2016 03:09:25:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15335422 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0171s; samplesPerSecond = 75002.9
08/16/2016 03:09:25:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14870081 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0172s; samplesPerSecond = 74513.9
08/16/2016 03:09:25:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18252916 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0171s; samplesPerSecond = 75064.5
08/16/2016 03:09:25: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.15802612 * 10000; EvalClassificationError = 0.07540000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.135917s
08/16/2016 03:09:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.22'

08/16/2016 03:09:25: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

08/16/2016 03:09:25: Starting minibatch loop.
08/16/2016 03:09:25:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17649696 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0172s; samplesPerSecond = 74405.6
08/16/2016 03:09:25:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17540615 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0170s; samplesPerSecond = 75218.9
08/16/2016 03:09:25:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15473456 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0171s; samplesPerSecond = 75060.1
08/16/2016 03:09:25:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17021160 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0171s; samplesPerSecond = 74937.1
08/16/2016 03:09:25:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15742464 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0170s; samplesPerSecond = 75285.3
08/16/2016 03:09:25:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16152945 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0171s; samplesPerSecond = 75051.3
08/16/2016 03:09:25:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14951353 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0172s; samplesPerSecond = 74267.5
08/16/2016 03:09:25: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16317336 * 10000; EvalClassificationError = 0.07840000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.135487s
08/16/2016 03:09:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.23'

08/16/2016 03:09:25: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

08/16/2016 03:09:25: Starting minibatch loop.
08/16/2016 03:09:25:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16322435 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0180s; samplesPerSecond = 71162.5
08/16/2016 03:09:25:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17743517 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0172s; samplesPerSecond = 74379.7
08/16/2016 03:09:26:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14414515 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0171s; samplesPerSecond = 74954.6
08/16/2016 03:09:26:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12805438 * 1280; EvalClassificationError = 0.05859375 * 1280; time = 0.0174s; samplesPerSecond = 73732.7
08/16/2016 03:09:26:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17812719 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0174s; samplesPerSecond = 73656.3
08/16/2016 03:09:26:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13290920 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0185s; samplesPerSecond = 69092.1
08/16/2016 03:09:26:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15600252 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0171s; samplesPerSecond = 74635.6
08/16/2016 03:09:26: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.15501089 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.138405s
08/16/2016 03:09:26: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.24'

08/16/2016 03:09:26: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

08/16/2016 03:09:26: Starting minibatch loop.
08/16/2016 03:09:26:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13686548 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0174s; samplesPerSecond = 73643.6
08/16/2016 03:09:26:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17400645 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0173s; samplesPerSecond = 73967.1
08/16/2016 03:09:26:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14073534 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0173s; samplesPerSecond = 74125.6
08/16/2016 03:09:26:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15342216 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0172s; samplesPerSecond = 74505.2
08/16/2016 03:09:26:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16745071 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0175s; samplesPerSecond = 72951.1
08/16/2016 03:09:26:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16927571 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0174s; samplesPerSecond = 73377.7
08/16/2016 03:09:26:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17954512 * 1280; EvalClassificationError = 0.09765625 * 1280; time = 0.0173s; samplesPerSecond = 74048.4
08/16/2016 03:09:26: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16094977 * 10000; EvalClassificationError = 0.07980000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.137433s
08/16/2016 03:09:26: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.25'

08/16/2016 03:09:26: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

08/16/2016 03:09:26: Starting minibatch loop.
08/16/2016 03:09:26:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15746422 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0170s; samplesPerSecond = 75360.6
08/16/2016 03:09:26:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19772153 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0168s; samplesPerSecond = 76285.8
08/16/2016 03:09:26:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16204095 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0170s; samplesPerSecond = 75082.1
08/16/2016 03:09:26:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14501700 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0172s; samplesPerSecond = 74592.1
08/16/2016 03:09:26:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16413703 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0171s; samplesPerSecond = 74959.0
08/16/2016 03:09:26:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12358284 * 1280; EvalClassificationError = 0.05312500 * 1280; time = 0.0171s; samplesPerSecond = 75020.5
08/16/2016 03:09:26:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16245909 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0172s; samplesPerSecond = 74448.9
08/16/2016 03:09:26: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15827272 * 10000; EvalClassificationError = 0.07500000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.135251s
08/16/2016 03:09:26: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.26'

08/16/2016 03:09:26: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

08/16/2016 03:09:26: Starting minibatch loop.
08/16/2016 03:09:26:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16253566 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0169s; samplesPerSecond = 75780.0
08/16/2016 03:09:26:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16306874 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0171s; samplesPerSecond = 74653.0
08/16/2016 03:09:26:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14200211 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0174s; samplesPerSecond = 73521.0
08/16/2016 03:09:26:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15200095 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0170s; samplesPerSecond = 75205.6
08/16/2016 03:09:26:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15755301 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0171s; samplesPerSecond = 74748.9
08/16/2016 03:09:26:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15269804 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0170s; samplesPerSecond = 75498.4
08/16/2016 03:09:26:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16627922 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0170s; samplesPerSecond = 75241.0
08/16/2016 03:09:26: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15596608 * 10000; EvalClassificationError = 0.07630000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.135367s
08/16/2016 03:09:26: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.27'

08/16/2016 03:09:26: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

08/16/2016 03:09:26: Starting minibatch loop.
08/16/2016 03:09:26:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15554502 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0174s; samplesPerSecond = 73745.5
08/16/2016 03:09:26:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16508815 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0169s; samplesPerSecond = 75838.4
08/16/2016 03:09:26:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16708322 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0173s; samplesPerSecond = 74181.4
08/16/2016 03:09:26:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14226341 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0171s; samplesPerSecond = 74932.7
08/16/2016 03:09:26:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14113979 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0170s; samplesPerSecond = 75218.9
08/16/2016 03:09:26:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15288944 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0170s; samplesPerSecond = 75196.8
08/16/2016 03:09:26:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16410732 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0172s; samplesPerSecond = 74479.2
08/16/2016 03:09:26: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15700085 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.135622s
08/16/2016 03:09:26: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.28'

08/16/2016 03:09:26: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

08/16/2016 03:09:26: Starting minibatch loop.
08/16/2016 03:09:26:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15318733 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0172s; samplesPerSecond = 74284.7
08/16/2016 03:09:26:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13557605 * 1280; EvalClassificationError = 0.05859375 * 1280; time = 0.0172s; samplesPerSecond = 74349.4
08/16/2016 03:09:26:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16530409 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0170s; samplesPerSecond = 75320.7
08/16/2016 03:09:26:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14492359 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0170s; samplesPerSecond = 75126.2
08/16/2016 03:09:26:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16227593 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0170s; samplesPerSecond = 75227.7
08/16/2016 03:09:27:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14070587 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0172s; samplesPerSecond = 74444.6
08/16/2016 03:09:27:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16054277 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0171s; samplesPerSecond = 74770.7
08/16/2016 03:09:27: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15657330 * 10000; EvalClassificationError = 0.07700000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.135515s
08/16/2016 03:09:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.29'

08/16/2016 03:09:27: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

08/16/2016 03:09:27: Starting minibatch loop.
08/16/2016 03:09:27:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15556115 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0171s; samplesPerSecond = 74796.9
08/16/2016 03:09:27:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14724373 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0173s; samplesPerSecond = 74121.3
08/16/2016 03:09:27:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14685409 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0172s; samplesPerSecond = 74631.2
08/16/2016 03:09:27:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16360621 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0172s; samplesPerSecond = 74284.7
08/16/2016 03:09:27:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15780845 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0173s; samplesPerSecond = 74164.2
08/16/2016 03:09:27:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15691624 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0173s; samplesPerSecond = 73860.4
08/16/2016 03:09:27:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15916882 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0172s; samplesPerSecond = 74297.7
08/16/2016 03:09:27: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15400255 * 10000; EvalClassificationError = 0.07670000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.13627s
08/16/2016 03:09:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.30'

08/16/2016 03:09:27: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

08/16/2016 03:09:27: Starting minibatch loop.
08/16/2016 03:09:27:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15854410 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0166s; samplesPerSecond = 76955.5
08/16/2016 03:09:27:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15420641 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0174s; samplesPerSecond = 73749.7
08/16/2016 03:09:27:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15646703 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0170s; samplesPerSecond = 75170.3
08/16/2016 03:09:27:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14557362 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0172s; samplesPerSecond = 74592.1
08/16/2016 03:09:27:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17078629 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0171s; samplesPerSecond = 74923.9
08/16/2016 03:09:27:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13947368 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0171s; samplesPerSecond = 74709.6
08/16/2016 03:09:27:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14868889 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0170s; samplesPerSecond = 75099.7
08/16/2016 03:09:27: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15281967 * 10000; EvalClassificationError = 0.07560000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.13511s
08/16/2016 03:09:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.31'

08/16/2016 03:09:27: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

08/16/2016 03:09:27: Starting minibatch loop.
08/16/2016 03:09:27:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15335749 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0171s; samplesPerSecond = 75029.3
08/16/2016 03:09:27:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14308778 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0168s; samplesPerSecond = 76345.0
08/16/2016 03:09:27:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14223814 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0174s; samplesPerSecond = 73758.2
08/16/2016 03:09:27:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15188780 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0173s; samplesPerSecond = 73975.6
08/16/2016 03:09:27:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15086713 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0172s; samplesPerSecond = 74336.5
08/16/2016 03:09:27:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16064487 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0171s; samplesPerSecond = 74718.3
08/16/2016 03:09:27:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15454378 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0171s; samplesPerSecond = 74827.5
08/16/2016 03:09:27: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15326571 * 10000; EvalClassificationError = 0.07660000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.135787s
08/16/2016 03:09:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.32'

08/16/2016 03:09:27: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

08/16/2016 03:09:27: Starting minibatch loop.
08/16/2016 03:09:27:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15866314 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0175s; samplesPerSecond = 73268.5
08/16/2016 03:09:27:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17100292 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0169s; samplesPerSecond = 75959.9
08/16/2016 03:09:27:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14906003 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0166s; samplesPerSecond = 77136.3
08/16/2016 03:09:27:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15649090 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0165s; samplesPerSecond = 77674.6
08/16/2016 03:09:27:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13756232 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0165s; samplesPerSecond = 77735.9
08/16/2016 03:09:27:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14187341 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0164s; samplesPerSecond = 78239.6
08/16/2016 03:09:27:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16106291 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0165s; samplesPerSecond = 77740.7
08/16/2016 03:09:27: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15331483 * 10000; EvalClassificationError = 0.07750000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.132478s
08/16/2016 03:09:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.33'

08/16/2016 03:09:27: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

08/16/2016 03:09:27: Starting minibatch loop.
08/16/2016 03:09:27:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14242122 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0175s; samplesPerSecond = 73042.7
08/16/2016 03:09:27:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15583344 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0173s; samplesPerSecond = 73847.6
08/16/2016 03:09:27:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15891840 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0172s; samplesPerSecond = 74405.6
08/16/2016 03:09:27:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14699554 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0172s; samplesPerSecond = 74418.6
08/16/2016 03:09:27:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15782814 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0171s; samplesPerSecond = 74814.4
08/16/2016 03:09:27:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15657234 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0171s; samplesPerSecond = 74818.8
08/16/2016 03:09:27:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15388899 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0171s; samplesPerSecond = 74770.7
08/16/2016 03:09:27: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15179636 * 10000; EvalClassificationError = 0.07640000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.136406s
08/16/2016 03:09:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.34'

08/16/2016 03:09:27: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

08/16/2016 03:09:27: Starting minibatch loop.
08/16/2016 03:09:27:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15962775 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0176s; samplesPerSecond = 72582.9
08/16/2016 03:09:27:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14119732 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0173s; samplesPerSecond = 74014.1
08/16/2016 03:09:27:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14686041 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0173s; samplesPerSecond = 74117.0
08/16/2016 03:09:27:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14855204 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0173s; samplesPerSecond = 73873.1
08/16/2016 03:09:27:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14080853 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0172s; samplesPerSecond = 74215.8
08/16/2016 03:09:27:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14345264 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0171s; samplesPerSecond = 74836.3
08/16/2016 03:09:27:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15913496 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0172s; samplesPerSecond = 74220.1
08/16/2016 03:09:27: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.14921476 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.136857s
08/16/2016 03:09:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.35'

08/16/2016 03:09:27: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

08/16/2016 03:09:27: Starting minibatch loop.
08/16/2016 03:09:27:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14721221 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0176s; samplesPerSecond = 72615.9
08/16/2016 03:09:27:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17289702 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0169s; samplesPerSecond = 75538.5
08/16/2016 03:09:27:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15483642 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0172s; samplesPerSecond = 74440.2
08/16/2016 03:09:27:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15603595 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0171s; samplesPerSecond = 74731.4
08/16/2016 03:09:28:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15346479 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0170s; samplesPerSecond = 75157.1
08/16/2016 03:09:28:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13617387 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0171s; samplesPerSecond = 74959.0
08/16/2016 03:09:28:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14273968 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0175s; samplesPerSecond = 73255.9
08/16/2016 03:09:28: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15350118 * 10000; EvalClassificationError = 0.07840000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.137351s
08/16/2016 03:09:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.36'

08/16/2016 03:09:28: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

08/16/2016 03:09:28: Starting minibatch loop.
08/16/2016 03:09:28:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16883855 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0175s; samplesPerSecond = 73130.3
08/16/2016 03:09:28:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14396729 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0172s; samplesPerSecond = 74241.6
08/16/2016 03:09:28:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14920344 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0171s; samplesPerSecond = 75073.3
08/16/2016 03:09:28:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12402153 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0172s; samplesPerSecond = 74440.2
08/16/2016 03:09:28:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15503287 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0173s; samplesPerSecond = 74168.5
08/16/2016 03:09:28:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14398069 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0173s; samplesPerSecond = 74142.7
08/16/2016 03:09:28:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16336031 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0171s; samplesPerSecond = 74705.3
08/16/2016 03:09:28: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.14997815 * 10000; EvalClassificationError = 0.07470000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.137636s
08/16/2016 03:09:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.37'

08/16/2016 03:09:28: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

08/16/2016 03:09:28: Starting minibatch loop.
08/16/2016 03:09:28:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16700900 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0175s; samplesPerSecond = 72942.8
08/16/2016 03:09:28:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14556198 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0168s; samplesPerSecond = 76404.2
08/16/2016 03:09:28:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13987448 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0164s; samplesPerSecond = 78148.8
08/16/2016 03:09:28:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15890775 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0170s; samplesPerSecond = 75373.9
08/16/2016 03:09:28:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13739610 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0171s; samplesPerSecond = 74635.6
08/16/2016 03:09:28:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15440745 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0177s; samplesPerSecond = 72431.0
08/16/2016 03:09:28:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13707781 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0173s; samplesPerSecond = 74181.4
08/16/2016 03:09:28: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.14876062 * 10000; EvalClassificationError = 0.07770000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.135623s
08/16/2016 03:09:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.38'

08/16/2016 03:09:28: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

08/16/2016 03:09:28: Starting minibatch loop.
08/16/2016 03:09:28:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14555575 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0173s; samplesPerSecond = 74048.4
08/16/2016 03:09:28:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13892099 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0168s; samplesPerSecond = 76185.9
08/16/2016 03:09:28:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14857800 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0175s; samplesPerSecond = 73205.6
08/16/2016 03:09:28:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14665322 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0172s; samplesPerSecond = 74237.3
08/16/2016 03:09:28:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15658584 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0171s; samplesPerSecond = 75038.1
08/16/2016 03:09:28:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17460575 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0171s; samplesPerSecond = 74950.2
08/16/2016 03:09:28:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18014574 * 1280; EvalClassificationError = 0.09609375 * 1280; time = 0.0173s; samplesPerSecond = 74147.0
08/16/2016 03:09:28: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15431096 * 10000; EvalClassificationError = 0.08030000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.136146s
08/16/2016 03:09:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.39'

08/16/2016 03:09:28: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

08/16/2016 03:09:28: Starting minibatch loop.
08/16/2016 03:09:28:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18008710 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0173s; samplesPerSecond = 73847.6
08/16/2016 03:09:28:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14646367 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0168s; samplesPerSecond = 76185.9
08/16/2016 03:09:28:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15315390 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0173s; samplesPerSecond = 74190.0
08/16/2016 03:09:28:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15180483 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0171s; samplesPerSecond = 74941.5
08/16/2016 03:09:28:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15421243 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0170s; samplesPerSecond = 75174.7
08/16/2016 03:09:28:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15762277 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0171s; samplesPerSecond = 75068.9
08/16/2016 03:09:28:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14054337 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0170s; samplesPerSecond = 75201.2
08/16/2016 03:09:28: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15281459 * 10000; EvalClassificationError = 0.07740000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.135428s
08/16/2016 03:09:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.40'

08/16/2016 03:09:28: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

08/16/2016 03:09:28: Starting minibatch loop.
08/16/2016 03:09:28:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16199744 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0171s; samplesPerSecond = 75024.9
08/16/2016 03:09:28:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13060474 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0171s; samplesPerSecond = 75064.5
08/16/2016 03:09:28:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14528205 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0170s; samplesPerSecond = 75121.8
08/16/2016 03:09:28:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14745121 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0171s; samplesPerSecond = 74657.3
08/16/2016 03:09:28:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14677806 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0172s; samplesPerSecond = 74371.0
08/16/2016 03:09:28:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14226584 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0170s; samplesPerSecond = 75117.4
08/16/2016 03:09:28:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15018520 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0170s; samplesPerSecond = 75311.8
08/16/2016 03:09:28: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14561322 * 10000; EvalClassificationError = 0.07320000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.135417s
08/16/2016 03:09:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.41'

08/16/2016 03:09:28: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

08/16/2016 03:09:28: Starting minibatch loop.
08/16/2016 03:09:28:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14121022 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0173s; samplesPerSecond = 74121.3
08/16/2016 03:09:28:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14013841 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0171s; samplesPerSecond = 74810.1
08/16/2016 03:09:28:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15148885 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0173s; samplesPerSecond = 74142.7
08/16/2016 03:09:28:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14152312 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0172s; samplesPerSecond = 74557.3
08/16/2016 03:09:28:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14899693 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0171s; samplesPerSecond = 74976.6
08/16/2016 03:09:28:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15725455 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0171s; samplesPerSecond = 74827.5
08/16/2016 03:09:28:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17800837 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0171s; samplesPerSecond = 74985.4
08/16/2016 03:09:28: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15123268 * 10000; EvalClassificationError = 0.07710000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.135757s
08/16/2016 03:09:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.42'

08/16/2016 03:09:28: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

08/16/2016 03:09:28: Starting minibatch loop.
08/16/2016 03:09:28:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16342373 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0177s; samplesPerSecond = 72504.8
08/16/2016 03:09:28:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12180157 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0172s; samplesPerSecond = 74613.8
08/16/2016 03:09:28:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14622226 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0172s; samplesPerSecond = 74297.7
08/16/2016 03:09:29:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15369153 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0171s; samplesPerSecond = 75020.5
08/16/2016 03:09:29:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15860214 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0171s; samplesPerSecond = 74722.7
08/16/2016 03:09:29:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14122791 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0172s; samplesPerSecond = 74410.0
08/16/2016 03:09:29:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16564732 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0172s; samplesPerSecond = 74470.6
08/16/2016 03:09:29: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14938010 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.136478s
08/16/2016 03:09:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.43'

08/16/2016 03:09:29: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

08/16/2016 03:09:29: Starting minibatch loop.
08/16/2016 03:09:29:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16123869 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0174s; samplesPerSecond = 73673.3
08/16/2016 03:09:29:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15577049 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0170s; samplesPerSecond = 75467.2
08/16/2016 03:09:29:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.12841341 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0170s; samplesPerSecond = 75347.3
08/16/2016 03:09:29:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14609432 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0170s; samplesPerSecond = 75077.7
08/16/2016 03:09:29:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15202403 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0171s; samplesPerSecond = 75073.3
08/16/2016 03:09:29:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13416462 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0171s; samplesPerSecond = 75011.7
08/16/2016 03:09:29:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15762558 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0171s; samplesPerSecond = 74748.9
08/16/2016 03:09:29: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.14863992 * 10000; EvalClassificationError = 0.07410000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.135458s
08/16/2016 03:09:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.44'

08/16/2016 03:09:29: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

08/16/2016 03:09:29: Starting minibatch loop.
08/16/2016 03:09:29:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16425940 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0176s; samplesPerSecond = 72727.3
08/16/2016 03:09:29:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13906997 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0166s; samplesPerSecond = 77318.0
08/16/2016 03:09:29:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15275793 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0175s; samplesPerSecond = 73214.0
08/16/2016 03:09:29:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15256977 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0170s; samplesPerSecond = 75104.1
08/16/2016 03:09:29:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14671402 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0170s; samplesPerSecond = 75090.9
08/16/2016 03:09:29:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13406668 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0171s; samplesPerSecond = 74858.2
08/16/2016 03:09:29:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14873400 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0171s; samplesPerSecond = 74976.6
08/16/2016 03:09:29: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.14704166 * 10000; EvalClassificationError = 0.07600000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.135606s
08/16/2016 03:09:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.45'

08/16/2016 03:09:29: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

08/16/2016 03:09:29: Starting minibatch loop.
08/16/2016 03:09:29:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12665195 * 1280; EvalClassificationError = 0.05703125 * 1280; time = 0.0174s; samplesPerSecond = 73630.9
08/16/2016 03:09:29:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16254129 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0167s; samplesPerSecond = 76632.9
08/16/2016 03:09:29:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14150286 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0178s; samplesPerSecond = 71728.8
08/16/2016 03:09:29:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13744445 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0172s; samplesPerSecond = 74332.2
08/16/2016 03:09:29:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14358301 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0170s; samplesPerSecond = 75245.4
08/16/2016 03:09:29:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14920058 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0170s; samplesPerSecond = 75201.2
08/16/2016 03:09:29:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14926167 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0171s; samplesPerSecond = 74810.1
08/16/2016 03:09:29: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14446525 * 10000; EvalClassificationError = 0.07150000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.136039s
08/16/2016 03:09:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.46'

08/16/2016 03:09:29: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

08/16/2016 03:09:29: Starting minibatch loop.
08/16/2016 03:09:29:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14675958 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0172s; samplesPerSecond = 74513.9
08/16/2016 03:09:29:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14883993 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0170s; samplesPerSecond = 75303.0
08/16/2016 03:09:29:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15345020 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0180s; samplesPerSecond = 71107.2
08/16/2016 03:09:29:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11605973 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0170s; samplesPerSecond = 75196.8
08/16/2016 03:09:29:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13467197 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0171s; samplesPerSecond = 74744.5
08/16/2016 03:09:29:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14876442 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0182s; samplesPerSecond = 70244.8
08/16/2016 03:09:29:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13533382 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0172s; samplesPerSecond = 74592.1
08/16/2016 03:09:29: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14057241 * 10000; EvalClassificationError = 0.07400000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.137726s
08/16/2016 03:09:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.47'

08/16/2016 03:09:29: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

08/16/2016 03:09:29: Starting minibatch loop.
08/16/2016 03:09:29:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14498210 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0174s; samplesPerSecond = 73758.2
08/16/2016 03:09:29:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14912128 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0173s; samplesPerSecond = 74134.1
08/16/2016 03:09:29:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14851680 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0172s; samplesPerSecond = 74544.3
08/16/2016 03:09:29:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13951359 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0175s; samplesPerSecond = 72967.7
08/16/2016 03:09:29:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13970785 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0171s; samplesPerSecond = 74932.7
08/16/2016 03:09:29:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13940907 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0173s; samplesPerSecond = 74044.1
08/16/2016 03:09:29:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.12628412 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0172s; samplesPerSecond = 74319.2
08/16/2016 03:09:29: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14128646 * 10000; EvalClassificationError = 0.07260000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.13674s
08/16/2016 03:09:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.48'

08/16/2016 03:09:29: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

08/16/2016 03:09:29: Starting minibatch loop.
08/16/2016 03:09:29:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15530841 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0176s; samplesPerSecond = 72620.0
08/16/2016 03:09:29:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12999675 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0171s; samplesPerSecond = 74692.2
08/16/2016 03:09:29:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14699607 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0172s; samplesPerSecond = 74461.9
08/16/2016 03:09:29:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14356289 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0173s; samplesPerSecond = 74091.2
08/16/2016 03:09:29:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14086623 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0173s; samplesPerSecond = 74129.8
08/16/2016 03:09:29:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13911195 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0171s; samplesPerSecond = 74766.4
08/16/2016 03:09:29:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17052746 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0170s; samplesPerSecond = 75165.9
08/16/2016 03:09:29: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.14581660 * 10000; EvalClassificationError = 0.07380000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.13634s
08/16/2016 03:09:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.49'

08/16/2016 03:09:29: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/16/2016 03:09:29: Starting minibatch loop.
08/16/2016 03:09:29:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14376967 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0175s; samplesPerSecond = 73151.2
08/16/2016 03:09:29:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13468318 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0171s; samplesPerSecond = 75002.9
08/16/2016 03:09:30:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13613789 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0172s; samplesPerSecond = 74496.6
08/16/2016 03:09:30:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14630637 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0171s; samplesPerSecond = 74639.9
08/16/2016 03:09:30:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13355980 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0171s; samplesPerSecond = 74875.7
08/16/2016 03:09:30:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14160790 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0171s; samplesPerSecond = 74888.8
08/16/2016 03:09:30:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14176865 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0170s; samplesPerSecond = 75157.1
08/16/2016 03:09:30: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.13893765 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.135975s
08/16/2016 03:09:30: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn'
08/16/2016 03:09:30: CNTKCommandTrainEnd: Simple_Demo

08/16/2016 03:09:30: Action "train" complete.


08/16/2016 03:09:30: ##############################################################################
08/16/2016 03:09:30: #                                                                            #
08/16/2016 03:09:30: # Action "write"                                                             #
08/16/2016 03:09:30: #                                                                            #
08/16/2016 03:09:30: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

08/16/2016 03:09:30: Action "write" complete.

08/16/2016 03:09:30: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 16 2016 02:54:53
		Last modified date: Fri Aug 12 05:31:21 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
		Built by svcphil on Philly-Pool3
		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/16/2016 03:09:31: -------------------------------------------------------------------
08/16/2016 03:09:31: Build info: 

08/16/2016 03:09:31: 		Built time: Aug 16 2016 02:54:53
08/16/2016 03:09:31: 		Last modified date: Fri Aug 12 05:31:21 2016
08/16/2016 03:09:31: 		Build type: Release
08/16/2016 03:09:31: 		Build target: GPU
08/16/2016 03:09:31: 		With 1bit-SGD: no
08/16/2016 03:09:31: 		Math lib: mkl
08/16/2016 03:09:31: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/16/2016 03:09:31: 		CUB_PATH: c:\src\cub-1.4.1
08/16/2016 03:09:31: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/16/2016 03:09:31: 		Build Branch: HEAD
08/16/2016 03:09:31: 		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
08/16/2016 03:09:31: 		Built by svcphil on Philly-Pool3
08/16/2016 03:09:31: 		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/16/2016 03:09:31: -------------------------------------------------------------------
08/16/2016 03:09:32: -------------------------------------------------------------------
08/16/2016 03:09:32: GPU info:

08/16/2016 03:09:32: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/16/2016 03:09:32: -------------------------------------------------------------------

08/16/2016 03:09:32: Running on cntk-muc01 at 2016/08/16 03:09:32
08/16/2016 03:09:32: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu  DeviceId=0  timestamping=true  makeMode=true



08/16/2016 03:09:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:09:32: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/16/2016 03:09:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:09:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:09:32: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/16/2016 03:09:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:09:32: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/16/2016 03:09:32: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/16/2016 03:09:32: Commands: Simple_Demo Simple_Demo_Output
08/16/2016 03:09:32: Precision = "float"
08/16/2016 03:09:32: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn
08/16/2016 03:09:32: CNTKCommandTrainInfo: Simple_Demo : 50
08/16/2016 03:09:32: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/16/2016 03:09:32: ##############################################################################
08/16/2016 03:09:32: #                                                                            #
08/16/2016 03:09:32: # Action "train"                                                             #
08/16/2016 03:09:32: #                                                                            #
08/16/2016 03:09:32: ##############################################################################

08/16/2016 03:09:32: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

08/16/2016 03:09:32: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/16/2016 03:09:32: Loaded model with 25 nodes on GPU 0.

08/16/2016 03:09:32: Training criterion node(s):
08/16/2016 03:09:32: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/16/2016 03:09:32: Evaluation criterion node(s):
08/16/2016 03:09:32: 	EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }
	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }


08/16/2016 03:09:32: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/16/2016 03:09:32: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/16/2016 03:09:32: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/16/2016 03:09:32: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/16/2016 03:09:32: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/16/2016 03:09:32: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/16/2016 03:09:32: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

08/16/2016 03:09:32: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/16/2016 03:09:32: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/16/2016 03:09:32: Starting minibatch loop.
08/16/2016 03:09:32:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.14376967 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.1860s; samplesPerSecond = 6882.2
08/16/2016 03:09:32:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.13468318 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0151s; samplesPerSecond = 84824.4
08/16/2016 03:09:32:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.13613789 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0151s; samplesPerSecond = 84801.9
08/16/2016 03:09:32:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14630637 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0151s; samplesPerSecond = 84594.5
08/16/2016 03:09:32:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.13355980 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0151s; samplesPerSecond = 84773.8
08/16/2016 03:09:32:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14160790 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0151s; samplesPerSecond = 84762.6
08/16/2016 03:09:32:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14176865 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0151s; samplesPerSecond = 84706.5
08/16/2016 03:09:32: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.13893765 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.292461s
08/16/2016 03:09:32: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/models/simple.dnn'
08/16/2016 03:09:32: CNTKCommandTrainEnd: Simple_Demo

08/16/2016 03:09:32: Action "train" complete.


08/16/2016 03:09:32: ##############################################################################
08/16/2016 03:09:32: #                                                                            #
08/16/2016 03:09:32: # Action "write"                                                             #
08/16/2016 03:09:32: #                                                                            #
08/16/2016 03:09:32: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

08/16/2016 03:09:32: Action "write" complete.

08/16/2016 03:09:32: __COMPLETED__