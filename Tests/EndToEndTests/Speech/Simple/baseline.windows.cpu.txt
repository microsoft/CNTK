=== Running /cygdrive/c/Jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Jun 15 2016 00:45:13
		Last modified date: Tue Jun 14 04:21:55 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 35cb5738e7ef794177a2fff06892a39700722dee
		Built by svcphil on cntk-muc02
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
06/15/2016 07:48:02: -------------------------------------------------------------------
06/15/2016 07:48:02: Build info: 

06/15/2016 07:48:02: 		Built time: Jun 15 2016 00:45:13
06/15/2016 07:48:02: 		Last modified date: Tue Jun 14 04:21:55 2016
06/15/2016 07:48:02: 		Build type: Release
06/15/2016 07:48:02: 		Build target: GPU
06/15/2016 07:48:02: 		With 1bit-SGD: no
06/15/2016 07:48:02: 		Math lib: mkl
06/15/2016 07:48:02: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
06/15/2016 07:48:02: 		CUB_PATH: c:\src\cub-1.4.1
06/15/2016 07:48:02: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
06/15/2016 07:48:02: 		Build Branch: HEAD
06/15/2016 07:48:02: 		Build SHA1: 35cb5738e7ef794177a2fff06892a39700722dee
06/15/2016 07:48:02: 		Built by svcphil on cntk-muc02
06/15/2016 07:48:02: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
06/15/2016 07:48:02: -------------------------------------------------------------------

06/15/2016 07:48:02: Running on Philly-Pool3 at 2016/06/15 07:48:02
06/15/2016 07:48:02: Command line: 
C:\Jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu  DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



06/15/2016 07:48:02: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
06/15/2016 07:48:02: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

06/15/2016 07:48:02: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

06/15/2016 07:48:02: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
06/15/2016 07:48:02: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

06/15/2016 07:48:02: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

06/15/2016 07:48:02: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
06/15/2016 07:48:02: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
06/15/2016 07:48:02: Commands: Simple_Demo Simple_Demo_Output
06/15/2016 07:48:02: Precision = "float"
06/15/2016 07:48:02: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn
06/15/2016 07:48:02: CNTKCommandTrainInfo: Simple_Demo : 50
06/15/2016 07:48:02: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

06/15/2016 07:48:02: ##############################################################################
06/15/2016 07:48:02: #                                                                            #
06/15/2016 07:48:02: # Action "train"                                                             #
06/15/2016 07:48:02: #                                                                            #
06/15/2016 07:48:02: ##############################################################################

06/15/2016 07:48:02: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

06/15/2016 07:48:02: Creating virgin network.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

06/15/2016 07:48:02: Created model with 25 nodes on CPU.

06/15/2016 07:48:02: Training criterion node(s):
06/15/2016 07:48:02: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

06/15/2016 07:48:02: Evaluation criterion node(s):

06/15/2016 07:48:02: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
000000FAF5CCB560: {[features Value[2 x *]] }
000000FAF5D68500: {[W0 Value[50 x 2]] }
000000FAF5D685A0: {[W1 Value[50 x 50]] }
000000FAF5D686E0: {[B1 Value[50 x 1]] }
000000FAF5D68820: {[B0 Value[50 x 1]] }
000000FAF5D688C0: {[InvStdOfFeatures Value[2]] }
000000FAF5D68F00: {[B2 Value[2 x 1]] }
000000FAF5D69180: {[W2 Value[2 x 50]] }
000000FAF5D69400: {[MeanOfFeatures Value[2]] }
000000FAF83BC100: {[labels Value[2 x *]] }
000000FAF83BC1A0: {[Prior Value[2]] }
000000FAF83BC380: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
000000FAF83BC4C0: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
000000FAF83BC560: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
000000FAF83BC600: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
000000FAF83BC880: {[MVNormalizedFeatures Value[2 x *]] }
000000FAF83BCBA0: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
000000FAF83BCD80: {[LogOfPrior Value[2]] }
000000FAF83BD000: {[ScaledLogLikelihood Value[2 x 1 x *]] }
000000FAF83BD140: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
000000FAF83BD280: {[W0*features Value[50 x *]] }
000000FAF83BD320: {[CrossEntropyWithSoftmax Value[1]] }
000000FAF83BD460: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
000000FAF83BD500: {[W2*H1 Gradient[2 x 1 x *]] }
000000FAF83BDAA0: {[B2 Gradient[2 x 1]] }
000000FAF83BDB40: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
000000FAF83BDDC0: {[CrossEntropyWithSoftmax Gradient[1]] }
000000FAF83BDFA0: {[EvalErrorPrediction Value[1]] }


06/15/2016 07:48:02: Precomputing --> 3 PreCompute nodes found.

06/15/2016 07:48:02: 	MeanOfFeatures = Mean()
06/15/2016 07:48:02: 	InvStdOfFeatures = InvStdDev()
06/15/2016 07:48:02: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

06/15/2016 07:48:02: Precomputing --> Completed.


06/15/2016 07:48:02: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

06/15/2016 07:48:02: Starting minibatch loop.
06/15/2016 07:48:02:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.80535259 * 1280; EvalErrorPrediction = 0.48125000 * 1280; time = 0.1534s; samplesPerSecond = 8343.3
06/15/2016 07:48:02:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.74649687 * 1280; EvalErrorPrediction = 0.50312500 * 1280; time = 0.0847s; samplesPerSecond = 15120.6
06/15/2016 07:48:02:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.70433893 * 1280; EvalErrorPrediction = 0.48593750 * 1280; time = 0.0832s; samplesPerSecond = 15381.1
06/15/2016 07:48:02:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.72196388 * 1280; EvalErrorPrediction = 0.49843750 * 1280; time = 0.0766s; samplesPerSecond = 16711.7
06/15/2016 07:48:03:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.72255802 * 1280; EvalErrorPrediction = 0.48046875 * 1280; time = 0.1265s; samplesPerSecond = 10117.9
06/15/2016 07:48:03:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.60346756 * 1280; EvalErrorPrediction = 0.39921875 * 1280; time = 0.0675s; samplesPerSecond = 18964.4
06/15/2016 07:48:03:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.28063698 * 1280; EvalErrorPrediction = 0.10156250 * 1280; time = 0.0688s; samplesPerSecond = 18610.1
06/15/2016 07:48:03: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.60884868 * 10000; EvalErrorPrediction = 0.38710000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.754998s
06/15/2016 07:48:03: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.1'

06/15/2016 07:48:03: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

06/15/2016 07:48:03: Starting minibatch loop.
06/15/2016 07:48:03:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.24440625 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.1228s; samplesPerSecond = 10422.3
06/15/2016 07:48:03:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21235788 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.1029s; samplesPerSecond = 12438.3
06/15/2016 07:48:03:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.23371706 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0891s; samplesPerSecond = 14363.8
06/15/2016 07:48:03:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.23075676 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0790s; samplesPerSecond = 16199.5
06/15/2016 07:48:03:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17314787 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0756s; samplesPerSecond = 16925.2
06/15/2016 07:48:03:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18103743 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0690s; samplesPerSecond = 18539.4
06/15/2016 07:48:03:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18745871 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0675s; samplesPerSecond = 18973.4
06/15/2016 07:48:04: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.20537053 * 10000; EvalErrorPrediction = 0.08160000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.671396s
06/15/2016 07:48:04: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.2'

06/15/2016 07:48:04: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

06/15/2016 07:48:04: Starting minibatch loop.
06/15/2016 07:48:04:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15202810 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.1242s; samplesPerSecond = 10307.6
06/15/2016 07:48:04:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20600349 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0937s; samplesPerSecond = 13664.7
06/15/2016 07:48:04:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.21713474 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0849s; samplesPerSecond = 15083.0
06/15/2016 07:48:04:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17632737 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0788s; samplesPerSecond = 16249.8
06/15/2016 07:48:04:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18420377 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0731s; samplesPerSecond = 17513.4
06/15/2016 07:48:04:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18768635 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0691s; samplesPerSecond = 18531.4
06/15/2016 07:48:04:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17461519 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0661s; samplesPerSecond = 19354.6
06/15/2016 07:48:04: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.18497550 * 10000; EvalErrorPrediction = 0.08140000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.655728s
06/15/2016 07:48:04: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.3'

06/15/2016 07:48:04: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

06/15/2016 07:48:04: Starting minibatch loop.
06/15/2016 07:48:04:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19367219 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0858s; samplesPerSecond = 14916.2
06/15/2016 07:48:05:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.22726382 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0727s; samplesPerSecond = 17613.1
06/15/2016 07:48:05:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16761923 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0690s; samplesPerSecond = 18560.1
06/15/2016 07:48:05:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18552155 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0667s; samplesPerSecond = 19202.5
06/15/2016 07:48:05:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17760520 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0665s; samplesPerSecond = 19258.3
06/15/2016 07:48:05:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18695402 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0559s; samplesPerSecond = 22897.2
06/15/2016 07:48:05:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15497789 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0600s; samplesPerSecond = 21322.0
06/15/2016 07:48:05: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.18170890 * 10000; EvalErrorPrediction = 0.08040000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.532472s
06/15/2016 07:48:05: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.4'

06/15/2016 07:48:05: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

06/15/2016 07:48:05: Starting minibatch loop.
06/15/2016 07:48:05:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16476545 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0788s; samplesPerSecond = 16234.8
06/15/2016 07:48:05:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14682755 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0583s; samplesPerSecond = 21956.2
06/15/2016 07:48:05:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15163760 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0554s; samplesPerSecond = 23111.4
06/15/2016 07:48:05:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17362747 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0597s; samplesPerSecond = 21427.3
06/15/2016 07:48:05:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16733751 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0598s; samplesPerSecond = 21420.1
06/15/2016 07:48:05:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17198248 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0596s; samplesPerSecond = 21461.7
06/15/2016 07:48:05:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15520964 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0571s; samplesPerSecond = 22416.8
06/15/2016 07:48:06: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16172705 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.486494s
06/15/2016 07:48:06: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.5'

06/15/2016 07:48:06: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

06/15/2016 07:48:06: Starting minibatch loop.
06/15/2016 07:48:06:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15769737 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0792s; samplesPerSecond = 16158.4
06/15/2016 07:48:06:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15069685 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0597s; samplesPerSecond = 21458.1
06/15/2016 07:48:06:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13598216 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0607s; samplesPerSecond = 21103.3
06/15/2016 07:48:06:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14951530 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0590s; samplesPerSecond = 21686.8
06/15/2016 07:48:06:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16281805 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0569s; samplesPerSecond = 22493.2
06/15/2016 07:48:06:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17920194 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0576s; samplesPerSecond = 22228.0
06/15/2016 07:48:06:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16924067 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0606s; samplesPerSecond = 21106.8
06/15/2016 07:48:06: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.16214037 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.487739s
06/15/2016 07:48:06: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.6'

06/15/2016 07:48:06: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

06/15/2016 07:48:06: Starting minibatch loop.
06/15/2016 07:48:06:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15275362 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0790s; samplesPerSecond = 16205.2
06/15/2016 07:48:06:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18097169 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0635s; samplesPerSecond = 20143.5
06/15/2016 07:48:06:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18449802 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0605s; samplesPerSecond = 21156.7
06/15/2016 07:48:06:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14730082 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0600s; samplesPerSecond = 21350.1
06/15/2016 07:48:07:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14997697 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0588s; samplesPerSecond = 21763.2
06/15/2016 07:48:07:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14873629 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0582s; samplesPerSecond = 22008.3
06/15/2016 07:48:07:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15338011 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0594s; samplesPerSecond = 21535.8
06/15/2016 07:48:07: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16427151 * 10000; EvalErrorPrediction = 0.07460000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.495321s
06/15/2016 07:48:07: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.7'

06/15/2016 07:48:07: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

06/15/2016 07:48:07: Starting minibatch loop.
06/15/2016 07:48:07:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17743570 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0789s; samplesPerSecond = 16226.8
06/15/2016 07:48:07:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15529243 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0629s; samplesPerSecond = 20339.7
06/15/2016 07:48:07:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15773594 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0605s; samplesPerSecond = 21147.9
06/15/2016 07:48:07:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18696561 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0595s; samplesPerSecond = 21497.1
06/15/2016 07:48:07:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15896473 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0624s; samplesPerSecond = 20511.2
06/15/2016 07:48:07:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17115736 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0601s; samplesPerSecond = 21289.7
06/15/2016 07:48:07:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17013454 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0577s; samplesPerSecond = 22185.6
06/15/2016 07:48:07: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16759005 * 10000; EvalErrorPrediction = 0.07670000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.499852s
06/15/2016 07:48:07: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.8'

06/15/2016 07:48:07: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

06/15/2016 07:48:07: Starting minibatch loop.
06/15/2016 07:48:08:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17123349 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.1178s; samplesPerSecond = 10865.0
06/15/2016 07:48:08:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16148000 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0600s; samplesPerSecond = 21350.1
06/15/2016 07:48:08:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14165161 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0558s; samplesPerSecond = 22947.7
06/15/2016 07:48:08:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13593888 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0560s; samplesPerSecond = 22854.3
06/15/2016 07:48:08:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16915498 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0575s; samplesPerSecond = 22257.8
06/15/2016 07:48:08:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17293506 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0558s; samplesPerSecond = 22959.6
06/15/2016 07:48:08:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15506458 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0585s; samplesPerSecond = 21879.6
06/15/2016 07:48:08: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.15931383 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.519094s
06/15/2016 07:48:09: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.9'

06/15/2016 07:48:09: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

06/15/2016 07:48:09: Starting minibatch loop.
06/15/2016 07:48:09:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17942336 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.1459s; samplesPerSecond = 8771.4
06/15/2016 07:48:09:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17676737 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.1172s; samplesPerSecond = 10925.8
06/15/2016 07:48:09:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16481185 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0924s; samplesPerSecond = 13854.6
06/15/2016 07:48:09:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16778483 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0829s; samplesPerSecond = 15444.9
06/15/2016 07:48:10:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14307494 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0769s; samplesPerSecond = 16640.7
06/15/2016 07:48:10:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15314693 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0720s; samplesPerSecond = 17789.9
06/15/2016 07:48:10:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16701956 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0676s; samplesPerSecond = 18934.1
06/15/2016 07:48:10: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16330491 * 10000; EvalErrorPrediction = 0.07730000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.720284s
06/15/2016 07:48:10: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.10'

06/15/2016 07:48:10: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

06/15/2016 07:48:10: Starting minibatch loop.
06/15/2016 07:48:10:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17279325 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0983s; samplesPerSecond = 13017.0
06/15/2016 07:48:10:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16952052 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0672s; samplesPerSecond = 19036.9
06/15/2016 07:48:10:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16738977 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0665s; samplesPerSecond = 19238.0
06/15/2016 07:48:10:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16992412 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0649s; samplesPerSecond = 19729.6
06/15/2016 07:48:10:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13462358 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0649s; samplesPerSecond = 19715.4
06/15/2016 07:48:10:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16262293 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0552s; samplesPerSecond = 23167.4
06/15/2016 07:48:10:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16357203 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0589s; samplesPerSecond = 21719.2
06/15/2016 07:48:10: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16459014 * 10000; EvalErrorPrediction = 0.07580000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.534534s
06/15/2016 07:48:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.11'

06/15/2016 07:48:11: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

06/15/2016 07:48:11: Starting minibatch loop.
06/15/2016 07:48:11:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19513361 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.1076s; samplesPerSecond = 11890.7
06/15/2016 07:48:11:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17741292 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0824s; samplesPerSecond = 15542.1
06/15/2016 07:48:11:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20324087 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0773s; samplesPerSecond = 16549.2
06/15/2016 07:48:11:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18037620 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0736s; samplesPerSecond = 17395.3
06/15/2016 07:48:11:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17229996 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0748s; samplesPerSecond = 17102.7
06/15/2016 07:48:11:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15508251 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0664s; samplesPerSecond = 19266.4
06/15/2016 07:48:11:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16498756 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0696s; samplesPerSecond = 18392.4
06/15/2016 07:48:11: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.17811724 * 10000; EvalErrorPrediction = 0.07840000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.612559s
06/15/2016 07:48:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.12'

06/15/2016 07:48:11: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

06/15/2016 07:48:11: Starting minibatch loop.
06/15/2016 07:48:12:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17905607 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.1390s; samplesPerSecond = 9209.5
06/15/2016 07:48:12:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17237868 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.1172s; samplesPerSecond = 10918.2
06/15/2016 07:48:12:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15478225 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0936s; samplesPerSecond = 13669.2
06/15/2016 07:48:12:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17471642 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0832s; samplesPerSecond = 15390.0
06/15/2016 07:48:12:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16506515 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0758s; samplesPerSecond = 16893.0
06/15/2016 07:48:12:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16242933 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0711s; samplesPerSecond = 17991.4
06/15/2016 07:48:12:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16958532 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0706s; samplesPerSecond = 18119.3
06/15/2016 07:48:12: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16643588 * 10000; EvalErrorPrediction = 0.07670000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.714181s
06/15/2016 07:48:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.13'

06/15/2016 07:48:12: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

06/15/2016 07:48:12: Starting minibatch loop.
06/15/2016 07:48:12:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16889555 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0959s; samplesPerSecond = 13350.4
06/15/2016 07:48:12:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15427818 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0686s; samplesPerSecond = 18658.1
06/15/2016 07:48:13:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20336878 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0701s; samplesPerSecond = 18260.4
06/15/2016 07:48:13:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16971745 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.1230s; samplesPerSecond = 10410.0
06/15/2016 07:48:13:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15063095 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0606s; samplesPerSecond = 21106.1
06/15/2016 07:48:13:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15653648 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0577s; samplesPerSecond = 22199.5
06/15/2016 07:48:13:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16588535 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0593s; samplesPerSecond = 21587.7
06/15/2016 07:48:13: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.16619141 * 10000; EvalErrorPrediction = 0.07710000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.590104s
06/15/2016 07:48:13: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.14'

06/15/2016 07:48:13: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

06/15/2016 07:48:13: Starting minibatch loop.
06/15/2016 07:48:13:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19676595 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0810s; samplesPerSecond = 15803.4
06/15/2016 07:48:13:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.22987738 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0581s; samplesPerSecond = 22049.2
06/15/2016 07:48:13:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17708364 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0563s; samplesPerSecond = 22734.5
06/15/2016 07:48:13:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17476530 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0574s; samplesPerSecond = 22296.9
06/15/2016 07:48:13:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16122503 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0587s; samplesPerSecond = 21822.5
06/15/2016 07:48:13:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17361937 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0612s; samplesPerSecond = 20915.4
06/15/2016 07:48:13:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15524387 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0577s; samplesPerSecond = 22171.4
06/15/2016 07:48:13: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.17955685 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.4855s
06/15/2016 07:48:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.15'

06/15/2016 07:48:14: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

06/15/2016 07:48:14: Starting minibatch loop.
06/15/2016 07:48:14:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17717791 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0754s; samplesPerSecond = 16966.9
06/15/2016 07:48:14:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17226894 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0601s; samplesPerSecond = 21314.5
06/15/2016 07:48:14:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13928263 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0561s; samplesPerSecond = 22807.9
06/15/2016 07:48:14:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14980845 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0576s; samplesPerSecond = 22232.6
06/15/2016 07:48:14:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15198617 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0555s; samplesPerSecond = 23048.5
06/15/2016 07:48:14:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16112480 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0581s; samplesPerSecond = 22045.0
06/15/2016 07:48:14:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17293167 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0574s; samplesPerSecond = 22312.1
06/15/2016 07:48:14: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.16020182 * 10000; EvalErrorPrediction = 0.07410000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.475065s
06/15/2016 07:48:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.16'

06/15/2016 07:48:14: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

06/15/2016 07:48:14: Starting minibatch loop.
06/15/2016 07:48:14:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17114060 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0715s; samplesPerSecond = 17896.6
06/15/2016 07:48:14:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15955999 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0634s; samplesPerSecond = 20192.8
06/15/2016 07:48:14:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15213799 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0594s; samplesPerSecond = 21532.9
06/15/2016 07:48:14:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16789312 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0565s; samplesPerSecond = 22640.4
06/15/2016 07:48:14:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17726035 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0585s; samplesPerSecond = 21874.4
06/15/2016 07:48:15:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17526207 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0584s; samplesPerSecond = 21912.9
06/15/2016 07:48:15:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17336807 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0634s; samplesPerSecond = 20198.8
06/15/2016 07:48:15: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16736165 * 10000; EvalErrorPrediction = 0.07790000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.487923s
06/15/2016 07:48:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.17'

06/15/2016 07:48:15: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

06/15/2016 07:48:15: Starting minibatch loop.
06/15/2016 07:48:15:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18521786 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0786s; samplesPerSecond = 16276.9
06/15/2016 07:48:15:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16549249 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0553s; samplesPerSecond = 23136.4
06/15/2016 07:48:15:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15361519 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0573s; samplesPerSecond = 22341.7
06/15/2016 07:48:15:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16726284 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0592s; samplesPerSecond = 21619.1
06/15/2016 07:48:15:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14880643 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0577s; samplesPerSecond = 22189.1
06/15/2016 07:48:15:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15056181 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0581s; samplesPerSecond = 22018.5
06/15/2016 07:48:15:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18099127 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0572s; samplesPerSecond = 22379.6
06/15/2016 07:48:15: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.16469803 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.479765s
06/15/2016 07:48:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.18'

06/15/2016 07:48:15: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

06/15/2016 07:48:15: Starting minibatch loop.
06/15/2016 07:48:15:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16070937 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0789s; samplesPerSecond = 16221.8
06/15/2016 07:48:15:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14254960 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0591s; samplesPerSecond = 21654.9
06/15/2016 07:48:16:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17875755 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0558s; samplesPerSecond = 22941.9
06/15/2016 07:48:16:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14477563 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0557s; samplesPerSecond = 22980.7
06/15/2016 07:48:16:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14461050 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0557s; samplesPerSecond = 22988.1
06/15/2016 07:48:16:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18452682 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0613s; samplesPerSecond = 20896.6
06/15/2016 07:48:16:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17267265 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0576s; samplesPerSecond = 22238.4
06/15/2016 07:48:16: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16178866 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.485473s
06/15/2016 07:48:16: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.19'

06/15/2016 07:48:16: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

06/15/2016 07:48:16: Starting minibatch loop.
06/15/2016 07:48:16:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15175894 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0797s; samplesPerSecond = 16064.9
06/15/2016 07:48:16:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16639475 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0601s; samplesPerSecond = 21301.0
06/15/2016 07:48:16:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14919484 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0557s; samplesPerSecond = 22984.4
06/15/2016 07:48:16:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15603719 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0616s; samplesPerSecond = 20768.1
06/15/2016 07:48:16:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16388106 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0595s; samplesPerSecond = 21521.3
06/15/2016 07:48:16:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17457786 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0593s; samplesPerSecond = 21586.3
06/15/2016 07:48:16:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17699947 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0569s; samplesPerSecond = 22493.6
06/15/2016 07:48:16: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16061273 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.487187s
06/15/2016 07:48:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.20'

06/15/2016 07:48:17: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

06/15/2016 07:48:17: Starting minibatch loop.
06/15/2016 07:48:17:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17350243 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0797s; samplesPerSecond = 16056.6
06/15/2016 07:48:17:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14557666 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0634s; samplesPerSecond = 20204.3
06/15/2016 07:48:17:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15787494 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0608s; samplesPerSecond = 21061.3
06/15/2016 07:48:17:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17384133 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0575s; samplesPerSecond = 22255.1
06/15/2016 07:48:17:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16346836 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0591s; samplesPerSecond = 21647.2
06/15/2016 07:48:17:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15387497 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0616s; samplesPerSecond = 20775.2
06/15/2016 07:48:17:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15881405 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0552s; samplesPerSecond = 23174.1
06/15/2016 07:48:17: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15990673 * 10000; EvalErrorPrediction = 0.07400000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.493085s
06/15/2016 07:48:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.21'

06/15/2016 07:48:17: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

06/15/2016 07:48:17: Starting minibatch loop.
06/15/2016 07:48:17:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15962188 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0787s; samplesPerSecond = 16254.8
06/15/2016 07:48:17:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14494109 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0598s; samplesPerSecond = 21419.4
06/15/2016 07:48:17:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16207740 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0567s; samplesPerSecond = 22588.9
06/15/2016 07:48:17:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13846774 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0576s; samplesPerSecond = 22228.0
06/15/2016 07:48:17:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16633983 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0605s; samplesPerSecond = 21143.7
06/15/2016 07:48:17:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16044865 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0595s; samplesPerSecond = 21511.9
06/15/2016 07:48:18:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19604635 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0562s; samplesPerSecond = 22776.2
06/15/2016 07:48:18: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16143629 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.538888s
06/15/2016 07:48:18: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.22'

06/15/2016 07:48:18: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

06/15/2016 07:48:18: Starting minibatch loop.
06/15/2016 07:48:18:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17537358 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0814s; samplesPerSecond = 15720.4
06/15/2016 07:48:18:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19615362 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0609s; samplesPerSecond = 21034.3
06/15/2016 07:48:18:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18770199 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0565s; samplesPerSecond = 22637.6
06/15/2016 07:48:18:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15181499 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0587s; samplesPerSecond = 21791.3
06/15/2016 07:48:18:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16218381 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0600s; samplesPerSecond = 21335.1
06/15/2016 07:48:18:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17625360 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0583s; samplesPerSecond = 21947.9
06/15/2016 07:48:18:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16335430 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0573s; samplesPerSecond = 22345.6
06/15/2016 07:48:18: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.17107432 * 10000; EvalErrorPrediction = 0.07770000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.487087s
06/15/2016 07:48:18: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.23'

06/15/2016 07:48:18: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

06/15/2016 07:48:18: Starting minibatch loop.
06/15/2016 07:48:18:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19653838 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0812s; samplesPerSecond = 15759.3
06/15/2016 07:48:19:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14431756 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.1198s; samplesPerSecond = 10687.2
06/15/2016 07:48:19:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16348419 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.1255s; samplesPerSecond = 10200.7
06/15/2016 07:48:19:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15587249 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0588s; samplesPerSecond = 21760.2
06/15/2016 07:48:19:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15973740 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0566s; samplesPerSecond = 22607.7
06/15/2016 07:48:19:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17249680 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0576s; samplesPerSecond = 22223.8
06/15/2016 07:48:19:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14780130 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0574s; samplesPerSecond = 22311.3
06/15/2016 07:48:19: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16152230 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.616516s
06/15/2016 07:48:19: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.24'

06/15/2016 07:48:19: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

06/15/2016 07:48:19: Starting minibatch loop.
06/15/2016 07:48:19:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15919970 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0794s; samplesPerSecond = 16115.8
06/15/2016 07:48:19:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14973243 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0603s; samplesPerSecond = 21219.5
06/15/2016 07:48:19:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16454341 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0612s; samplesPerSecond = 20925.3
06/15/2016 07:48:19:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15375748 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0568s; samplesPerSecond = 22536.0
06/15/2016 07:48:19:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15537601 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0580s; samplesPerSecond = 22059.8
06/15/2016 07:48:19:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14606795 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0555s; samplesPerSecond = 23053.1
06/15/2016 07:48:19:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16131563 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0551s; samplesPerSecond = 23249.1
06/15/2016 07:48:20: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.15718755 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.484111s
06/15/2016 07:48:20: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.25'

06/15/2016 07:48:20: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

06/15/2016 07:48:20: Starting minibatch loop.
06/15/2016 07:48:20:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16084294 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0788s; samplesPerSecond = 16237.3
06/15/2016 07:48:20:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14869900 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0561s; samplesPerSecond = 22836.3
06/15/2016 07:48:20:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15454650 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0586s; samplesPerSecond = 21850.1
06/15/2016 07:48:20:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17597771 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0553s; samplesPerSecond = 23131.8
06/15/2016 07:48:20:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15749536 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0591s; samplesPerSecond = 21671.0
06/15/2016 07:48:20:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15394645 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0566s; samplesPerSecond = 22602.1
06/15/2016 07:48:20:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15662699 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0580s; samplesPerSecond = 22059.5
06/15/2016 07:48:20: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15990753 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.484592s
06/15/2016 07:48:22: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.26'

06/15/2016 07:48:22: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

06/15/2016 07:48:22: Starting minibatch loop.
06/15/2016 07:48:22:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16528015 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.1442s; samplesPerSecond = 8879.5
06/15/2016 07:48:22:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15882976 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.1134s; samplesPerSecond = 11286.7
06/15/2016 07:48:22:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16982448 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0947s; samplesPerSecond = 13512.4
06/15/2016 07:48:22:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16238184 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0853s; samplesPerSecond = 15014.7
06/15/2016 07:48:22:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16284833 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0759s; samplesPerSecond = 16867.2
06/15/2016 07:48:22:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19325085 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0682s; samplesPerSecond = 18761.2
06/15/2016 07:48:22:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16514435 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0718s; samplesPerSecond = 17829.5
06/15/2016 07:48:22: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16354396 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.717824s
06/15/2016 07:48:22: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.27'

06/15/2016 07:48:22: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

06/15/2016 07:48:22: Starting minibatch loop.
06/15/2016 07:48:23:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14816061 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0959s; samplesPerSecond = 13340.7
06/15/2016 07:48:23:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16256834 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.1267s; samplesPerSecond = 10100.8
06/15/2016 07:48:23:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16535304 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0673s; samplesPerSecond = 19010.8
06/15/2016 07:48:23:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16272936 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0657s; samplesPerSecond = 19480.1
06/15/2016 07:48:23:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13527870 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0600s; samplesPerSecond = 21326.9
06/15/2016 07:48:23:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15502572 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0587s; samplesPerSecond = 21808.0
06/15/2016 07:48:23:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17108698 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0557s; samplesPerSecond = 22992.2
06/15/2016 07:48:23: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15766368 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.585051s
06/15/2016 07:48:23: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.28'

06/15/2016 07:48:23: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

06/15/2016 07:48:23: Starting minibatch loop.
06/15/2016 07:48:23:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15449502 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0798s; samplesPerSecond = 16041.9
06/15/2016 07:48:23:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15199747 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0581s; samplesPerSecond = 22017.0
06/15/2016 07:48:23:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15376375 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0575s; samplesPerSecond = 22264.0
06/15/2016 07:48:23:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16323447 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0619s; samplesPerSecond = 20665.2
06/15/2016 07:48:23:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16567492 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0605s; samplesPerSecond = 21170.0
06/15/2016 07:48:24:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15234828 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0567s; samplesPerSecond = 22573.8
06/15/2016 07:48:24:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15832376 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0582s; samplesPerSecond = 22004.1
06/15/2016 07:48:24: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16024633 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.487452s
06/15/2016 07:48:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.29'

06/15/2016 07:48:24: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

06/15/2016 07:48:24: Starting minibatch loop.
06/15/2016 07:48:24:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15084908 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.1178s; samplesPerSecond = 10862.2
06/15/2016 07:48:24:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15775607 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0891s; samplesPerSecond = 14362.3
06/15/2016 07:48:24:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17160110 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0804s; samplesPerSecond = 15921.2
06/15/2016 07:48:24:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17667308 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0730s; samplesPerSecond = 17542.4
06/15/2016 07:48:24:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15995951 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0675s; samplesPerSecond = 18971.1
06/15/2016 07:48:24:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17257719 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0671s; samplesPerSecond = 19089.4
06/15/2016 07:48:24:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15350113 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0655s; samplesPerSecond = 19544.7
06/15/2016 07:48:24: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16108268 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.635794s
06/15/2016 07:48:24: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.30'

06/15/2016 07:48:24: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

06/15/2016 07:48:24: Starting minibatch loop.
06/15/2016 07:48:25:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15518786 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.1206s; samplesPerSecond = 10610.8
06/15/2016 07:48:25:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14340931 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0979s; samplesPerSecond = 13080.6
06/15/2016 07:48:25:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16290309 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0889s; samplesPerSecond = 14400.6
06/15/2016 07:48:25:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15956206 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0810s; samplesPerSecond = 15799.0
06/15/2016 07:48:25:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14706302 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0741s; samplesPerSecond = 17271.9
06/15/2016 07:48:25:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15134172 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0691s; samplesPerSecond = 18517.4
06/15/2016 07:48:25:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17137251 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0676s; samplesPerSecond = 18938.8
06/15/2016 07:48:25: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15736821 * 10000; EvalErrorPrediction = 0.07390000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.664287s
06/15/2016 07:48:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.31'

06/15/2016 07:48:25: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

06/15/2016 07:48:25: Starting minibatch loop.
06/15/2016 07:48:25:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15624075 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0895s; samplesPerSecond = 14306.0
06/15/2016 07:48:25:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15517461 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0678s; samplesPerSecond = 18874.3
06/15/2016 07:48:25:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19338963 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0696s; samplesPerSecond = 18388.4
06/15/2016 07:48:26:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16177597 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0647s; samplesPerSecond = 19773.5
06/15/2016 07:48:26:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16567717 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0697s; samplesPerSecond = 18371.8
06/15/2016 07:48:26:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14497013 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0618s; samplesPerSecond = 20717.3
06/15/2016 07:48:26:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15376711 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0574s; samplesPerSecond = 22304.3
06/15/2016 07:48:26: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.16248485 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.533875s
06/15/2016 07:48:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.32'

06/15/2016 07:48:27: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

06/15/2016 07:48:27: Starting minibatch loop.
06/15/2016 07:48:27:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18120123 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.1462s; samplesPerSecond = 8756.6
06/15/2016 07:48:27:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14043349 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.1182s; samplesPerSecond = 10830.9
06/15/2016 07:48:27:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17824593 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0933s; samplesPerSecond = 13714.8
06/15/2016 07:48:27:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13574996 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0808s; samplesPerSecond = 15843.2
06/15/2016 07:48:27:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15541019 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0746s; samplesPerSecond = 17155.4
06/15/2016 07:48:27:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16226425 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0665s; samplesPerSecond = 19249.6
06/15/2016 07:48:27:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14442911 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0661s; samplesPerSecond = 19354.9
06/15/2016 07:48:27: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15691283 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.709089s
06/15/2016 07:48:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.33'

06/15/2016 07:48:28: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

06/15/2016 07:48:28: Starting minibatch loop.
06/15/2016 07:48:28:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17156503 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0958s; samplesPerSecond = 13363.7
06/15/2016 07:48:28:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18490155 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.1238s; samplesPerSecond = 10336.8
06/15/2016 07:48:28:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14035821 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0679s; samplesPerSecond = 18846.0
06/15/2016 07:48:28:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16975417 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0673s; samplesPerSecond = 19005.5
06/15/2016 07:48:28:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14822750 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0578s; samplesPerSecond = 22143.4
06/15/2016 07:48:28:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15052710 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0588s; samplesPerSecond = 21770.9
06/15/2016 07:48:28:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15564251 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0557s; samplesPerSecond = 22974.9
06/15/2016 07:48:28: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.16209944 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.581349s
06/15/2016 07:48:28: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.34'

06/15/2016 07:48:28: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

06/15/2016 07:48:28: Starting minibatch loop.
06/15/2016 07:48:28:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15489039 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0808s; samplesPerSecond = 15846.9
06/15/2016 07:48:28:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18242209 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0570s; samplesPerSecond = 22465.6
06/15/2016 07:48:28:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15495112 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0574s; samplesPerSecond = 22306.3
06/15/2016 07:48:28:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15382075 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0570s; samplesPerSecond = 22459.7
06/15/2016 07:48:29:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19759736 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 0.0591s; samplesPerSecond = 21666.3
06/15/2016 07:48:29:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.21950512 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0556s; samplesPerSecond = 23017.4
06/15/2016 07:48:29:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18655958 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0606s; samplesPerSecond = 21121.1
06/15/2016 07:48:29: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.17944308 * 10000; EvalErrorPrediction = 0.08210000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.489596s
06/15/2016 07:48:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.35'

06/15/2016 07:48:29: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

06/15/2016 07:48:29: Starting minibatch loop.
06/15/2016 07:48:29:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17979805 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0873s; samplesPerSecond = 14659.4
06/15/2016 07:48:29:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16006212 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0634s; samplesPerSecond = 20182.6
06/15/2016 07:48:29:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16692369 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0589s; samplesPerSecond = 21717.7
06/15/2016 07:48:29:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15646319 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0578s; samplesPerSecond = 22151.8
06/15/2016 07:48:29:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17878346 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0571s; samplesPerSecond = 22429.4
06/15/2016 07:48:29:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14215250 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0587s; samplesPerSecond = 21804.7
06/15/2016 07:48:29:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15307131 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0596s; samplesPerSecond = 21460.7
06/15/2016 07:48:29: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.16211174 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.49834s
06/15/2016 07:48:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.36'

06/15/2016 07:48:29: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

06/15/2016 07:48:29: Starting minibatch loop.
06/15/2016 07:48:30:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15634547 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0769s; samplesPerSecond = 16650.2
06/15/2016 07:48:30:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16554438 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0620s; samplesPerSecond = 20652.8
06/15/2016 07:48:30:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15607874 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0577s; samplesPerSecond = 22197.9
06/15/2016 07:48:30:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15218344 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0625s; samplesPerSecond = 20495.4
06/15/2016 07:48:30:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15415950 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0660s; samplesPerSecond = 19405.7
06/15/2016 07:48:30:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14868073 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0631s; samplesPerSecond = 20282.7
06/15/2016 07:48:30:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15062923 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0573s; samplesPerSecond = 22340.9
06/15/2016 07:48:30: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15656752 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.499431s
06/15/2016 07:48:30: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.37'

06/15/2016 07:48:30: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

06/15/2016 07:48:30: Starting minibatch loop.
06/15/2016 07:48:30:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15233108 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0758s; samplesPerSecond = 16885.9
06/15/2016 07:48:30:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16225232 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0607s; samplesPerSecond = 21071.3
06/15/2016 07:48:30:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15424628 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0558s; samplesPerSecond = 22955.9
06/15/2016 07:48:30:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15449228 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0561s; samplesPerSecond = 22798.9
06/15/2016 07:48:30:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13860159 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0571s; samplesPerSecond = 22408.2
06/15/2016 07:48:30:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17696233 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0574s; samplesPerSecond = 22293.4
06/15/2016 07:48:30:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15650635 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0602s; samplesPerSecond = 21266.7
06/15/2016 07:48:31: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15648502 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.482447s
06/15/2016 07:48:31: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.38'

06/15/2016 07:48:31: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

06/15/2016 07:48:31: Starting minibatch loop.
06/15/2016 07:48:31:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18022705 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.1152s; samplesPerSecond = 11115.1
06/15/2016 07:48:31:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13405222 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0934s; samplesPerSecond = 13700.7
06/15/2016 07:48:31:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16807442 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0947s; samplesPerSecond = 13521.2
06/15/2016 07:48:31:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19246693 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0806s; samplesPerSecond = 15885.6
06/15/2016 07:48:31:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16414404 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0736s; samplesPerSecond = 17394.6
06/15/2016 07:48:31:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13911600 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0642s; samplesPerSecond = 19934.0
06/15/2016 07:48:31:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17872267 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0662s; samplesPerSecond = 19330.1
06/15/2016 07:48:31: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16482506 * 10000; EvalErrorPrediction = 0.07910000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.652518s
06/15/2016 07:48:31: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.39'

06/15/2016 07:48:31: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

06/15/2016 07:48:31: Starting minibatch loop.
06/15/2016 07:48:31:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17295868 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0876s; samplesPerSecond = 14611.9
06/15/2016 07:48:32:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14534304 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0657s; samplesPerSecond = 19468.9
06/15/2016 07:48:32:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15357785 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0655s; samplesPerSecond = 19540.8
06/15/2016 07:48:32:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17446322 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0655s; samplesPerSecond = 19543.2
06/15/2016 07:48:32:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17159219 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0653s; samplesPerSecond = 19614.5
06/15/2016 07:48:32:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15918436 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0573s; samplesPerSecond = 22338.2
06/15/2016 07:48:32:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17683630 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0600s; samplesPerSecond = 21343.6
06/15/2016 07:48:32: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.16483335 * 10000; EvalErrorPrediction = 0.07980000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.521239s
06/15/2016 07:48:32: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.40'

06/15/2016 07:48:32: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

06/15/2016 07:48:32: Starting minibatch loop.
06/15/2016 07:48:32:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16571494 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0751s; samplesPerSecond = 17039.9
06/15/2016 07:48:32:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18527714 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 0.0587s; samplesPerSecond = 21806.9
06/15/2016 07:48:32:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16611278 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0583s; samplesPerSecond = 21968.2
06/15/2016 07:48:32:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15872264 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0574s; samplesPerSecond = 22296.9
06/15/2016 07:48:32:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14150887 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0563s; samplesPerSecond = 22720.4
06/15/2016 07:48:32:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16662998 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0545s; samplesPerSecond = 23492.3
06/15/2016 07:48:32:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14293776 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0638s; samplesPerSecond = 20054.8
06/15/2016 07:48:32: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.15923179 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.479079s
06/15/2016 07:48:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.41'

06/15/2016 07:48:33: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

06/15/2016 07:48:33: Starting minibatch loop.
06/15/2016 07:48:33:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17740039 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0706s; samplesPerSecond = 18118.8
06/15/2016 07:48:33:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14767481 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0618s; samplesPerSecond = 20726.1
06/15/2016 07:48:33:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14615030 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.1042s; samplesPerSecond = 12279.6
06/15/2016 07:48:33:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16420789 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0593s; samplesPerSecond = 21583.3
06/15/2016 07:48:33:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15241370 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0571s; samplesPerSecond = 22408.2
06/15/2016 07:48:33:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14737477 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0576s; samplesPerSecond = 22210.7
06/15/2016 07:48:33:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13798800 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0591s; samplesPerSecond = 21670.7
06/15/2016 07:48:33: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15416294 * 10000; EvalErrorPrediction = 0.07400000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.523896s
06/15/2016 07:48:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.42'

06/15/2016 07:48:33: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

06/15/2016 07:48:33: Starting minibatch loop.
06/15/2016 07:48:33:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15693729 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.1087s; samplesPerSecond = 11773.5
06/15/2016 07:48:33:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14618573 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0590s; samplesPerSecond = 21706.7
06/15/2016 07:48:33:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15928676 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0611s; samplesPerSecond = 20952.3
06/15/2016 07:48:34:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16867056 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0599s; samplesPerSecond = 21365.0
06/15/2016 07:48:34:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16087327 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0606s; samplesPerSecond = 21109.2
06/15/2016 07:48:34:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14101043 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0592s; samplesPerSecond = 21616.1
06/15/2016 07:48:34:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14974689 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0581s; samplesPerSecond = 22021.5
06/15/2016 07:48:34: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.15562563 * 10000; EvalErrorPrediction = 0.07520000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.52192s
06/15/2016 07:48:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.43'

06/15/2016 07:48:34: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

06/15/2016 07:48:34: Starting minibatch loop.
06/15/2016 07:48:34:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14796841 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0795s; samplesPerSecond = 16099.6
06/15/2016 07:48:34:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14918211 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0608s; samplesPerSecond = 21038.4
06/15/2016 07:48:34:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15513802 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0563s; samplesPerSecond = 22724.9
06/15/2016 07:48:34:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14623923 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0581s; samplesPerSecond = 22043.1
06/15/2016 07:48:34:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14407172 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0589s; samplesPerSecond = 21731.0
06/15/2016 07:48:34:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16345730 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0589s; samplesPerSecond = 21721.8
06/15/2016 07:48:34:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15924301 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0595s; samplesPerSecond = 21521.6
06/15/2016 07:48:34: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.15365020 * 10000; EvalErrorPrediction = 0.07430000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.4874s
06/15/2016 07:48:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.44'

06/15/2016 07:48:34: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

06/15/2016 07:48:34: Starting minibatch loop.
06/15/2016 07:48:35:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16813549 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0781s; samplesPerSecond = 16388.0
06/15/2016 07:48:35:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16452762 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0545s; samplesPerSecond = 23487.5
06/15/2016 07:48:35:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16311617 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0651s; samplesPerSecond = 19650.9
06/15/2016 07:48:35:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16382108 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0552s; samplesPerSecond = 23184.6
06/15/2016 07:48:35:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15133505 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0576s; samplesPerSecond = 22206.4
06/15/2016 07:48:35:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16009884 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0563s; samplesPerSecond = 22720.0
06/15/2016 07:48:35:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16060934 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0575s; samplesPerSecond = 22253.5
06/15/2016 07:48:35: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15942911 * 10000; EvalErrorPrediction = 0.07870000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.480078s
06/15/2016 07:48:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.45'

06/15/2016 07:48:35: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

06/15/2016 07:48:35: Starting minibatch loop.
06/15/2016 07:48:35:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15722451 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0778s; samplesPerSecond = 16457.1
06/15/2016 07:48:35:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15389168 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0589s; samplesPerSecond = 21724.4
06/15/2016 07:48:35:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17203934 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0605s; samplesPerSecond = 21163.0
06/15/2016 07:48:35:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15514479 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0575s; samplesPerSecond = 22271.7
06/15/2016 07:48:35:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14723239 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0566s; samplesPerSecond = 22622.0
06/15/2016 07:48:35:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15953364 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0578s; samplesPerSecond = 22127.3
06/15/2016 07:48:35:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15588722 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0564s; samplesPerSecond = 22710.7
06/15/2016 07:48:35: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.15945631 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.478228s
06/15/2016 07:48:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.46'

06/15/2016 07:48:36: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

06/15/2016 07:48:36: Starting minibatch loop.
06/15/2016 07:48:36:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17869904 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0792s; samplesPerSecond = 16154.9
06/15/2016 07:48:36:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15475154 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0581s; samplesPerSecond = 22015.4
06/15/2016 07:48:36:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15057180 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0589s; samplesPerSecond = 21725.8
06/15/2016 07:48:36:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16164136 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0585s; samplesPerSecond = 21877.0
06/15/2016 07:48:36:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14805112 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0594s; samplesPerSecond = 21533.6
06/15/2016 07:48:36:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17377362 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0556s; samplesPerSecond = 23017.9
06/15/2016 07:48:36:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14311152 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0572s; samplesPerSecond = 22374.9
06/15/2016 07:48:36: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.15917430 * 10000; EvalErrorPrediction = 0.07800000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.481267s
06/15/2016 07:48:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.47'

06/15/2016 07:48:36: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

06/15/2016 07:48:36: Starting minibatch loop.
06/15/2016 07:48:36:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13142520 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.1139s; samplesPerSecond = 11233.9
06/15/2016 07:48:36:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16240219 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0983s; samplesPerSecond = 13017.3
06/15/2016 07:48:36:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14128618 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0852s; samplesPerSecond = 15019.2
06/15/2016 07:48:37:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14996614 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0779s; samplesPerSecond = 16424.8
06/15/2016 07:48:37:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16271091 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0714s; samplesPerSecond = 17917.1
06/15/2016 07:48:37:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16002464 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0667s; samplesPerSecond = 19178.0
06/15/2016 07:48:37:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17468157 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0664s; samplesPerSecond = 19279.7
06/15/2016 07:48:37: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.15473656 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.639859s
06/15/2016 07:48:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.48'

06/15/2016 07:48:37: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

06/15/2016 07:48:37: Starting minibatch loop.
06/15/2016 07:48:37:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17040737 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0965s; samplesPerSecond = 13268.8
06/15/2016 07:48:37:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16321230 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0712s; samplesPerSecond = 17965.4
06/15/2016 07:48:37:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14699109 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0667s; samplesPerSecond = 19202.5
06/15/2016 07:48:37:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14780426 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0602s; samplesPerSecond = 21250.8
06/15/2016 07:48:37:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15308733 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0611s; samplesPerSecond = 20945.8
06/15/2016 07:48:37:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14773550 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0571s; samplesPerSecond = 22435.7
06/15/2016 07:48:37:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17239637 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0563s; samplesPerSecond = 22720.0
06/15/2016 07:48:38: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.15859116 * 10000; EvalErrorPrediction = 0.07800000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.522867s
06/15/2016 07:48:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.49'

06/15/2016 07:48:38: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

06/15/2016 07:48:38: Starting minibatch loop.
06/15/2016 07:48:38:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15344126 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0810s; samplesPerSecond = 15794.3
06/15/2016 07:48:38:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14576006 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0587s; samplesPerSecond = 21822.9
06/15/2016 07:48:38:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15096581 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.1076s; samplesPerSecond = 11895.2
06/15/2016 07:48:38:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14030428 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0576s; samplesPerSecond = 22206.8
06/15/2016 07:48:38:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16037850 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0594s; samplesPerSecond = 21563.0
06/15/2016 07:48:38:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14711046 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0558s; samplesPerSecond = 22941.1
06/15/2016 07:48:38:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14397373 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0582s; samplesPerSecond = 22002.2
06/15/2016 07:48:38: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15362316 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.534419s
06/15/2016 07:48:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn'
06/15/2016 07:48:38: CNTKCommandTrainEnd: Simple_Demo

06/15/2016 07:48:38: Action "train" complete.


06/15/2016 07:48:38: ##############################################################################
06/15/2016 07:48:38: #                                                                            #
06/15/2016 07:48:38: # Action "write"                                                             #
06/15/2016 07:48:38: #                                                                            #
06/15/2016 07:48:38: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
000000FAF83BC100: {[features Value[2 x *1]] }
000000FAF83BC420: {[B1 Value[50 x 1]] }
000000FAF83BC7E0: {[W0 Value[50 x 2]] }
000000FAF83BC880: {[B0 Value[50 x 1]] }
000000FAF83BC920: {[W1 Value[50 x 50]] }
000000FAF83BC9C0: {[W2 Value[2 x 50]] }
000000FAF83BD1E0: {[InvStdOfFeatures Value[2]] }
000000FAF83BD460: {[B2 Value[2 x 1]] }
000000FAF83BD5A0: {[MeanOfFeatures Value[2]] }
000000FAF83BD960: {[labels Value[2 x *1]] }
000000FAF83BDF00: {[Prior Value[2]] }
000000FAF8475590: {[W0*features+B0 Value[50 x 1 x *1]] }
000000FAF8475810: {[H1 Value[50 x 1 x *1]] }
000000FAF8475950: {[LogOfPrior Value[2]] }
000000FAF8475B30: {[W2*H1 Value[2 x 1 x *1]] }
000000FAF8475BD0: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
000000FAF84760D0: {[W0*features Value[50 x *1]] }
000000FAF8476210: {[MVNormalizedFeatures Value[2 x *1]] }
000000FAF8476350: {[HLast Value[2 x 1 x *1]] }
000000FAF8476670: {[H2 Value[50 x 1 x *1]] }
000000FAF8476850: {[W1*H1 Value[50 x 1 x *1]] }
000000FAF84772F0: {[W1*H1+B1 Value[50 x 1 x *1]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

06/15/2016 07:48:38: Action "write" complete.

06/15/2016 07:48:38: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/Jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Jun 15 2016 00:45:13
		Last modified date: Tue Jun 14 04:21:55 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 35cb5738e7ef794177a2fff06892a39700722dee
		Built by svcphil on cntk-muc02
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
06/15/2016 07:48:42: -------------------------------------------------------------------
06/15/2016 07:48:42: Build info: 

06/15/2016 07:48:42: 		Built time: Jun 15 2016 00:45:13
06/15/2016 07:48:42: 		Last modified date: Tue Jun 14 04:21:55 2016
06/15/2016 07:48:42: 		Build type: Release
06/15/2016 07:48:42: 		Build target: GPU
06/15/2016 07:48:42: 		With 1bit-SGD: no
06/15/2016 07:48:42: 		Math lib: mkl
06/15/2016 07:48:42: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
06/15/2016 07:48:42: 		CUB_PATH: c:\src\cub-1.4.1
06/15/2016 07:48:42: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
06/15/2016 07:48:42: 		Build Branch: HEAD
06/15/2016 07:48:42: 		Build SHA1: 35cb5738e7ef794177a2fff06892a39700722dee
06/15/2016 07:48:42: 		Built by svcphil on cntk-muc02
06/15/2016 07:48:42: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
06/15/2016 07:48:42: -------------------------------------------------------------------

06/15/2016 07:48:42: Running on Philly-Pool3 at 2016/06/15 07:48:42
06/15/2016 07:48:42: Command line: 
C:\Jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu  DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



06/15/2016 07:48:42: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
06/15/2016 07:48:42: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

06/15/2016 07:48:42: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

06/15/2016 07:48:42: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
06/15/2016 07:48:42: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

06/15/2016 07:48:42: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

06/15/2016 07:48:42: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\Jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
06/15/2016 07:48:42: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
06/15/2016 07:48:42: Commands: Simple_Demo Simple_Demo_Output
06/15/2016 07:48:42: Precision = "float"
06/15/2016 07:48:42: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn
06/15/2016 07:48:42: CNTKCommandTrainInfo: Simple_Demo : 50
06/15/2016 07:48:42: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

06/15/2016 07:48:42: ##############################################################################
06/15/2016 07:48:42: #                                                                            #
06/15/2016 07:48:42: # Action "train"                                                             #
06/15/2016 07:48:42: #                                                                            #
06/15/2016 07:48:42: ##############################################################################

06/15/2016 07:48:42: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

06/15/2016 07:48:42: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

06/15/2016 07:48:42: Loaded model with 25 nodes on CPU.

06/15/2016 07:48:42: Training criterion node(s):
06/15/2016 07:48:42: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

06/15/2016 07:48:42: Evaluation criterion node(s):

06/15/2016 07:48:42: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
00000061112F7DF0: {[B0 Value[50 x 1]] }
00000061113000C0: {[labels Value[2 x *1]] }
0000006111300840: {[Prior Value[2]] }
00000061113008E0: {[MeanOfFeatures Value[2]] }
0000006111300A20: {[features Value[2 x *1]] }
0000006111300AC0: {[B1 Value[50 x 1]] }
0000006111300C00: {[B2 Value[2 x 1]] }
0000006111300F20: {[InvStdOfFeatures Value[2]] }
0000006113BAC1A0: {[W0*features Value[50 x *1]] }
0000006113BAC240: {[CrossEntropyWithSoftmax Gradient[1]] }
0000006113BAC380: {[LogOfPrior Value[2]] }
0000006113BAC740: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
0000006113BAC7E0: {[W0 Value[50 x 2]] }
0000006113BAC880: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
0000006113BACA60: {[B2 Gradient[2 x 1]] }
0000006113BACB00: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
0000006113BACD80: {[W2 Value[2 x 50]] }
0000006113BACE20: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
0000006113BAD000: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
0000006113BAD3C0: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0000006113BAD460: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
0000006113BAD500: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }
0000006113BAD6E0: {[MVNormalizedFeatures Value[2 x *1]] }
0000006113BAD780: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
0000006113BADB40: {[EvalErrorPrediction Value[1]] }
0000006113BADBE0: {[CrossEntropyWithSoftmax Value[1]] }
0000006113BADC80: {[W2*H1 Gradient[2 x 1 x *1]] }
0000006113BADDC0: {[W1 Value[50 x 50]] }

06/15/2016 07:48:42: No PreCompute nodes found, skipping PreCompute step.

06/15/2016 07:48:42: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

06/15/2016 07:48:42: Starting minibatch loop.
06/15/2016 07:48:43:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.15344126 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.1681s; samplesPerSecond = 7613.3
06/15/2016 07:48:43:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.14576006 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.1298s; samplesPerSecond = 9864.4
06/15/2016 07:48:43:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15096581 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0924s; samplesPerSecond = 13856.9
06/15/2016 07:48:43:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14030428 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0834s; samplesPerSecond = 15342.2
06/15/2016 07:48:43:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.16037850 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.1346s; samplesPerSecond = 9508.6
06/15/2016 07:48:43:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14711046 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0676s; samplesPerSecond = 18945.0
06/15/2016 07:48:43:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14397373 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0680s; samplesPerSecond = 18828.2
06/15/2016 07:48:43: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15362316 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.817591s
06/15/2016 07:48:43: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/models/simple.dnn'
06/15/2016 07:48:43: CNTKCommandTrainEnd: Simple_Demo

06/15/2016 07:48:43: Action "train" complete.


06/15/2016 07:48:43: ##############################################################################
06/15/2016 07:48:43: #                                                                            #
06/15/2016 07:48:43: # Action "write"                                                             #
06/15/2016 07:48:43: #                                                                            #
06/15/2016 07:48:43: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
000000611130A240: {[H1 Value[50 x 1 x *2]] }
000000611130A2E0: {[W2*H1 Value[2 x 1 x *2]] }
000000611130A560: {[W1*H1+B1 Value[50 x 1 x *2]] }
000000611130A6A0: {[MVNormalizedFeatures Value[2 x *2]] }
000000611130A7E0: {[W1*H1 Value[50 x 1 x *2]] }
000000611130A880: {[W0*features+B0 Value[50 x 1 x *2]] }
000000611130ACE0: {[HLast Value[2 x 1 x *2]] }
000000611130B1E0: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
000000611130B280: {[H2 Value[50 x 1 x *2]] }
000000611130BA00: {[LogOfPrior Value[2]] }
000000611130BAA0: {[W0*features Value[50 x *2]] }
0000006113BAC240: {[labels Value[2 x *2]] }
0000006113BAC4C0: {[W1 Value[50 x 50]] }
0000006113BAC560: {[features Value[2 x *2]] }
0000006113BACA60: {[Prior Value[2]] }
0000006113BACC40: {[B2 Value[2 x 1]] }
0000006113BAD0A0: {[B1 Value[50 x 1]] }
0000006113BAD280: {[B0 Value[50 x 1]] }
0000006113BAD3C0: {[InvStdOfFeatures Value[2]] }
0000006113BAD500: {[W0 Value[50 x 2]] }
0000006113BAD6E0: {[W2 Value[2 x 50]] }
0000006113BADBE0: {[MeanOfFeatures Value[2]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160615074114.852173\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

06/15/2016 07:48:43: Action "write" complete.

06/15/2016 07:48:43: __COMPLETED__