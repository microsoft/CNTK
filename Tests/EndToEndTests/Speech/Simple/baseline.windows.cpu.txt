CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2673 v3 @ 2.40GHz
    Hardware threads: 8
    Total Memory: 29359668 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
CNTK 2.2+ (HEAD 720355, Nov  1 2017 19:56:16) at 2017/11/01 21:23:12

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
-------------------------------------------------------------------
Build info: 

		Built time: Nov  1 2017 19:45:14
		Last modified date: Sat Oct 14 21:29:36 2017
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		With ASGD: yes
		Math lib: mkl
		CUDA version: 0.0.0
		CUDNN version: 6.0.21
		Build Branch: HEAD
		Build SHA1: 720355de01ba6bea62e879f86599830251c60365
		MPI distribution: Microsoft MPI
		MPI version: 7.0.12437.6
-------------------------------------------------------------------
No GPUs found

Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
11/01/2017 21:23:12: Commands: Simple_Demo Simple_Demo_Output
11/01/2017 21:23:12: precision = "float"
11/01/2017 21:23:12: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

11/01/2017 21:23:12: ##############################################################################
11/01/2017 21:23:12: #                                                                            #
11/01/2017 21:23:12: # Simple_Demo command (train action)                                         #
11/01/2017 21:23:12: #                                                                            #
11/01/2017 21:23:12: ##############################################################################

11/01/2017 21:23:12: 
Creating virgin network.
SimpleNetworkBuilder Using CPU
11/01/2017 21:23:12: 
Model has 25 nodes. Using CPU.

11/01/2017 21:23:12: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
11/01/2017 21:23:12: Evaluation criterion: EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 4 are aliased.
	W1*H1 (gradient) reuses W1*H1+B1 (gradient)
	W2*H1 (gradient) reuses HLast (gradient)

Memory Sharing: Out of 40 matrices, 20 are shared as 5, and 20 are not shared.

Here are the ones that share memory:
	{ PosteriorProb : [2 x 1 x *]
	  ScaledLogLikelihood : [2 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W0*features+B0 : [50 x 1 x *]
	  W1 : [50 x 50] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0 : [50 x 2] (gradient)
	  W0*features : [50 x *] }
	{ H1 : [50 x 1 x *] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *]
	  W0*features : [50 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ HLast : [2 x 1 x *] (gradient)
	  W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *]
	  W2*H1 : [2 x 1 x *] (gradient) }

Here are the ones that don't share memory:
	{B1 : [50 x 1]}
	{B2 : [2 x 1]}
	{W0 : [50 x 2]}
	{MVNormalizedFeatures : [2 x *]}
	{W2 : [2 x 50] (gradient)}
	{features : [2 x *]}
	{MeanOfFeatures : [2]}
	{InvStdOfFeatures : [2]}
	{W1 : [50 x 50]}
	{B1 : [50 x 1] (gradient)}
	{W2 : [2 x 50]}
	{labels : [2 x *]}
	{Prior : [2]}
	{B0 : [50 x 1]}
	{CrossEntropyWithSoftmax : [1]}
	{B2 : [2 x 1] (gradient)}
	{B0 : [50 x 1] (gradient)}
	{LogOfPrior : [2]}
	{EvalClassificationError : [1]}
	{CrossEntropyWithSoftmax : [1] (gradient)}


11/01/2017 21:23:12: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

11/01/2017 21:23:12: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
11/01/2017 21:23:12: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
11/01/2017 21:23:12: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
11/01/2017 21:23:12: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
11/01/2017 21:23:12: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
11/01/2017 21:23:12: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


11/01/2017 21:23:12: Precomputing --> 3 PreCompute nodes found.

11/01/2017 21:23:12: 	MeanOfFeatures = Mean()
11/01/2017 21:23:12: 	InvStdOfFeatures = InvStdDev()
11/01/2017 21:23:12: 	Prior = Mean()

11/01/2017 21:23:12: Precomputing --> Completed.


11/01/2017 21:23:12: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.82292490 * 1280; EvalClassificationError = 0.51875000 * 1280; time = 0.0097s; samplesPerSecond = 131878.5
11/01/2017 21:23:12:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.77976751 * 1280; EvalClassificationError = 0.50781250 * 1280; time = 0.0135s; samplesPerSecond = 94833.8
11/01/2017 21:23:12:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.72312775 * 1280; EvalClassificationError = 0.48828125 * 1280; time = 0.0063s; samplesPerSecond = 202631.0
11/01/2017 21:23:12:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71024914 * 1280; EvalClassificationError = 0.51484375 * 1280; time = 0.0153s; samplesPerSecond = 83859.1
11/01/2017 21:23:12:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.69842205 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0118s; samplesPerSecond = 108195.8
11/01/2017 21:23:12:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.71133003 * 1280; EvalClassificationError = 0.50781250 * 1280; time = 0.0062s; samplesPerSecond = 205907.0
11/01/2017 21:23:12:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.70956345 * 1280; EvalClassificationError = 0.50156250 * 1280; time = 0.0064s; samplesPerSecond = 201181.9
11/01/2017 21:23:12: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.73301484 * 10000; EvalClassificationError = 0.50560000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.0750655s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.1'

11/01/2017 21:23:12: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70886793 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0065s; samplesPerSecond = 196349.1
11/01/2017 21:23:12:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74700851 * 1280; EvalClassificationError = 0.46406250 * 1280; time = 0.0063s; samplesPerSecond = 203323.1
11/01/2017 21:23:12:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.74863882 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0066s; samplesPerSecond = 193651.9
11/01/2017 21:23:12:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.74191208 * 1280; EvalClassificationError = 0.49140625 * 1280; time = 0.0062s; samplesPerSecond = 205999.7
11/01/2017 21:23:12:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.70860500 * 1280; EvalClassificationError = 0.44843750 * 1280; time = 0.0064s; samplesPerSecond = 201432.1
11/01/2017 21:23:12:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.53535042 * 1280; EvalClassificationError = 0.27968750 * 1280; time = 0.0064s; samplesPerSecond = 200658.4
11/01/2017 21:23:12:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.21460075 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0064s; samplesPerSecond = 199404.9
11/01/2017 21:23:12: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.58241870 * 10000; EvalClassificationError = 0.36300000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.0519246s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.2'

11/01/2017 21:23:12: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.22909684 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0067s; samplesPerSecond = 191421.9
11/01/2017 21:23:12:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.23779182 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0066s; samplesPerSecond = 192608.6
11/01/2017 21:23:12:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20463772 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0064s; samplesPerSecond = 200982.9
11/01/2017 21:23:12:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.22727094 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0062s; samplesPerSecond = 206268.6
11/01/2017 21:23:12:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19903297 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0062s; samplesPerSecond = 204947.6
11/01/2017 21:23:12:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18024206 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0062s; samplesPerSecond = 207829.3
11/01/2017 21:23:12:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16613483 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0060s; samplesPerSecond = 214448.5
11/01/2017 21:23:12: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.20095107 * 10000; EvalClassificationError = 0.07710000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.051385s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.3'

11/01/2017 21:23:12: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14966704 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0068s; samplesPerSecond = 187848.5
11/01/2017 21:23:12:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17832068 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0063s; samplesPerSecond = 204221.6
11/01/2017 21:23:12:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17098393 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0063s; samplesPerSecond = 204159.8
11/01/2017 21:23:12:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20655484 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0061s; samplesPerSecond = 208360.5
11/01/2017 21:23:12:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18620372 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 208577.8
11/01/2017 21:23:12:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16608553 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0062s; samplesPerSecond = 205546.5
11/01/2017 21:23:12:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17946663 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0061s; samplesPerSecond = 208343.5
11/01/2017 21:23:12: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.17554318 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.0507154s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.4'

11/01/2017 21:23:12: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16107727 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0063s; samplesPerSecond = 201841.8
11/01/2017 21:23:12:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17702957 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0062s; samplesPerSecond = 206365.1
11/01/2017 21:23:12:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16816747 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0061s; samplesPerSecond = 210599.1
11/01/2017 21:23:12:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16303196 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0060s; samplesPerSecond = 211917.0
11/01/2017 21:23:12:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18440723 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0065s; samplesPerSecond = 197244.7
11/01/2017 21:23:12:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17460804 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0060s; samplesPerSecond = 212155.9
11/01/2017 21:23:12:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17822361 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 210056.5
11/01/2017 21:23:12: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16998304 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.0504823s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.5'

11/01/2017 21:23:12: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17073421 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0068s; samplesPerSecond = 188918.7
11/01/2017 21:23:12:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19878130 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0064s; samplesPerSecond = 200028.1
11/01/2017 21:23:12:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17884784 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0064s; samplesPerSecond = 199094.7
11/01/2017 21:23:12:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17260475 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0064s; samplesPerSecond = 198736.2
11/01/2017 21:23:12:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18292947 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0065s; samplesPerSecond = 196907.9
11/01/2017 21:23:12:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17320642 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0066s; samplesPerSecond = 194970.4
11/01/2017 21:23:12:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.20213203 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0067s; samplesPerSecond = 190711.7
11/01/2017 21:23:12: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.18083037 * 10000; EvalClassificationError = 0.08030000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.0526473s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.6'

11/01/2017 21:23:12: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19412189 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0067s; samplesPerSecond = 190916.5
11/01/2017 21:23:12:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17304285 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0063s; samplesPerSecond = 201679.6
11/01/2017 21:23:12:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18250563 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0065s; samplesPerSecond = 195470.6
11/01/2017 21:23:12:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14360967 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0074s; samplesPerSecond = 173465.2
11/01/2017 21:23:12:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14653416 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0064s; samplesPerSecond = 199147.4
11/01/2017 21:23:12:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17601280 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0065s; samplesPerSecond = 197436.4
11/01/2017 21:23:12:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17025948 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0066s; samplesPerSecond = 194676.8
11/01/2017 21:23:12: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17132054 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.0541218s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.7'

11/01/2017 21:23:12: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18863795 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0068s; samplesPerSecond = 189130.9
11/01/2017 21:23:12:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17956793 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0063s; samplesPerSecond = 201787.7
11/01/2017 21:23:12:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17792096 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0065s; samplesPerSecond = 196774.7
11/01/2017 21:23:12:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16579628 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0065s; samplesPerSecond = 198004.5
11/01/2017 21:23:12:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17047586 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0065s; samplesPerSecond = 198295.9
11/01/2017 21:23:12:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19057112 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0065s; samplesPerSecond = 196892.8
11/01/2017 21:23:12:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15224905 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0065s; samplesPerSecond = 197177.9
11/01/2017 21:23:12: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.17549664 * 10000; EvalClassificationError = 0.08030000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.0525689s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.8'

11/01/2017 21:23:12: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20855846 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0067s; samplesPerSecond = 191817.8
11/01/2017 21:23:12:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20733099 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0065s; samplesPerSecond = 197108.1
11/01/2017 21:23:12:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18903909 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0065s; samplesPerSecond = 196198.7
11/01/2017 21:23:12:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19406390 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0065s; samplesPerSecond = 196623.6
11/01/2017 21:23:12:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17630005 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0065s; samplesPerSecond = 197692.6
11/01/2017 21:23:12:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15012922 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0077s; samplesPerSecond = 166627.6
11/01/2017 21:23:12:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15329018 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0065s; samplesPerSecond = 196439.5
11/01/2017 21:23:12: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.18181522 * 10000; EvalClassificationError = 0.07800000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.0537586s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.9'

11/01/2017 21:23:12: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16431608 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0066s; samplesPerSecond = 192643.4
11/01/2017 21:23:12:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15332191 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0069s; samplesPerSecond = 185249.5
11/01/2017 21:23:12:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17685854 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0065s; samplesPerSecond = 196805.0
11/01/2017 21:23:12:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17415705 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0067s; samplesPerSecond = 191803.4
11/01/2017 21:23:12:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19191818 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0065s; samplesPerSecond = 197964.7
11/01/2017 21:23:12:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15995913 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0065s; samplesPerSecond = 196069.4
11/01/2017 21:23:12:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15455236 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0066s; samplesPerSecond = 193827.8
11/01/2017 21:23:12: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16563136 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.053269s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.10'

11/01/2017 21:23:12: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16918705 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0076s; samplesPerSecond = 167329.0
11/01/2017 21:23:12:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15994205 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0064s; samplesPerSecond = 201090.3
11/01/2017 21:23:12:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17205780 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0064s; samplesPerSecond = 198967.9
11/01/2017 21:23:12:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16319451 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0072s; samplesPerSecond = 178731.0
11/01/2017 21:23:12:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15153379 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0064s; samplesPerSecond = 199187.7
11/01/2017 21:23:12:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15329399 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0064s; samplesPerSecond = 198520.4
11/01/2017 21:23:12:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15840025 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0065s; samplesPerSecond = 196551.1
11/01/2017 21:23:12: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16564042 * 10000; EvalClassificationError = 0.07490000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.0539005s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.11'

11/01/2017 21:23:12: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16317443 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0068s; samplesPerSecond = 188618.1
11/01/2017 21:23:12:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17074150 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0064s; samplesPerSecond = 199491.9
11/01/2017 21:23:12:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17058637 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0065s; samplesPerSecond = 196123.5
11/01/2017 21:23:12:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16313033 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0068s; samplesPerSecond = 187153.7
11/01/2017 21:23:12:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15805526 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0066s; samplesPerSecond = 193257.1
11/01/2017 21:23:12:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16143885 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0065s; samplesPerSecond = 196596.4
11/01/2017 21:23:12:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14267378 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0065s; samplesPerSecond = 195982.4
11/01/2017 21:23:12: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16131670 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.0532008s
11/01/2017 21:23:12: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.12'

11/01/2017 21:23:12: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:12: Starting minibatch loop.
11/01/2017 21:23:12:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14920977 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0066s; samplesPerSecond = 192617.3
11/01/2017 21:23:12:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18177191 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0065s; samplesPerSecond = 196862.5
11/01/2017 21:23:13:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17361002 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0072s; samplesPerSecond = 178783.4
11/01/2017 21:23:13:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15493879 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0066s; samplesPerSecond = 194410.7
11/01/2017 21:23:13:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15254741 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0065s; samplesPerSecond = 197095.9
11/01/2017 21:23:13:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17198906 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0067s; samplesPerSecond = 192333.7
11/01/2017 21:23:13:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15650930 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0065s; samplesPerSecond = 197613.2
11/01/2017 21:23:13: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16411139 * 10000; EvalClassificationError = 0.07390000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.0534074s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.13'

11/01/2017 21:23:13: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18763435 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0067s; samplesPerSecond = 190179.0
11/01/2017 21:23:13:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19376431 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0064s; samplesPerSecond = 200636.4
11/01/2017 21:23:13:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15803502 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0065s; samplesPerSecond = 196099.5
11/01/2017 21:23:13:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18706799 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0065s; samplesPerSecond = 195865.4
11/01/2017 21:23:13:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17851391 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0065s; samplesPerSecond = 195452.7
11/01/2017 21:23:13:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15969095 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0064s; samplesPerSecond = 199243.5
11/01/2017 21:23:13:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15674105 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0068s; samplesPerSecond = 188512.5
11/01/2017 21:23:13: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.17456428 * 10000; EvalClassificationError = 0.07970000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.0528743s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.14'

11/01/2017 21:23:13: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16807166 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0066s; samplesPerSecond = 192968.7
11/01/2017 21:23:13:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14487256 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0071s; samplesPerSecond = 179214.0
11/01/2017 21:23:13:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16923070 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0065s; samplesPerSecond = 195491.5
11/01/2017 21:23:13:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16383924 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0064s; samplesPerSecond = 198622.1
11/01/2017 21:23:13:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16629281 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0063s; samplesPerSecond = 202029.8
11/01/2017 21:23:13:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16055689 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0066s; samplesPerSecond = 195181.5
11/01/2017 21:23:13:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15666065 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0067s; samplesPerSecond = 190365.7
11/01/2017 21:23:13: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16106061 * 10000; EvalClassificationError = 0.07400000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.053476s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.15'

11/01/2017 21:23:13: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16057069 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0068s; samplesPerSecond = 187603.5
11/01/2017 21:23:13:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15552318 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0064s; samplesPerSecond = 198572.8
11/01/2017 21:23:13:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16812978 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0065s; samplesPerSecond = 196923.1
11/01/2017 21:23:13:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16662107 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0064s; samplesPerSecond = 200485.6
11/01/2017 21:23:13:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18013892 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0064s; samplesPerSecond = 200206.5
11/01/2017 21:23:13:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16758633 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0063s; samplesPerSecond = 203194.0
11/01/2017 21:23:13:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17382107 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0064s; samplesPerSecond = 201390.9
11/01/2017 21:23:13: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.16673342 * 10000; EvalClassificationError = 0.07770000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.0520548s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.16'

11/01/2017 21:23:13: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15741988 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0076s; samplesPerSecond = 167822.6
11/01/2017 21:23:13:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16492192 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0063s; samplesPerSecond = 202910.5
11/01/2017 21:23:13:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18577306 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0065s; samplesPerSecond = 197698.7
11/01/2017 21:23:13:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16102166 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0063s; samplesPerSecond = 201755.9
11/01/2017 21:23:13:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15495462 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0063s; samplesPerSecond = 203113.3
11/01/2017 21:23:13:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15126581 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0066s; samplesPerSecond = 194952.6
11/01/2017 21:23:13:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15345888 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0064s; samplesPerSecond = 200353.7
11/01/2017 21:23:13: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16122606 * 10000; EvalClassificationError = 0.07560000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.0528533s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.17'

11/01/2017 21:23:13: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15050437 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0067s; samplesPerSecond = 191436.2
11/01/2017 21:23:13:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16195562 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0066s; samplesPerSecond = 195175.5
11/01/2017 21:23:13:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16647663 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0065s; samplesPerSecond = 195985.4
11/01/2017 21:23:13:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15378642 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0065s; samplesPerSecond = 197543.1
11/01/2017 21:23:13:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14804459 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0066s; samplesPerSecond = 193490.8
11/01/2017 21:23:13:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15810299 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0065s; samplesPerSecond = 196874.6
11/01/2017 21:23:13:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15576086 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0067s; samplesPerSecond = 192151.8
11/01/2017 21:23:13: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15669098 * 10000; EvalClassificationError = 0.07460000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.0530748s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.18'

11/01/2017 21:23:13: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15712075 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0068s; samplesPerSecond = 188890.9
11/01/2017 21:23:13:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14908159 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0066s; samplesPerSecond = 194339.9
11/01/2017 21:23:13:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16572511 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0066s; samplesPerSecond = 194994.1
11/01/2017 21:23:13:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14920244 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0067s; samplesPerSecond = 190215.8
11/01/2017 21:23:13:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17894831 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0066s; samplesPerSecond = 193824.9
11/01/2017 21:23:13:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16353998 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0066s; samplesPerSecond = 195196.3
11/01/2017 21:23:13:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17957926 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0066s; samplesPerSecond = 194792.3
11/01/2017 21:23:13: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16370313 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.0538269s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.19'

11/01/2017 21:23:13: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15389562 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0068s; samplesPerSecond = 187545.8
11/01/2017 21:23:13:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15102513 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0065s; samplesPerSecond = 195952.4
11/01/2017 21:23:13:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15534651 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0067s; samplesPerSecond = 191556.5
11/01/2017 21:23:13:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16748581 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0066s; samplesPerSecond = 193403.1
11/01/2017 21:23:13:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15846524 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0065s; samplesPerSecond = 197427.3
11/01/2017 21:23:13:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15586524 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0066s; samplesPerSecond = 193219.2
11/01/2017 21:23:13:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16819944 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0072s; samplesPerSecond = 176932.4
11/01/2017 21:23:13: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.15685707 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.0539078s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.20'

11/01/2017 21:23:13: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16044340 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0069s; samplesPerSecond = 185512.6
11/01/2017 21:23:13:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15007935 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0065s; samplesPerSecond = 197284.3
11/01/2017 21:23:13:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15607800 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0064s; samplesPerSecond = 198983.3
11/01/2017 21:23:13:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14384956 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0067s; samplesPerSecond = 191866.7
11/01/2017 21:23:13:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16455445 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0065s; samplesPerSecond = 196478.7
11/01/2017 21:23:13:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16868095 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0070s; samplesPerSecond = 181955.2
11/01/2017 21:23:13:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16089735 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0063s; samplesPerSecond = 203271.4
11/01/2017 21:23:13: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15813573 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.0533498s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.21'

11/01/2017 21:23:13: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15188613 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0068s; samplesPerSecond = 187529.3
11/01/2017 21:23:13:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13540928 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0065s; samplesPerSecond = 198059.6
11/01/2017 21:23:13:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16405823 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0066s; samplesPerSecond = 192896.0
11/01/2017 21:23:13:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16412592 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0064s; samplesPerSecond = 198659.1
11/01/2017 21:23:13:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15334053 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0067s; samplesPerSecond = 191967.4
11/01/2017 21:23:13:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15161142 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0071s; samplesPerSecond = 180185.3
11/01/2017 21:23:13:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19276161 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0066s; samplesPerSecond = 194460.9
11/01/2017 21:23:13: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16042131 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.0540697s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.22'

11/01/2017 21:23:13: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16362531 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0070s; samplesPerSecond = 182341.4
11/01/2017 21:23:13:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17052588 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0065s; samplesPerSecond = 196273.9
11/01/2017 21:23:13:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16147277 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0065s; samplesPerSecond = 197396.8
11/01/2017 21:23:13:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15935979 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0066s; samplesPerSecond = 194878.4
11/01/2017 21:23:13:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15040669 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0067s; samplesPerSecond = 191276.0
11/01/2017 21:23:13:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15705538 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0066s; samplesPerSecond = 192977.4
11/01/2017 21:23:13:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14803991 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0065s; samplesPerSecond = 197497.3
11/01/2017 21:23:13: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.15887429 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.0538031s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.23'

11/01/2017 21:23:13: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17891968 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0066s; samplesPerSecond = 195020.9
11/01/2017 21:23:13:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18593401 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0073s; samplesPerSecond = 175619.1
11/01/2017 21:23:13:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15016153 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0066s; samplesPerSecond = 193511.3
11/01/2017 21:23:13:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13410354 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0067s; samplesPerSecond = 191153.2
11/01/2017 21:23:13:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18014808 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0072s; samplesPerSecond = 177748.2
11/01/2017 21:23:13:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13521652 * 1280; EvalClassificationError = 0.05468750 * 1280; time = 0.0066s; samplesPerSecond = 194670.9
11/01/2017 21:23:13:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16168003 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0067s; samplesPerSecond = 189908.2
11/01/2017 21:23:13: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16157942 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.0545967s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.24'

11/01/2017 21:23:13: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14394493 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0069s; samplesPerSecond = 185730.7
11/01/2017 21:23:13:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17737844 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0065s; samplesPerSecond = 197232.6
11/01/2017 21:23:13:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14675848 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0065s; samplesPerSecond = 196726.4
11/01/2017 21:23:13:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15966973 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0066s; samplesPerSecond = 192994.9
11/01/2017 21:23:13:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16962910 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0067s; samplesPerSecond = 191835.0
11/01/2017 21:23:13:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17309241 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0065s; samplesPerSecond = 196662.9
11/01/2017 21:23:13:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17608728 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0067s; samplesPerSecond = 192056.7
11/01/2017 21:23:13: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16261599 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.0533544s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.25'

11/01/2017 21:23:13: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14521163 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0069s; samplesPerSecond = 186051.9
11/01/2017 21:23:13:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17816315 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0070s; samplesPerSecond = 183950.3
11/01/2017 21:23:13:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16222804 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0071s; samplesPerSecond = 180757.8
11/01/2017 21:23:13:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14471769 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0070s; samplesPerSecond = 183244.6
11/01/2017 21:23:13:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16901412 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0066s; samplesPerSecond = 193263.0
11/01/2017 21:23:13:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12451992 * 1280; EvalClassificationError = 0.05156250 * 1280; time = 0.0067s; samplesPerSecond = 191253.2
11/01/2017 21:23:13:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16381998 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0066s; samplesPerSecond = 193596.2
11/01/2017 21:23:13: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15583677 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.0550199s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.26'

11/01/2017 21:23:13: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16974587 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0069s; samplesPerSecond = 184361.0
11/01/2017 21:23:13:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16734040 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0064s; samplesPerSecond = 200012.5
11/01/2017 21:23:13:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14435437 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0067s; samplesPerSecond = 190029.4
11/01/2017 21:23:13:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14967251 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0065s; samplesPerSecond = 195622.9
11/01/2017 21:23:13:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15140119 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0066s; samplesPerSecond = 193599.1
11/01/2017 21:23:13:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15337348 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0066s; samplesPerSecond = 194552.5
11/01/2017 21:23:13:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16948471 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0068s; samplesPerSecond = 189410.8
11/01/2017 21:23:13: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15804446 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.0535512s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.27'

11/01/2017 21:23:13: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16823567 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0069s; samplesPerSecond = 186624.3
11/01/2017 21:23:13:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18711199 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0072s; samplesPerSecond = 176883.5
11/01/2017 21:23:13:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16808908 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0066s; samplesPerSecond = 194009.9
11/01/2017 21:23:13:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14899797 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0070s; samplesPerSecond = 182640.6
11/01/2017 21:23:13:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13890085 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0066s; samplesPerSecond = 192655.0
11/01/2017 21:23:13:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15160456 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0068s; samplesPerSecond = 189475.2
11/01/2017 21:23:13:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16486330 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0064s; samplesPerSecond = 199215.6
11/01/2017 21:23:13: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16216464 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.0546882s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.28'

11/01/2017 21:23:13: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15835047 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0070s; samplesPerSecond = 183596.8
11/01/2017 21:23:13:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12738988 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0068s; samplesPerSecond = 189581.9
11/01/2017 21:23:13:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16784017 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0067s; samplesPerSecond = 192039.4
11/01/2017 21:23:13:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14756398 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0066s; samplesPerSecond = 192989.1
11/01/2017 21:23:13:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16398015 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0065s; samplesPerSecond = 198351.2
11/01/2017 21:23:13:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14491773 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0066s; samplesPerSecond = 195107.1
11/01/2017 21:23:13:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17005758 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0066s; samplesPerSecond = 192533.3
11/01/2017 21:23:13: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15876682 * 10000; EvalClassificationError = 0.07520000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.0538213s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.29'

11/01/2017 21:23:13: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16122854 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0075s; samplesPerSecond = 170821.5
11/01/2017 21:23:13:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15242996 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0066s; samplesPerSecond = 195145.7
11/01/2017 21:23:13:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16156366 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0066s; samplesPerSecond = 194911.0
11/01/2017 21:23:13:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18074350 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0067s; samplesPerSecond = 191961.6
11/01/2017 21:23:13:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17172971 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0066s; samplesPerSecond = 194653.1
11/01/2017 21:23:13:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16896391 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0069s; samplesPerSecond = 184632.3
11/01/2017 21:23:13:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17258558 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0067s; samplesPerSecond = 191599.6
11/01/2017 21:23:13: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16581212 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.0546158s
11/01/2017 21:23:13: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.30'

11/01/2017 21:23:13: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:13: Starting minibatch loop.
11/01/2017 21:23:13:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16897341 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0068s; samplesPerSecond = 189444.4
11/01/2017 21:23:13:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16999079 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0067s; samplesPerSecond = 191688.5
11/01/2017 21:23:13:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18994858 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0067s; samplesPerSecond = 191499.2
11/01/2017 21:23:14:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14698901 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0068s; samplesPerSecond = 188860.2
11/01/2017 21:23:14:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17408609 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0067s; samplesPerSecond = 190210.1
11/01/2017 21:23:14:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14637957 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0065s; samplesPerSecond = 195599.0
11/01/2017 21:23:14:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15711260 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0067s; samplesPerSecond = 191602.4
11/01/2017 21:23:14: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.16452833 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.0545255s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.31'

11/01/2017 21:23:14: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16301155 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0068s; samplesPerSecond = 188213.2
11/01/2017 21:23:14:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14686811 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0065s; samplesPerSecond = 195859.4
11/01/2017 21:23:14:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13885868 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0067s; samplesPerSecond = 190984.9
11/01/2017 21:23:14:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15732203 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0066s; samplesPerSecond = 194331.0
11/01/2017 21:23:14:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14985113 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0068s; samplesPerSecond = 187249.5
11/01/2017 21:23:14:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16477876 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0067s; samplesPerSecond = 192458.1
11/01/2017 21:23:14:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15139704 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0066s; samplesPerSecond = 195160.6
11/01/2017 21:23:14: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15504646 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.0538595s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.32'

11/01/2017 21:23:14: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16162615 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0069s; samplesPerSecond = 186765.9
11/01/2017 21:23:14:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17066774 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0066s; samplesPerSecond = 193041.5
11/01/2017 21:23:14:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15118866 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0067s; samplesPerSecond = 190785.6
11/01/2017 21:23:14:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15539317 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0066s; samplesPerSecond = 194976.3
11/01/2017 21:23:14:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14059925 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0066s; samplesPerSecond = 193338.9
11/01/2017 21:23:14:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14768224 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0073s; samplesPerSecond = 174944.6
11/01/2017 21:23:14:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16787491 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0066s; samplesPerSecond = 192492.8
11/01/2017 21:23:14: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15615273 * 10000; EvalClassificationError = 0.07420000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.0546088s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.33'

11/01/2017 21:23:14: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13651539 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0068s; samplesPerSecond = 188609.7
11/01/2017 21:23:14:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15933937 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0065s; samplesPerSecond = 198240.6
11/01/2017 21:23:14:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16713123 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0066s; samplesPerSecond = 193523.0
11/01/2017 21:23:14:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14403682 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0067s; samplesPerSecond = 190221.4
11/01/2017 21:23:14:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16177711 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0066s; samplesPerSecond = 193986.4
11/01/2017 21:23:14:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16950946 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0067s; samplesPerSecond = 190711.7
11/01/2017 21:23:14:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16325788 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0067s; samplesPerSecond = 192458.1
11/01/2017 21:23:14: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15603064 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.0535158s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.34'

11/01/2017 21:23:14: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16672218 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0069s; samplesPerSecond = 185682.2
11/01/2017 21:23:14:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14191244 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0068s; samplesPerSecond = 188454.2
11/01/2017 21:23:14:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15464182 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0067s; samplesPerSecond = 191889.7
11/01/2017 21:23:14:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15669637 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0066s; samplesPerSecond = 193798.4
11/01/2017 21:23:14:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14840527 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0074s; samplesPerSecond = 172516.0
11/01/2017 21:23:14:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14536982 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0067s; samplesPerSecond = 191484.9
11/01/2017 21:23:14:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15993872 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0067s; samplesPerSecond = 191158.9
11/01/2017 21:23:14: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15363689 * 10000; EvalClassificationError = 0.07430000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.0550149s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.35'

11/01/2017 21:23:14: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14913617 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0069s; samplesPerSecond = 184608.3
11/01/2017 21:23:14:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18486346 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0066s; samplesPerSecond = 194316.2
11/01/2017 21:23:14:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14803815 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0068s; samplesPerSecond = 189321.1
11/01/2017 21:23:14:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15396142 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0066s; samplesPerSecond = 193904.1
11/01/2017 21:23:14:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14669008 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0064s; samplesPerSecond = 200680.4
11/01/2017 21:23:14:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13682356 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0067s; samplesPerSecond = 191996.2
11/01/2017 21:23:14:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14860611 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0067s; samplesPerSecond = 191616.8
11/01/2017 21:23:14: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15330526 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.0537727s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.36'

11/01/2017 21:23:14: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16894727 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0069s; samplesPerSecond = 184361.0
11/01/2017 21:23:14:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14590974 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0066s; samplesPerSecond = 193435.3
11/01/2017 21:23:14:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14945178 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0069s; samplesPerSecond = 186787.7
11/01/2017 21:23:14:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12509642 * 1280; EvalClassificationError = 0.05546875 * 1280; time = 0.0073s; samplesPerSecond = 175804.9
11/01/2017 21:23:14:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16078548 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0067s; samplesPerSecond = 191898.3
11/01/2017 21:23:14:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14524541 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0068s; samplesPerSecond = 188612.5
11/01/2017 21:23:14:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15974007 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0067s; samplesPerSecond = 191565.1
11/01/2017 21:23:14: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15064030 * 10000; EvalClassificationError = 0.07130000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.0549513s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.37'

11/01/2017 21:23:14: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16746533 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0068s; samplesPerSecond = 187137.2
11/01/2017 21:23:14:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14641263 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0066s; samplesPerSecond = 193216.3
11/01/2017 21:23:14:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14680200 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0068s; samplesPerSecond = 187175.6
11/01/2017 21:23:14:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15910602 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0066s; samplesPerSecond = 193373.9
11/01/2017 21:23:14:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13705206 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0067s; samplesPerSecond = 190581.1
11/01/2017 21:23:14:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15457411 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0066s; samplesPerSecond = 193403.1
11/01/2017 21:23:14:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13793421 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0066s; samplesPerSecond = 193954.1
11/01/2017 21:23:14: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15023104 * 10000; EvalClassificationError = 0.07270000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.0539889s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.38'

11/01/2017 21:23:14: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14781336 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0070s; samplesPerSecond = 182255.7
11/01/2017 21:23:14:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13780373 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0072s; samplesPerSecond = 176676.0
11/01/2017 21:23:14:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15107229 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0067s; samplesPerSecond = 189660.5
11/01/2017 21:23:14:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15137215 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0067s; samplesPerSecond = 190927.9
11/01/2017 21:23:14:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15106091 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0067s; samplesPerSecond = 190229.9
11/01/2017 21:23:14:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16847758 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0070s; samplesPerSecond = 182074.2
11/01/2017 21:23:14:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17596827 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0068s; samplesPerSecond = 188401.5
11/01/2017 21:23:14: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15368643 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.0555342s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.39'

11/01/2017 21:23:14: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18560023 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0068s; samplesPerSecond = 189408.0
11/01/2017 21:23:14:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14538550 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0066s; samplesPerSecond = 193957.0
11/01/2017 21:23:14:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15225167 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0066s; samplesPerSecond = 193467.5
11/01/2017 21:23:14:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14976583 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0067s; samplesPerSecond = 190945.0
11/01/2017 21:23:14:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15456047 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0068s; samplesPerSecond = 188044.5
11/01/2017 21:23:14:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15915203 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0068s; samplesPerSecond = 189399.5
11/01/2017 21:23:14:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14317951 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0066s; samplesPerSecond = 193403.1
11/01/2017 21:23:14: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15353802 * 10000; EvalClassificationError = 0.07380000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.053992s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.40'

11/01/2017 21:23:14: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16386417 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0084s; samplesPerSecond = 153086.2
11/01/2017 21:23:14:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13388830 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0066s; samplesPerSecond = 193263.0
11/01/2017 21:23:14:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14691501 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0066s; samplesPerSecond = 193414.8
11/01/2017 21:23:14:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15103045 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0067s; samplesPerSecond = 189699.9
11/01/2017 21:23:14:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14908123 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0069s; samplesPerSecond = 185075.4
11/01/2017 21:23:14:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14839292 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0068s; samplesPerSecond = 188888.1
11/01/2017 21:23:14:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15130339 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0068s; samplesPerSecond = 189581.9
11/01/2017 21:23:14: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14857450 * 10000; EvalClassificationError = 0.07150000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.0562707s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.41'

11/01/2017 21:23:14: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14376714 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0068s; samplesPerSecond = 187708.1
11/01/2017 21:23:14:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14518967 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0066s; samplesPerSecond = 193739.8
11/01/2017 21:23:14:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15640395 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0068s; samplesPerSecond = 189542.6
11/01/2017 21:23:14:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15552306 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0068s; samplesPerSecond = 189217.6
11/01/2017 21:23:14:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15926437 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0067s; samplesPerSecond = 191321.8
11/01/2017 21:23:14:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16413417 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0066s; samplesPerSecond = 193675.3
11/01/2017 21:23:14:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17426586 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0075s; samplesPerSecond = 171680.7
11/01/2017 21:23:14: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15598937 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.0549359s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.42'

11/01/2017 21:23:14: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15915550 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0070s; samplesPerSecond = 183778.7
11/01/2017 21:23:14:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12504526 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0065s; samplesPerSecond = 196198.7
11/01/2017 21:23:14:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14653273 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0067s; samplesPerSecond = 189930.7
11/01/2017 21:23:14:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15579858 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0067s; samplesPerSecond = 189823.7
11/01/2017 21:23:14:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16196203 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0066s; samplesPerSecond = 192977.4
11/01/2017 21:23:14:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13869290 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0066s; samplesPerSecond = 193528.9
11/01/2017 21:23:14:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16450052 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0069s; samplesPerSecond = 186510.1
11/01/2017 21:23:14: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14961912 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.0544153s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.43'

11/01/2017 21:23:14: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16129720 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0070s; samplesPerSecond = 183968.8
11/01/2017 21:23:14:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15699992 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0071s; samplesPerSecond = 180770.5
11/01/2017 21:23:14:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.12957594 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0067s; samplesPerSecond = 190845.4
11/01/2017 21:23:14:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15337911 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0067s; samplesPerSecond = 189908.2
11/01/2017 21:23:14:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15539365 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0066s; samplesPerSecond = 193035.6
11/01/2017 21:23:14:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13564830 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0073s; samplesPerSecond = 174775.0
11/01/2017 21:23:14:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16038427 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0066s; samplesPerSecond = 194283.8
11/01/2017 21:23:14: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.15072843 * 10000; EvalClassificationError = 0.07290000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.0552658s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.44'

11/01/2017 21:23:14: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15498866 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0071s; samplesPerSecond = 181537.1
11/01/2017 21:23:14:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13802530 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0072s; samplesPerSecond = 178663.7
11/01/2017 21:23:14:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15443592 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0066s; samplesPerSecond = 192733.4
11/01/2017 21:23:14:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15640545 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0067s; samplesPerSecond = 191596.7
11/01/2017 21:23:14:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14921556 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0066s; samplesPerSecond = 192866.9
11/01/2017 21:23:14:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13979316 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0067s; samplesPerSecond = 190564.1
11/01/2017 21:23:14:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15376225 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0066s; samplesPerSecond = 195208.2
11/01/2017 21:23:14: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.14844585 * 10000; EvalClassificationError = 0.07350000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.0550602s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.45'

11/01/2017 21:23:14: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12914567 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0069s; samplesPerSecond = 186624.3
11/01/2017 21:23:14:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16664014 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0066s; samplesPerSecond = 193751.5
11/01/2017 21:23:14:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15111380 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0066s; samplesPerSecond = 193569.9
11/01/2017 21:23:14:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14401274 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0076s; samplesPerSecond = 167355.3
11/01/2017 21:23:14:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15081401 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0070s; samplesPerSecond = 183855.2
11/01/2017 21:23:14:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15450606 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0067s; samplesPerSecond = 190990.6
11/01/2017 21:23:14:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14936638 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0068s; samplesPerSecond = 189083.4
11/01/2017 21:23:14: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14963281 * 10000; EvalClassificationError = 0.07190000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.0551913s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.46'

11/01/2017 21:23:14: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15209731 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0071s; samplesPerSecond = 179367.2
11/01/2017 21:23:14:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15732058 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0069s; samplesPerSecond = 185865.5
11/01/2017 21:23:14:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16360991 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0067s; samplesPerSecond = 191883.9
11/01/2017 21:23:14:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11951761 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0066s; samplesPerSecond = 193268.8
11/01/2017 21:23:14:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13802361 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0068s; samplesPerSecond = 189346.3
11/01/2017 21:23:14:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15337911 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0067s; samplesPerSecond = 190908.0
11/01/2017 21:23:14:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14004936 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0067s; samplesPerSecond = 190119.7
11/01/2017 21:23:14: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14584784 * 10000; EvalClassificationError = 0.07130000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.054711s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.47'

11/01/2017 21:23:14: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15177785 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0070s; samplesPerSecond = 183063.7
11/01/2017 21:23:14:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15497259 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0070s; samplesPerSecond = 182107.9
11/01/2017 21:23:14:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15238948 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0069s; samplesPerSecond = 185563.7
11/01/2017 21:23:14:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14401445 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0070s; samplesPerSecond = 183496.8
11/01/2017 21:23:14:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14763961 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0070s; samplesPerSecond = 181740.7
11/01/2017 21:23:14:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14290299 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0066s; samplesPerSecond = 193992.3
11/01/2017 21:23:14:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13556595 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0066s; samplesPerSecond = 192515.9
11/01/2017 21:23:14: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14651825 * 10000; EvalClassificationError = 0.07240000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.0553701s
11/01/2017 21:23:14: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.48'

11/01/2017 21:23:14: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:14: Starting minibatch loop.
11/01/2017 21:23:14:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16257683 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0070s; samplesPerSecond = 184027.0
11/01/2017 21:23:14:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13693665 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0067s; samplesPerSecond = 190905.2
11/01/2017 21:23:15:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15928245 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0067s; samplesPerSecond = 190603.8
11/01/2017 21:23:15:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15061383 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0066s; samplesPerSecond = 193555.2
11/01/2017 21:23:15:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14774189 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0067s; samplesPerSecond = 190442.2
11/01/2017 21:23:15:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14288821 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0067s; samplesPerSecond = 191976.0
11/01/2017 21:23:15:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18438740 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0067s; samplesPerSecond = 192460.9
11/01/2017 21:23:15: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.15321824 * 10000; EvalClassificationError = 0.07010000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.0541204s
11/01/2017 21:23:15: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.49'

11/01/2017 21:23:15: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:15: Starting minibatch loop.
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14232290 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0096s; samplesPerSecond = 133894.0
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13767104 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0066s; samplesPerSecond = 193382.7
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14364078 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0087s; samplesPerSecond = 147691.7
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15275373 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0092s; samplesPerSecond = 138526.6
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13829832 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0069s; samplesPerSecond = 185701.0
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15360451 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0067s; samplesPerSecond = 190026.6
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15102844 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0067s; samplesPerSecond = 189956.1
11/01/2017 21:23:15: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14561042 * 10000; EvalClassificationError = 0.07280000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.0618728s
11/01/2017 21:23:15: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn'

11/01/2017 21:23:15: Action "train" complete.


11/01/2017 21:23:15: ##############################################################################
11/01/2017 21:23:15: #                                                                            #
11/01/2017 21:23:15: # Simple_Demo_Output command (write action)                                  #
11/01/2017 21:23:15: #                                                                            #
11/01/2017 21:23:15: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1]
	  W1*H1+B1 : [50 x 1 x *1]
	  W2*H1 : [2 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  HLast : [2 x 1 x *1]
	  MVNormalizedFeatures : [2 x *1]
	  W0*features+B0 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] }

Here are the ones that don't share memory:
	{features : [2 x *1]}
	{InvStdOfFeatures : [2]}
	{Prior : [2]}
	{W1 : [50 x 50]}
	{B2 : [2 x 1]}
	{B0 : [50 x 1]}
	{ScaledLogLikelihood : [2 x 1 x *1]}
	{labels : [2 x *1]}
	{B1 : [50 x 1]}
	{LogOfPrior : [2]}
	{MeanOfFeatures : [2]}
	{W0 : [50 x 2]}
	{W2 : [2 x 50]}

Minibatch[0]: ActualMBSize = 603
Written to D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

11/01/2017 21:23:15: Action "write" complete.

11/01/2017 21:23:15: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
CNTK 2.2+ (HEAD 720355, Nov  1 2017 19:56:16) at 2017/11/01 21:23:15

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
-------------------------------------------------------------------
Build info: 

		Built time: Nov  1 2017 19:45:14
		Last modified date: Sat Oct 14 21:29:36 2017
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		With ASGD: yes
		Math lib: mkl
		CUDA version: 0.0.0
		CUDNN version: 6.0.21
		Build Branch: HEAD
		Build SHA1: 720355de01ba6bea62e879f86599830251c60365
		MPI distribution: Microsoft MPI
		MPI version: 7.0.12437.6
-------------------------------------------------------------------
No GPUs found

Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
11/01/2017 21:23:15: Commands: Simple_Demo Simple_Demo_Output
11/01/2017 21:23:15: precision = "float"
11/01/2017 21:23:15: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

11/01/2017 21:23:15: ##############################################################################
11/01/2017 21:23:15: #                                                                            #
11/01/2017 21:23:15: # Simple_Demo command (train action)                                         #
11/01/2017 21:23:15: #                                                                            #
11/01/2017 21:23:15: ##############################################################################

11/01/2017 21:23:15: 
Starting from checkpoint. Loading network from 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn.49'.
SimpleNetworkBuilder Using CPU
11/01/2017 21:23:15: 
Model has 25 nodes. Using CPU.

11/01/2017 21:23:15: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
11/01/2017 21:23:15: Evaluation criterion: EvalClassificationError = ClassificationError

11/01/2017 21:23:15: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

11/01/2017 21:23:15: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
11/01/2017 21:23:15: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
11/01/2017 21:23:15: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
11/01/2017 21:23:15: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
11/01/2017 21:23:15: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
11/01/2017 21:23:15: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

11/01/2017 21:23:15: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/01/2017 21:23:15: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

11/01/2017 21:23:15: Starting minibatch loop.
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.14232290 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0198s; samplesPerSecond = 64783.6
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.13767104 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0060s; samplesPerSecond = 214125.6
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.14364078 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0064s; samplesPerSecond = 199741.0
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.15275373 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0062s; samplesPerSecond = 204836.1
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.13829832 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0065s; samplesPerSecond = 197781.1
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.15360451 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0064s; samplesPerSecond = 201033.4
11/01/2017 21:23:15:  Epoch[50 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.15102844 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0063s; samplesPerSecond = 203420.0
11/01/2017 21:23:15: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14561042 * 10000; EvalClassificationError = 0.07280000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.0645983s
11/01/2017 21:23:15: SGD: Saving checkpoint model 'D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/models/simple.dnn'

11/01/2017 21:23:15: Action "train" complete.


11/01/2017 21:23:15: ##############################################################################
11/01/2017 21:23:15: #                                                                            #
11/01/2017 21:23:15: # Simple_Demo_Output command (write action)                                  #
11/01/2017 21:23:15: #                                                                            #
11/01/2017 21:23:15: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }
	{ H2 : [50 x 1 x *2]
	  HLast : [2 x 1 x *2]
	  MVNormalizedFeatures : [2 x *2]
	  W0*features+B0 : [50 x 1 x *2]
	  W1*H1 : [50 x 1 x *2] }
	{ H1 : [50 x 1 x *2]
	  W0*features : [50 x *2]
	  W1*H1+B1 : [50 x 1 x *2]
	  W2*H1 : [2 x 1 x *2] }

Here are the ones that don't share memory:
	{W1 : [50 x 50]}
	{InvStdOfFeatures : [2]}
	{LogOfPrior : [2]}
	{B0 : [50 x 1]}
	{MeanOfFeatures : [2]}
	{Prior : [2]}
	{B1 : [50 x 1]}
	{labels : [2 x *2]}
	{W0 : [50 x 2]}
	{ScaledLogLikelihood : [2 x 1 x *2]}
	{B2 : [2 x 1]}
	{W2 : [2 x 50]}
	{features : [2 x *2]}

Minibatch[0]: ActualMBSize = 603
Written to D:\cntk-test-20171101212226.695298\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

11/01/2017 21:23:15: Action "write" complete.

11/01/2017 21:23:15: __COMPLETED__
