CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
    Hardware threads: 6
    Total Memory: 58719796 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
CNTK 2.3.1+ (HEAD db192c, Jan 10 2018 22:59:43) at 2018/01/11 08:57:55

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
-------------------------------------------------------------------
Build info: 

		Built time: Jan 10 2018 22:47:38
		Last modified date: Wed Jan 10 22:18:32 2018
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		With ASGD: yes
		Math lib: mkl
		CUDA version: 9.0.0
		CUDNN version: 7.0.5
		Build Branch: HEAD
		Build SHA1: db192cd3cb9ac688cae719c41e5930a4e3f628ea
		MPI distribution: Microsoft MPI
		MPI version: 7.0.12437.6
-------------------------------------------------------------------
-------------------------------------------------------------------
GPU info:

		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8124 MB; free memory = 8001 MB
-------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
01/11/2018 08:57:55: Commands: Simple_Demo Simple_Demo_Output
01/11/2018 08:57:55: precision = "float"
01/11/2018 08:57:55: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

01/11/2018 08:57:55: ##############################################################################
01/11/2018 08:57:55: #                                                                            #
01/11/2018 08:57:55: # Simple_Demo command (train action)                                         #
01/11/2018 08:57:55: #                                                                            #
01/11/2018 08:57:55: ##############################################################################

01/11/2018 08:57:55: 
Creating virgin network.
SimpleNetworkBuilder Using CPU
01/11/2018 08:57:55: 
Model has 25 nodes. Using CPU.

01/11/2018 08:57:55: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
01/11/2018 08:57:55: Evaluation criterion: EvalClassificationError = ClassificationError


Allocating matrices for forward and/or backward propagation.

Gradient Memory Aliasing: 4 are aliased.
	W1*H1 (gradient) reuses W1*H1+B1 (gradient)
	W2*H1 (gradient) reuses HLast (gradient)

Memory Sharing: Out of 40 matrices, 20 are shared as 5, and 20 are not shared.

Here are the ones that share memory:
	{ PosteriorProb : [2 x 1 x *]
	  ScaledLogLikelihood : [2 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0 : [50 x 2] (gradient)
	  W0*features : [50 x *] }
	{ H1 : [50 x 1 x *] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *]
	  W0*features : [50 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ HLast : [2 x 1 x *] (gradient)
	  W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *]
	  W2*H1 : [2 x 1 x *] (gradient) }
	{ H2 : [50 x 1 x *]
	  W0*features+B0 : [50 x 1 x *]
	  W1 : [50 x 50] (gradient)
	  W1*H1 : [50 x 1 x *] }

Here are the ones that don't share memory:
	{MeanOfFeatures : [2]}
	{InvStdOfFeatures : [2]}
	{features : [2 x *]}
	{B0 : [50 x 1]}
	{W0 : [50 x 2]}
	{B2 : [2 x 1]}
	{EvalClassificationError : [1]}
	{W2 : [2 x 50] (gradient)}
	{Prior : [2]}
	{CrossEntropyWithSoftmax : [1]}
	{B1 : [50 x 1] (gradient)}
	{B2 : [2 x 1] (gradient)}
	{CrossEntropyWithSoftmax : [1] (gradient)}
	{B0 : [50 x 1] (gradient)}
	{B1 : [50 x 1]}
	{W1 : [50 x 50]}
	{W2 : [2 x 50]}
	{labels : [2 x *]}
	{MVNormalizedFeatures : [2 x *]}
	{LogOfPrior : [2]}


01/11/2018 08:57:55: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

01/11/2018 08:57:55: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
01/11/2018 08:57:55: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
01/11/2018 08:57:55: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
01/11/2018 08:57:55: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
01/11/2018 08:57:55: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
01/11/2018 08:57:55: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


01/11/2018 08:57:55: Precomputing --> 3 PreCompute nodes found.

01/11/2018 08:57:55: 	MeanOfFeatures = Mean()
01/11/2018 08:57:55: 	InvStdOfFeatures = InvStdDev()
01/11/2018 08:57:55: 	Prior = Mean()

01/11/2018 08:57:55: Precomputing --> Completed.


01/11/2018 08:57:55: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:55: Starting minibatch loop.
01/11/2018 08:57:55:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.82292490 * 1280; EvalClassificationError = 0.51875000 * 1280; time = 0.0068s; samplesPerSecond = 188429.3
01/11/2018 08:57:55:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.77976751 * 1280; EvalClassificationError = 0.50781250 * 1280; time = 0.0052s; samplesPerSecond = 243842.0
01/11/2018 08:57:55:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.72312794 * 1280; EvalClassificationError = 0.48828125 * 1280; time = 0.0056s; samplesPerSecond = 230253.1
01/11/2018 08:57:55:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71024914 * 1280; EvalClassificationError = 0.51484375 * 1280; time = 0.0052s; samplesPerSecond = 243851.3
01/11/2018 08:57:55:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.69842186 * 1280; EvalClassificationError = 0.50078125 * 1280; time = 0.0052s; samplesPerSecond = 247687.6
01/11/2018 08:57:55:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.71133003 * 1280; EvalClassificationError = 0.50781250 * 1280; time = 0.0052s; samplesPerSecond = 245676.7
01/11/2018 08:57:55:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.70956345 * 1280; EvalClassificationError = 0.50156250 * 1280; time = 0.0052s; samplesPerSecond = 246509.4
01/11/2018 08:57:55: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.73301484 * 10000; EvalClassificationError = 0.50560000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.043241s
01/11/2018 08:57:55: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.1'

01/11/2018 08:57:55: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:55: Starting minibatch loop.
01/11/2018 08:57:55:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70886807 * 1280; EvalClassificationError = 0.49296875 * 1280; time = 0.0055s; samplesPerSecond = 232241.7
01/11/2018 08:57:55:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74700866 * 1280; EvalClassificationError = 0.46406250 * 1280; time = 0.0052s; samplesPerSecond = 245676.7
01/11/2018 08:57:55:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.74863911 * 1280; EvalClassificationError = 0.51171875 * 1280; time = 0.0052s; samplesPerSecond = 246742.2
01/11/2018 08:57:55:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.74191303 * 1280; EvalClassificationError = 0.49140625 * 1280; time = 0.0061s; samplesPerSecond = 208326.6
01/11/2018 08:57:55:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.70860958 * 1280; EvalClassificationError = 0.44843750 * 1280; time = 0.0052s; samplesPerSecond = 247142.4
01/11/2018 08:57:55:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.53537674 * 1280; EvalClassificationError = 0.27968750 * 1280; time = 0.0054s; samplesPerSecond = 236502.7
01/11/2018 08:57:55:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.21461830 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0053s; samplesPerSecond = 243175.0
01/11/2018 08:57:55: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.58242515 * 10000; EvalClassificationError = 0.36300000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.0435233s
01/11/2018 08:57:55: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.2'

01/11/2018 08:57:55: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:55: Starting minibatch loop.
01/11/2018 08:57:55:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.22909825 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0055s; samplesPerSecond = 230647.3
01/11/2018 08:57:55:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.23779914 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0052s; samplesPerSecond = 245436.4
01/11/2018 08:57:55:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20465937 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0068s; samplesPerSecond = 188440.4
01/11/2018 08:57:55:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.22730808 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0054s; samplesPerSecond = 237542.9
01/11/2018 08:57:55:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19903498 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0052s; samplesPerSecond = 246490.4
01/11/2018 08:57:55:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18025875 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0052s; samplesPerSecond = 244821.5
01/11/2018 08:57:55:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16614008 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0052s; samplesPerSecond = 247061.3
01/11/2018 08:57:55: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.20096183 * 10000; EvalClassificationError = 0.07710000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.0441472s
01/11/2018 08:57:55: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.3'

01/11/2018 08:57:55: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:55: Starting minibatch loop.
01/11/2018 08:57:55:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14967010 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0055s; samplesPerSecond = 233351.0
01/11/2018 08:57:55:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17833936 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0052s; samplesPerSecond = 245889.0
01/11/2018 08:57:55:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17100439 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0052s; samplesPerSecond = 246737.5
01/11/2018 08:57:55:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.20658674 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0055s; samplesPerSecond = 232132.2
01/11/2018 08:57:55:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18623204 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0052s; samplesPerSecond = 246594.9
01/11/2018 08:57:55:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16607418 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0052s; samplesPerSecond = 247563.1
01/11/2018 08:57:55:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17943296 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0053s; samplesPerSecond = 240082.5
01/11/2018 08:57:55: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.17554689 * 10000; EvalClassificationError = 0.07780000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.0427098s
01/11/2018 08:57:55: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.4'

01/11/2018 08:57:55: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:55: Starting minibatch loop.
01/11/2018 08:57:55:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16107254 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0055s; samplesPerSecond = 232786.5
01/11/2018 08:57:56:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17703226 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0052s; samplesPerSecond = 244237.5
01/11/2018 08:57:56:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16815813 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0052s; samplesPerSecond = 245441.1
01/11/2018 08:57:56:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16302562 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0054s; samplesPerSecond = 238028.8
01/11/2018 08:57:56:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18440428 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0052s; samplesPerSecond = 246139.6
01/11/2018 08:57:56:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17460585 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0052s; samplesPerSecond = 246059.2
01/11/2018 08:57:56:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17822142 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0054s; samplesPerSecond = 237243.5
01/11/2018 08:57:56: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16997924 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.0427429s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.5'

01/11/2018 08:57:56: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17073472 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0054s; samplesPerSecond = 237529.7
01/11/2018 08:57:56:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19877164 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0052s; samplesPerSecond = 246870.7
01/11/2018 08:57:56:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17885361 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0052s; samplesPerSecond = 246262.8
01/11/2018 08:57:56:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17261200 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0052s; samplesPerSecond = 243972.2
01/11/2018 08:57:56:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18293324 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0052s; samplesPerSecond = 245281.2
01/11/2018 08:57:56:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17321815 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0052s; samplesPerSecond = 247166.3
01/11/2018 08:57:56:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.20214634 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0054s; samplesPerSecond = 238814.9
01/11/2018 08:57:56: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.18083456 * 10000; EvalClassificationError = 0.08030000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.0423824s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.6'

01/11/2018 08:57:56: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19412596 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0054s; samplesPerSecond = 235627.6
01/11/2018 08:57:56:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17305954 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0053s; samplesPerSecond = 242773.7
01/11/2018 08:57:56:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18254080 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0052s; samplesPerSecond = 245365.8
01/11/2018 08:57:56:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14360499 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0052s; samplesPerSecond = 244232.9
01/11/2018 08:57:56:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14654765 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0057s; samplesPerSecond = 226180.4
01/11/2018 08:57:56:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17602434 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0056s; samplesPerSecond = 229333.1
01/11/2018 08:57:56:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17026329 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0052s; samplesPerSecond = 244452.1
01/11/2018 08:57:56: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17133093 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.0434785s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.7'

01/11/2018 08:57:56: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18866835 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0055s; samplesPerSecond = 233999.4
01/11/2018 08:57:56:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17958219 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0054s; samplesPerSecond = 235350.4
01/11/2018 08:57:56:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17793877 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0052s; samplesPerSecond = 244158.3
01/11/2018 08:57:56:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16580863 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0052s; samplesPerSecond = 246153.8
01/11/2018 08:57:56:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17047133 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0058s; samplesPerSecond = 219226.9
01/11/2018 08:57:56:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19052963 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0052s; samplesPerSecond = 244368.1
01/11/2018 08:57:56:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15223265 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0052s; samplesPerSecond = 245653.1
01/11/2018 08:57:56: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.17550333 * 10000; EvalClassificationError = 0.08030000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.0435454s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.8'

01/11/2018 08:57:56: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.20843947 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0054s; samplesPerSecond = 236537.7
01/11/2018 08:57:56:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20732338 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0053s; samplesPerSecond = 242126.2
01/11/2018 08:57:56:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18901725 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0052s; samplesPerSecond = 247004.1
01/11/2018 08:57:56:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19406786 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0052s; samplesPerSecond = 244232.9
01/11/2018 08:57:56:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17628584 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0052s; samplesPerSecond = 244172.3
01/11/2018 08:57:56:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15008898 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0052s; samplesPerSecond = 244246.8
01/11/2018 08:57:56:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15322666 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0052s; samplesPerSecond = 245511.7
01/11/2018 08:57:56: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.18178018 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.0426667s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.9'

01/11/2018 08:57:56: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16429756 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0054s; samplesPerSecond = 235744.8
01/11/2018 08:57:56:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15331361 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0053s; samplesPerSecond = 242483.9
01/11/2018 08:57:56:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17683187 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0053s; samplesPerSecond = 243322.9
01/11/2018 08:57:56:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17412157 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0052s; samplesPerSecond = 245941.0
01/11/2018 08:57:56:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19193020 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0052s; samplesPerSecond = 243958.2
01/11/2018 08:57:56:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15996323 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0052s; samplesPerSecond = 244957.3
01/11/2018 08:57:56:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15454798 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0052s; samplesPerSecond = 244000.1
01/11/2018 08:57:56: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16562075 * 10000; EvalClassificationError = 0.07510000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.043172s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.10'

01/11/2018 08:57:56: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16918814 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0055s; samplesPerSecond = 234123.5
01/11/2018 08:57:56:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15994136 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0053s; samplesPerSecond = 242369.2
01/11/2018 08:57:56:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17205191 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0059s; samplesPerSecond = 215818.8
01/11/2018 08:57:56:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16319113 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0052s; samplesPerSecond = 244069.9
01/11/2018 08:57:56:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15153427 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0053s; samplesPerSecond = 243096.4
01/11/2018 08:57:56:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15329037 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0052s; samplesPerSecond = 246433.5
01/11/2018 08:57:56:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15840683 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0052s; samplesPerSecond = 244741.9
01/11/2018 08:57:56: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16564078 * 10000; EvalClassificationError = 0.07490000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.0434633s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.11'

01/11/2018 08:57:56: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16317813 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0064s; samplesPerSecond = 199943.8
01/11/2018 08:57:56:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17073774 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0057s; samplesPerSecond = 226356.4
01/11/2018 08:57:56:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17058880 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0053s; samplesPerSecond = 240945.7
01/11/2018 08:57:56:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16312370 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0052s; samplesPerSecond = 245314.1
01/11/2018 08:57:56:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15805721 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0053s; samplesPerSecond = 240977.5
01/11/2018 08:57:56:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16143732 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0053s; samplesPerSecond = 242852.0
01/11/2018 08:57:56:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14267178 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0053s; samplesPerSecond = 239997.0
01/11/2018 08:57:56: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16131581 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.044473s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.12'

01/11/2018 08:57:56: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14920561 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0056s; samplesPerSecond = 228115.2
01/11/2018 08:57:56:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18176687 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0053s; samplesPerSecond = 239853.1
01/11/2018 08:57:56:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17360897 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0056s; samplesPerSecond = 228767.5
01/11/2018 08:57:56:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15493827 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0053s; samplesPerSecond = 240172.6
01/11/2018 08:57:56:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15254312 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0055s; samplesPerSecond = 233172.4
01/11/2018 08:57:56:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17198753 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0085s; samplesPerSecond = 151352.1
01/11/2018 08:57:56:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15650759 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0066s; samplesPerSecond = 194623.5
01/11/2018 08:57:56: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16410955 * 10000; EvalClassificationError = 0.07390000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.0480673s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.13'

01/11/2018 08:57:56: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18765523 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0055s; samplesPerSecond = 234733.2
01/11/2018 08:57:56:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19378638 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0055s; samplesPerSecond = 234445.1
01/11/2018 08:57:56:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15804451 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0053s; samplesPerSecond = 241966.0
01/11/2018 08:57:56:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18707528 * 1280; EvalClassificationError = 0.09062500 * 1280; time = 0.0052s; samplesPerSecond = 243893.1
01/11/2018 08:57:56:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17851853 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0053s; samplesPerSecond = 240624.1
01/11/2018 08:57:56:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15969524 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0052s; samplesPerSecond = 244344.8
01/11/2018 08:57:56:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15674477 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0052s; samplesPerSecond = 245624.8
01/11/2018 08:57:56: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.17457382 * 10000; EvalClassificationError = 0.07970000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.0429118s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.14'

01/11/2018 08:57:56: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16807188 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0055s; samplesPerSecond = 234513.8
01/11/2018 08:57:56:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14487201 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0057s; samplesPerSecond = 224999.6
01/11/2018 08:57:56:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16922855 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0082s; samplesPerSecond = 156749.4
01/11/2018 08:57:56:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16383696 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0053s; samplesPerSecond = 242259.1
01/11/2018 08:57:56:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16629224 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0052s; samplesPerSecond = 246111.2
01/11/2018 08:57:56:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16055603 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0053s; samplesPerSecond = 243295.1
01/11/2018 08:57:56:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15666027 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0053s; samplesPerSecond = 242782.9
01/11/2018 08:57:56: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16105973 * 10000; EvalClassificationError = 0.07400000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.0460036s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.15'

01/11/2018 08:57:56: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16056929 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0057s; samplesPerSecond = 224813.8
01/11/2018 08:57:56:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15552216 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0055s; samplesPerSecond = 232600.4
01/11/2018 08:57:56:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16812882 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0056s; samplesPerSecond = 230348.4
01/11/2018 08:57:56:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16662073 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0053s; samplesPerSecond = 243531.2
01/11/2018 08:57:56:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18013902 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0056s; samplesPerSecond = 229267.4
01/11/2018 08:57:56:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16758661 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0052s; samplesPerSecond = 244284.1
01/11/2018 08:57:56:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17382126 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0053s; samplesPerSecond = 240533.7
01/11/2018 08:57:56: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.16673308 * 10000; EvalClassificationError = 0.07770000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.0438656s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.16'

01/11/2018 08:57:56: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15741982 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0054s; samplesPerSecond = 236590.1
01/11/2018 08:57:56:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16492159 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0053s; samplesPerSecond = 239821.6
01/11/2018 08:57:56:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18577268 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0053s; samplesPerSecond = 241523.1
01/11/2018 08:57:56:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16102133 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0053s; samplesPerSecond = 241309.1
01/11/2018 08:57:56:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15495420 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0055s; samplesPerSecond = 231109.5
01/11/2018 08:57:56:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15126572 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0053s; samplesPerSecond = 242337.0
01/11/2018 08:57:56:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15345907 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0053s; samplesPerSecond = 242052.9
01/11/2018 08:57:56: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.16122592 * 10000; EvalClassificationError = 0.07560000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.043107s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.17'

01/11/2018 08:57:56: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15050393 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0055s; samplesPerSecond = 232048.0
01/11/2018 08:57:56:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16195492 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0053s; samplesPerSecond = 239830.6
01/11/2018 08:57:56:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16647577 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0053s; samplesPerSecond = 241290.9
01/11/2018 08:57:56:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15378642 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0053s; samplesPerSecond = 242640.2
01/11/2018 08:57:56:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14804449 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0055s; samplesPerSecond = 233644.9
01/11/2018 08:57:56:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15810242 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0052s; samplesPerSecond = 246319.6
01/11/2018 08:57:56:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15576038 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0056s; samplesPerSecond = 227871.5
01/11/2018 08:57:56: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15669054 * 10000; EvalClassificationError = 0.07460000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.0434822s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.18'

01/11/2018 08:57:56: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15712020 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0055s; samplesPerSecond = 232858.5
01/11/2018 08:57:56:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14908109 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0057s; samplesPerSecond = 225853.1
01/11/2018 08:57:56:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16572497 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0061s; samplesPerSecond = 210720.4
01/11/2018 08:57:56:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14920216 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0052s; samplesPerSecond = 244079.2
01/11/2018 08:57:56:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17894874 * 1280; EvalClassificationError = 0.08437500 * 1280; time = 0.0055s; samplesPerSecond = 233032.3
01/11/2018 08:57:56:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16354017 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0053s; samplesPerSecond = 241500.3
01/11/2018 08:57:56:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17957954 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0053s; samplesPerSecond = 240982.0
01/11/2018 08:57:56: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16370315 * 10000; EvalClassificationError = 0.07820000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.0443544s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.19'

01/11/2018 08:57:56: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15389599 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0055s; samplesPerSecond = 231167.9
01/11/2018 08:57:56:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15102414 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0052s; samplesPerSecond = 243860.6
01/11/2018 08:57:56:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15534561 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0053s; samplesPerSecond = 241395.6
01/11/2018 08:57:56:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16748443 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0053s; samplesPerSecond = 242690.8
01/11/2018 08:57:56:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15846500 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0068s; samplesPerSecond = 189287.5
01/11/2018 08:57:56:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15586486 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0054s; samplesPerSecond = 239037.9
01/11/2018 08:57:56:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16819916 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0053s; samplesPerSecond = 242268.2
01/11/2018 08:57:56: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.15685659 * 10000; EvalClassificationError = 0.07370000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.0444512s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.20'

01/11/2018 08:57:56: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16044323 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0055s; samplesPerSecond = 232850.0
01/11/2018 08:57:56:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15007892 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0054s; samplesPerSecond = 238895.1
01/11/2018 08:57:56:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15607736 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0053s; samplesPerSecond = 239422.4
01/11/2018 08:57:56:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14384913 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0053s; samplesPerSecond = 239494.1
01/11/2018 08:57:56:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16455374 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0056s; samplesPerSecond = 230352.5
01/11/2018 08:57:56:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16868019 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0053s; samplesPerSecond = 242176.6
01/11/2018 08:57:56:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16089697 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0052s; samplesPerSecond = 244186.3
01/11/2018 08:57:56: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15813529 * 10000; EvalClassificationError = 0.07680000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.0435525s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.21'

01/11/2018 08:57:56: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15188577 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0056s; samplesPerSecond = 229744.8
01/11/2018 08:57:56:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13540854 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0054s; samplesPerSecond = 238623.4
01/11/2018 08:57:56:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16405766 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0053s; samplesPerSecond = 240533.7
01/11/2018 08:57:56:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16412554 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0053s; samplesPerSecond = 240055.5
01/11/2018 08:57:56:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15334044 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0053s; samplesPerSecond = 243512.7
01/11/2018 08:57:56:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15161128 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0053s; samplesPerSecond = 239893.5
01/11/2018 08:57:56:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19276104 * 1280; EvalClassificationError = 0.09218750 * 1280; time = 0.0053s; samplesPerSecond = 239646.5
01/11/2018 08:57:56: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16042100 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.0435126s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.22'

01/11/2018 08:57:56: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16362655 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0055s; samplesPerSecond = 231080.3
01/11/2018 08:57:56:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17052763 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0054s; samplesPerSecond = 238832.7
01/11/2018 08:57:56:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16147366 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0053s; samplesPerSecond = 243050.3
01/11/2018 08:57:56:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15935931 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0053s; samplesPerSecond = 240651.3
01/11/2018 08:57:56:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15040693 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0059s; samplesPerSecond = 218560.6
01/11/2018 08:57:56:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15705509 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0053s; samplesPerSecond = 239619.6
01/11/2018 08:57:56:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14803944 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0053s; samplesPerSecond = 239382.1
01/11/2018 08:57:56: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.15887462 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.0440061s
01/11/2018 08:57:56: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.23'

01/11/2018 08:57:56: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:56: Starting minibatch loop.
01/11/2018 08:57:56:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17891910 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0055s; samplesPerSecond = 234858.1
01/11/2018 08:57:56:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18593357 * 1280; EvalClassificationError = 0.08984375 * 1280; time = 0.0058s; samplesPerSecond = 220712.5
01/11/2018 08:57:56:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15016093 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0053s; samplesPerSecond = 240163.6
01/11/2018 08:57:56:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13410311 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0070s; samplesPerSecond = 183425.8
01/11/2018 08:57:56:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18014774 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0055s; samplesPerSecond = 234359.3
01/11/2018 08:57:56:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13521624 * 1280; EvalClassificationError = 0.05468750 * 1280; time = 0.0054s; samplesPerSecond = 237520.9
01/11/2018 08:57:56:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16167946 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0054s; samplesPerSecond = 239243.4
01/11/2018 08:57:56: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16157897 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.0469228s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.24'

01/11/2018 08:57:57: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14394454 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0059s; samplesPerSecond = 217129.5
01/11/2018 08:57:57:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17737890 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0053s; samplesPerSecond = 239283.6
01/11/2018 08:57:57:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14675832 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0053s; samplesPerSecond = 239965.5
01/11/2018 08:57:57:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15966926 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0054s; samplesPerSecond = 239176.3
01/11/2018 08:57:57:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16962838 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0054s; samplesPerSecond = 238396.8
01/11/2018 08:57:57:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17309103 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0052s; samplesPerSecond = 244093.1
01/11/2018 08:57:57:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17608633 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0054s; samplesPerSecond = 237944.8
01/11/2018 08:57:57: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16261558 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.0437065s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.25'

01/11/2018 08:57:57: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14521136 * 1280; EvalClassificationError = 0.06406250 * 1280; time = 0.0059s; samplesPerSecond = 217284.3
01/11/2018 08:57:57:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17816341 * 1280; EvalClassificationError = 0.09140625 * 1280; time = 0.0054s; samplesPerSecond = 238277.0
01/11/2018 08:57:57:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16222775 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0053s; samplesPerSecond = 240114.1
01/11/2018 08:57:57:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14471712 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0053s; samplesPerSecond = 242204.1
01/11/2018 08:57:57:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16901345 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0053s; samplesPerSecond = 239722.8
01/11/2018 08:57:57:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12451944 * 1280; EvalClassificationError = 0.05156250 * 1280; time = 0.0054s; samplesPerSecond = 237670.8
01/11/2018 08:57:57:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16381931 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0054s; samplesPerSecond = 238912.9
01/11/2018 08:57:57: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.15583629 * 10000; EvalClassificationError = 0.07440000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.0436837s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.26'

01/11/2018 08:57:57: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16974432 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0066s; samplesPerSecond = 194860.6
01/11/2018 08:57:57:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16733959 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0053s; samplesPerSecond = 242603.4
01/11/2018 08:57:57:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14435410 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0055s; samplesPerSecond = 230909.4
01/11/2018 08:57:57:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14967275 * 1280; EvalClassificationError = 0.06093750 * 1280; time = 0.0102s; samplesPerSecond = 125222.6
01/11/2018 08:57:57:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15140128 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0087s; samplesPerSecond = 147292.4
01/11/2018 08:57:57:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15337329 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0080s; samplesPerSecond = 159422.1
01/11/2018 08:57:57:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16948423 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0089s; samplesPerSecond = 144451.6
01/11/2018 08:57:57: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15804399 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.0618725s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.27'

01/11/2018 08:57:57: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16823483 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0093s; samplesPerSecond = 138169.3
01/11/2018 08:57:57:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18711014 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0092s; samplesPerSecond = 139640.4
01/11/2018 08:57:57:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16809006 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0086s; samplesPerSecond = 148887.4
01/11/2018 08:57:57:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14899678 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0095s; samplesPerSecond = 135379.5
01/11/2018 08:57:57:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13890100 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0116s; samplesPerSecond = 110062.1
01/11/2018 08:57:57:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15160398 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0054s; samplesPerSecond = 236712.7
01/11/2018 08:57:57:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16486292 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0053s; samplesPerSecond = 241341.0
01/11/2018 08:57:57: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16216410 * 10000; EvalClassificationError = 0.07620000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.066152s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.28'

01/11/2018 08:57:57: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15834999 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0058s; samplesPerSecond = 222210.6
01/11/2018 08:57:57:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12738945 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0056s; samplesPerSecond = 229156.6
01/11/2018 08:57:57:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16783931 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0054s; samplesPerSecond = 236901.0
01/11/2018 08:57:57:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14756327 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0054s; samplesPerSecond = 238627.9
01/11/2018 08:57:57:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16397915 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0071s; samplesPerSecond = 179309.4
01/11/2018 08:57:57:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14491739 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0082s; samplesPerSecond = 156983.9
01/11/2018 08:57:57:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17005672 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0086s; samplesPerSecond = 148522.9
01/11/2018 08:57:57: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15876620 * 10000; EvalClassificationError = 0.07520000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.0518658s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.29'

01/11/2018 08:57:57: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16122813 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0056s; samplesPerSecond = 227677.0
01/11/2018 08:57:57:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15242901 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0062s; samplesPerSecond = 205375.1
01/11/2018 08:57:57:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16156187 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0058s; samplesPerSecond = 220765.8
01/11/2018 08:57:57:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18074212 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0128s; samplesPerSecond = 99620.2
01/11/2018 08:57:57:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17172852 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0054s; samplesPerSecond = 235857.7
01/11/2018 08:57:57:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16896315 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0054s; samplesPerSecond = 238427.9
01/11/2018 08:57:57:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17258568 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0054s; samplesPerSecond = 236905.4
01/11/2018 08:57:57: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16581123 * 10000; EvalClassificationError = 0.07720000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.0526785s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.30'

01/11/2018 08:57:57: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16897371 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0055s; samplesPerSecond = 232994.2
01/11/2018 08:57:57:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16999123 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0059s; samplesPerSecond = 217409.8
01/11/2018 08:57:57:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18995028 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0054s; samplesPerSecond = 235441.3
01/11/2018 08:57:57:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14698973 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0056s; samplesPerSecond = 230079.3
01/11/2018 08:57:57:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17408600 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0055s; samplesPerSecond = 231101.2
01/11/2018 08:57:57:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14637899 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0066s; samplesPerSecond = 192858.2
01/11/2018 08:57:57:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15711212 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0054s; samplesPerSecond = 236101.4
01/11/2018 08:57:57: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.16452855 * 10000; EvalClassificationError = 0.07810000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.0457108s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.31'

01/11/2018 08:57:57: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16301141 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0056s; samplesPerSecond = 228115.2
01/11/2018 08:57:57:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14686766 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0059s; samplesPerSecond = 217409.8
01/11/2018 08:57:57:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13885765 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0054s; samplesPerSecond = 237023.9
01/11/2018 08:57:57:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15732145 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0054s; samplesPerSecond = 237547.3
01/11/2018 08:57:57:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14985046 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0057s; samplesPerSecond = 225952.8
01/11/2018 08:57:57:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16477799 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0055s; samplesPerSecond = 231812.7
01/11/2018 08:57:57:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15139637 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0057s; samplesPerSecond = 224384.3
01/11/2018 08:57:57: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15504583 * 10000; EvalClassificationError = 0.07450000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.0450112s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.32'

01/11/2018 08:57:57: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16162547 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0056s; samplesPerSecond = 228298.3
01/11/2018 08:57:57:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17066709 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0058s; samplesPerSecond = 222264.7
01/11/2018 08:57:57:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15118799 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0054s; samplesPerSecond = 237168.8
01/11/2018 08:57:57:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15539179 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0053s; samplesPerSecond = 240565.3
01/11/2018 08:57:57:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14059863 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0054s; samplesPerSecond = 236084.0
01/11/2018 08:57:57:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14768147 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0054s; samplesPerSecond = 236349.9
01/11/2018 08:57:57:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16787405 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0054s; samplesPerSecond = 237874.0
01/11/2018 08:57:57: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15615193 * 10000; EvalClassificationError = 0.07420000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.0441319s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.33'

01/11/2018 08:57:57: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13651472 * 1280; EvalClassificationError = 0.06328125 * 1280; time = 0.0058s; samplesPerSecond = 220902.9
01/11/2018 08:57:57:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15933846 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0053s; samplesPerSecond = 240046.5
01/11/2018 08:57:57:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16713061 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0060s; samplesPerSecond = 212448.1
01/11/2018 08:57:57:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14403610 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0058s; samplesPerSecond = 221572.1
01/11/2018 08:57:57:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16177626 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0054s; samplesPerSecond = 235571.3
01/11/2018 08:57:57:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16950884 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0054s; samplesPerSecond = 236306.2
01/11/2018 08:57:57:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16325636 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0054s; samplesPerSecond = 235475.9
01/11/2018 08:57:57: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15602977 * 10000; EvalClassificationError = 0.07570000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.0448938s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.34'

01/11/2018 08:57:57: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16672130 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0057s; samplesPerSecond = 225685.9
01/11/2018 08:57:57:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14191186 * 1280; EvalClassificationError = 0.06562500 * 1280; time = 0.0055s; samplesPerSecond = 234664.3
01/11/2018 08:57:57:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15464017 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0054s; samplesPerSecond = 235827.3
01/11/2018 08:57:57:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15669522 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0056s; samplesPerSecond = 228103.0
01/11/2018 08:57:57:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14840374 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0054s; samplesPerSecond = 235684.0
01/11/2018 08:57:57:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14536872 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0054s; samplesPerSecond = 235562.6
01/11/2018 08:57:57:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15993757 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0053s; samplesPerSecond = 241500.3
01/11/2018 08:57:57: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15363567 * 10000; EvalClassificationError = 0.07430000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.0441678s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.35'

01/11/2018 08:57:57: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14913379 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0057s; samplesPerSecond = 223222.1
01/11/2018 08:57:57:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18486055 * 1280; EvalClassificationError = 0.08515625 * 1280; time = 0.0054s; samplesPerSecond = 235558.3
01/11/2018 08:57:57:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14803748 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0054s; samplesPerSecond = 235363.3
01/11/2018 08:57:57:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15396066 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0058s; samplesPerSecond = 222284.0
01/11/2018 08:57:57:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14668965 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0054s; samplesPerSecond = 239131.7
01/11/2018 08:57:57:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13682280 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0055s; samplesPerSecond = 230905.2
01/11/2018 08:57:57:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14860535 * 1280; EvalClassificationError = 0.07109375 * 1280; time = 0.0056s; samplesPerSecond = 226890.0
01/11/2018 08:57:57: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15330402 * 10000; EvalClassificationError = 0.07300000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.0447653s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.36'

01/11/2018 08:57:57: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16894621 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0057s; samplesPerSecond = 224183.8
01/11/2018 08:57:57:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14590818 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0055s; samplesPerSecond = 233040.8
01/11/2018 08:57:57:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14945059 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0061s; samplesPerSecond = 209034.2
01/11/2018 08:57:57:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12509546 * 1280; EvalClassificationError = 0.05546875 * 1280; time = 0.0057s; samplesPerSecond = 225427.5
01/11/2018 08:57:57:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16078463 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0054s; samplesPerSecond = 235324.4
01/11/2018 08:57:57:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14524503 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0055s; samplesPerSecond = 234355.0
01/11/2018 08:57:57:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15973969 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0055s; samplesPerSecond = 233738.7
01/11/2018 08:57:57: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15063938 * 10000; EvalClassificationError = 0.07130000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.0452361s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.37'

01/11/2018 08:57:57: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16746423 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0056s; samplesPerSecond = 229390.7
01/11/2018 08:57:57:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14641221 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0056s; samplesPerSecond = 228542.9
01/11/2018 08:57:57:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14680085 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0055s; samplesPerSecond = 234359.3
01/11/2018 08:57:57:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15910463 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0058s; samplesPerSecond = 221606.6
01/11/2018 08:57:57:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13705096 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0067s; samplesPerSecond = 190737.3
01/11/2018 08:57:57:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15457335 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0054s; samplesPerSecond = 236297.5
01/11/2018 08:57:57:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13793306 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0055s; samplesPerSecond = 232031.2
01/11/2018 08:57:57: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15022997 * 10000; EvalClassificationError = 0.07270000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.0458116s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.38'

01/11/2018 08:57:57: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14781227 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0057s; samplesPerSecond = 223105.3
01/11/2018 08:57:57:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13780270 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0055s; samplesPerSecond = 232562.4
01/11/2018 08:57:57:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15107102 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0056s; samplesPerSecond = 228070.5
01/11/2018 08:57:57:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15137210 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0055s; samplesPerSecond = 233623.5
01/11/2018 08:57:57:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15106049 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0054s; samplesPerSecond = 235013.3
01/11/2018 08:57:57:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16847763 * 1280; EvalClassificationError = 0.08593750 * 1280; time = 0.0055s; samplesPerSecond = 231837.9
01/11/2018 08:57:57:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17596769 * 1280; EvalClassificationError = 0.08750000 * 1280; time = 0.0061s; samplesPerSecond = 209942.8
01/11/2018 08:57:57: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15368572 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.04557s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.39'

01/11/2018 08:57:57: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18559849 * 1280; EvalClassificationError = 0.08906250 * 1280; time = 0.0058s; samplesPerSecond = 222272.4
01/11/2018 08:57:57:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14538469 * 1280; EvalClassificationError = 0.06250000 * 1280; time = 0.0055s; samplesPerSecond = 234647.1
01/11/2018 08:57:57:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15225065 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0055s; samplesPerSecond = 233841.2
01/11/2018 08:57:57:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14976544 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0053s; samplesPerSecond = 241924.8
01/11/2018 08:57:57:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15455961 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0055s; samplesPerSecond = 234647.1
01/11/2018 08:57:57:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15915122 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0057s; samplesPerSecond = 226472.5
01/11/2018 08:57:57:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14317856 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0055s; samplesPerSecond = 233922.4
01/11/2018 08:57:57: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15353707 * 10000; EvalClassificationError = 0.07380000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.0444573s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.40'

01/11/2018 08:57:57: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16386302 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0057s; samplesPerSecond = 225634.2
01/11/2018 08:57:57:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13388731 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0053s; samplesPerSecond = 241045.5
01/11/2018 08:57:57:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14691362 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0055s; samplesPerSecond = 233849.8
01/11/2018 08:57:57:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15102911 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0055s; samplesPerSecond = 233674.7
01/11/2018 08:57:57:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14908104 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0055s; samplesPerSecond = 234832.2
01/11/2018 08:57:57:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14839187 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0057s; samplesPerSecond = 226284.3
01/11/2018 08:57:57:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15130234 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0055s; samplesPerSecond = 232625.8
01/11/2018 08:57:57: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14857347 * 10000; EvalClassificationError = 0.07150000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.0442286s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.41'

01/11/2018 08:57:57: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14376595 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0057s; samplesPerSecond = 223155.9
01/11/2018 08:57:57:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14518886 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0055s; samplesPerSecond = 234677.2
01/11/2018 08:57:57:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15640280 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0055s; samplesPerSecond = 232600.4
01/11/2018 08:57:57:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15552249 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0055s; samplesPerSecond = 232111.1
01/11/2018 08:57:57:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15926309 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0054s; samplesPerSecond = 234922.7
01/11/2018 08:57:57:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16413403 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0061s; samplesPerSecond = 209372.7
01/11/2018 08:57:57:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17426624 * 1280; EvalClassificationError = 0.08671875 * 1280; time = 0.0062s; samplesPerSecond = 205003.4
01/11/2018 08:57:57: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15598872 * 10000; EvalClassificationError = 0.07530000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.0457635s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.42'

01/11/2018 08:57:57: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15915492 * 1280; EvalClassificationError = 0.07968750 * 1280; time = 0.0057s; samplesPerSecond = 223401.3
01/11/2018 08:57:57:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12504425 * 1280; EvalClassificationError = 0.06015625 * 1280; time = 0.0055s; samplesPerSecond = 231644.9
01/11/2018 08:57:57:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14653146 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0056s; samplesPerSecond = 230174.4
01/11/2018 08:57:57:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15579753 * 1280; EvalClassificationError = 0.07734375 * 1280; time = 0.0055s; samplesPerSecond = 232469.4
01/11/2018 08:57:57:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16196094 * 1280; EvalClassificationError = 0.08281250 * 1280; time = 0.0053s; samplesPerSecond = 242208.6
01/11/2018 08:57:57:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13869267 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0057s; samplesPerSecond = 224070.0
01/11/2018 08:57:57:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16449947 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0055s; samplesPerSecond = 233414.8
01/11/2018 08:57:57: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14961818 * 10000; EvalClassificationError = 0.07480000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.0446887s
01/11/2018 08:57:57: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.43'

01/11/2018 08:57:57: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:57: Starting minibatch loop.
01/11/2018 08:57:57:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16129632 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0057s; samplesPerSecond = 223047.0
01/11/2018 08:57:57:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15699940 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0055s; samplesPerSecond = 233909.6
01/11/2018 08:57:57:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.12957487 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0054s; samplesPerSecond = 238095.2
01/11/2018 08:57:58:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15337787 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0055s; samplesPerSecond = 234234.9
01/11/2018 08:57:58:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15539284 * 1280; EvalClassificationError = 0.08125000 * 1280; time = 0.0057s; samplesPerSecond = 225225.2
01/11/2018 08:57:58:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13564787 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0056s; samplesPerSecond = 230091.7
01/11/2018 08:57:58:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16038342 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0055s; samplesPerSecond = 232964.5
01/11/2018 08:57:58: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.15072761 * 10000; EvalClassificationError = 0.07290000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.0447236s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.44'

01/11/2018 08:57:58: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:58: Starting minibatch loop.
01/11/2018 08:57:58:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15498720 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0055s; samplesPerSecond = 231783.3
01/11/2018 08:57:58:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13802453 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0055s; samplesPerSecond = 232245.9
01/11/2018 08:57:58:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15443432 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0061s; samplesPerSecond = 211015.7
01/11/2018 08:57:58:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15640388 * 1280; EvalClassificationError = 0.08359375 * 1280; time = 0.0055s; samplesPerSecond = 231875.7
01/11/2018 08:57:58:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14921451 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0056s; samplesPerSecond = 229419.5
01/11/2018 08:57:58:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13979187 * 1280; EvalClassificationError = 0.06796875 * 1280; time = 0.0055s; samplesPerSecond = 232254.3
01/11/2018 08:57:58:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15376129 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0055s; samplesPerSecond = 233155.4
01/11/2018 08:57:58: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.14844467 * 10000; EvalClassificationError = 0.07350000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.0451756s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.45'

01/11/2018 08:57:58: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:58: Starting minibatch loop.
01/11/2018 08:57:58:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12914503 * 1280; EvalClassificationError = 0.05937500 * 1280; time = 0.0057s; samplesPerSecond = 222883.9
01/11/2018 08:57:58:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16663969 * 1280; EvalClassificationError = 0.07890625 * 1280; time = 0.0055s; samplesPerSecond = 232010.2
01/11/2018 08:57:58:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15111256 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0055s; samplesPerSecond = 230701.3
01/11/2018 08:57:58:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14401226 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0055s; samplesPerSecond = 232435.7
01/11/2018 08:57:58:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15081224 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0055s; samplesPerSecond = 230988.6
01/11/2018 08:57:58:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15450358 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0055s; samplesPerSecond = 232727.3
01/11/2018 08:57:58:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14936523 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0053s; samplesPerSecond = 240438.8
01/11/2018 08:57:58: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14963163 * 10000; EvalClassificationError = 0.07190000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.0455241s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.46'

01/11/2018 08:57:58: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:58: Starting minibatch loop.
01/11/2018 08:57:58:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15209539 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0058s; samplesPerSecond = 222295.5
01/11/2018 08:57:58:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15731974 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0057s; samplesPerSecond = 222942.1
01/11/2018 08:57:58:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16360829 * 1280; EvalClassificationError = 0.08828125 * 1280; time = 0.0055s; samplesPerSecond = 230938.5
01/11/2018 08:57:58:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11951685 * 1280; EvalClassificationError = 0.05781250 * 1280; time = 0.0054s; samplesPerSecond = 238694.6
01/11/2018 08:57:58:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13802252 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0056s; samplesPerSecond = 230087.5
01/11/2018 08:57:58:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15337820 * 1280; EvalClassificationError = 0.07343750 * 1280; time = 0.0055s; samplesPerSecond = 231226.4
01/11/2018 08:57:58:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14004879 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0055s; samplesPerSecond = 232212.2
01/11/2018 08:57:58: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14584675 * 10000; EvalClassificationError = 0.07130000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.0451517s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.47'

01/11/2018 08:57:58: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:58: Starting minibatch loop.
01/11/2018 08:57:58:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15177681 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0057s; samplesPerSecond = 223144.2
01/11/2018 08:57:58:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15497117 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0054s; samplesPerSecond = 236795.9
01/11/2018 08:57:58:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15238912 * 1280; EvalClassificationError = 0.07656250 * 1280; time = 0.0056s; samplesPerSecond = 230485.3
01/11/2018 08:57:58:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14401383 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0056s; samplesPerSecond = 230518.5
01/11/2018 08:57:58:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14763846 * 1280; EvalClassificationError = 0.07421875 * 1280; time = 0.0056s; samplesPerSecond = 230120.6
01/11/2018 08:57:58:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14290242 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0055s; samplesPerSecond = 230901.1
01/11/2018 08:57:58:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13556471 * 1280; EvalClassificationError = 0.06718750 * 1280; time = 0.0055s; samplesPerSecond = 232380.8
01/11/2018 08:57:58: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14651746 * 10000; EvalClassificationError = 0.07240000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.0447939s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.48'

01/11/2018 08:57:58: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:58: Starting minibatch loop.
01/11/2018 08:57:58:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16257586 * 1280; EvalClassificationError = 0.08046875 * 1280; time = 0.0057s; samplesPerSecond = 223054.8
01/11/2018 08:57:58:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13693576 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0055s; samplesPerSecond = 231151.2
01/11/2018 08:57:58:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15928183 * 1280; EvalClassificationError = 0.07500000 * 1280; time = 0.0055s; samplesPerSecond = 231569.4
01/11/2018 08:57:58:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15061345 * 1280; EvalClassificationError = 0.06640625 * 1280; time = 0.0056s; samplesPerSecond = 229880.9
01/11/2018 08:57:58:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14774194 * 1280; EvalClassificationError = 0.06953125 * 1280; time = 0.0056s; samplesPerSecond = 227839.1
01/11/2018 08:57:58:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14288816 * 1280; EvalClassificationError = 0.06171875 * 1280; time = 0.0056s; samplesPerSecond = 230290.4
01/11/2018 08:57:58:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18438673 * 1280; EvalClassificationError = 0.08203125 * 1280; time = 0.0057s; samplesPerSecond = 225205.4
01/11/2018 08:57:58: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.15321768 * 10000; EvalClassificationError = 0.07010000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.045215s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.49'

01/11/2018 08:57:58: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:58: Starting minibatch loop.
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14232208 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0058s; samplesPerSecond = 222430.8
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13767112 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0066s; samplesPerSecond = 192872.7
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14364009 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0056s; samplesPerSecond = 227345.4
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15275316 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0069s; samplesPerSecond = 185016.6
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13829746 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0057s; samplesPerSecond = 224313.5
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15360365 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0058s; samplesPerSecond = 220880.1
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15102768 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0056s; samplesPerSecond = 229345.5
01/11/2018 08:57:58: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14560978 * 10000; EvalClassificationError = 0.07280000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.0480007s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn'

01/11/2018 08:57:58: Action "train" complete.


01/11/2018 08:57:58: ##############################################################################
01/11/2018 08:57:58: #                                                                            #
01/11/2018 08:57:58: # Simple_Demo_Output command (write action)                                  #
01/11/2018 08:57:58: #                                                                            #
01/11/2018 08:57:58: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1]
	  W1*H1+B1 : [50 x 1 x *1]
	  W2*H1 : [2 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  HLast : [2 x 1 x *1]
	  MVNormalizedFeatures : [2 x *1]
	  W0*features+B0 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] }

Here are the ones that don't share memory:
	{B2 : [2 x 1]}
	{B1 : [50 x 1]}
	{B0 : [50 x 1]}
	{MeanOfFeatures : [2]}
	{LogOfPrior : [2]}
	{W2 : [2 x 50]}
	{W0 : [50 x 2]}
	{Prior : [2]}
	{W1 : [50 x 50]}
	{labels : [2 x *1]}
	{InvStdOfFeatures : [2]}
	{ScaledLogLikelihood : [2 x 1 x *1]}
	{features : [2 x *1]}

Minibatch[0]: ActualMBSize = 603
Written to C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

01/11/2018 08:57:58: Action "write" complete.

01/11/2018 08:57:58: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu DeviceId=-1 timestamping=true forceDeterministicAlgorithms=true makeMode=true
CNTK 2.3.1+ (HEAD db192c, Jan 10 2018 22:59:43) at 2018/01/11 08:57:58

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  forceDeterministicAlgorithms=true  makeMode=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
-------------------------------------------------------------------
Build info: 

		Built time: Jan 10 2018 22:47:38
		Last modified date: Wed Jan 10 22:18:32 2018
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		With ASGD: yes
		Math lib: mkl
		CUDA version: 9.0.0
		CUDNN version: 7.0.5
		Build Branch: HEAD
		Build SHA1: db192cd3cb9ac688cae719c41e5930a4e3f628ea
		MPI distribution: Microsoft MPI
		MPI version: 7.0.12437.6
-------------------------------------------------------------------
-------------------------------------------------------------------
GPU info:

		Device[0]: cores = 3072; computeCapability = 5.2; type = "Tesla M60"; total memory = 8124 MB; free memory = 8001 MB
-------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:forceDeterministicAlgorithms=true
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ClassificationError
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
01/11/2018 08:57:58: Commands: Simple_Demo Simple_Demo_Output
01/11/2018 08:57:58: precision = "float"
01/11/2018 08:57:58: WARNING: forceDeterministicAlgorithms flag is specified. Using 1 CPU thread for processing.

01/11/2018 08:57:58: ##############################################################################
01/11/2018 08:57:58: #                                                                            #
01/11/2018 08:57:58: # Simple_Demo command (train action)                                         #
01/11/2018 08:57:58: #                                                                            #
01/11/2018 08:57:58: ##############################################################################

01/11/2018 08:57:58: 
Starting from checkpoint. Loading network from 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn.49'.
SimpleNetworkBuilder Using CPU
01/11/2018 08:57:58: 
Model has 25 nodes. Using CPU.

01/11/2018 08:57:58: Training criterion:   CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
01/11/2018 08:57:58: Evaluation criterion: EvalClassificationError = ClassificationError

01/11/2018 08:57:58: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

01/11/2018 08:57:58: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
01/11/2018 08:57:58: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
01/11/2018 08:57:58: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
01/11/2018 08:57:58: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
01/11/2018 08:57:58: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
01/11/2018 08:57:58: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

01/11/2018 08:57:58: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

01/11/2018 08:57:58: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

01/11/2018 08:57:58: Starting minibatch loop.
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.14232208 * 1280; EvalClassificationError = 0.06875000 * 1280; time = 0.0161s; samplesPerSecond = 79652.0
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.13767112 * 1280; EvalClassificationError = 0.07187500 * 1280; time = 0.0052s; samplesPerSecond = 244994.8
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.14364009 * 1280; EvalClassificationError = 0.07031250 * 1280; time = 0.0054s; samplesPerSecond = 236027.4
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.15275316 * 1280; EvalClassificationError = 0.07812500 * 1280; time = 0.0052s; samplesPerSecond = 244349.4
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.13829746 * 1280; EvalClassificationError = 0.06484375 * 1280; time = 0.0052s; samplesPerSecond = 245917.4
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.15360365 * 1280; EvalClassificationError = 0.07578125 * 1280; time = 0.0052s; samplesPerSecond = 244419.4
01/11/2018 08:57:58:  Epoch[50 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.15102768 * 1280; EvalClassificationError = 0.07265625 * 1280; time = 0.0052s; samplesPerSecond = 247970.7
01/11/2018 08:57:58: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14560978 * 10000; EvalClassificationError = 0.07280000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.053394s
01/11/2018 08:57:58: SGD: Saving checkpoint model 'C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/models/simple.dnn'

01/11/2018 08:57:58: Action "train" complete.


01/11/2018 08:57:58: ##############################################################################
01/11/2018 08:57:58: #                                                                            #
01/11/2018 08:57:58: # Simple_Demo_Output command (write action)                                  #
01/11/2018 08:57:58: #                                                                            #
01/11/2018 08:57:58: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalClassificationError = ClassificationError()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalClassificationError = ClassificationError (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 12 are shared as 3, and 13 are not shared.

Here are the ones that share memory:
	{ CrossEntropyWithSoftmax : [1]
	  EvalClassificationError : [1]
	  PosteriorProb : [2 x 1 x *2] }
	{ H2 : [50 x 1 x *2]
	  HLast : [2 x 1 x *2]
	  MVNormalizedFeatures : [2 x *2]
	  W0*features+B0 : [50 x 1 x *2]
	  W1*H1 : [50 x 1 x *2] }
	{ H1 : [50 x 1 x *2]
	  W0*features : [50 x *2]
	  W1*H1+B1 : [50 x 1 x *2]
	  W2*H1 : [2 x 1 x *2] }

Here are the ones that don't share memory:
	{B1 : [50 x 1]}
	{B0 : [50 x 1]}
	{B2 : [2 x 1]}
	{ScaledLogLikelihood : [2 x 1 x *2]}
	{InvStdOfFeatures : [2]}
	{labels : [2 x *2]}
	{LogOfPrior : [2]}
	{MeanOfFeatures : [2]}
	{features : [2 x *2]}
	{W2 : [2 x 50]}
	{W1 : [50 x 50]}
	{W0 : [50 x 2]}
	{Prior : [2]}

Minibatch[0]: ActualMBSize = 603
Written to C:\local\cygwin-2.8.2-x64\tmp\cntk-test-20180111085400.505371\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

01/11/2018 08:57:58: Action "write" complete.

01/11/2018 08:57:58: __COMPLETED__