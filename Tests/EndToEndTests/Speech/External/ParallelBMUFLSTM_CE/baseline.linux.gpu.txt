CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
+ [[ -d /home/philly/data/CNTKTestData ]]
+ '[' '' == Windows_NT ']'
+ ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE
+ [[ -d /home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE ]]
+ LogFileName=stderr
+ Instances=3
++ threadsPerInstance 3
+++ nproc
++ local threads=8
++ [[ 8 -eq 0 ]]
++ echo 8
+ NumCPUThreads=8
+ cntkmpirun '-n 3' cntk.cntk 'numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]'
+ '[' '' == Windows_NT ']'
+ MPIMode=1
+ MPIArgs='-n 3'
+ cntkrun cntk.cntk 'numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]'
+ configFileName=cntk.cntk
+ additionalCNTKArgs='numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]'
+ '[' '' == Windows_NT ']'
+ CNTKArgs='configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DeviceId=0 timestamping=true numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]'
+ '[' stderr '!=' '' ']'
+ CNTKArgs='configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DeviceId=0 timestamping=true numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr'
+ modelsDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/Models
+ [[ 1 == 1 ]]
+ '[' -d /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/Models ']'
+ mkdir -p /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/Models
+ [[ 1 == 0 ]]
+ run mpiexec -n 3 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DeviceId=0 timestamping=true numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE 'speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]' stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
+ cmd=mpiexec
+ shift
+ '[' '' == 1 ']'
+ echo === Running mpiexec -n 3 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DeviceId=0 timestamping=true numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE 'speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]' stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
=== Running mpiexec -n 3 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DeviceId=0 timestamping=true numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
+ mpiexec -n 3 /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu DeviceId=0 timestamping=true numCPUThreads=8 ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE 'speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]' stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
CNTK 2.0.beta2.0+ (HEAD 36d742, Nov  8 2016 20:05:18) on localhost at 2016/11/08 20:14:45

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=8  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
CNTK 2.0.beta2.0+ (HEAD 36d742, Nov  8 2016 20:05:18) on localhost at 2016/11/08 20:14:45

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=8  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
CNTK 2.0.beta2.0+ (HEAD 36d742, Nov  8 2016 20:05:18) on localhost at 2016/11/08 20:14:45

/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=8  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
11/08/2016 20:14:47: Redirecting stderr to file /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr_speechTrain.logrank0
11/08/2016 20:14:48: Redirecting stderr to file /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr_speechTrain.logrank1
11/08/2016 20:14:48: Redirecting stderr to file /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr_speechTrain.logrank2
+ return 0
+ local ExitCode=0
+ [[ 1 == 1 ]]
+ '[' -d /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/Models ']'
+ rm -rf /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/Models
+ return 0
+ return 0
+ [[ -d /home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE ]]
+ ExitCode=0
+ sed 's/^/MPI Rank 0: /' /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr_speechTrain.logrank0
MPI Rank 0: CNTK 2.0.beta2.0+ (HEAD 36d742, Nov  8 2016 20:05:18) on localhost at 2016/11/08 20:14:45
MPI Rank 0: 
MPI Rank 0: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=8  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
MPI Rank 0: 11/08/2016 20:14:47: Using 8 CPU threads.
MPI Rank 0: 
MPI Rank 0: 11/08/2016 20:14:47: ##############################################################################
MPI Rank 0: 11/08/2016 20:14:47: #                                                                            #
MPI Rank 0: 11/08/2016 20:14:47: # speechTrain command (train action)                                         #
MPI Rank 0: 11/08/2016 20:14:47: #                                                                            #
MPI Rank 0: 11/08/2016 20:14:47: ##############################################################################
MPI Rank 0: 
MPI Rank 0: WARNING: option syncPeroid in BlockMomentumSGD is going to be deprecated. Please use blockSizePerWorker instead in the future.
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 11/08/2016 20:14:47: 
MPI Rank 0: Model has 82 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 11/08/2016 20:14:47: Training criterion:   cr = CrossEntropyWithSoftmax
MPI Rank 0: 11/08/2016 20:14:47: Evaluation criterion: Err = ClassificationError
MPI Rank 0: 
MPI Rank 0: 11/08/2016 20:14:47: Training 2619524 parameters in 20 parameter tensors.
MPI Rank 0: 
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 11/08/2016 20:14:53: Finished Epoch[ 1 of 3]: [Training] cr = 4.61989670 * 20480; Err = 0.87758789 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.00050000002; epochTime=4.56141s
MPI Rank 0: Parallel training (3 workers) using BlockMomentumSGD with block momentum = 0.6667, block momentum time constant (per worker) = 295956.4155, block learning rate = 1.0000, block size per worker = 120000 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.21 seconds since last report (0.01 seconds on comm.); 20480 samples processed by 3 workers (8149 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 16.93k samplesPerSecond , throughputPerWorker = 5.64k samplesPerSecond
MPI Rank 0: 11/08/2016 20:14:54: Finished Epoch[ 2 of 3]: [Training] cr = 3.98514175 * 20480; Err = 0.86894531 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.00050000002; epochTime=1.20983s
MPI Rank 0: Parallel training (3 workers) using BlockMomentumSGD with block momentum = 0.6667, block momentum time constant (per worker) = 295956.4155, block learning rate = 1.0000, block size per worker = 120000 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.64 seconds since last report (0.01 seconds on comm.); 20480 samples processed by 3 workers (7769 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 31.88k samplesPerSecond , throughputPerWorker = 10.63k samplesPerSecond
MPI Rank 0: 11/08/2016 20:14:55: Finished Epoch[ 3 of 3]: [Training] cr = 3.79299145 * 20480; Err = 0.87036133 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 0.00050000002; epochTime=0.642816s
MPI Rank 0: 
MPI Rank 0: 11/08/2016 20:14:56: __COMPLETED__
+ sed 's/^/MPI Rank 1: /' /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr_speechTrain.logrank1
MPI Rank 1: CNTK 2.0.beta2.0+ (HEAD 36d742, Nov  8 2016 20:05:18) on localhost at 2016/11/08 20:14:45
MPI Rank 1: 
MPI Rank 1: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=8  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
MPI Rank 1: 11/08/2016 20:14:48: Using 8 CPU threads.
MPI Rank 1: 
MPI Rank 1: 11/08/2016 20:14:48: ##############################################################################
MPI Rank 1: 11/08/2016 20:14:48: #                                                                            #
MPI Rank 1: 11/08/2016 20:14:48: # speechTrain command (train action)                                         #
MPI Rank 1: 11/08/2016 20:14:48: #                                                                            #
MPI Rank 1: 11/08/2016 20:14:48: ##############################################################################
MPI Rank 1: 
MPI Rank 1: WARNING: option syncPeroid in BlockMomentumSGD is going to be deprecated. Please use blockSizePerWorker instead in the future.
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 11/08/2016 20:14:48: 
MPI Rank 1: Model has 82 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 11/08/2016 20:14:48: Training criterion:   cr = CrossEntropyWithSoftmax
MPI Rank 1: 11/08/2016 20:14:48: Evaluation criterion: Err = ClassificationError
MPI Rank 1: 
MPI Rank 1: 11/08/2016 20:14:48: Training 2619524 parameters in 20 parameter tensors.
MPI Rank 1: 
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 11/08/2016 20:14:53: Finished Epoch[ 1 of 3]: [Training] cr = 4.61989670 * 20480; Err = 0.87758789 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.00050000002; epochTime=4.50628s
MPI Rank 1: Parallel training (3 workers) using BlockMomentumSGD with block momentum = 0.6667, block momentum time constant (per worker) = 295956.4155, block learning rate = 1.0000, block size per worker = 120000 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.21 seconds since last report (0.01 seconds on comm.); 20480 samples processed by 3 workers (7332 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 16.94k samplesPerSecond , throughputPerWorker = 5.65k samplesPerSecond
MPI Rank 1: 11/08/2016 20:14:54: Finished Epoch[ 2 of 3]: [Training] cr = 3.98514175 * 20480; Err = 0.86894531 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.00050000002; epochTime=1.20961s
MPI Rank 1: Parallel training (3 workers) using BlockMomentumSGD with block momentum = 0.6667, block momentum time constant (per worker) = 295956.4155, block learning rate = 1.0000, block size per worker = 120000 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.07-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.07 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.64 seconds since last report (0.01 seconds on comm.); 20480 samples processed by 3 workers (7561 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 31.87k samplesPerSecond , throughputPerWorker = 10.62k samplesPerSecond
MPI Rank 1: 11/08/2016 20:14:55: Finished Epoch[ 3 of 3]: [Training] cr = 3.79299145 * 20480; Err = 0.87036133 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 0.00050000002; epochTime=0.642956s
MPI Rank 1: 
MPI Rank 1: 11/08/2016 20:14:56: __COMPLETED__
+ sed 's/^/MPI Rank 2: /' /tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr_speechTrain.logrank2
MPI Rank 2: CNTK 2.0.beta2.0+ (HEAD 36d742, Nov  8 2016 20:05:18) on localhost at 2016/11/08 20:14:45
MPI Rank 2: 
MPI Rank 2: /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/1bitsgd/release/bin/cntk  configFile=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  OutputDir=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=8  ConfigDir=/home/philly/data/CNTKTestData/Speech/Models/BMUF_LSTM_CE  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=/tmp/cntk-test-20161108201317.493630/Speech/External_ParallelBMUFLSTM_CE@release_gpu/stderr
MPI Rank 2: 11/08/2016 20:14:48: Using 8 CPU threads.
MPI Rank 2: 
MPI Rank 2: 11/08/2016 20:14:48: ##############################################################################
MPI Rank 2: 11/08/2016 20:14:48: #                                                                            #
MPI Rank 2: 11/08/2016 20:14:48: # speechTrain command (train action)                                         #
MPI Rank 2: 11/08/2016 20:14:48: #                                                                            #
MPI Rank 2: 11/08/2016 20:14:48: ##############################################################################
MPI Rank 2: 
MPI Rank 2: WARNING: option syncPeroid in BlockMomentumSGD is going to be deprecated. Please use blockSizePerWorker instead in the future.
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: reading script file glob_0000.scp ... 948 entries
MPI Rank 2: total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/state.list
MPI Rank 2: htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
MPI Rank 2: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 2: label set 0: 129 classes
MPI Rank 2: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 2: 11/08/2016 20:14:48: 
MPI Rank 2: Model has 82 nodes. Using GPU 0.
MPI Rank 2: 
MPI Rank 2: 11/08/2016 20:14:48: Training criterion:   cr = CrossEntropyWithSoftmax
MPI Rank 2: 11/08/2016 20:14:48: Evaluation criterion: Err = ClassificationError
MPI Rank 2: 
MPI Rank 2: 11/08/2016 20:14:48: Training 2619524 parameters in 20 parameter tensors.
MPI Rank 2: 
MPI Rank 2: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 2: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 2: 11/08/2016 20:14:53: Finished Epoch[ 1 of 3]: [Training] cr = 4.61989670 * 20480; Err = 0.87758789 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.00050000002; epochTime=4.56936s
MPI Rank 2: Parallel training (3 workers) using BlockMomentumSGD with block momentum = 0.6667, block momentum time constant (per worker) = 295956.4155, block learning rate = 1.0000, block size per worker = 120000 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 2: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.19-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.19 seconds
MPI Rank 2: 		(model aggregation stats) 1-th sync:     1.21 seconds since last report (0.01 seconds on comm.); 20480 samples processed by 3 workers (4999 by me);
MPI Rank 2: 		(model aggregation stats) 1-th sync: totalThroughput = 16.93k samplesPerSecond , throughputPerWorker = 5.64k samplesPerSecond
MPI Rank 2: 11/08/2016 20:14:54: Finished Epoch[ 2 of 3]: [Training] cr = 3.98514175 * 20480; Err = 0.86894531 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.00050000002; epochTime=1.2097s
MPI Rank 2: Parallel training (3 workers) using BlockMomentumSGD with block momentum = 0.6667, block momentum time constant (per worker) = 295956.4155, block learning rate = 1.0000, block size per worker = 120000 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 2: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats) 1-th sync:     0.64 seconds since last report (0.01 seconds on comm.); 20480 samples processed by 3 workers (5150 by me);
MPI Rank 2: 		(model aggregation stats) 1-th sync: totalThroughput = 31.88k samplesPerSecond , throughputPerWorker = 10.63k samplesPerSecond
MPI Rank 2: 11/08/2016 20:14:55: Finished Epoch[ 3 of 3]: [Training] cr = 3.79299145 * 20480; Err = 0.87036133 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 0.00050000002; epochTime=0.642736s
MPI Rank 2: 
MPI Rank 2: 11/08/2016 20:14:56: __COMPLETED__
+ exit 0