CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on dphaim-26-new at 2016/12/15 08:27:41

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
12/15/2016 08:27:43: -------------------------------------------------------------------
12/15/2016 08:27:43: Build info: 

12/15/2016 08:27:43: 		Built time: Dec 15 2016 06:29:34
12/15/2016 08:27:43: 		Last modified date: Wed Dec 14 12:53:20 2016
12/15/2016 08:27:43: 		Build type: Release
12/15/2016 08:27:43: 		Build target: GPU
12/15/2016 08:27:43: 		With ASGD: yes
12/15/2016 08:27:43: 		Math lib: mkl
12/15/2016 08:27:43: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
12/15/2016 08:27:43: 		CUB_PATH: c:\src\cub-1.4.1
12/15/2016 08:27:43: 		CUDNN_PATH: C:\local\cudnn-8.0-windows10-x64-v5.1
12/15/2016 08:27:43: 		Build Branch: HEAD
12/15/2016 08:27:43: 		Build SHA1: 5f1fabfe95e68af0787193f8849159f824d914d5 (modified)
12/15/2016 08:27:43: 		Built by svcphil on liana-08-w
12/15/2016 08:27:43: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
12/15/2016 08:27:43: -------------------------------------------------------------------
12/15/2016 08:27:46: -------------------------------------------------------------------
12/15/2016 08:27:46: GPU info:

12/15/2016 08:27:46: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:27:46: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:27:46: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:27:46: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
12/15/2016 08:27:46: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:precision=float
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
        labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
12/15/2016 08:27:46: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
12/15/2016 08:27:46: precision = "float"

12/15/2016 08:27:46: ##############################################################################
12/15/2016 08:27:46: #                                                                            #
12/15/2016 08:27:46: # dptPre1 command (train action)                                             #
12/15/2016 08:27:46: #                                                                            #
12/15/2016 08:27:46: ##############################################################################

12/15/2016 08:27:46: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/15/2016 08:27:47: 
Model has 19 nodes. Using GPU 0.

12/15/2016 08:27:47: Training criterion:   ce = CrossEntropyWithSoftmax
12/15/2016 08:27:47: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }


12/15/2016 08:27:47: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

12/15/2016 08:27:47: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/15/2016 08:27:47: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:27:47: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/15/2016 08:27:47: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/15/2016 08:27:47: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/15/2016 08:27:47: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/15/2016 08:27:47: Starting minibatch loop.
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.77545433 * 2560; err = 0.83984375 * 2560; time = 0.4511s; samplesPerSecond = 5675.0
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.92129173 * 2560; err = 0.69921875 * 2560; time = 0.0301s; samplesPerSecond = 85024.4
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.54243622 * 2560; err = 0.64882812 * 2560; time = 0.0299s; samplesPerSecond = 85492.9
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.20117416 * 2560; err = 0.60156250 * 2560; time = 0.0299s; samplesPerSecond = 85701.9
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.98474121 * 2560; err = 0.55273438 * 2560; time = 0.0300s; samplesPerSecond = 85341.9
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87129364 * 2560; err = 0.51562500 * 2560; time = 0.0300s; samplesPerSecond = 85214.0
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.83400879 * 2560; err = 0.52812500 * 2560; time = 0.0300s; samplesPerSecond = 85322.0
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71646271 * 2560; err = 0.49335937 * 2560; time = 0.0299s; samplesPerSecond = 85658.8
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66541901 * 2560; err = 0.46328125 * 2560; time = 0.0299s; samplesPerSecond = 85615.9
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.57725983 * 2560; err = 0.46054688 * 2560; time = 0.0299s; samplesPerSecond = 85570.1
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.61621094 * 2560; err = 0.45390625 * 2560; time = 0.0288s; samplesPerSecond = 88864.2
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.56063995 * 2560; err = 0.44140625 * 2560; time = 0.0263s; samplesPerSecond = 97490.4
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.52853241 * 2560; err = 0.44492188 * 2560; time = 0.0262s; samplesPerSecond = 97542.4
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53460999 * 2560; err = 0.46210937 * 2560; time = 0.0264s; samplesPerSecond = 97017.5
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46377869 * 2560; err = 0.44140625 * 2560; time = 0.0263s; samplesPerSecond = 97290.3
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43344116 * 2560; err = 0.42617187 * 2560; time = 0.0264s; samplesPerSecond = 96984.4
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.43215027 * 2560; err = 0.42148438 * 2560; time = 0.0263s; samplesPerSecond = 97257.0
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.37987366 * 2560; err = 0.41250000 * 2560; time = 0.0262s; samplesPerSecond = 97557.3
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35841980 * 2560; err = 0.40039063 * 2560; time = 0.0263s; samplesPerSecond = 97375.4
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.44842224 * 2560; err = 0.42656250 * 2560; time = 0.0263s; samplesPerSecond = 97520.1
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.43927917 * 2560; err = 0.42539063 * 2560; time = 0.0262s; samplesPerSecond = 97572.1
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.41734009 * 2560; err = 0.42539063 * 2560; time = 0.0263s; samplesPerSecond = 97423.6
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.33211670 * 2560; err = 0.40468750 * 2560; time = 0.0238s; samplesPerSecond = 107730.5
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36109009 * 2560; err = 0.40429688 * 2560; time = 0.0235s; samplesPerSecond = 109145.2
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.30958252 * 2560; err = 0.39804688 * 2560; time = 0.0235s; samplesPerSecond = 108760.3
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25348511 * 2560; err = 0.36992188 * 2560; time = 0.0237s; samplesPerSecond = 107921.3
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.30338745 * 2560; err = 0.39570312 * 2560; time = 0.0237s; samplesPerSecond = 107794.0
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36117859 * 2560; err = 0.40859375 * 2560; time = 0.0237s; samplesPerSecond = 108158.4
12/15/2016 08:27:48:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.29568787 * 2560; err = 0.39531250 * 2560; time = 0.0236s; samplesPerSecond = 108281.9
12/15/2016 08:27:49:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.35455017 * 2560; err = 0.40859375 * 2560; time = 0.0236s; samplesPerSecond = 108281.9
12/15/2016 08:27:49:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.32246399 * 2560; err = 0.39921875 * 2560; time = 0.0236s; samplesPerSecond = 108437.8
12/15/2016 08:27:49:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.27023926 * 2560; err = 0.38242188 * 2560; time = 0.0229s; samplesPerSecond = 111649.0
12/15/2016 08:27:49: Finished Epoch[ 1 of 2]: [Training] ce = 1.65206318 * 81920; err = 0.46723633 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=1.63098s
12/15/2016 08:27:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech.1'

12/15/2016 08:27:49: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/15/2016 08:27:49: Starting minibatch loop.
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.24553871 * 2560; err = 0.38984375 * 2560; time = 0.0256s; samplesPerSecond = 100117.3
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23801517 * 2560; err = 0.36718750 * 2560; time = 0.0236s; samplesPerSecond = 108313.9
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.26358624 * 2560; err = 0.39218750 * 2560; time = 0.0236s; samplesPerSecond = 108295.6
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.26325531 * 2560; err = 0.38203125 * 2560; time = 0.0236s; samplesPerSecond = 108447.0
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.27975998 * 2560; err = 0.36562500 * 2560; time = 0.0222s; samplesPerSecond = 115539.1
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18315849 * 2560; err = 0.35195312 * 2560; time = 0.0214s; samplesPerSecond = 119670.9
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.19740906 * 2560; err = 0.37070313 * 2560; time = 0.0214s; samplesPerSecond = 119749.3
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.23275757 * 2560; err = 0.36835937 * 2560; time = 0.0214s; samplesPerSecond = 119615.0
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.27090912 * 2560; err = 0.38945313 * 2560; time = 0.0213s; samplesPerSecond = 120176.5
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.25143051 * 2560; err = 0.37500000 * 2560; time = 0.0214s; samplesPerSecond = 119754.9
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.21462936 * 2560; err = 0.37187500 * 2560; time = 0.0214s; samplesPerSecond = 119648.5
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19433441 * 2560; err = 0.36796875 * 2560; time = 0.0215s; samplesPerSecond = 118992.3
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.16462097 * 2560; err = 0.36171875 * 2560; time = 0.0213s; samplesPerSecond = 120069.4
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16609802 * 2560; err = 0.36484375 * 2560; time = 0.0215s; samplesPerSecond = 119219.5
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.14834595 * 2560; err = 0.34492187 * 2560; time = 0.0214s; samplesPerSecond = 119553.5
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.11703033 * 2560; err = 0.34804687 * 2560; time = 0.0215s; samplesPerSecond = 119286.1
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.17735901 * 2560; err = 0.35703125 * 2560; time = 0.0214s; samplesPerSecond = 119531.2
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13435669 * 2560; err = 0.35664062 * 2560; time = 0.0215s; samplesPerSecond = 119086.4
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14561310 * 2560; err = 0.35039063 * 2560; time = 0.0203s; samplesPerSecond = 126257.6
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11020966 * 2560; err = 0.33281250 * 2560; time = 0.0194s; samplesPerSecond = 132217.7
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.16456146 * 2560; err = 0.35078125 * 2560; time = 0.0192s; samplesPerSecond = 133035.4
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.14552612 * 2560; err = 0.35742188 * 2560; time = 0.0194s; samplesPerSecond = 131727.9
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09541931 * 2560; err = 0.34492187 * 2560; time = 0.0196s; samplesPerSecond = 130712.3
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12883606 * 2560; err = 0.34218750 * 2560; time = 0.0196s; samplesPerSecond = 130565.6
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.08879089 * 2560; err = 0.33867188 * 2560; time = 0.0196s; samplesPerSecond = 130452.5
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08555603 * 2560; err = 0.32695313 * 2560; time = 0.0196s; samplesPerSecond = 130605.6
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.12885132 * 2560; err = 0.34492187 * 2560; time = 0.0202s; samplesPerSecond = 126507.2
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.12917175 * 2560; err = 0.34921875 * 2560; time = 0.0199s; samplesPerSecond = 128443.1
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.12189331 * 2560; err = 0.34570313 * 2560; time = 0.0200s; samplesPerSecond = 128192.3
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08549500 * 2560; err = 0.32773438 * 2560; time = 0.0195s; samplesPerSecond = 130953.0
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08267212 * 2560; err = 0.34023437 * 2560; time = 0.0196s; samplesPerSecond = 130645.6
12/15/2016 08:27:49:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07620239 * 2560; err = 0.32578125 * 2560; time = 0.0192s; samplesPerSecond = 133083.8
12/15/2016 08:27:49: Finished Epoch[ 2 of 2]: [Training] ce = 1.16660604 * 81920; err = 0.35634766 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.675883s
12/15/2016 08:27:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech'

12/15/2016 08:27:49: Action "train" complete.


12/15/2016 08:27:49: ##############################################################################
12/15/2016 08:27:49: #                                                                            #
12/15/2016 08:27:49: # addLayer2 command (edit action)                                            #
12/15/2016 08:27:49: #                                                                            #
12/15/2016 08:27:49: ##############################################################################


12/15/2016 08:27:49: Action "edit" complete.


12/15/2016 08:27:49: ##############################################################################
12/15/2016 08:27:49: #                                                                            #
12/15/2016 08:27:49: # dptPre2 command (train action)                                             #
12/15/2016 08:27:49: #                                                                            #
12/15/2016 08:27:49: ##############################################################################

12/15/2016 08:27:49: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/15/2016 08:27:50: 
Model has 24 nodes. Using GPU 0.

12/15/2016 08:27:50: Training criterion:   ce = CrossEntropyWithSoftmax
12/15/2016 08:27:50: Evaluation criterion: err = ClassificationError

12/15/2016 08:27:50: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

12/15/2016 08:27:50: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/15/2016 08:27:50: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:27:50: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:27:50: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:27:50: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/15/2016 08:27:50: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/15/2016 08:27:50: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/15/2016 08:27:50: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/15/2016 08:27:50: Starting minibatch loop.
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.95234604 * 2560; err = 0.81796875 * 2560; time = 0.0354s; samplesPerSecond = 72351.1
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.60234756 * 2560; err = 0.63789063 * 2560; time = 0.0264s; samplesPerSecond = 96793.7
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.15345764 * 2560; err = 0.57734375 * 2560; time = 0.0264s; samplesPerSecond = 96966.0
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.80804749 * 2560; err = 0.50703125 * 2560; time = 0.0263s; samplesPerSecond = 97216.4
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.62714386 * 2560; err = 0.47343750 * 2560; time = 0.0265s; samplesPerSecond = 96636.6
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.58302765 * 2560; err = 0.45625000 * 2560; time = 0.0263s; samplesPerSecond = 97275.5
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.57416840 * 2560; err = 0.46406250 * 2560; time = 0.0250s; samplesPerSecond = 102449.2
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.49049683 * 2560; err = 0.44609375 * 2560; time = 0.0241s; samplesPerSecond = 106356.5
12/15/2016 08:27:50:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.43992004 * 2560; err = 0.41835937 * 2560; time = 0.0241s; samplesPerSecond = 106039.3
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.39899445 * 2560; err = 0.41093750 * 2560; time = 0.0241s; samplesPerSecond = 106215.3
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41018677 * 2560; err = 0.40273437 * 2560; time = 0.0241s; samplesPerSecond = 106118.4
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.35843353 * 2560; err = 0.39804688 * 2560; time = 0.0242s; samplesPerSecond = 105798.2
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.32144775 * 2560; err = 0.39375000 * 2560; time = 0.0243s; samplesPerSecond = 105332.5
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.33142242 * 2560; err = 0.40546875 * 2560; time = 0.0242s; samplesPerSecond = 105741.4
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.27800903 * 2560; err = 0.37812500 * 2560; time = 0.0242s; samplesPerSecond = 105903.3
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28858032 * 2560; err = 0.39453125 * 2560; time = 0.0243s; samplesPerSecond = 105519.1
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.29140320 * 2560; err = 0.37968750 * 2560; time = 0.0242s; samplesPerSecond = 105920.8
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.27164612 * 2560; err = 0.39023438 * 2560; time = 0.0243s; samplesPerSecond = 105488.7
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29244080 * 2560; err = 0.38710937 * 2560; time = 0.0237s; samplesPerSecond = 107866.7
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32063599 * 2560; err = 0.39843750 * 2560; time = 0.0223s; samplesPerSecond = 114875.5
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.30206909 * 2560; err = 0.38476563 * 2560; time = 0.0223s; samplesPerSecond = 114844.6
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.31644287 * 2560; err = 0.39726563 * 2560; time = 0.0223s; samplesPerSecond = 114885.8
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.23897095 * 2560; err = 0.37187500 * 2560; time = 0.0223s; samplesPerSecond = 114890.9
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.26500854 * 2560; err = 0.38203125 * 2560; time = 0.0223s; samplesPerSecond = 114839.4
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.22773132 * 2560; err = 0.37265625 * 2560; time = 0.0223s; samplesPerSecond = 114829.1
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19237976 * 2560; err = 0.35507813 * 2560; time = 0.0222s; samplesPerSecond = 115144.2
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.20592957 * 2560; err = 0.36640625 * 2560; time = 0.0222s; samplesPerSecond = 115377.7
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.24901123 * 2560; err = 0.37304688 * 2560; time = 0.0223s; samplesPerSecond = 114860.0
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.17727051 * 2560; err = 0.34882812 * 2560; time = 0.0224s; samplesPerSecond = 114444.1
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.17915344 * 2560; err = 0.35585937 * 2560; time = 0.0222s; samplesPerSecond = 115299.7
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19775085 * 2560; err = 0.35703125 * 2560; time = 0.0224s; samplesPerSecond = 114536.3
12/15/2016 08:27:51:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.15687256 * 2560; err = 0.34179688 * 2560; time = 0.0218s; samplesPerSecond = 117657.9
12/15/2016 08:27:51: Finished Epoch[ 1 of 2]: [Training] ce = 1.48446083 * 81920; err = 0.42325439 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=1.00573s
12/15/2016 08:27:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.1'

12/15/2016 08:27:51: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/15/2016 08:27:51: Starting minibatch loop.
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.16664762 * 2560; err = 0.36015625 * 2560; time = 0.0328s; samplesPerSecond = 78020.2
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18870592 * 2560; err = 0.35781250 * 2560; time = 0.0370s; samplesPerSecond = 69202.3
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.16170998 * 2560; err = 0.35625000 * 2560; time = 0.0397s; samplesPerSecond = 64439.8
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.15019836 * 2560; err = 0.35468750 * 2560; time = 0.0346s; samplesPerSecond = 74039.8
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.19214973 * 2560; err = 0.34375000 * 2560; time = 0.0344s; samplesPerSecond = 74312.8
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.13505096 * 2560; err = 0.35156250 * 2560; time = 0.0345s; samplesPerSecond = 74164.2
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14320908 * 2560; err = 0.35351563 * 2560; time = 0.0345s; samplesPerSecond = 74125.6
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17766418 * 2560; err = 0.36562500 * 2560; time = 0.0344s; samplesPerSecond = 74349.4
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.17257156 * 2560; err = 0.35937500 * 2560; time = 0.0345s; samplesPerSecond = 74239.5
12/15/2016 08:27:51:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18593597 * 2560; err = 0.36171875 * 2560; time = 0.0345s; samplesPerSecond = 74271.8
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14419098 * 2560; err = 0.34921875 * 2560; time = 0.0345s; samplesPerSecond = 74295.5
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13939972 * 2560; err = 0.34453125 * 2560; time = 0.0333s; samplesPerSecond = 76913.8
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.10049133 * 2560; err = 0.34375000 * 2560; time = 0.0308s; samplesPerSecond = 83181.7
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.12730560 * 2560; err = 0.34609375 * 2560; time = 0.0307s; samplesPerSecond = 83507.3
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.09851990 * 2560; err = 0.33828125 * 2560; time = 0.0307s; samplesPerSecond = 83374.0
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.07665558 * 2560; err = 0.33906250 * 2560; time = 0.0308s; samplesPerSecond = 83011.8
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.12044830 * 2560; err = 0.33828125 * 2560; time = 0.0310s; samplesPerSecond = 82612.6
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.07696686 * 2560; err = 0.33203125 * 2560; time = 0.0309s; samplesPerSecond = 82751.5
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11485138 * 2560; err = 0.34687500 * 2560; time = 0.0309s; samplesPerSecond = 82802.3
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08272247 * 2560; err = 0.32343750 * 2560; time = 0.0309s; samplesPerSecond = 82885.4
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.12735596 * 2560; err = 0.33164063 * 2560; time = 0.0309s; samplesPerSecond = 82890.8
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09644012 * 2560; err = 0.33906250 * 2560; time = 0.0290s; samplesPerSecond = 88239.3
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.04909515 * 2560; err = 0.32617188 * 2560; time = 0.0278s; samplesPerSecond = 91937.5
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.09852905 * 2560; err = 0.33984375 * 2560; time = 0.0278s; samplesPerSecond = 92192.5
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.10007629 * 2560; err = 0.34218750 * 2560; time = 0.0277s; samplesPerSecond = 92322.1
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07532043 * 2560; err = 0.33085938 * 2560; time = 0.0277s; samplesPerSecond = 92338.8
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.10989685 * 2560; err = 0.34257813 * 2560; time = 0.0279s; samplesPerSecond = 91785.9
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.08709106 * 2560; err = 0.33593750 * 2560; time = 0.0277s; samplesPerSecond = 92268.9
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09781799 * 2560; err = 0.33789063 * 2560; time = 0.0278s; samplesPerSecond = 91970.5
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08734741 * 2560; err = 0.32304688 * 2560; time = 0.0279s; samplesPerSecond = 91874.8
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.07466431 * 2560; err = 0.32851562 * 2560; time = 0.0279s; samplesPerSecond = 91888.0
12/15/2016 08:27:52:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07492981 * 2560; err = 0.33671875 * 2560; time = 0.0270s; samplesPerSecond = 94702.6
12/15/2016 08:27:52: Finished Epoch[ 2 of 2]: [Training] ce = 1.11981125 * 81920; err = 0.34313965 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=1.00648s
12/15/2016 08:27:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech'

12/15/2016 08:27:52: Action "train" complete.


12/15/2016 08:27:52: ##############################################################################
12/15/2016 08:27:52: #                                                                            #
12/15/2016 08:27:52: # addLayer3 command (edit action)                                            #
12/15/2016 08:27:52: #                                                                            #
12/15/2016 08:27:52: ##############################################################################


12/15/2016 08:27:53: Action "edit" complete.


12/15/2016 08:27:53: ##############################################################################
12/15/2016 08:27:53: #                                                                            #
12/15/2016 08:27:53: # speechTrain command (train action)                                         #
12/15/2016 08:27:53: #                                                                            #
12/15/2016 08:27:53: ##############################################################################

12/15/2016 08:27:53: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
12/15/2016 08:27:53: 
Model has 29 nodes. Using GPU 0.

12/15/2016 08:27:53: Training criterion:   ce = CrossEntropyWithSoftmax
12/15/2016 08:27:53: Evaluation criterion: err = ClassificationError

12/15/2016 08:27:53: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

12/15/2016 08:27:53: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
12/15/2016 08:27:53: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:27:53: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:27:53: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:27:53: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
12/15/2016 08:27:53: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
12/15/2016 08:27:53: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
12/15/2016 08:27:53: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

12/15/2016 08:27:53: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

12/15/2016 08:27:53: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

12/15/2016 08:27:54: Starting minibatch loop.
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.04590569 * 2560; err = 0.84531250 * 2560; time = 0.0420s; samplesPerSecond = 61001.8
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.57098885 * 2560; err = 0.61679688 * 2560; time = 0.0307s; samplesPerSecond = 83311.6
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.05973740 * 2560; err = 0.56210938 * 2560; time = 0.0308s; samplesPerSecond = 83092.6
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.69117279 * 2560; err = 0.47187500 * 2560; time = 0.0308s; samplesPerSecond = 83111.5
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.51774445 * 2560; err = 0.44218750 * 2560; time = 0.0309s; samplesPerSecond = 82738.1
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.46015549 * 2560; err = 0.42109375 * 2560; time = 0.0307s; samplesPerSecond = 83276.4
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.46027374 * 2560; err = 0.42656250 * 2560; time = 0.0306s; samplesPerSecond = 83687.5
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.37528534 * 2560; err = 0.40507813 * 2560; time = 0.0289s; samplesPerSecond = 88704.1
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.33106689 * 2560; err = 0.38593750 * 2560; time = 0.0280s; samplesPerSecond = 91288.4
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.28873444 * 2560; err = 0.37773438 * 2560; time = 0.0281s; samplesPerSecond = 91132.4
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31904449 * 2560; err = 0.38242188 * 2560; time = 0.0280s; samplesPerSecond = 91582.3
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27923431 * 2560; err = 0.37070313 * 2560; time = 0.0281s; samplesPerSecond = 91038.4
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.24601440 * 2560; err = 0.37460938 * 2560; time = 0.0280s; samplesPerSecond = 91431.8
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.26049347 * 2560; err = 0.38242188 * 2560; time = 0.0280s; samplesPerSecond = 91412.2
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.20057983 * 2560; err = 0.35703125 * 2560; time = 0.0281s; samplesPerSecond = 91054.6
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.22241669 * 2560; err = 0.37070313 * 2560; time = 0.0281s; samplesPerSecond = 91087.0
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.21280518 * 2560; err = 0.36406250 * 2560; time = 0.0281s; samplesPerSecond = 91252.6
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20003662 * 2560; err = 0.36562500 * 2560; time = 0.0279s; samplesPerSecond = 91772.7
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21828003 * 2560; err = 0.37148437 * 2560; time = 0.0259s; samplesPerSecond = 99013.7
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.25399475 * 2560; err = 0.37812500 * 2560; time = 0.0259s; samplesPerSecond = 99013.7
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.24552917 * 2560; err = 0.36523438 * 2560; time = 0.0258s; samplesPerSecond = 99371.2
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.25040588 * 2560; err = 0.38789062 * 2560; time = 0.0258s; samplesPerSecond = 99382.7
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.18212585 * 2560; err = 0.35117188 * 2560; time = 0.0257s; samplesPerSecond = 99467.7
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21176453 * 2560; err = 0.37226562 * 2560; time = 0.0259s; samplesPerSecond = 98899.0
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17892761 * 2560; err = 0.35507813 * 2560; time = 0.0258s; samplesPerSecond = 99217.1
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.14774170 * 2560; err = 0.34453125 * 2560; time = 0.0258s; samplesPerSecond = 99375.0
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13611145 * 2560; err = 0.35507813 * 2560; time = 0.0263s; samplesPerSecond = 97408.8
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.19631958 * 2560; err = 0.36054687 * 2560; time = 0.0262s; samplesPerSecond = 97863.1
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.12956238 * 2560; err = 0.33593750 * 2560; time = 0.0260s; samplesPerSecond = 98461.5
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14312744 * 2560; err = 0.35000000 * 2560; time = 0.0249s; samplesPerSecond = 102654.6
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.15689087 * 2560; err = 0.34687500 * 2560; time = 0.0241s; samplesPerSecond = 106281.4
12/15/2016 08:27:54:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.11358643 * 2560; err = 0.34023437 * 2560; time = 0.0237s; samplesPerSecond = 108062.5
12/15/2016 08:27:54: Finished Epoch[ 1 of 4]: [Training] ce = 1.41581430 * 81920; err = 0.40427246 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=1.14401s
12/15/2016 08:27:54: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.1'

12/15/2016 08:27:54: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

12/15/2016 08:27:55: Starting minibatch loop.
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.21363411 * 5120; err = 0.37382813 * 5120; time = 0.0413s; samplesPerSecond = 124061.1
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.29641857 * 5120; err = 0.38437500 * 5120; time = 0.0302s; samplesPerSecond = 169345.8
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.16644230 * 5120; err = 0.35410156 * 5120; time = 0.0300s; samplesPerSecond = 170814.7
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.12385674 * 5120; err = 0.34394531 * 5120; time = 0.0298s; samplesPerSecond = 171794.8
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16217117 * 5120; err = 0.35527344 * 5120; time = 0.0303s; samplesPerSecond = 168765.2
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.15096054 * 5120; err = 0.34667969 * 5120; time = 0.0298s; samplesPerSecond = 171956.3
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.14951859 * 5120; err = 0.35722656 * 5120; time = 0.0300s; samplesPerSecond = 170700.8
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.12703094 * 5120; err = 0.35234375 * 5120; time = 0.0298s; samplesPerSecond = 171950.6
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.08262787 * 5120; err = 0.32871094 * 5120; time = 0.0298s; samplesPerSecond = 171985.2
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.09813309 * 5120; err = 0.34316406 * 5120; time = 0.0298s; samplesPerSecond = 171599.0
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.09296646 * 5120; err = 0.33066406 * 5120; time = 0.0303s; samplesPerSecond = 168826.5
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.06959076 * 5120; err = 0.33457031 * 5120; time = 0.0296s; samplesPerSecond = 173177.7
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.10550385 * 5120; err = 0.34003906 * 5120; time = 0.0296s; samplesPerSecond = 172751.2
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.17286682 * 5120; err = 0.35781250 * 5120; time = 0.0300s; samplesPerSecond = 170689.4
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.09042511 * 5120; err = 0.33437500 * 5120; time = 0.0299s; samplesPerSecond = 171501.3
12/15/2016 08:27:55:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.05333099 * 5120; err = 0.32109375 * 5120; time = 0.0293s; samplesPerSecond = 174881.3
12/15/2016 08:27:55: Finished Epoch[ 2 of 4]: [Training] ce = 1.13471737 * 81920; err = 0.34738770 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.492854s
12/15/2016 08:27:55: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.2'

12/15/2016 08:27:55: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

12/15/2016 08:27:55: Starting minibatch loop.
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.07283278 * 5120; err = 0.33144531 * 5120; time = 0.0310s; samplesPerSecond = 165006.9
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10864496 * 5120; err = 0.33847656 * 5120; time = 0.0296s; samplesPerSecond = 172780.3
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.09635391 * 5120; err = 0.34003906 * 5120; time = 0.0296s; samplesPerSecond = 172727.9
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.04911957 * 5120; err = 0.32265625 * 5120; time = 0.0295s; samplesPerSecond = 173606.4
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07482147 * 5120; err = 0.32617188 * 5120; time = 0.0296s; samplesPerSecond = 172961.3
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.08483620 * 5120; err = 0.33300781 * 5120; time = 0.0296s; samplesPerSecond = 172885.4
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.07054214 * 5120; err = 0.33359375 * 5120; time = 0.0296s; samplesPerSecond = 172704.6
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.08102493 * 5120; err = 0.33828125 * 5120; time = 0.0296s; samplesPerSecond = 172990.5
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.09007339 * 5120; err = 0.34667969 * 5120; time = 0.0296s; samplesPerSecond = 173154.3
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.01481857 * 5120; err = 0.31113281 * 5120; time = 0.0296s; samplesPerSecond = 173002.2
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03558655 * 5120; err = 0.32617188 * 5120; time = 0.0296s; samplesPerSecond = 172762.9
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.06111603 * 5120; err = 0.32792969 * 5120; time = 0.0296s; samplesPerSecond = 172885.4
12/15/2016 08:27:55:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.07036591 * 5120; err = 0.33632812 * 5120; time = 0.0298s; samplesPerSecond = 171679.6
12/15/2016 08:27:56:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.09597321 * 5120; err = 0.34609375 * 5120; time = 0.0298s; samplesPerSecond = 171708.4
12/15/2016 08:27:56:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.01984863 * 5120; err = 0.31386719 * 5120; time = 0.0297s; samplesPerSecond = 172454.4
12/15/2016 08:27:56:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.03527679 * 5120; err = 0.33007813 * 5120; time = 0.0292s; samplesPerSecond = 175510.8
12/15/2016 08:27:56: Finished Epoch[ 3 of 4]: [Training] ce = 1.06632719 * 81920; err = 0.33137207 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.478391s
12/15/2016 08:27:56: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.3'

12/15/2016 08:27:56: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

12/15/2016 08:27:56: Starting minibatch loop.
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02741594 * 5120; err = 0.32421875 * 5120; time = 0.0309s; samplesPerSecond = 165465.5
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.01295928 * 4926; err = 0.32034105 * 4926; time = 0.0852s; samplesPerSecond = 57827.8
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02364674 * 5120; err = 0.31992188 * 5120; time = 0.0297s; samplesPerSecond = 172628.9
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.03672848 * 5120; err = 0.32011719 * 5120; time = 0.0297s; samplesPerSecond = 172553.2
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.02935562 * 5120; err = 0.31679687 * 5120; time = 0.0295s; samplesPerSecond = 173577.0
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00096855 * 5120; err = 0.31757812 * 5120; time = 0.0295s; samplesPerSecond = 173347.8
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.00992546 * 5120; err = 0.31582031 * 5120; time = 0.0295s; samplesPerSecond = 173300.8
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.00176849 * 5120; err = 0.30585937 * 5120; time = 0.0295s; samplesPerSecond = 173400.6
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.98247986 * 5120; err = 0.31875000 * 5120; time = 0.0297s; samplesPerSecond = 172623.1
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98934326 * 5120; err = 0.30722656 * 5120; time = 0.0298s; samplesPerSecond = 171996.8
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03892670 * 5120; err = 0.32167969 * 5120; time = 0.0298s; samplesPerSecond = 171685.3
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.98335724 * 5120; err = 0.30175781 * 5120; time = 0.0298s; samplesPerSecond = 172054.6
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.99534912 * 5120; err = 0.30839844 * 5120; time = 0.0298s; samplesPerSecond = 171587.5
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96878967 * 5120; err = 0.30332031 * 5120; time = 0.0297s; samplesPerSecond = 172570.7
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97430573 * 5120; err = 0.30078125 * 5120; time = 0.0296s; samplesPerSecond = 173212.9
12/15/2016 08:27:56:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96726532 * 5120; err = 0.30078125 * 5120; time = 0.0291s; samplesPerSecond = 175781.9
12/15/2016 08:27:56: Finished Epoch[ 4 of 4]: [Training] ce = 1.00289879 * 81920; err = 0.31274414 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.53633s
12/15/2016 08:27:56: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082728.104126\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech'

12/15/2016 08:27:56: Action "train" complete.

12/15/2016 08:27:56: __COMPLETED__
