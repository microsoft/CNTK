CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-SlaveTest/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu DeviceId=0 timestamping=true
CNTK 1.7.2+ (HEAD f564f7, Oct 13 2016 07:56:09) on DPHAIM-22 at 2016/10/14 09:31:28

C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
10/14/2016 09:31:29: -------------------------------------------------------------------
10/14/2016 09:31:29: Build info: 

10/14/2016 09:31:29: 		Built time: Oct 13 2016 07:56:09
10/14/2016 09:31:29: 		Last modified date: Wed Oct 12 00:57:03 2016
10/14/2016 09:31:29: 		Build type: Release
10/14/2016 09:31:29: 		Build target: GPU
10/14/2016 09:31:29: 		With 1bit-SGD: no
10/14/2016 09:31:29: 		Math lib: mkl
10/14/2016 09:31:29: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
10/14/2016 09:31:29: 		CUB_PATH: c:\src\cub-1.4.1
10/14/2016 09:31:29: 		CUDNN_PATH: C:\local\cudnn-8.0-windows10-x64-v5.1
10/14/2016 09:31:29: 		Build Branch: HEAD
10/14/2016 09:31:29: 		Build SHA1: f564f708c8ad80bf7fabe9c840bbb0c63b34f138
10/14/2016 09:31:29: 		Built by svcphil on LIANA-09-w
10/14/2016 09:31:29: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
10/14/2016 09:31:29: -------------------------------------------------------------------
10/14/2016 09:31:29: -------------------------------------------------------------------
10/14/2016 09:31:29: GPU info:

10/14/2016 09:31:29: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
10/14/2016 09:31:29: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
10/14/2016 09:31:29: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:precision=float
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
        labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
10/14/2016 09:31:29: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
10/14/2016 09:31:29: precision = "float"

10/14/2016 09:31:29: ##############################################################################
10/14/2016 09:31:29: #                                                                            #
10/14/2016 09:31:29: # dptPre1 command (train action)                                             #
10/14/2016 09:31:29: #                                                                            #
10/14/2016 09:31:29: ##############################################################################

10/14/2016 09:31:29: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
10/14/2016 09:31:30: 
Model has 19 nodes. Using GPU 0.

10/14/2016 09:31:30: Training criterion:   ce = CrossEntropyWithSoftmax
10/14/2016 09:31:30: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }


10/14/2016 09:31:30: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

10/14/2016 09:31:30: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
10/14/2016 09:31:30: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:30: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
10/14/2016 09:31:30: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

10/14/2016 09:31:30: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

10/14/2016 09:31:30: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

10/14/2016 09:31:30: Starting minibatch loop.
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.77545433 * 2560; err = 0.83984375 * 2560; time = 0.2562s; samplesPerSecond = 9991.8
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.92129173 * 2560; err = 0.69921875 * 2560; time = 0.0187s; samplesPerSecond = 136737.5
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.54243622 * 2560; err = 0.64882812 * 2560; time = 0.0186s; samplesPerSecond = 137449.7
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.20117416 * 2560; err = 0.60156250 * 2560; time = 0.0186s; samplesPerSecond = 137516.1
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.98474121 * 2560; err = 0.55273438 * 2560; time = 0.0185s; samplesPerSecond = 138460.7
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87129364 * 2560; err = 0.51562500 * 2560; time = 0.0186s; samplesPerSecond = 137656.6
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.83400879 * 2560; err = 0.52812500 * 2560; time = 0.0186s; samplesPerSecond = 137434.9
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71646271 * 2560; err = 0.49335937 * 2560; time = 0.0187s; samplesPerSecond = 136737.5
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66541901 * 2560; err = 0.46328125 * 2560; time = 0.0189s; samplesPerSecond = 135679.5
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.57725983 * 2560; err = 0.46054688 * 2560; time = 0.0188s; samplesPerSecond = 135902.7
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.61621094 * 2560; err = 0.45390625 * 2560; time = 0.0189s; samplesPerSecond = 135270.8
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.56063995 * 2560; err = 0.44140625 * 2560; time = 0.0188s; samplesPerSecond = 135960.5
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.52853241 * 2560; err = 0.44492188 * 2560; time = 0.0187s; samplesPerSecond = 136569.8
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53460999 * 2560; err = 0.46210937 * 2560; time = 0.0190s; samplesPerSecond = 134928.6
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46377869 * 2560; err = 0.44140625 * 2560; time = 0.0188s; samplesPerSecond = 136018.3
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43344116 * 2560; err = 0.42617187 * 2560; time = 0.0189s; samplesPerSecond = 135335.2
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.43215027 * 2560; err = 0.42148438 * 2560; time = 0.0185s; samplesPerSecond = 138072.4
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.37987366 * 2560; err = 0.41250000 * 2560; time = 0.0188s; samplesPerSecond = 135837.8
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35841980 * 2560; err = 0.40039063 * 2560; time = 0.0189s; samplesPerSecond = 135643.5
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.44842224 * 2560; err = 0.42656250 * 2560; time = 0.0188s; samplesPerSecond = 136228.2
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.43927917 * 2560; err = 0.42539063 * 2560; time = 0.0187s; samplesPerSecond = 137199.2
10/14/2016 09:31:30:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.41734009 * 2560; err = 0.42539063 * 2560; time = 0.0189s; samplesPerSecond = 135801.8
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.33211670 * 2560; err = 0.40468750 * 2560; time = 0.0189s; samplesPerSecond = 135092.3
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36109009 * 2560; err = 0.40429688 * 2560; time = 0.0190s; samplesPerSecond = 135042.5
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.30958252 * 2560; err = 0.39804688 * 2560; time = 0.0187s; samplesPerSecond = 136584.3
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25348511 * 2560; err = 0.36992188 * 2560; time = 0.0190s; samplesPerSecond = 135006.9
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.30338745 * 2560; err = 0.39570312 * 2560; time = 0.0189s; samplesPerSecond = 135370.9
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36117859 * 2560; err = 0.40859375 * 2560; time = 0.0190s; samplesPerSecond = 135071.0
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.29568787 * 2560; err = 0.39531250 * 2560; time = 0.0189s; samplesPerSecond = 135578.9
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.35455017 * 2560; err = 0.40859375 * 2560; time = 0.0190s; samplesPerSecond = 134623.5
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.32246399 * 2560; err = 0.39921875 * 2560; time = 0.0188s; samplesPerSecond = 136184.7
10/14/2016 09:31:31:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.27023926 * 2560; err = 0.38242188 * 2560; time = 0.0183s; samplesPerSecond = 139608.4
10/14/2016 09:31:31: Finished Epoch[ 1 of 2]: [Training] ce = 1.65206318 * 81920; err = 0.46723633 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=1.01494s
10/14/2016 09:31:31: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech.1'

10/14/2016 09:31:31: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:31: Starting minibatch loop.
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.24553871 * 2560; err = 0.38984375 * 2560; time = 0.0211s; samplesPerSecond = 121160.5
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23801517 * 2560; err = 0.36718750 * 2560; time = 0.0191s; samplesPerSecond = 133933.2
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.26358624 * 2560; err = 0.39218750 * 2560; time = 0.0190s; samplesPerSecond = 134857.5
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.26325531 * 2560; err = 0.38203125 * 2560; time = 0.0188s; samplesPerSecond = 135953.3
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.27975998 * 2560; err = 0.36562500 * 2560; time = 0.0189s; samplesPerSecond = 135492.7
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18315849 * 2560; err = 0.35195312 * 2560; time = 0.0189s; samplesPerSecond = 135629.1
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.19740906 * 2560; err = 0.37070313 * 2560; time = 0.0188s; samplesPerSecond = 135931.6
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.23275757 * 2560; err = 0.36835937 * 2560; time = 0.0190s; samplesPerSecond = 134482.0
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.27090912 * 2560; err = 0.38945313 * 2560; time = 0.0189s; samplesPerSecond = 135449.7
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.25143051 * 2560; err = 0.37500000 * 2560; time = 0.0188s; samplesPerSecond = 136402.4
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.21462936 * 2560; err = 0.37187500 * 2560; time = 0.0189s; samplesPerSecond = 135142.3
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19433441 * 2560; err = 0.36796875 * 2560; time = 0.0188s; samplesPerSecond = 136126.8
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.16462097 * 2560; err = 0.36171875 * 2560; time = 0.0190s; samplesPerSecond = 134900.1
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16609802 * 2560; err = 0.36484375 * 2560; time = 0.0189s; samplesPerSecond = 135406.7
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.14834595 * 2560; err = 0.34492187 * 2560; time = 0.0188s; samplesPerSecond = 136438.7
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.11703033 * 2560; err = 0.34804687 * 2560; time = 0.0186s; samplesPerSecond = 137560.5
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.17735901 * 2560; err = 0.35703125 * 2560; time = 0.0187s; samplesPerSecond = 136927.7
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13435669 * 2560; err = 0.35664062 * 2560; time = 0.0188s; samplesPerSecond = 136467.8
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14561310 * 2560; err = 0.35039063 * 2560; time = 0.0186s; samplesPerSecond = 137752.9
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11020966 * 2560; err = 0.33281250 * 2560; time = 0.0186s; samplesPerSecond = 137886.5
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.16456146 * 2560; err = 0.35078125 * 2560; time = 0.0186s; samplesPerSecond = 137309.6
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.14552612 * 2560; err = 0.35742188 * 2560; time = 0.0185s; samplesPerSecond = 138124.5
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09541931 * 2560; err = 0.34492187 * 2560; time = 0.0186s; samplesPerSecond = 137715.9
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12883606 * 2560; err = 0.34218750 * 2560; time = 0.0186s; samplesPerSecond = 137678.8
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.08879089 * 2560; err = 0.33867188 * 2560; time = 0.0186s; samplesPerSecond = 137530.9
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08555603 * 2560; err = 0.32695313 * 2560; time = 0.0186s; samplesPerSecond = 137457.0
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.12885132 * 2560; err = 0.34492187 * 2560; time = 0.0189s; samplesPerSecond = 135751.4
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.12917175 * 2560; err = 0.34921875 * 2560; time = 0.0188s; samplesPerSecond = 136373.3
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.12189331 * 2560; err = 0.34570313 * 2560; time = 0.0187s; samplesPerSecond = 136942.3
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08549500 * 2560; err = 0.32773438 * 2560; time = 0.0189s; samplesPerSecond = 135220.8
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08267212 * 2560; err = 0.34023437 * 2560; time = 0.0188s; samplesPerSecond = 136264.4
10/14/2016 09:31:31:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07620239 * 2560; err = 0.32578125 * 2560; time = 0.0183s; samplesPerSecond = 140266.3
10/14/2016 09:31:31: Finished Epoch[ 2 of 2]: [Training] ce = 1.16660604 * 81920; err = 0.35634766 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.605672s
10/14/2016 09:31:31: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech'

10/14/2016 09:31:31: Action "train" complete.


10/14/2016 09:31:31: ##############################################################################
10/14/2016 09:31:31: #                                                                            #
10/14/2016 09:31:31: # addLayer2 command (edit action)                                            #
10/14/2016 09:31:31: #                                                                            #
10/14/2016 09:31:31: ##############################################################################


10/14/2016 09:31:31: Action "edit" complete.


10/14/2016 09:31:31: ##############################################################################
10/14/2016 09:31:31: #                                                                            #
10/14/2016 09:31:31: # dptPre2 command (train action)                                             #
10/14/2016 09:31:31: #                                                                            #
10/14/2016 09:31:31: ##############################################################################

10/14/2016 09:31:31: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
10/14/2016 09:31:32: 
Model has 24 nodes. Using GPU 0.

10/14/2016 09:31:32: Training criterion:   ce = CrossEntropyWithSoftmax
10/14/2016 09:31:32: Evaluation criterion: err = ClassificationError

10/14/2016 09:31:32: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

10/14/2016 09:31:32: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
10/14/2016 09:31:32: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:32: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:32: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:32: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
10/14/2016 09:31:32: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

10/14/2016 09:31:32: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

10/14/2016 09:31:32: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

10/14/2016 09:31:32: Starting minibatch loop.
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.79919090 * 2560; err = 0.81406250 * 2560; time = 0.0323s; samplesPerSecond = 79308.5
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.49960213 * 2560; err = 0.60390625 * 2560; time = 0.0227s; samplesPerSecond = 112581.9
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.11137619 * 2560; err = 0.56250000 * 2560; time = 0.0229s; samplesPerSecond = 111610.1
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.76882019 * 2560; err = 0.48632813 * 2560; time = 0.0230s; samplesPerSecond = 111318.9
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.59860382 * 2560; err = 0.46484375 * 2560; time = 0.0228s; samplesPerSecond = 112379.3
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.55104752 * 2560; err = 0.44257812 * 2560; time = 0.0228s; samplesPerSecond = 112404.0
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.54163055 * 2560; err = 0.45625000 * 2560; time = 0.0229s; samplesPerSecond = 111639.3
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.46673431 * 2560; err = 0.42773438 * 2560; time = 0.0227s; samplesPerSecond = 112636.4
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.43453674 * 2560; err = 0.42148438 * 2560; time = 0.0229s; samplesPerSecond = 112025.2
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.37832031 * 2560; err = 0.40078125 * 2560; time = 0.0225s; samplesPerSecond = 113525.5
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.40836029 * 2560; err = 0.40351562 * 2560; time = 0.0226s; samplesPerSecond = 113450.0
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.36233521 * 2560; err = 0.39765625 * 2560; time = 0.0226s; samplesPerSecond = 113164.2
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.32512360 * 2560; err = 0.38945313 * 2560; time = 0.0226s; samplesPerSecond = 113424.9
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.32436371 * 2560; err = 0.40078125 * 2560; time = 0.0226s; samplesPerSecond = 113429.9
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.27654266 * 2560; err = 0.38046875 * 2560; time = 0.0226s; samplesPerSecond = 113435.0
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28040466 * 2560; err = 0.39023438 * 2560; time = 0.0227s; samplesPerSecond = 112869.8
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.28345337 * 2560; err = 0.38164063 * 2560; time = 0.0226s; samplesPerSecond = 113304.4
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.25077209 * 2560; err = 0.38164063 * 2560; time = 0.0226s; samplesPerSecond = 113374.7
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.27092590 * 2560; err = 0.38437500 * 2560; time = 0.0227s; samplesPerSecond = 112849.9
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.34506226 * 2560; err = 0.40937500 * 2560; time = 0.0227s; samplesPerSecond = 112815.1
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.33160400 * 2560; err = 0.39531250 * 2560; time = 0.0227s; samplesPerSecond = 112715.7
10/14/2016 09:31:32:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.32417908 * 2560; err = 0.40039063 * 2560; time = 0.0226s; samplesPerSecond = 113194.2
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.24446411 * 2560; err = 0.37343750 * 2560; time = 0.0228s; samplesPerSecond = 112261.0
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.27272034 * 2560; err = 0.38710937 * 2560; time = 0.0227s; samplesPerSecond = 112581.9
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.22947998 * 2560; err = 0.37343750 * 2560; time = 0.0229s; samplesPerSecond = 112000.7
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19538879 * 2560; err = 0.35859375 * 2560; time = 0.0228s; samplesPerSecond = 112162.6
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.20155334 * 2560; err = 0.37578125 * 2560; time = 0.0228s; samplesPerSecond = 112108.6
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25414124 * 2560; err = 0.37421875 * 2560; time = 0.0229s; samplesPerSecond = 111868.6
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.18393860 * 2560; err = 0.34765625 * 2560; time = 0.0228s; samplesPerSecond = 112458.3
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.18773804 * 2560; err = 0.35742188 * 2560; time = 0.0229s; samplesPerSecond = 111981.1
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19469299 * 2560; err = 0.35625000 * 2560; time = 0.0227s; samplesPerSecond = 112934.5
10/14/2016 09:31:33:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.16215820 * 2560; err = 0.33945313 * 2560; time = 0.0221s; samplesPerSecond = 115868.6
10/14/2016 09:31:33: Finished Epoch[ 1 of 2]: [Training] ce = 1.47060204 * 81920; err = 0.41995850 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.916249s
10/14/2016 09:31:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.1'

10/14/2016 09:31:33: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:33: Starting minibatch loop.
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.17322750 * 2560; err = 0.36562500 * 2560; time = 0.0250s; samplesPerSecond = 102297.7
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18700581 * 2560; err = 0.36523438 * 2560; time = 0.0229s; samplesPerSecond = 111873.4
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15305710 * 2560; err = 0.35625000 * 2560; time = 0.0229s; samplesPerSecond = 111853.9
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.16534157 * 2560; err = 0.35195312 * 2560; time = 0.0227s; samplesPerSecond = 112547.3
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.20508575 * 2560; err = 0.35781250 * 2560; time = 0.0226s; samplesPerSecond = 113309.4
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.14411507 * 2560; err = 0.35390625 * 2560; time = 0.0227s; samplesPerSecond = 112621.5
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14619522 * 2560; err = 0.35585937 * 2560; time = 0.0228s; samplesPerSecond = 112408.9
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17611618 * 2560; err = 0.35820313 * 2560; time = 0.0228s; samplesPerSecond = 112354.6
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.18331375 * 2560; err = 0.36601563 * 2560; time = 0.0228s; samplesPerSecond = 112330.0
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.19414444 * 2560; err = 0.36328125 * 2560; time = 0.0228s; samplesPerSecond = 112133.2
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14636459 * 2560; err = 0.34882812 * 2560; time = 0.0228s; samplesPerSecond = 112108.6
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13707428 * 2560; err = 0.34296875 * 2560; time = 0.0229s; samplesPerSecond = 111673.4
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.10562134 * 2560; err = 0.34531250 * 2560; time = 0.0228s; samplesPerSecond = 112084.1
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.12617188 * 2560; err = 0.35625000 * 2560; time = 0.0228s; samplesPerSecond = 112325.0
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.10491180 * 2560; err = 0.33398438 * 2560; time = 0.0229s; samplesPerSecond = 111912.6
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.07516937 * 2560; err = 0.33789063 * 2560; time = 0.0226s; samplesPerSecond = 113164.2
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.12402802 * 2560; err = 0.33320312 * 2560; time = 0.0226s; samplesPerSecond = 113044.2
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.07574005 * 2560; err = 0.32500000 * 2560; time = 0.0229s; samplesPerSecond = 111956.6
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11410980 * 2560; err = 0.35039063 * 2560; time = 0.0228s; samplesPerSecond = 112394.1
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08050842 * 2560; err = 0.33359375 * 2560; time = 0.0226s; samplesPerSecond = 113189.2
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.12032166 * 2560; err = 0.33515625 * 2560; time = 0.0226s; samplesPerSecond = 113505.4
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09879761 * 2560; err = 0.33437500 * 2560; time = 0.0226s; samplesPerSecond = 113284.4
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.04387970 * 2560; err = 0.31992188 * 2560; time = 0.0226s; samplesPerSecond = 113475.2
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10072937 * 2560; err = 0.33945313 * 2560; time = 0.0226s; samplesPerSecond = 113219.2
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09740295 * 2560; err = 0.33554688 * 2560; time = 0.0226s; samplesPerSecond = 113389.7
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07432556 * 2560; err = 0.32382813 * 2560; time = 0.0226s; samplesPerSecond = 113299.4
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.11010437 * 2560; err = 0.34101562 * 2560; time = 0.0227s; samplesPerSecond = 112924.6
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.08828430 * 2560; err = 0.33515625 * 2560; time = 0.0226s; samplesPerSecond = 113429.9
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09696045 * 2560; err = 0.34218750 * 2560; time = 0.0226s; samplesPerSecond = 113209.2
10/14/2016 09:31:33:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.07973328 * 2560; err = 0.31914063 * 2560; time = 0.0227s; samplesPerSecond = 112934.5
10/14/2016 09:31:34:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.07892456 * 2560; err = 0.33125000 * 2560; time = 0.0228s; samplesPerSecond = 112221.6
10/14/2016 09:31:34:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07525024 * 2560; err = 0.33945313 * 2560; time = 0.0222s; samplesPerSecond = 115362.1
10/14/2016 09:31:34: Finished Epoch[ 2 of 2]: [Training] ce = 1.12131300 * 81920; err = 0.34368896 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.731747s
10/14/2016 09:31:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech'

10/14/2016 09:31:34: Action "train" complete.


10/14/2016 09:31:34: ##############################################################################
10/14/2016 09:31:34: #                                                                            #
10/14/2016 09:31:34: # addLayer3 command (edit action)                                            #
10/14/2016 09:31:34: #                                                                            #
10/14/2016 09:31:34: ##############################################################################


10/14/2016 09:31:34: Action "edit" complete.


10/14/2016 09:31:34: ##############################################################################
10/14/2016 09:31:34: #                                                                            #
10/14/2016 09:31:34: # speechTrain command (train action)                                         #
10/14/2016 09:31:34: #                                                                            #
10/14/2016 09:31:34: ##############################################################################

10/14/2016 09:31:34: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
10/14/2016 09:31:34: 
Model has 29 nodes. Using GPU 0.

10/14/2016 09:31:34: Training criterion:   ce = CrossEntropyWithSoftmax
10/14/2016 09:31:34: Evaluation criterion: err = ClassificationError

10/14/2016 09:31:34: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

10/14/2016 09:31:34: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
10/14/2016 09:31:34: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:34: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:34: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:34: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
10/14/2016 09:31:34: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
10/14/2016 09:31:34: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
10/14/2016 09:31:34: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

10/14/2016 09:31:34: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

10/14/2016 09:31:34: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

10/14/2016 09:31:34: Starting minibatch loop.
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.05308037 * 2560; err = 0.84570313 * 2560; time = 0.0384s; samplesPerSecond = 66678.8
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.54534264 * 2560; err = 0.61289063 * 2560; time = 0.0267s; samplesPerSecond = 95876.6
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.04219437 * 2560; err = 0.55664063 * 2560; time = 0.0266s; samplesPerSecond = 96208.0
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.69051361 * 2560; err = 0.47304687 * 2560; time = 0.0269s; samplesPerSecond = 95241.6
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.51447601 * 2560; err = 0.43632813 * 2560; time = 0.0269s; samplesPerSecond = 95209.8
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.46680908 * 2560; err = 0.42265625 * 2560; time = 0.0269s; samplesPerSecond = 95341.0
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.45935211 * 2560; err = 0.42187500 * 2560; time = 0.0268s; samplesPerSecond = 95518.8
10/14/2016 09:31:34:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.37553558 * 2560; err = 0.40273437 * 2560; time = 0.0268s; samplesPerSecond = 95401.4
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.33034363 * 2560; err = 0.38632813 * 2560; time = 0.0273s; samplesPerSecond = 93776.3
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.28698120 * 2560; err = 0.37617187 * 2560; time = 0.0268s; samplesPerSecond = 95483.2
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31902313 * 2560; err = 0.38437500 * 2560; time = 0.0267s; samplesPerSecond = 95855.0
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27717133 * 2560; err = 0.37539062 * 2560; time = 0.0265s; samplesPerSecond = 96534.6
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.24647217 * 2560; err = 0.37460938 * 2560; time = 0.0264s; samplesPerSecond = 96881.6
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.25260620 * 2560; err = 0.38632813 * 2560; time = 0.0281s; samplesPerSecond = 90983.4
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.19903870 * 2560; err = 0.35585937 * 2560; time = 0.0262s; samplesPerSecond = 97803.2
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.21954803 * 2560; err = 0.37226562 * 2560; time = 0.0265s; samplesPerSecond = 96614.7
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.21195068 * 2560; err = 0.35898438 * 2560; time = 0.0267s; samplesPerSecond = 96002.4
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.19517822 * 2560; err = 0.36953125 * 2560; time = 0.0267s; samplesPerSecond = 95930.5
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.22365723 * 2560; err = 0.37265625 * 2560; time = 0.0266s; samplesPerSecond = 96161.1
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.26116333 * 2560; err = 0.38085938 * 2560; time = 0.0265s; samplesPerSecond = 96432.7
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.25077515 * 2560; err = 0.37070313 * 2560; time = 0.0266s; samplesPerSecond = 96381.9
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.25315857 * 2560; err = 0.38320312 * 2560; time = 0.0268s; samplesPerSecond = 95383.6
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.18275757 * 2560; err = 0.35468750 * 2560; time = 0.0268s; samplesPerSecond = 95394.2
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21010132 * 2560; err = 0.37343750 * 2560; time = 0.0269s; samplesPerSecond = 95061.3
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17427979 * 2560; err = 0.35976562 * 2560; time = 0.0270s; samplesPerSecond = 94835.9
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.14313049 * 2560; err = 0.34062500 * 2560; time = 0.0269s; samplesPerSecond = 95202.7
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13857422 * 2560; err = 0.35234375 * 2560; time = 0.0266s; samplesPerSecond = 96139.4
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.19849548 * 2560; err = 0.35312500 * 2560; time = 0.0270s; samplesPerSecond = 94980.2
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.13391418 * 2560; err = 0.33125000 * 2560; time = 0.0270s; samplesPerSecond = 94857.0
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14261475 * 2560; err = 0.35351563 * 2560; time = 0.0269s; samplesPerSecond = 95209.8
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.15215454 * 2560; err = 0.34609375 * 2560; time = 0.0269s; samplesPerSecond = 95337.4
10/14/2016 09:31:35:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.10493164 * 2560; err = 0.33242187 * 2560; time = 0.0263s; samplesPerSecond = 97405.1
10/14/2016 09:31:35: Finished Epoch[ 1 of 4]: [Training] ce = 1.41422892 * 81920; err = 0.40363770 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=1.04512s
10/14/2016 09:31:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.1'

10/14/2016 09:31:35: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:35: Starting minibatch loop.
10/14/2016 09:31:35:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.20340281 * 5120; err = 0.37304688 * 5120; time = 0.0453s; samplesPerSecond = 113106.7
10/14/2016 09:31:35:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.42403650 * 5120; err = 0.40468750 * 5120; time = 0.0330s; samplesPerSecond = 155339.8
10/14/2016 09:31:35:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.25105305 * 5120; err = 0.37578125 * 5120; time = 0.0330s; samplesPerSecond = 155001.2
10/14/2016 09:31:35:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.15185928 * 5120; err = 0.35332031 * 5120; time = 0.0330s; samplesPerSecond = 155020.0
10/14/2016 09:31:35:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.15706062 * 5120; err = 0.35136719 * 5120; time = 0.0330s; samplesPerSecond = 155193.8
10/14/2016 09:31:35:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.12380981 * 5120; err = 0.33984375 * 5120; time = 0.0330s; samplesPerSecond = 154959.0
10/14/2016 09:31:35:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.10895309 * 5120; err = 0.34335938 * 5120; time = 0.0330s; samplesPerSecond = 155368.1
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07364273 * 5120; err = 0.33339844 * 5120; time = 0.0333s; samplesPerSecond = 153767.6
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.08244247 * 5120; err = 0.32890625 * 5120; time = 0.0320s; samplesPerSecond = 160035.0
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.10229111 * 5120; err = 0.34804687 * 5120; time = 0.0316s; samplesPerSecond = 162040.7
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.09083862 * 5120; err = 0.32949219 * 5120; time = 0.0317s; samplesPerSecond = 161493.8
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07336807 * 5120; err = 0.33378906 * 5120; time = 0.0319s; samplesPerSecond = 160748.5
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.08632355 * 5120; err = 0.33476563 * 5120; time = 0.0318s; samplesPerSecond = 160900.0
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.20552521 * 5120; err = 0.36640625 * 5120; time = 0.0316s; samplesPerSecond = 161846.1
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08646393 * 5120; err = 0.33515625 * 5120; time = 0.0317s; samplesPerSecond = 161453.1
10/14/2016 09:31:36:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06277771 * 5120; err = 0.32441406 * 5120; time = 0.0315s; samplesPerSecond = 162431.4
10/14/2016 09:31:36: Finished Epoch[ 2 of 4]: [Training] ce = 1.14274054 * 81920; err = 0.34848633 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.533668s
10/14/2016 09:31:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.2'

10/14/2016 09:31:36: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:36: Starting minibatch loop.
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.07757759 * 5120; err = 0.33906250 * 5120; time = 0.0337s; samplesPerSecond = 151874.7
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10256577 * 5120; err = 0.33554688 * 5120; time = 0.0321s; samplesPerSecond = 159740.4
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08794174 * 5120; err = 0.33652344 * 5120; time = 0.0318s; samplesPerSecond = 160864.6
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.05023384 * 5120; err = 0.32402344 * 5120; time = 0.0318s; samplesPerSecond = 161021.5
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07754555 * 5120; err = 0.33027344 * 5120; time = 0.0318s; samplesPerSecond = 161006.3
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.09322929 * 5120; err = 0.33457031 * 5120; time = 0.0318s; samplesPerSecond = 160889.9
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06973267 * 5120; err = 0.33222656 * 5120; time = 0.0320s; samplesPerSecond = 160170.2
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07723465 * 5120; err = 0.33691406 * 5120; time = 0.0320s; samplesPerSecond = 159980.0
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.10391693 * 5120; err = 0.35078125 * 5120; time = 0.0319s; samplesPerSecond = 160406.0
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.02986145 * 5120; err = 0.31796875 * 5120; time = 0.0321s; samplesPerSecond = 159536.3
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03675385 * 5120; err = 0.32324219 * 5120; time = 0.0319s; samplesPerSecond = 160718.2
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.05694733 * 5120; err = 0.32890625 * 5120; time = 0.0320s; samplesPerSecond = 159985.0
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.07095642 * 5120; err = 0.33867188 * 5120; time = 0.0320s; samplesPerSecond = 160025.0
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.10888519 * 5120; err = 0.35234375 * 5120; time = 0.0319s; samplesPerSecond = 160295.5
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.03184204 * 5120; err = 0.31855469 * 5120; time = 0.0319s; samplesPerSecond = 160496.5
10/14/2016 09:31:36:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.03542175 * 5120; err = 0.32597656 * 5120; time = 0.0318s; samplesPerSecond = 161016.4
10/14/2016 09:31:36: Finished Epoch[ 3 of 4]: [Training] ce = 1.06941538 * 81920; err = 0.33284912 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.515415s
10/14/2016 09:31:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.3'

10/14/2016 09:31:37: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

10/14/2016 09:31:37: Starting minibatch loop.
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02287865 * 5120; err = 0.32441406 * 5120; time = 0.0337s; samplesPerSecond = 151784.7
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.00036656 * 4926; err = 0.31282988 * 4926; time = 0.0869s; samplesPerSecond = 56712.6
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02111568 * 5120; err = 0.31992188 * 5120; time = 0.0316s; samplesPerSecond = 162163.9
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.03787308 * 5120; err = 0.32167969 * 5120; time = 0.0314s; samplesPerSecond = 163171.6
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.02998810 * 5120; err = 0.31914063 * 5120; time = 0.0316s; samplesPerSecond = 162169.0
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99880371 * 5120; err = 0.31699219 * 5120; time = 0.0316s; samplesPerSecond = 161810.3
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01209679 * 5120; err = 0.31308594 * 5120; time = 0.0316s; samplesPerSecond = 161974.1
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.01306152 * 5120; err = 0.31640625 * 5120; time = 0.0318s; samplesPerSecond = 161117.8
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.98222580 * 5120; err = 0.31835938 * 5120; time = 0.0318s; samplesPerSecond = 161036.7
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98958893 * 5120; err = 0.30781250 * 5120; time = 0.0319s; samplesPerSecond = 160391.0
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03325119 * 5120; err = 0.31757812 * 5120; time = 0.0320s; samplesPerSecond = 160080.0
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.98376541 * 5120; err = 0.29882813 * 5120; time = 0.0319s; samplesPerSecond = 160411.1
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00050964 * 5120; err = 0.30898437 * 5120; time = 0.0318s; samplesPerSecond = 160996.2
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.97206116 * 5120; err = 0.30859375 * 5120; time = 0.0320s; samplesPerSecond = 160045.0
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97620392 * 5120; err = 0.30156250 * 5120; time = 0.0319s; samplesPerSecond = 160738.4
10/14/2016 09:31:37:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97575836 * 5120; err = 0.30410156 * 5120; time = 0.0315s; samplesPerSecond = 162560.3
10/14/2016 09:31:37: Finished Epoch[ 4 of 4]: [Training] ce = 1.00333567 * 81920; err = 0.31326904 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.570341s
10/14/2016 09:31:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161014093126.548102\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech'

10/14/2016 09:31:37: Action "train" complete.

10/14/2016 09:31:37: __COMPLETED__