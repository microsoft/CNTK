CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3530 @ 2.80GHz
    Hardware threads: 4
    Total Memory: 12580404 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-SlaveTest/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta3.0+ (HEAD 73542d, Nov 22 2016 13:21:29) on cntk-muc00 at 2016/11/24 05:51:08

C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
11/24/2016 05:51:08: -------------------------------------------------------------------
11/24/2016 05:51:08: Build info: 

11/24/2016 05:51:08: 		Built time: Nov 22 2016 13:21:29
11/24/2016 05:51:08: 		Last modified date: Tue Nov 22 13:07:57 2016
11/24/2016 05:51:08: 		Build type: Release
11/24/2016 05:51:08: 		Build target: GPU
11/24/2016 05:51:08: 		With 1bit-SGD: no
11/24/2016 05:51:08: 		With ASGD: yes
11/24/2016 05:51:08: 		Math lib: mkl
11/24/2016 05:51:08: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
11/24/2016 05:51:08: 		CUB_PATH: c:\src\cub-1.4.1
11/24/2016 05:51:08: 		CUDNN_PATH: C:\local\cudnn-8.0-windows10-x64-v5.1
11/24/2016 05:51:08: 		Build Branch: HEAD
11/24/2016 05:51:08: 		Build SHA1: 73542d173d5c829ef744eb26cba06230dfbe1983 (modified)
11/24/2016 05:51:08: 		Built by svcphil on Philly-Pool1
11/24/2016 05:51:08: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
11/24/2016 05:51:08: -------------------------------------------------------------------
11/24/2016 05:51:09: -------------------------------------------------------------------
11/24/2016 05:51:09: GPU info:

11/24/2016 05:51:09: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
11/24/2016 05:51:09: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:precision=float
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
        labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
11/24/2016 05:51:09: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
11/24/2016 05:51:09: precision = "float"

11/24/2016 05:51:09: ##############################################################################
11/24/2016 05:51:09: #                                                                            #
11/24/2016 05:51:09: # dptPre1 command (train action)                                             #
11/24/2016 05:51:09: #                                                                            #
11/24/2016 05:51:09: ##############################################################################

11/24/2016 05:51:09: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 05:51:10: 
Model has 19 nodes. Using GPU 0.

11/24/2016 05:51:10: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 05:51:10: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }


11/24/2016 05:51:10: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

11/24/2016 05:51:10: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 05:51:10: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:10: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 05:51:10: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 05:51:10: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 05:51:10: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 05:51:10: Starting minibatch loop.
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.77545395 * 2560; err = 0.83984375 * 2560; time = 0.9344s; samplesPerSecond = 2739.7
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.92129135 * 2560; err = 0.69921875 * 2560; time = 0.0116s; samplesPerSecond = 220139.3
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.54243622 * 2560; err = 0.64882812 * 2560; time = 0.0116s; samplesPerSecond = 220918.2
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.20117416 * 2560; err = 0.60156250 * 2560; time = 0.0115s; samplesPerSecond = 222010.2
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.98474197 * 2560; err = 0.55273438 * 2560; time = 0.0116s; samplesPerSecond = 221549.1
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87129364 * 2560; err = 0.51562500 * 2560; time = 0.0115s; samplesPerSecond = 221856.3
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.83400879 * 2560; err = 0.52812500 * 2560; time = 0.0116s; samplesPerSecond = 221261.9
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71646118 * 2560; err = 0.49335937 * 2560; time = 0.0116s; samplesPerSecond = 220899.1
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.66542053 * 2560; err = 0.46328125 * 2560; time = 0.0115s; samplesPerSecond = 221741.0
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.57725983 * 2560; err = 0.46054688 * 2560; time = 0.0116s; samplesPerSecond = 221128.1
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.61620941 * 2560; err = 0.45390625 * 2560; time = 0.0115s; samplesPerSecond = 222164.4
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.56064148 * 2560; err = 0.44140625 * 2560; time = 0.0115s; samplesPerSecond = 221779.4
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.52853241 * 2560; err = 0.44492188 * 2560; time = 0.0116s; samplesPerSecond = 221166.3
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53460693 * 2560; err = 0.46210937 * 2560; time = 0.0115s; samplesPerSecond = 221952.5
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46377258 * 2560; err = 0.44101563 * 2560; time = 0.0116s; samplesPerSecond = 221529.9
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43344116 * 2560; err = 0.42617187 * 2560; time = 0.0115s; samplesPerSecond = 221817.9
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.43211365 * 2560; err = 0.42148438 * 2560; time = 0.0116s; samplesPerSecond = 221319.3
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.37977600 * 2560; err = 0.41289063 * 2560; time = 0.0116s; samplesPerSecond = 221070.8
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35835876 * 2560; err = 0.40000000 * 2560; time = 0.0115s; samplesPerSecond = 221952.5
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.44833679 * 2560; err = 0.42617187 * 2560; time = 0.0115s; samplesPerSecond = 221952.5
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.43916626 * 2560; err = 0.42421875 * 2560; time = 0.0116s; samplesPerSecond = 221510.8
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.41724548 * 2560; err = 0.42539063 * 2560; time = 0.0115s; samplesPerSecond = 221914.0
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.33214111 * 2560; err = 0.40468750 * 2560; time = 0.0116s; samplesPerSecond = 221472.4
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36114807 * 2560; err = 0.40429688 * 2560; time = 0.0116s; samplesPerSecond = 220044.7
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.30970764 * 2560; err = 0.39843750 * 2560; time = 0.0116s; samplesPerSecond = 221319.3
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25345764 * 2560; err = 0.37109375 * 2560; time = 0.0116s; samplesPerSecond = 221549.1
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.30331726 * 2560; err = 0.39687500 * 2560; time = 0.0115s; samplesPerSecond = 222145.1
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36109314 * 2560; err = 0.40937500 * 2560; time = 0.0116s; samplesPerSecond = 221185.4
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.29548035 * 2560; err = 0.39492187 * 2560; time = 0.0115s; samplesPerSecond = 221779.4
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.35542297 * 2560; err = 0.41250000 * 2560; time = 0.0115s; samplesPerSecond = 221702.6
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.32324219 * 2560; err = 0.39843750 * 2560; time = 0.0116s; samplesPerSecond = 221510.8
11/24/2016 05:51:11:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.26611328 * 2560; err = 0.38398437 * 2560; time = 0.0114s; samplesPerSecond = 224207.4
11/24/2016 05:51:11: Finished Epoch[ 1 of 2]: [Training] ce = 1.65196457 * 81920; err = 0.46741943 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=1.45486s
11/24/2016 05:51:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech.1'

11/24/2016 05:51:11: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:11: Starting minibatch loop.
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.24464846 * 2560; err = 0.39101562 * 2560; time = 0.0124s; samplesPerSecond = 205738.2
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23796568 * 2560; err = 0.36914063 * 2560; time = 0.0116s; samplesPerSecond = 220082.5
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.26215553 * 2560; err = 0.39218750 * 2560; time = 0.0116s; samplesPerSecond = 220518.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.26262550 * 2560; err = 0.38398437 * 2560; time = 0.0116s; samplesPerSecond = 220842.0
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.27904701 * 2560; err = 0.36250000 * 2560; time = 0.0116s; samplesPerSecond = 220784.8
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18363762 * 2560; err = 0.35546875 * 2560; time = 0.0116s; samplesPerSecond = 220366.7
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.19679031 * 2560; err = 0.37343750 * 2560; time = 0.0117s; samplesPerSecond = 219309.5
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.23404694 * 2560; err = 0.37304688 * 2560; time = 0.0116s; samplesPerSecond = 221223.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.27192001 * 2560; err = 0.38593750 * 2560; time = 0.0116s; samplesPerSecond = 220499.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.25266266 * 2560; err = 0.37773438 * 2560; time = 0.0116s; samplesPerSecond = 220537.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.20625992 * 2560; err = 0.36601563 * 2560; time = 0.0120s; samplesPerSecond = 213493.5
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18923492 * 2560; err = 0.36835937 * 2560; time = 0.0116s; samplesPerSecond = 220746.7
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.16404114 * 2560; err = 0.36210938 * 2560; time = 0.0116s; samplesPerSecond = 220632.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16829834 * 2560; err = 0.36054687 * 2560; time = 0.0116s; samplesPerSecond = 220006.9
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.15110931 * 2560; err = 0.34882812 * 2560; time = 0.0116s; samplesPerSecond = 221587.5
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.11652832 * 2560; err = 0.35468750 * 2560; time = 0.0116s; samplesPerSecond = 220537.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.17863464 * 2560; err = 0.36015625 * 2560; time = 0.0117s; samplesPerSecond = 218355.5
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13985901 * 2560; err = 0.35820313 * 2560; time = 0.0125s; samplesPerSecond = 204964.0
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.15102844 * 2560; err = 0.35468750 * 2560; time = 0.0119s; samplesPerSecond = 214819.2
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11725464 * 2560; err = 0.33906250 * 2560; time = 0.0118s; samplesPerSecond = 217077.9
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.17304688 * 2560; err = 0.35078125 * 2560; time = 0.0118s; samplesPerSecond = 216692.1
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.14964294 * 2560; err = 0.35664062 * 2560; time = 0.0118s; samplesPerSecond = 217096.3
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09995422 * 2560; err = 0.34960938 * 2560; time = 0.0117s; samplesPerSecond = 218411.4
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.14054871 * 2560; err = 0.35546875 * 2560; time = 0.0118s; samplesPerSecond = 217317.5
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.10378418 * 2560; err = 0.34101562 * 2560; time = 0.0116s; samplesPerSecond = 221109.0
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.09910583 * 2560; err = 0.33281250 * 2560; time = 0.0116s; samplesPerSecond = 221395.8
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.13848267 * 2560; err = 0.34570313 * 2560; time = 0.0116s; samplesPerSecond = 221510.8
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.13355103 * 2560; err = 0.34023437 * 2560; time = 0.0116s; samplesPerSecond = 221453.3
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.12416992 * 2560; err = 0.35156250 * 2560; time = 0.0116s; samplesPerSecond = 221051.7
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08649292 * 2560; err = 0.32968750 * 2560; time = 0.0116s; samplesPerSecond = 220480.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.09048157 * 2560; err = 0.34062500 * 2560; time = 0.0116s; samplesPerSecond = 220423.6
11/24/2016 05:51:11:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07804260 * 2560; err = 0.32968750 * 2560; time = 0.0115s; samplesPerSecond = 222492.6
11/24/2016 05:51:11: Finished Epoch[ 2 of 2]: [Training] ce = 1.16953287 * 81920; err = 0.35815430 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.377687s
11/24/2016 05:51:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech'

11/24/2016 05:51:12: Action "train" complete.


11/24/2016 05:51:12: ##############################################################################
11/24/2016 05:51:12: #                                                                            #
11/24/2016 05:51:12: # addLayer2 command (edit action)                                            #
11/24/2016 05:51:12: #                                                                            #
11/24/2016 05:51:12: ##############################################################################


11/24/2016 05:51:12: Action "edit" complete.


11/24/2016 05:51:12: ##############################################################################
11/24/2016 05:51:12: #                                                                            #
11/24/2016 05:51:12: # dptPre2 command (train action)                                             #
11/24/2016 05:51:12: #                                                                            #
11/24/2016 05:51:12: ##############################################################################

11/24/2016 05:51:12: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 05:51:12: 
Model has 24 nodes. Using GPU 0.

11/24/2016 05:51:12: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 05:51:12: Evaluation criterion: err = ClassificationError

11/24/2016 05:51:12: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

11/24/2016 05:51:12: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 05:51:12: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:12: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:12: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:12: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 05:51:12: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 05:51:12: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 05:51:12: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 05:51:12: Starting minibatch loop.
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.75458946 * 2560; err = 0.81328125 * 2560; time = 0.0205s; samplesPerSecond = 124914.6
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.48310242 * 2560; err = 0.60429687 * 2560; time = 0.0169s; samplesPerSecond = 151613.9
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.10525322 * 2560; err = 0.56210938 * 2560; time = 0.0169s; samplesPerSecond = 151721.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.76446762 * 2560; err = 0.48359375 * 2560; time = 0.0169s; samplesPerSecond = 151622.8
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.59635010 * 2560; err = 0.46093750 * 2560; time = 0.0169s; samplesPerSecond = 151793.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.54905396 * 2560; err = 0.44453125 * 2560; time = 0.0169s; samplesPerSecond = 151856.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.54326477 * 2560; err = 0.45312500 * 2560; time = 0.0169s; samplesPerSecond = 151757.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.46788788 * 2560; err = 0.43046875 * 2560; time = 0.0169s; samplesPerSecond = 151847.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.43234406 * 2560; err = 0.41601563 * 2560; time = 0.0168s; samplesPerSecond = 152037.1
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.37492981 * 2560; err = 0.40351562 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.40872192 * 2560; err = 0.40546875 * 2560; time = 0.0168s; samplesPerSecond = 151973.9
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.36253204 * 2560; err = 0.39453125 * 2560; time = 0.0169s; samplesPerSecond = 151748.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.32599792 * 2560; err = 0.38984375 * 2560; time = 0.0169s; samplesPerSecond = 151829.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.32576294 * 2560; err = 0.40351562 * 2560; time = 0.0169s; samplesPerSecond = 151721.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.27705231 * 2560; err = 0.38046875 * 2560; time = 0.0169s; samplesPerSecond = 151739.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28065491 * 2560; err = 0.39179687 * 2560; time = 0.0169s; samplesPerSecond = 151748.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.28199768 * 2560; err = 0.38085938 * 2560; time = 0.0169s; samplesPerSecond = 151838.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.24859619 * 2560; err = 0.37929687 * 2560; time = 0.0169s; samplesPerSecond = 151901.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.26257324 * 2560; err = 0.38007812 * 2560; time = 0.0169s; samplesPerSecond = 151631.8
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.34178772 * 2560; err = 0.40585938 * 2560; time = 0.0169s; samplesPerSecond = 151712.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.33152466 * 2560; err = 0.39179687 * 2560; time = 0.0168s; samplesPerSecond = 152190.7
11/24/2016 05:51:12:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.32487488 * 2560; err = 0.40078125 * 2560; time = 0.0169s; samplesPerSecond = 151685.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.24589233 * 2560; err = 0.37421875 * 2560; time = 0.0169s; samplesPerSecond = 151712.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.27312317 * 2560; err = 0.38398437 * 2560; time = 0.0169s; samplesPerSecond = 151838.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.22917175 * 2560; err = 0.37890625 * 2560; time = 0.0169s; samplesPerSecond = 151703.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19546814 * 2560; err = 0.35820313 * 2560; time = 0.0169s; samplesPerSecond = 151757.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.19499817 * 2560; err = 0.36914063 * 2560; time = 0.0169s; samplesPerSecond = 151694.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25497131 * 2560; err = 0.37226562 * 2560; time = 0.0170s; samplesPerSecond = 150234.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.18477783 * 2560; err = 0.34453125 * 2560; time = 0.0169s; samplesPerSecond = 151551.0
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.19327393 * 2560; err = 0.36289063 * 2560; time = 0.0169s; samplesPerSecond = 151578.0
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19387207 * 2560; err = 0.35820313 * 2560; time = 0.0169s; samplesPerSecond = 151829.7
11/24/2016 05:51:13:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.16335144 * 2560; err = 0.34257813 * 2560; time = 0.0169s; samplesPerSecond = 151703.7
11/24/2016 05:51:13: Finished Epoch[ 1 of 2]: [Training] ce = 1.46788187 * 81920; err = 0.41940918 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.70502s
11/24/2016 05:51:13: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.1'

11/24/2016 05:51:13: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:13: Starting minibatch loop.
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.17136545 * 2560; err = 0.36484375 * 2560; time = 0.0175s; samplesPerSecond = 145960.4
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.18364286 * 2560; err = 0.35742188 * 2560; time = 0.0169s; samplesPerSecond = 151631.8
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15444794 * 2560; err = 0.35976562 * 2560; time = 0.0169s; samplesPerSecond = 151291.3
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.16754875 * 2560; err = 0.35703125 * 2560; time = 0.0169s; samplesPerSecond = 151676.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.20176353 * 2560; err = 0.35351563 * 2560; time = 0.0169s; samplesPerSecond = 151658.8
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.14280739 * 2560; err = 0.35390625 * 2560; time = 0.0169s; samplesPerSecond = 151757.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.15013046 * 2560; err = 0.35898438 * 2560; time = 0.0169s; samplesPerSecond = 151658.8
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17789917 * 2560; err = 0.36093750 * 2560; time = 0.0169s; samplesPerSecond = 151676.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.18394852 * 2560; err = 0.36796875 * 2560; time = 0.0169s; samplesPerSecond = 151874.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.19100342 * 2560; err = 0.36250000 * 2560; time = 0.0187s; samplesPerSecond = 136744.8
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14559326 * 2560; err = 0.34843750 * 2560; time = 0.0169s; samplesPerSecond = 151300.2
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13130646 * 2560; err = 0.34023437 * 2560; time = 0.0171s; samplesPerSecond = 149637.6
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.10303650 * 2560; err = 0.34804687 * 2560; time = 0.0170s; samplesPerSecond = 150685.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.13034515 * 2560; err = 0.35468750 * 2560; time = 0.0170s; samplesPerSecond = 150898.9
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.10243835 * 2560; err = 0.33242187 * 2560; time = 0.0169s; samplesPerSecond = 151640.8
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.07932129 * 2560; err = 0.34296875 * 2560; time = 0.0169s; samplesPerSecond = 151829.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.12233124 * 2560; err = 0.33437500 * 2560; time = 0.0169s; samplesPerSecond = 151856.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.08132324 * 2560; err = 0.32773438 * 2560; time = 0.0168s; samplesPerSecond = 151937.8
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11637878 * 2560; err = 0.34492187 * 2560; time = 0.0168s; samplesPerSecond = 152082.2
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.07997284 * 2560; err = 0.32656250 * 2560; time = 0.0168s; samplesPerSecond = 152028.0
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.12148438 * 2560; err = 0.33750000 * 2560; time = 0.0169s; samplesPerSecond = 151820.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.10175629 * 2560; err = 0.33710937 * 2560; time = 0.0169s; samplesPerSecond = 151856.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.05232086 * 2560; err = 0.32343750 * 2560; time = 0.0169s; samplesPerSecond = 151838.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10686646 * 2560; err = 0.33984375 * 2560; time = 0.0169s; samplesPerSecond = 151604.9
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.10232544 * 2560; err = 0.33828125 * 2560; time = 0.0169s; samplesPerSecond = 151910.8
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08003540 * 2560; err = 0.32304688 * 2560; time = 0.0169s; samplesPerSecond = 151730.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.11729431 * 2560; err = 0.34726563 * 2560; time = 0.0169s; samplesPerSecond = 151775.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.09414063 * 2560; err = 0.33281250 * 2560; time = 0.0169s; samplesPerSecond = 151748.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.10393066 * 2560; err = 0.34492187 * 2560; time = 0.0169s; samplesPerSecond = 151766.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08433228 * 2560; err = 0.32304688 * 2560; time = 0.0168s; samplesPerSecond = 152082.2
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08205566 * 2560; err = 0.33398438 * 2560; time = 0.0175s; samplesPerSecond = 146377.7
11/24/2016 05:51:13:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07085266 * 2560; err = 0.33085938 * 2560; time = 0.0170s; samplesPerSecond = 150916.7
11/24/2016 05:51:13: Finished Epoch[ 2 of 2]: [Training] ce = 1.12293749 * 81920; err = 0.34404297 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.547238s
11/24/2016 05:51:13: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech'

11/24/2016 05:51:13: Action "train" complete.


11/24/2016 05:51:13: ##############################################################################
11/24/2016 05:51:13: #                                                                            #
11/24/2016 05:51:13: # addLayer3 command (edit action)                                            #
11/24/2016 05:51:13: #                                                                            #
11/24/2016 05:51:13: ##############################################################################


11/24/2016 05:51:13: Action "edit" complete.


11/24/2016 05:51:13: ##############################################################################
11/24/2016 05:51:13: #                                                                            #
11/24/2016 05:51:13: # speechTrain command (train action)                                         #
11/24/2016 05:51:13: #                                                                            #
11/24/2016 05:51:13: ##############################################################################

11/24/2016 05:51:13: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 05:51:14: 
Model has 29 nodes. Using GPU 0.

11/24/2016 05:51:14: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 05:51:14: Evaluation criterion: err = ClassificationError

11/24/2016 05:51:14: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

11/24/2016 05:51:14: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 05:51:14: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:14: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:14: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:14: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 05:51:14: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 05:51:14: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 05:51:14: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 05:51:14: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 05:51:14: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 05:51:14: Starting minibatch loop.
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.07056923 * 2560; err = 0.84531250 * 2560; time = 0.0271s; samplesPerSecond = 94384.8
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.55888176 * 2560; err = 0.61562500 * 2560; time = 0.0228s; samplesPerSecond = 112310.3
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.04375076 * 2560; err = 0.56445313 * 2560; time = 0.0229s; samplesPerSecond = 111785.5
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.69157791 * 2560; err = 0.47539063 * 2560; time = 0.0227s; samplesPerSecond = 112532.4
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.51498489 * 2560; err = 0.44062500 * 2560; time = 0.0227s; samplesPerSecond = 112785.3
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.46821365 * 2560; err = 0.42226562 * 2560; time = 0.0227s; samplesPerSecond = 112800.2
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.46100616 * 2560; err = 0.42773438 * 2560; time = 0.0227s; samplesPerSecond = 112964.4
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.37981873 * 2560; err = 0.40585938 * 2560; time = 0.0227s; samplesPerSecond = 112904.6
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.32841187 * 2560; err = 0.38476563 * 2560; time = 0.0226s; samplesPerSecond = 113039.3
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.29073639 * 2560; err = 0.37929687 * 2560; time = 0.0227s; samplesPerSecond = 112830.0
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31770630 * 2560; err = 0.38750000 * 2560; time = 0.0227s; samplesPerSecond = 112785.3
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27957764 * 2560; err = 0.37656250 * 2560; time = 0.0226s; samplesPerSecond = 113039.3
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.24806824 * 2560; err = 0.37656250 * 2560; time = 0.0227s; samplesPerSecond = 112874.8
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.25571442 * 2560; err = 0.38281250 * 2560; time = 0.0227s; samplesPerSecond = 112835.0
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.20023193 * 2560; err = 0.35468750 * 2560; time = 0.0227s; samplesPerSecond = 112765.4
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.21815186 * 2560; err = 0.36992188 * 2560; time = 0.0227s; samplesPerSecond = 112805.1
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.21470337 * 2560; err = 0.36250000 * 2560; time = 0.0227s; samplesPerSecond = 112924.6
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.19512329 * 2560; err = 0.36914063 * 2560; time = 0.0227s; samplesPerSecond = 112820.1
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.22082825 * 2560; err = 0.37226562 * 2560; time = 0.0227s; samplesPerSecond = 112884.7
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.26091309 * 2560; err = 0.38007812 * 2560; time = 0.0227s; samplesPerSecond = 112964.4
11/24/2016 05:51:14:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.25477905 * 2560; err = 0.37304688 * 2560; time = 0.0227s; samplesPerSecond = 112700.9
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.25330505 * 2560; err = 0.38789062 * 2560; time = 0.0227s; samplesPerSecond = 112849.9
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.18610229 * 2560; err = 0.35312500 * 2560; time = 0.0227s; samplesPerSecond = 113009.3
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21104431 * 2560; err = 0.37304688 * 2560; time = 0.0227s; samplesPerSecond = 112844.9
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17974548 * 2560; err = 0.35976562 * 2560; time = 0.0227s; samplesPerSecond = 112780.3
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.14411316 * 2560; err = 0.34335938 * 2560; time = 0.0227s; samplesPerSecond = 112825.0
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13709106 * 2560; err = 0.35937500 * 2560; time = 0.0227s; samplesPerSecond = 112964.4
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.19863586 * 2560; err = 0.35546875 * 2560; time = 0.0227s; samplesPerSecond = 112939.5
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.13143311 * 2560; err = 0.33632812 * 2560; time = 0.0227s; samplesPerSecond = 112810.1
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14582825 * 2560; err = 0.35390625 * 2560; time = 0.0227s; samplesPerSecond = 112864.8
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.15142822 * 2560; err = 0.34414062 * 2560; time = 0.0227s; samplesPerSecond = 112984.4
11/24/2016 05:51:15:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.10935974 * 2560; err = 0.33593750 * 2560; time = 0.0227s; samplesPerSecond = 112750.5
11/24/2016 05:51:15: Finished Epoch[ 1 of 4]: [Training] ce = 1.41630735 * 81920; err = 0.40527344 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.898212s
11/24/2016 05:51:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.1'

11/24/2016 05:51:15: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:15: Starting minibatch loop.
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.22820740 * 5120; err = 0.37812500 * 5120; time = 0.0377s; samplesPerSecond = 135877.5
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.31571598 * 5120; err = 0.39550781 * 5120; time = 0.0328s; samplesPerSecond = 156259.5
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.24376888 * 5120; err = 0.37734375 * 5120; time = 0.0328s; samplesPerSecond = 156326.3
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.14649582 * 5120; err = 0.35214844 * 5120; time = 0.0327s; samplesPerSecond = 156412.3
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16329956 * 5120; err = 0.35488281 * 5120; time = 0.0328s; samplesPerSecond = 156240.5
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.14149628 * 5120; err = 0.35000000 * 5120; time = 0.0327s; samplesPerSecond = 156369.3
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.13500900 * 5120; err = 0.35585937 * 5120; time = 0.0328s; samplesPerSecond = 156312.0
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.09544220 * 5120; err = 0.34414062 * 5120; time = 0.0331s; samplesPerSecond = 154566.0
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.08209763 * 5120; err = 0.33046875 * 5120; time = 0.0329s; samplesPerSecond = 155391.7
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.10732346 * 5120; err = 0.34785156 * 5120; time = 0.0329s; samplesPerSecond = 155618.4
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.09839096 * 5120; err = 0.32832031 * 5120; time = 0.0329s; samplesPerSecond = 155448.3
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.07094650 * 5120; err = 0.32890625 * 5120; time = 0.0329s; samplesPerSecond = 155420.0
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.09997559 * 5120; err = 0.34023437 * 5120; time = 0.0329s; samplesPerSecond = 155410.5
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.18798370 * 5120; err = 0.36308594 * 5120; time = 0.0329s; samplesPerSecond = 155504.9
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.09574738 * 5120; err = 0.32988281 * 5120; time = 0.0330s; samplesPerSecond = 155255.0
11/24/2016 05:51:15:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06641541 * 5120; err = 0.32910156 * 5120; time = 0.0330s; samplesPerSecond = 155330.4
11/24/2016 05:51:15: Finished Epoch[ 2 of 4]: [Training] ce = 1.14239473 * 81920; err = 0.35036621 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.53406s
11/24/2016 05:51:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.2'

11/24/2016 05:51:15: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:15: Starting minibatch loop.
11/24/2016 05:51:15:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.08608227 * 5120; err = 0.33886719 * 5120; time = 0.0335s; samplesPerSecond = 152662.7
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.09881420 * 5120; err = 0.33789063 * 5120; time = 0.0329s; samplesPerSecond = 155415.3
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08656654 * 5120; err = 0.33320312 * 5120; time = 0.0329s; samplesPerSecond = 155471.9
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.05067940 * 5120; err = 0.32265625 * 5120; time = 0.0330s; samplesPerSecond = 155363.4
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07605171 * 5120; err = 0.33066406 * 5120; time = 0.0329s; samplesPerSecond = 155670.4
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.09028854 * 5120; err = 0.33593750 * 5120; time = 0.0329s; samplesPerSecond = 155542.7
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.06775436 * 5120; err = 0.32988281 * 5120; time = 0.0330s; samplesPerSecond = 155302.1
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07758789 * 5120; err = 0.33769531 * 5120; time = 0.0329s; samplesPerSecond = 155618.4
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.10700989 * 5120; err = 0.35351563 * 5120; time = 0.0329s; samplesPerSecond = 155405.8
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.03470688 * 5120; err = 0.31757812 * 5120; time = 0.0329s; samplesPerSecond = 155448.3
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.04021149 * 5120; err = 0.32675781 * 5120; time = 0.0329s; samplesPerSecond = 155538.0
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.06423187 * 5120; err = 0.33378906 * 5120; time = 0.0329s; samplesPerSecond = 155523.8
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05658569 * 5120; err = 0.33515625 * 5120; time = 0.0329s; samplesPerSecond = 155528.6
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.08156891 * 5120; err = 0.34882812 * 5120; time = 0.0330s; samplesPerSecond = 155339.8
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.02355042 * 5120; err = 0.31582031 * 5120; time = 0.0330s; samplesPerSecond = 155363.4
11/24/2016 05:51:16:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.03975220 * 5120; err = 0.32773438 * 5120; time = 0.0329s; samplesPerSecond = 155585.3
11/24/2016 05:51:16: Finished Epoch[ 3 of 4]: [Training] ce = 1.06759014 * 81920; err = 0.33287354 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.530611s
11/24/2016 05:51:16: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.3'

11/24/2016 05:51:16: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

11/24/2016 05:51:16: Starting minibatch loop.
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02325706 * 5120; err = 0.32675781 * 5120; time = 0.0335s; samplesPerSecond = 152913.4
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.00381188 * 4926; err = 0.31303289 * 4926; time = 0.0927s; samplesPerSecond = 53167.3
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02477665 * 5120; err = 0.32207031 * 5120; time = 0.0329s; samplesPerSecond = 155453.0
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.04062290 * 5120; err = 0.32128906 * 5120; time = 0.0329s; samplesPerSecond = 155448.3
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.03128586 * 5120; err = 0.32382813 * 5120; time = 0.0329s; samplesPerSecond = 155528.6
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00122795 * 5120; err = 0.31484375 * 5120; time = 0.0329s; samplesPerSecond = 155471.9
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01075020 * 5120; err = 0.31718750 * 5120; time = 0.0329s; samplesPerSecond = 155434.1
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.00836792 * 5120; err = 0.30996094 * 5120; time = 0.0330s; samplesPerSecond = 155330.4
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99221420 * 5120; err = 0.32324219 * 5120; time = 0.0329s; samplesPerSecond = 155415.3
11/24/2016 05:51:16:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98309784 * 5120; err = 0.30781250 * 5120; time = 0.0330s; samplesPerSecond = 155349.2
11/24/2016 05:51:17:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03575821 * 5120; err = 0.32050781 * 5120; time = 0.0330s; samplesPerSecond = 155311.5
11/24/2016 05:51:17:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.98441544 * 5120; err = 0.30351563 * 5120; time = 0.0330s; samplesPerSecond = 155062.2
11/24/2016 05:51:17:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00168228 * 5120; err = 0.31035156 * 5120; time = 0.0330s; samplesPerSecond = 155034.1
11/24/2016 05:51:17:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.97049561 * 5120; err = 0.30664063 * 5120; time = 0.0330s; samplesPerSecond = 155297.4
11/24/2016 05:51:17:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97470551 * 5120; err = 0.29707031 * 5120; time = 0.0330s; samplesPerSecond = 155358.7
11/24/2016 05:51:17:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97818756 * 5120; err = 0.30332031 * 5120; time = 0.0330s; samplesPerSecond = 155269.1
11/24/2016 05:51:17: Finished Epoch[ 4 of 4]: [Training] ce = 1.00425549 * 81920; err = 0.31396484 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.592748s
11/24/2016 05:51:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161124055102.584029\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech'

11/24/2016 05:51:17: Action "train" complete.

11/24/2016 05:51:17: __COMPLETED__