precision = "float"
command = speechTrain
deviceId = $DeviceId$

parallelTrain = false

frameMode = false
truncated = true

speechTrain = [
    action = "train"
    modelPath = "$RunDir$/models/cntkSpeech.dnn"
    #deviceId = $DeviceId$
    traceLevel = 1
    
    SGD = [
        epochSize = 20480
        minibatchSize = 20
        learningRatesPerMB = 0.5
        numMBsToShowResult = 10
        momentumPerMB = 0:0.9
        maxEpochs = 4
        keepCheckPointFiles = true       
    ]
    reader = [
        readerType = "Kaldi2Reader"
        readMethod = "blockRandomize"
        miniBatchMode = "partial"
        nbruttsineachrecurrentiter = 32
        randomize = "auto"
        verbosity = 0

        features = [
            dim = 363
            type = "real"
            scpFile = "$DataDir$/glob_0000.counts"
            rx= "$DataDir$/glob_0000.feats"
            featureTransform=NO_FEATURE_TRANSFORM
        ]

        labels = [
            mlfFile = "$DataDir$/glob_0000.labels"
            labelMappingFile = "$DataDir$/state.kaldi.list"
          
            labelDim = 132
            labelType = "category"
        ]
    ]

    # define network using BrainScript
    ExperimentalNetworkBuilder=[

        WeightParam(m,n) = Parameter(m, n, init='uniform', initValueScale=1, initOnCPUOnly=true, randomSeed=1)
        BiasParam(m) = ParameterTensor(m, init='fixedValue', value=0.0)
        #BiasParam(m) = Parameter(m, 1, init='fixedValue', value=0.0)
        ScalarParam() = Parameter(1, 1, init='fixedValue', value=0.0)

        NewBeta() = Exp(ScalarParam())
        Stabilize(in) = Scale(NewBeta(), in)

        LSTMPComponentWithSelfStab(inputDim, outputDim, cellDim, inputx) =
        [
            // parameter macros--these carry their own weight matrices
            B() = BiasParam(cellDim)
            Wmr = WeightParam(outputDim, cellDim);

            W(v) = WeightParam(cellDim, inputDim) * Stabilize(v)    // input-to-hidden
            H(h) = WeightParam(cellDim, outputDim) * Stabilize(h)   // hidden-to-hidden
            C(c) = DiagTimes(WeightParam(cellDim, 1), Stabilize(c)) // cell-to-hiddden

            // LSTM cell
            # TODO: This is temporary test code for the new ShiftNode (until we switch PastValue() itself over)
            PastValueShift(dimDummy, input) = Shift(input, /*fromOffsets=*/-1, /*boundaryValue=*/Constant(0.1), dim=-1)
            PastValue1 = PastValue
            #PastValue1 = PastValueShift
            dh = PastValue1(outputDim, output);                     // hidden state(t-1)
            dc = PastValue1(cellDim, ct);                           // cell(t-1)

            // note: the W(inputx) here are all different, they all come with their own set of weights; same for H(dh), C(dc), and B()
            it = Sigmoid(W(inputx) + B() + H(dh) + C(dc))           // input gate(t)
            bit = it .* Tanh(W(inputx) + (H(dh) + B()))             // applied to tanh of input network

            ft = Sigmoid(W(inputx) + B() + H(dh) + C(dc))           // forget-me-not gate(t)
            bft = ft .* dc                                          // applied to cell(t-1)

            ct = bft + bit                                          // c(t) is sum of both

            ot = Sigmoid(W(inputx) + B() + H(dh) + C(ct))           // output gate(t)
            mt = ot .* Tanh(ct)                                     // applied to tanh(cell(t))

            output = Wmr * Stabilize(mt)                            // projection
        ]

        // define basic I/O
        baseFeatDim = 33
        featDim = 11 * baseFeatDim
        labelDim = 132

        // hidden dimensions
        cellDim = 1024
        hiddenDim = 256
        numLSTMs = 3        // number of hidden LSTM model layers

        // features
        features = Input((1 : featDim),  tag='feature') // TEST: Artificially reading data transposed
        realFeatures = Transpose (features)             //       and swapping them back to (featDim:1), for testing Transpose()
        labels   = Input(labelDim, tag='label')
        feashift = RowSlice(featDim - baseFeatDim, baseFeatDim, realFeatures);

        featNorm = MeanVarNorm(feashift)

        // define the stack of hidden LSTM layers
        LSTMoutput[k:1..numLSTMs] = if k == 1
                                    then LSTMPComponentWithSelfStab(baseFeatDim, hiddenDim, cellDim, featNorm)
                                    else LSTMPComponentWithSelfStab(hiddenDim,   hiddenDim, cellDim, LSTMoutput[k-1].output)

        // and add a softmax layer on top
        W(in) = WeightParam(labelDim, hiddenDim) * Stabilize(in)
        B = BiasParam(labelDim)
        
        LSTMoutputW = W(LSTMoutput[numLSTMs].output) + B;

        // training
        cr = CrossEntropyWithSoftmax(labels, LSTMoutputW, tag='criterion')  // this is the objective
        Err = ClassificationError(labels, LSTMoutputW, tag='eval')              // this also gets tracked

        // decoding
        logPrior = LogPrior(labels)	 
        ScaledLogLikelihood = Minus(LSTMoutputW, logPrior, tag='output')    // sadly we can't say x - y since we want to assign a tag
    ]
]
