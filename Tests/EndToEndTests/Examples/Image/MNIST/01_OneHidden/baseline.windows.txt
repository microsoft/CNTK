=== Running /cygdrive/c/R/CNTK3/x64/release/cntk.exe configFile=C:\R\CNTK3\Examples\Image\MNIST\Config/01_OneHidden.cntk currentDirectory=C:\R\CNTK3\Examples\Image\MNIST\Data RunDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu DataDir=C:\R\CNTK3\Examples\Image\MNIST\Data ConfigDir=C:\R\CNTK3\Examples\Image\MNIST\Config OutputDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu DeviceId=0 timestamping=true MNISTtrain=[reader=[randomize=none]] imageLayout="cudnn"
-------------------------------------------------------------------
Build info: 

		Built time: Apr  7 2016 15:32:16
		Last modified date: Thu Apr  7 09:19:53 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\R\cub-1.4.1
		CUDNN_PATH: C:\R\cudnn-7.0-win-x64-v4.0-prod\cuda
		Build Branch: mahilleb/MNISTLinux
		Build SHA1: 5161c21b466987a144f96bad84f8763b08b05c40
		Built by mahilleb on mahilleb57
		Build Path: C:\R\CNTK3\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\R\CNTK3\Examples\Image\MNIST\Data
04/07/2016 14:48:56: -------------------------------------------------------------------
04/07/2016 14:48:56: Build info: 

04/07/2016 14:48:56: 		Built time: Apr  7 2016 15:32:16
04/07/2016 14:48:56: 		Last modified date: Thu Apr  7 09:19:53 2016
04/07/2016 14:48:56: 		Build type: Release
04/07/2016 14:48:56: 		Build target: GPU
04/07/2016 14:48:56: 		With 1bit-SGD: yes
04/07/2016 14:48:56: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
04/07/2016 14:48:56: 		CUB_PATH: C:\R\cub-1.4.1
04/07/2016 14:48:56: 		CUDNN_PATH: C:\R\cudnn-7.0-win-x64-v4.0-prod\cuda
04/07/2016 14:48:56: 		Build Branch: mahilleb/MNISTLinux
04/07/2016 14:48:56: 		Build SHA1: 5161c21b466987a144f96bad84f8763b08b05c40
04/07/2016 14:48:56: 		Built by mahilleb on mahilleb57
04/07/2016 14:48:56: 		Build Path: C:\R\CNTK3\Source\CNTK\
04/07/2016 14:48:56: -------------------------------------------------------------------

04/07/2016 14:48:56: Running on mahilleb57 at 2016/04/07 14:48:56
04/07/2016 14:48:56: Command line: 
C:\R\CNTK3\x64\release\cntk.exe  configFile=C:\R\CNTK3\Examples\Image\MNIST\Config/01_OneHidden.cntk  currentDirectory=C:\R\CNTK3\Examples\Image\MNIST\Data  RunDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu  DataDir=C:\R\CNTK3\Examples\Image\MNIST\Data  ConfigDir=C:\R\CNTK3\Examples\Image\MNIST\Config  OutputDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu  DeviceId=0  timestamping=true  MNISTtrain=[reader=[randomize=none]]  imageLayout="cudnn"



04/07/2016 14:48:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/07/2016 14:48:56: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
deviceId = 0
imageLayout = "cudnn"
command = MNISTtrain:MNISTtest
precision = "float"
modelPath = "$ModelDir$/01_OneHidden"
ndlMacros = "$ConfigDir$/Macros.ndl"
traceLevel=1
numMBsToShowResult=500
initOnCPUOnly=true
MNISTtrain = [
    action = "train"
    NDLNetworkBuilder = [
        networkDescription = "$ConfigDir$/01_OneHidden.ndl"
    ]
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerMB = 0.1
        momentumPerMB = 0
        maxEpochs = 30
    ]
    reader = [
        readerType = "UCIFastReader"
        file = "$DataDir$/Train-28x28.txt"
        features = [
            dim = 784
            start = 1
        ]
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "$DataDir$/labelsmap.txt"
        ]
    ]    
]
MNISTtest = [
    action = "test"
    minibatchSize = 16
    reader = [
        readerType = "UCIFastReader"
        file = "$DataDir$/Test-28x28.txt"
        features = [
            dim = 784
            start = 1
        ]
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "$DataDir$/labelsmap.txt"
        ]
    ]    
]
currentDirectory=C:\R\CNTK3\Examples\Image\MNIST\Data
RunDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu
DataDir=C:\R\CNTK3\Examples\Image\MNIST\Data
ConfigDir=C:\R\CNTK3\Examples\Image\MNIST\Config
OutputDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu
DeviceId=0
timestamping=true
MNISTtrain=[reader=[randomize=none]]
imageLayout="cudnn"

04/07/2016 14:48:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/07/2016 14:48:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/07/2016 14:48:56: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models"
deviceId = 0
imageLayout = "cudnn"
command = MNISTtrain:MNISTtest
precision = "float"
modelPath = "C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden"
ndlMacros = "C:\R\CNTK3\Examples\Image\MNIST\Config/Macros.ndl"
traceLevel=1
numMBsToShowResult=500
initOnCPUOnly=true
MNISTtrain = [
    action = "train"
    NDLNetworkBuilder = [
        networkDescription = "C:\R\CNTK3\Examples\Image\MNIST\Config/01_OneHidden.ndl"
    ]
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerMB = 0.1
        momentumPerMB = 0
        maxEpochs = 30
    ]
    reader = [
        readerType = "UCIFastReader"
        file = "C:\R\CNTK3\Examples\Image\MNIST\Data/Train-28x28.txt"
        features = [
            dim = 784
            start = 1
        ]
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "C:\R\CNTK3\Examples\Image\MNIST\Data/labelsmap.txt"
        ]
    ]    
]
MNISTtest = [
    action = "test"
    minibatchSize = 16
    reader = [
        readerType = "UCIFastReader"
        file = "C:\R\CNTK3\Examples\Image\MNIST\Data/Test-28x28.txt"
        features = [
            dim = 784
            start = 1
        ]
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "C:\R\CNTK3\Examples\Image\MNIST\Data/labelsmap.txt"
        ]
    ]    
]
currentDirectory=C:\R\CNTK3\Examples\Image\MNIST\Data
RunDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu
DataDir=C:\R\CNTK3\Examples\Image\MNIST\Data
ConfigDir=C:\R\CNTK3\Examples\Image\MNIST\Config
OutputDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu
DeviceId=0
timestamping=true
MNISTtrain=[reader=[randomize=none]]
imageLayout="cudnn"

04/07/2016 14:48:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/07/2016 14:48:56: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: 01_OneHidden.cntk:command=MNISTtrain:MNISTtest
configparameters: 01_OneHidden.cntk:ConfigDir=C:\R\CNTK3\Examples\Image\MNIST\Config
configparameters: 01_OneHidden.cntk:currentDirectory=C:\R\CNTK3\Examples\Image\MNIST\Data
configparameters: 01_OneHidden.cntk:DataDir=C:\R\CNTK3\Examples\Image\MNIST\Data
configparameters: 01_OneHidden.cntk:deviceId=0
configparameters: 01_OneHidden.cntk:imageLayout=cudnn
configparameters: 01_OneHidden.cntk:initOnCPUOnly=true
configparameters: 01_OneHidden.cntk:MNISTtest=[
    action = "test"
    minibatchSize = 16
    reader = [
        readerType = "UCIFastReader"
        file = "C:\R\CNTK3\Examples\Image\MNIST\Data/Test-28x28.txt"
        features = [
            dim = 784
            start = 1
        ]
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "C:\R\CNTK3\Examples\Image\MNIST\Data/labelsmap.txt"
        ]
    ]    
]

configparameters: 01_OneHidden.cntk:MNISTtrain=[
    action = "train"
    NDLNetworkBuilder = [
        networkDescription = "C:\R\CNTK3\Examples\Image\MNIST\Config/01_OneHidden.ndl"
    ]
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerMB = 0.1
        momentumPerMB = 0
        maxEpochs = 30
    ]
    reader = [
        readerType = "UCIFastReader"
        file = "C:\R\CNTK3\Examples\Image\MNIST\Data/Train-28x28.txt"
        features = [
            dim = 784
            start = 1
        ]
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "C:\R\CNTK3\Examples\Image\MNIST\Data/labelsmap.txt"
        ]
    ]    
] [reader=[randomize=none]]

configparameters: 01_OneHidden.cntk:ModelDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models
configparameters: 01_OneHidden.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden
configparameters: 01_OneHidden.cntk:ndlMacros=C:\R\CNTK3\Examples\Image\MNIST\Config/Macros.ndl
configparameters: 01_OneHidden.cntk:numMBsToShowResult=500
configparameters: 01_OneHidden.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu
configparameters: 01_OneHidden.cntk:precision=float
configparameters: 01_OneHidden.cntk:RootDir=..
configparameters: 01_OneHidden.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu
configparameters: 01_OneHidden.cntk:timestamping=true
configparameters: 01_OneHidden.cntk:traceLevel=1
04/07/2016 14:48:56: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/07/2016 14:48:56: Commands: MNISTtrain MNISTtest
04/07/2016 14:48:56: Precision = "float"
04/07/2016 14:48:56: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden
04/07/2016 14:48:56: CNTKCommandTrainInfo: MNISTtrain : 30
04/07/2016 14:48:56: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 30

04/07/2016 14:48:56: ##############################################################################
04/07/2016 14:48:56: #                                                                            #
04/07/2016 14:48:56: # Action "train"                                                             #
04/07/2016 14:48:56: #                                                                            #
04/07/2016 14:48:56: ##############################################################################

04/07/2016 14:48:56: CNTKCommandTrainBegin: MNISTtrain
NDLBuilder Using GPU 0
Reading UCI file C:\R\CNTK3\Examples\Image\MNIST\Data/Train-28x28.txt

04/07/2016 14:48:56: Creating virgin network.

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	errTop5 = ErrorPrediction()
	ol.z = Plus()

Validating network. 17 nodes to process in pass 1.


Validating network. 9 nodes to process in pass 2.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [10 x *]
Validating --> ol.W = LearnableParameter() :  -> [10 x 200]
Validating --> h1.W = LearnableParameter() :  -> [200 x 784]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> features = InputValue() :  -> [784 x *]
Validating --> featScaled = ElementTimes (featScale, features) : [1 x 1], [784 x *] -> [784 x 1 x *]
Validating --> h1.t = Times (h1.W, featScaled) : [200 x 784], [784 x 1 x *] -> [200 x 1 x *]
Validating --> h1.b = LearnableParameter() :  -> [200 x 1]
Validating --> h1.z = Plus (h1.t, h1.b) : [200 x 1 x *], [200 x 1] -> [200 x 1 x *]
Validating --> h1.y = Sigmoid (h1.z) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> ol.t = Times (ol.W, h1.y) : [10 x 200], [200 x 1 x *] -> [10 x 1 x *]
Validating --> ol.b = LearnableParameter() :  -> [10 x 1]
Validating --> ol.z = Plus (ol.t, ol.b) : [10 x 1 x *], [10 x 1] -> [10 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, ol.z) : [10 x *], [10 x 1 x *] -> [1]
Validating --> err = ErrorPrediction (labels, ol.z) : [10 x *], [10 x 1 x *] -> [1]
Validating --> unnamed81 = LearnableParameter() :  -> [1 x 1]
Validating --> errTop5 = ErrorPrediction (labels, ol.z, unnamed81) : [10 x *], [10 x 1 x *], [1 x 1] -> [1]


9 out of 17 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/07/2016 14:48:57: Created model with 17 nodes on GPU 0.

04/07/2016 14:48:57: Training criterion node(s):
04/07/2016 14:48:57: 	ce = CrossEntropyWithSoftmax

04/07/2016 14:48:57: Evaluation criterion node(s):

04/07/2016 14:48:57: 	errTop5 = ErrorPrediction
04/07/2016 14:48:57: 	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.
04/07/2016 14:48:57: No PreCompute nodes found, skipping PreCompute step.

04/07/2016 14:48:57: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
UCIFastReader: Starting at epoch 0, counting lines to determine record count...
 60000 records found.
starting epoch 0 at record count 0, and file position 0
already there from last epoch

04/07/2016 14:48:58: Starting minibatch loop.
04/07/2016 14:48:59:  Epoch[ 1 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  1.28930847; EvalErr[0]PerSample = 0.37568750; EvalErr[1]PerSample = 0.37568750; TotalTime = 0.8859s; SamplesPerSecond = 18061.6
04/07/2016 14:48:59:  Epoch[ 1 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.50096338; EvalErr[0]PerSample = 0.13118750; EvalErr[1]PerSample = 0.13118750; TotalTime = 0.7452s; SamplesPerSecond = 21472.0
04/07/2016 14:49:00:  Epoch[ 1 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.39348669; EvalErr[0]PerSample = 0.11293750; EvalErr[1]PerSample = 0.11293750; TotalTime = 0.6847s; SamplesPerSecond = 23367.7
04/07/2016 14:49:01: Finished Epoch[ 1 of 30]: [Training Set] TrainLossPerSample = 0.64864165; TotalSamplesSeen = 60000; EvalErrPerSample [0]=0.18426667; [1]=0.18426667; AvgLearningRatePerSample = 0.003125; EpochTime=3.40798
04/07/2016 14:49:01: Finished Epoch[ 1 of 30]:     Criterion Node [ce] Per Sample = 0.64864165
04/07/2016 14:49:01: Finished Epoch[ 1 of 30]:     Evaluation Node [errTop5] Per Sample = 0.18426667
04/07/2016 14:49:01: Finished Epoch[ 1 of 30]:     Evaluation Node [err] Per Sample = 0.18426667
04/07/2016 14:49:01: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.1'

04/07/2016 14:49:01: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 1 at record count 60000, and file position 0
already there from last epoch

04/07/2016 14:49:01: Starting minibatch loop.
04/07/2016 14:49:01:  Epoch[ 2 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.33642883; EvalErr[0]PerSample = 0.09581250; EvalErr[1]PerSample = 0.09581250; TotalTime = 0.4110s; SamplesPerSecond = 38925.4
04/07/2016 14:49:01:  Epoch[ 2 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.31968060; EvalErr[0]PerSample = 0.09237500; EvalErr[1]PerSample = 0.09237500; TotalTime = 0.3961s; SamplesPerSecond = 40392.4
04/07/2016 14:49:02:  Epoch[ 2 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.30829694; EvalErr[0]PerSample = 0.09081250; EvalErr[1]PerSample = 0.09081250; TotalTime = 0.4017s; SamplesPerSecond = 39828.9
04/07/2016 14:49:02: Finished Epoch[ 2 of 30]: [Training Set] TrainLossPerSample = 0.31219226; TotalSamplesSeen = 120000; EvalErrPerSample [0]=0.090116665; [1]=0.090116665; AvgLearningRatePerSample = 0.003125; EpochTime=1.50626
04/07/2016 14:49:02: Finished Epoch[ 2 of 30]:     Criterion Node [ce] Per Sample = 0.31219226
04/07/2016 14:49:02: Finished Epoch[ 2 of 30]:     Evaluation Node [errTop5] Per Sample = 0.090116665
04/07/2016 14:49:02: Finished Epoch[ 2 of 30]:     Evaluation Node [err] Per Sample = 0.090116665
04/07/2016 14:49:02: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.2'

04/07/2016 14:49:02: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 2 at record count 120000, and file position 0
already there from last epoch

04/07/2016 14:49:02: Starting minibatch loop.
04/07/2016 14:49:02:  Epoch[ 3 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.28846320; EvalErr[0]PerSample = 0.08293750; EvalErr[1]PerSample = 0.08293750; TotalTime = 0.3928s; SamplesPerSecond = 40736.8
04/07/2016 14:49:03:  Epoch[ 3 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.27885980; EvalErr[0]PerSample = 0.07968750; EvalErr[1]PerSample = 0.07968750; TotalTime = 0.4249s; SamplesPerSecond = 37659.1
04/07/2016 14:49:03:  Epoch[ 3 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.27336786; EvalErr[0]PerSample = 0.08018750; EvalErr[1]PerSample = 0.08018750; TotalTime = 0.4066s; SamplesPerSecond = 39353.7
04/07/2016 14:49:04: Finished Epoch[ 3 of 30]: [Training Set] TrainLossPerSample = 0.27297238; TotalSamplesSeen = 180000; EvalErrPerSample [0]=0.078716666; [1]=0.078716666; AvgLearningRatePerSample = 0.003125; EpochTime=1.52499
04/07/2016 14:49:04: Finished Epoch[ 3 of 30]:     Criterion Node [ce] Per Sample = 0.27297238
04/07/2016 14:49:04: Finished Epoch[ 3 of 30]:     Evaluation Node [errTop5] Per Sample = 0.078716666
04/07/2016 14:49:04: Finished Epoch[ 3 of 30]:     Evaluation Node [err] Per Sample = 0.078716666
04/07/2016 14:49:04: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.3'

04/07/2016 14:49:04: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 3 at record count 180000, and file position 0
already there from last epoch

04/07/2016 14:49:04: Starting minibatch loop.
04/07/2016 14:49:04:  Epoch[ 4 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.25608041; EvalErr[0]PerSample = 0.07331250; EvalErr[1]PerSample = 0.07331250; TotalTime = 0.4032s; SamplesPerSecond = 39686.1
04/07/2016 14:49:04:  Epoch[ 4 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.24877383; EvalErr[0]PerSample = 0.07125000; EvalErr[1]PerSample = 0.07125000; TotalTime = 0.4093s; SamplesPerSecond = 39093.1
04/07/2016 14:49:05:  Epoch[ 4 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.24436157; EvalErr[0]PerSample = 0.07162500; EvalErr[1]PerSample = 0.07162500; TotalTime = 0.4462s; SamplesPerSecond = 35858.4
04/07/2016 14:49:05: Finished Epoch[ 4 of 30]: [Training Set] TrainLossPerSample = 0.24334691; TotalSamplesSeen = 240000; EvalErrPerSample [0]=0.069933333; [1]=0.069933333; AvgLearningRatePerSample = 0.003125; EpochTime=1.59941
04/07/2016 14:49:05: Finished Epoch[ 4 of 30]:     Criterion Node [ce] Per Sample = 0.24334691
04/07/2016 14:49:05: Finished Epoch[ 4 of 30]:     Evaluation Node [errTop5] Per Sample = 0.069933333
04/07/2016 14:49:05: Finished Epoch[ 4 of 30]:     Evaluation Node [err] Per Sample = 0.069933333
04/07/2016 14:49:05: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.4'

04/07/2016 14:49:05: Starting Epoch 5: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 4 at record count 240000, and file position 0
already there from last epoch

04/07/2016 14:49:05: Starting minibatch loop.
04/07/2016 14:49:06:  Epoch[ 5 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.22827538; EvalErr[0]PerSample = 0.06593750; EvalErr[1]PerSample = 0.06593750; TotalTime = 0.4427s; SamplesPerSecond = 36145.2
04/07/2016 14:49:06:  Epoch[ 5 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.22302122; EvalErr[0]PerSample = 0.06368750; EvalErr[1]PerSample = 0.06368750; TotalTime = 0.4201s; SamplesPerSecond = 38090.3
04/07/2016 14:49:07:  Epoch[ 5 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.21961777; EvalErr[0]PerSample = 0.06381250; EvalErr[1]PerSample = 0.06381250; TotalTime = 0.4232s; SamplesPerSecond = 37806.1
04/07/2016 14:49:07: Finished Epoch[ 5 of 30]: [Training Set] TrainLossPerSample = 0.2180291; TotalSamplesSeen = 300000; EvalErrPerSample [0]=0.0623; [1]=0.0623; AvgLearningRatePerSample = 0.003125; EpochTime=1.63154
04/07/2016 14:49:07: Finished Epoch[ 5 of 30]:     Criterion Node [ce] Per Sample = 0.2180291
04/07/2016 14:49:07: Finished Epoch[ 5 of 30]:     Evaluation Node [errTop5] Per Sample = 0.0623
04/07/2016 14:49:07: Finished Epoch[ 5 of 30]:     Evaluation Node [err] Per Sample = 0.0623
04/07/2016 14:49:07: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.5'

04/07/2016 14:49:07: Starting Epoch 6: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 5 at record count 300000, and file position 0
already there from last epoch

04/07/2016 14:49:07: Starting minibatch loop.
04/07/2016 14:49:07:  Epoch[ 6 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.20467020; EvalErr[0]PerSample = 0.05868750; EvalErr[1]PerSample = 0.05868750; TotalTime = 0.4071s; SamplesPerSecond = 39298.3
04/07/2016 14:49:08:  Epoch[ 6 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.20118964; EvalErr[0]PerSample = 0.05825000; EvalErr[1]PerSample = 0.05825000; TotalTime = 0.4105s; SamplesPerSecond = 38974.6
04/07/2016 14:49:08:  Epoch[ 6 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.19883932; EvalErr[0]PerSample = 0.05775000; EvalErr[1]PerSample = 0.05775000; TotalTime = 0.4028s; SamplesPerSecond = 39719.1
04/07/2016 14:49:08: Finished Epoch[ 6 of 30]: [Training Set] TrainLossPerSample = 0.19664152; TotalSamplesSeen = 360000; EvalErrPerSample [0]=0.05635; [1]=0.05635; AvgLearningRatePerSample = 0.003125; EpochTime=1.54017
04/07/2016 14:49:08: Finished Epoch[ 6 of 30]:     Criterion Node [ce] Per Sample = 0.19664152
04/07/2016 14:49:08: Finished Epoch[ 6 of 30]:     Evaluation Node [errTop5] Per Sample = 0.05635
04/07/2016 14:49:08: Finished Epoch[ 6 of 30]:     Evaluation Node [err] Per Sample = 0.05635
04/07/2016 14:49:09: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.6'

04/07/2016 14:49:09: Starting Epoch 7: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 6 at record count 360000, and file position 0
already there from last epoch

04/07/2016 14:49:09: Starting minibatch loop.
04/07/2016 14:49:09:  Epoch[ 7 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.18476917; EvalErr[0]PerSample = 0.05306250; EvalErr[1]PerSample = 0.05306250; TotalTime = 0.4088s; SamplesPerSecond = 39141.9
04/07/2016 14:49:09:  Epoch[ 7 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.18272620; EvalErr[0]PerSample = 0.05325000; EvalErr[1]PerSample = 0.05325000; TotalTime = 0.3998s; SamplesPerSecond = 40015.8
04/07/2016 14:49:10:  Epoch[ 7 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.18130524; EvalErr[0]PerSample = 0.05287500; EvalErr[1]PerSample = 0.05287500; TotalTime = 0.4255s; SamplesPerSecond = 37601.1
04/07/2016 14:49:10: Finished Epoch[ 7 of 30]: [Training Set] TrainLossPerSample = 0.17858277; TotalSamplesSeen = 420000; EvalErrPerSample [0]=0.051366668; [1]=0.051366668; AvgLearningRatePerSample = 0.003125; EpochTime=1.55222
04/07/2016 14:49:10: Finished Epoch[ 7 of 30]:     Criterion Node [ce] Per Sample = 0.17858277
04/07/2016 14:49:10: Finished Epoch[ 7 of 30]:     Evaluation Node [errTop5] Per Sample = 0.051366668
04/07/2016 14:49:10: Finished Epoch[ 7 of 30]:     Evaluation Node [err] Per Sample = 0.051366668
04/07/2016 14:49:10: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.7'

04/07/2016 14:49:10: Starting Epoch 8: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 7 at record count 420000, and file position 0
already there from last epoch

04/07/2016 14:49:10: Starting minibatch loop.
04/07/2016 14:49:11:  Epoch[ 8 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.16791026; EvalErr[0]PerSample = 0.04856250; EvalErr[1]PerSample = 0.04856250; TotalTime = 0.4023s; SamplesPerSecond = 39773.9
04/07/2016 14:49:11:  Epoch[ 8 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.16702440; EvalErr[0]PerSample = 0.04756250; EvalErr[1]PerSample = 0.04756250; TotalTime = 0.4014s; SamplesPerSecond = 39855.8
04/07/2016 14:49:11:  Epoch[ 8 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.16637323; EvalErr[0]PerSample = 0.04706250; EvalErr[1]PerSample = 0.04706250; TotalTime = 0.4006s; SamplesPerSecond = 39935.7
04/07/2016 14:49:12: Finished Epoch[ 8 of 30]: [Training Set] TrainLossPerSample = 0.16323005; TotalSamplesSeen = 480000; EvalErrPerSample [0]=0.046350002; [1]=0.046350002; AvgLearningRatePerSample = 0.003125; EpochTime=1.50533
04/07/2016 14:49:12: Finished Epoch[ 8 of 30]:     Criterion Node [ce] Per Sample = 0.16323005
04/07/2016 14:49:12: Finished Epoch[ 8 of 30]:     Evaluation Node [errTop5] Per Sample = 0.046350002
04/07/2016 14:49:12: Finished Epoch[ 8 of 30]:     Evaluation Node [err] Per Sample = 0.046350002
04/07/2016 14:49:12: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.8'

04/07/2016 14:49:12: Starting Epoch 9: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 8 at record count 480000, and file position 0
already there from last epoch

04/07/2016 14:49:12: Starting minibatch loop.
04/07/2016 14:49:12:  Epoch[ 9 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.15350847; EvalErr[0]PerSample = 0.04406250; EvalErr[1]PerSample = 0.04406250; TotalTime = 0.4002s; SamplesPerSecond = 39978.2
04/07/2016 14:49:12:  Epoch[ 9 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.15356984; EvalErr[0]PerSample = 0.04381250; EvalErr[1]PerSample = 0.04381250; TotalTime = 0.4039s; SamplesPerSecond = 39612.3
04/07/2016 14:49:13:  Epoch[ 9 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.15354349; EvalErr[0]PerSample = 0.04325000; EvalErr[1]PerSample = 0.04325000; TotalTime = 0.4011s; SamplesPerSecond = 39890.7
04/07/2016 14:49:13: Finished Epoch[ 9 of 30]: [Training Set] TrainLossPerSample = 0.15006728; TotalSamplesSeen = 540000; EvalErrPerSample [0]=0.042533334; [1]=0.042533334; AvgLearningRatePerSample = 0.003125; EpochTime=1.50807
04/07/2016 14:49:13: Finished Epoch[ 9 of 30]:     Criterion Node [ce] Per Sample = 0.15006728
04/07/2016 14:49:13: Finished Epoch[ 9 of 30]:     Evaluation Node [errTop5] Per Sample = 0.042533334
04/07/2016 14:49:13: Finished Epoch[ 9 of 30]:     Evaluation Node [err] Per Sample = 0.042533334
04/07/2016 14:49:13: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.9'

04/07/2016 14:49:13: Starting Epoch 10: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 9 at record count 540000, and file position 0
already there from last epoch

04/07/2016 14:49:13: Starting minibatch loop.
04/07/2016 14:49:14:  Epoch[10 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.14108638; EvalErr[0]PerSample = 0.04043750; EvalErr[1]PerSample = 0.04043750; TotalTime = 0.4020s; SamplesPerSecond = 39805.4
04/07/2016 14:49:14:  Epoch[10 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.14194075; EvalErr[0]PerSample = 0.04112500; EvalErr[1]PerSample = 0.04112500; TotalTime = 0.3985s; SamplesPerSecond = 40155.4
04/07/2016 14:49:14:  Epoch[10 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.14241907; EvalErr[0]PerSample = 0.04043750; EvalErr[1]PerSample = 0.04043750; TotalTime = 0.3966s; SamplesPerSecond = 40343.1
04/07/2016 14:49:15: Finished Epoch[10 of 30]: [Training Set] TrainLossPerSample = 0.13867831; TotalSamplesSeen = 600000; EvalErrPerSample [0]=0.039433334; [1]=0.039433334; AvgLearningRatePerSample = 0.003125; EpochTime=1.49635
04/07/2016 14:49:15: Finished Epoch[10 of 30]:     Criterion Node [ce] Per Sample = 0.13867831
04/07/2016 14:49:15: Finished Epoch[10 of 30]:     Evaluation Node [errTop5] Per Sample = 0.039433334
04/07/2016 14:49:15: Finished Epoch[10 of 30]:     Evaluation Node [err] Per Sample = 0.039433334
04/07/2016 14:49:15: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.10'

04/07/2016 14:49:15: Starting Epoch 11: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 10 at record count 600000, and file position 0
already there from last epoch

04/07/2016 14:49:15: Starting minibatch loop.
04/07/2016 14:49:15:  Epoch[11 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.13026932; EvalErr[0]PerSample = 0.03768750; EvalErr[1]PerSample = 0.03768750; TotalTime = 0.4008s; SamplesPerSecond = 39923.9
04/07/2016 14:49:16:  Epoch[11 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.13180487; EvalErr[0]PerSample = 0.03762500; EvalErr[1]PerSample = 0.03762500; TotalTime = 0.4001s; SamplesPerSecond = 39991.1
04/07/2016 14:49:16:  Epoch[11 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.13268649; EvalErr[0]PerSample = 0.03768750; EvalErr[1]PerSample = 0.03768750; TotalTime = 0.4010s; SamplesPerSecond = 39898.8
04/07/2016 14:49:16: Finished Epoch[11 of 30]: [Training Set] TrainLossPerSample = 0.1287349; TotalSamplesSeen = 660000; EvalErrPerSample [0]=0.036533333; [1]=0.036533333; AvgLearningRatePerSample = 0.003125; EpochTime=1.50423
04/07/2016 14:49:16: Finished Epoch[11 of 30]:     Criterion Node [ce] Per Sample = 0.1287349
04/07/2016 14:49:16: Finished Epoch[11 of 30]:     Evaluation Node [errTop5] Per Sample = 0.036533333
04/07/2016 14:49:16: Finished Epoch[11 of 30]:     Evaluation Node [err] Per Sample = 0.036533333
04/07/2016 14:49:16: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.11'

04/07/2016 14:49:16: Starting Epoch 12: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 11 at record count 660000, and file position 0
already there from last epoch

04/07/2016 14:49:16: Starting minibatch loop.
04/07/2016 14:49:17:  Epoch[12 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.12077362; EvalErr[0]PerSample = 0.03375000; EvalErr[1]PerSample = 0.03375000; TotalTime = 0.3991s; SamplesPerSecond = 40094.1
04/07/2016 14:49:17:  Epoch[12 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.12290393; EvalErr[0]PerSample = 0.03518750; EvalErr[1]PerSample = 0.03518750; TotalTime = 0.4015s; SamplesPerSecond = 39850.5
04/07/2016 14:49:17:  Epoch[12 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.12410324; EvalErr[0]PerSample = 0.03525000; EvalErr[1]PerSample = 0.03525000; TotalTime = 0.4013s; SamplesPerSecond = 39872.8
04/07/2016 14:49:18: Finished Epoch[12 of 30]: [Training Set] TrainLossPerSample = 0.11998519; TotalSamplesSeen = 720000; EvalErrPerSample [0]=0.033800002; [1]=0.033800002; AvgLearningRatePerSample = 0.003125; EpochTime=1.50444
04/07/2016 14:49:18: Finished Epoch[12 of 30]:     Criterion Node [ce] Per Sample = 0.11998519
04/07/2016 14:49:18: Finished Epoch[12 of 30]:     Evaluation Node [errTop5] Per Sample = 0.033800002
04/07/2016 14:49:18: Finished Epoch[12 of 30]:     Evaluation Node [err] Per Sample = 0.033800002
04/07/2016 14:49:18: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.12'

04/07/2016 14:49:18: Starting Epoch 13: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 12 at record count 720000, and file position 0
already there from last epoch

04/07/2016 14:49:18: Starting minibatch loop.
04/07/2016 14:49:18:  Epoch[13 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.11238457; EvalErr[0]PerSample = 0.03125000; EvalErr[1]PerSample = 0.03125000; TotalTime = 0.4007s; SamplesPerSecond = 39930.7
04/07/2016 14:49:19:  Epoch[13 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.11503398; EvalErr[0]PerSample = 0.03281250; EvalErr[1]PerSample = 0.03281250; TotalTime = 0.4017s; SamplesPerSecond = 39835.7
04/07/2016 14:49:19:  Epoch[13 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.11648001; EvalErr[0]PerSample = 0.03312500; EvalErr[1]PerSample = 0.03312500; TotalTime = 0.3994s; SamplesPerSecond = 40064.2
04/07/2016 14:49:19: Finished Epoch[13 of 30]: [Training Set] TrainLossPerSample = 0.11223369; TotalSamplesSeen = 780000; EvalErrPerSample [0]=0.031550001; [1]=0.031550001; AvgLearningRatePerSample = 0.003125; EpochTime=1.50349
04/07/2016 14:49:19: Finished Epoch[13 of 30]:     Criterion Node [ce] Per Sample = 0.11223369
04/07/2016 14:49:19: Finished Epoch[13 of 30]:     Evaluation Node [errTop5] Per Sample = 0.031550001
04/07/2016 14:49:19: Finished Epoch[13 of 30]:     Evaluation Node [err] Per Sample = 0.031550001
04/07/2016 14:49:19: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.13'

04/07/2016 14:49:19: Starting Epoch 14: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 13 at record count 780000, and file position 0
already there from last epoch

04/07/2016 14:49:19: Starting minibatch loop.
04/07/2016 14:49:20:  Epoch[14 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.10493344; EvalErr[0]PerSample = 0.02881250; EvalErr[1]PerSample = 0.02881250; TotalTime = 0.4009s; SamplesPerSecond = 39908.0
04/07/2016 14:49:20:  Epoch[14 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.10803001; EvalErr[0]PerSample = 0.03037500; EvalErr[1]PerSample = 0.03037500; TotalTime = 0.4019s; SamplesPerSecond = 39812.9
04/07/2016 14:49:21:  Epoch[14 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.10966496; EvalErr[0]PerSample = 0.03131250; EvalErr[1]PerSample = 0.03131250; TotalTime = 0.3999s; SamplesPerSecond = 40009.5
04/07/2016 14:49:21: Finished Epoch[14 of 30]: [Training Set] TrainLossPerSample = 0.10532398; TotalSamplesSeen = 840000; EvalErrPerSample [0]=0.029366666; [1]=0.029366666; AvgLearningRatePerSample = 0.003125; EpochTime=1.50479
04/07/2016 14:49:21: Finished Epoch[14 of 30]:     Criterion Node [ce] Per Sample = 0.10532398
04/07/2016 14:49:21: Finished Epoch[14 of 30]:     Evaluation Node [errTop5] Per Sample = 0.029366666
04/07/2016 14:49:21: Finished Epoch[14 of 30]:     Evaluation Node [err] Per Sample = 0.029366666
04/07/2016 14:49:21: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.14'

04/07/2016 14:49:21: Starting Epoch 15: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 14 at record count 840000, and file position 0
already there from last epoch

04/07/2016 14:49:21: Starting minibatch loop.
04/07/2016 14:49:21:  Epoch[15 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.09828265; EvalErr[0]PerSample = 0.02781250; EvalErr[1]PerSample = 0.02781250; TotalTime = 0.4005s; SamplesPerSecond = 39951.0
04/07/2016 14:49:22:  Epoch[15 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.10175670; EvalErr[0]PerSample = 0.02887500; EvalErr[1]PerSample = 0.02887500; TotalTime = 0.3984s; SamplesPerSecond = 40164.4
04/07/2016 14:49:22:  Epoch[15 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.10353468; EvalErr[0]PerSample = 0.02975000; EvalErr[1]PerSample = 0.02975000; TotalTime = 0.3979s; SamplesPerSecond = 40211.4
04/07/2016 14:49:22: Finished Epoch[15 of 30]: [Training Set] TrainLossPerSample = 0.099128082; TotalSamplesSeen = 900000; EvalErrPerSample [0]=0.027900001; [1]=0.027900001; AvgLearningRatePerSample = 0.003125; EpochTime=1.4965
04/07/2016 14:49:22: Finished Epoch[15 of 30]:     Criterion Node [ce] Per Sample = 0.099128082
04/07/2016 14:49:22: Finished Epoch[15 of 30]:     Evaluation Node [errTop5] Per Sample = 0.027900001
04/07/2016 14:49:22: Finished Epoch[15 of 30]:     Evaluation Node [err] Per Sample = 0.027900001
04/07/2016 14:49:22: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.15'

04/07/2016 14:49:22: Starting Epoch 16: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 15 at record count 900000, and file position 0
already there from last epoch

04/07/2016 14:49:22: Starting minibatch loop.
04/07/2016 14:49:23:  Epoch[16 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.09231853; EvalErr[0]PerSample = 0.02643750; EvalErr[1]PerSample = 0.02643750; TotalTime = 0.4014s; SamplesPerSecond = 39863.1
04/07/2016 14:49:23:  Epoch[16 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.09610316; EvalErr[0]PerSample = 0.02700000; EvalErr[1]PerSample = 0.02700000; TotalTime = 0.4001s; SamplesPerSecond = 39993.7
04/07/2016 14:49:24:  Epoch[16 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.09798691; EvalErr[0]PerSample = 0.02768750; EvalErr[1]PerSample = 0.02768750; TotalTime = 0.4012s; SamplesPerSecond = 39878.7
04/07/2016 14:49:24: Finished Epoch[16 of 30]: [Training Set] TrainLossPerSample = 0.09354043; TotalSamplesSeen = 960000; EvalErrPerSample [0]=0.0262; [1]=0.0262; AvgLearningRatePerSample = 0.003125; EpochTime=1.50569
04/07/2016 14:49:24: Finished Epoch[16 of 30]:     Criterion Node [ce] Per Sample = 0.09354043
04/07/2016 14:49:24: Finished Epoch[16 of 30]:     Evaluation Node [errTop5] Per Sample = 0.0262
04/07/2016 14:49:24: Finished Epoch[16 of 30]:     Evaluation Node [err] Per Sample = 0.0262
04/07/2016 14:49:24: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.16'

04/07/2016 14:49:24: Starting Epoch 17: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 16 at record count 960000, and file position 0
already there from last epoch

04/07/2016 14:49:24: Starting minibatch loop.
04/07/2016 14:49:24:  Epoch[17 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.08694670; EvalErr[0]PerSample = 0.02512500; EvalErr[1]PerSample = 0.02512500; TotalTime = 0.4001s; SamplesPerSecond = 39986.7
04/07/2016 14:49:25:  Epoch[17 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.09097736; EvalErr[0]PerSample = 0.02537500; EvalErr[1]PerSample = 0.02537500; TotalTime = 0.4006s; SamplesPerSecond = 39935.5
04/07/2016 14:49:25:  Epoch[17 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.09293706; EvalErr[0]PerSample = 0.02662500; EvalErr[1]PerSample = 0.02662500; TotalTime = 0.4002s; SamplesPerSecond = 39975.6
04/07/2016 14:49:25: Finished Epoch[17 of 30]: [Training Set] TrainLossPerSample = 0.088473409; TotalSamplesSeen = 1020000; EvalErrPerSample [0]=0.024916667; [1]=0.024916667; AvgLearningRatePerSample = 0.003125; EpochTime=1.50249
04/07/2016 14:49:25: Finished Epoch[17 of 30]:     Criterion Node [ce] Per Sample = 0.088473409
04/07/2016 14:49:25: Finished Epoch[17 of 30]:     Evaluation Node [errTop5] Per Sample = 0.024916667
04/07/2016 14:49:25: Finished Epoch[17 of 30]:     Evaluation Node [err] Per Sample = 0.024916667
04/07/2016 14:49:25: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.17'

04/07/2016 14:49:25: Starting Epoch 18: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 17 at record count 1020000, and file position 0
already there from last epoch

04/07/2016 14:49:25: Starting minibatch loop.
04/07/2016 14:49:26:  Epoch[18 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.08208772; EvalErr[0]PerSample = 0.02268750; EvalErr[1]PerSample = 0.02268750; TotalTime = 0.4007s; SamplesPerSecond = 39931.9
04/07/2016 14:49:26:  Epoch[18 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.08630401; EvalErr[0]PerSample = 0.02412500; EvalErr[1]PerSample = 0.02412500; TotalTime = 0.4005s; SamplesPerSecond = 39951.7
04/07/2016 14:49:27:  Epoch[18 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.08831522; EvalErr[0]PerSample = 0.02512500; EvalErr[1]PerSample = 0.02512500; TotalTime = 0.4077s; SamplesPerSecond = 39240.1
04/07/2016 14:49:27: Finished Epoch[18 of 30]: [Training Set] TrainLossPerSample = 0.083854452; TotalSamplesSeen = 1080000; EvalErrPerSample [0]=0.023250001; [1]=0.023250001; AvgLearningRatePerSample = 0.003125; EpochTime=1.52544
04/07/2016 14:49:27: Finished Epoch[18 of 30]:     Criterion Node [ce] Per Sample = 0.083854452
04/07/2016 14:49:27: Finished Epoch[18 of 30]:     Evaluation Node [errTop5] Per Sample = 0.023250001
04/07/2016 14:49:27: Finished Epoch[18 of 30]:     Evaluation Node [err] Per Sample = 0.023250001
04/07/2016 14:49:27: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.18'

04/07/2016 14:49:27: Starting Epoch 19: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 18 at record count 1080000, and file position 0
already there from last epoch

04/07/2016 14:49:27: Starting minibatch loop.
04/07/2016 14:49:27:  Epoch[19 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.07767484; EvalErr[0]PerSample = 0.02112500; EvalErr[1]PerSample = 0.02112500; TotalTime = 0.4860s; SamplesPerSecond = 32919.6
04/07/2016 14:49:28:  Epoch[19 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.08202056; EvalErr[0]PerSample = 0.02268750; EvalErr[1]PerSample = 0.02268750; TotalTime = 0.4952s; SamplesPerSecond = 32309.7
04/07/2016 14:49:28:  Epoch[19 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.08406421; EvalErr[0]PerSample = 0.02356250; EvalErr[1]PerSample = 0.02356250; TotalTime = 0.4924s; SamplesPerSecond = 32494.2
04/07/2016 14:49:29: Finished Epoch[19 of 30]: [Training Set] TrainLossPerSample = 0.079624176; TotalSamplesSeen = 1140000; EvalErrPerSample [0]=0.021883333; [1]=0.021883333; AvgLearningRatePerSample = 0.003125; EpochTime=1.82496
04/07/2016 14:49:29: Finished Epoch[19 of 30]:     Criterion Node [ce] Per Sample = 0.079624176
04/07/2016 14:49:29: Finished Epoch[19 of 30]:     Evaluation Node [errTop5] Per Sample = 0.021883333
04/07/2016 14:49:29: Finished Epoch[19 of 30]:     Evaluation Node [err] Per Sample = 0.021883333
04/07/2016 14:49:29: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.19'

04/07/2016 14:49:29: Starting Epoch 20: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 19 at record count 1140000, and file position 0
already there from last epoch

04/07/2016 14:49:29: Starting minibatch loop.
04/07/2016 14:49:29:  Epoch[20 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.07365132; EvalErr[0]PerSample = 0.01987500; EvalErr[1]PerSample = 0.01987500; TotalTime = 0.4603s; SamplesPerSecond = 34759.9
04/07/2016 14:49:30:  Epoch[20 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.07807613; EvalErr[0]PerSample = 0.02200000; EvalErr[1]PerSample = 0.02200000; TotalTime = 0.4763s; SamplesPerSecond = 33593.6
04/07/2016 14:49:30:  Epoch[20 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.08013644; EvalErr[0]PerSample = 0.02243750; EvalErr[1]PerSample = 0.02243750; TotalTime = 0.4585s; SamplesPerSecond = 34893.4
04/07/2016 14:49:31: Finished Epoch[20 of 30]: [Training Set] TrainLossPerSample = 0.075732835; TotalSamplesSeen = 1200000; EvalErrPerSample [0]=0.020933334; [1]=0.020933334; AvgLearningRatePerSample = 0.003125; EpochTime=1.7424
04/07/2016 14:49:31: Finished Epoch[20 of 30]:     Criterion Node [ce] Per Sample = 0.075732835
04/07/2016 14:49:31: Finished Epoch[20 of 30]:     Evaluation Node [errTop5] Per Sample = 0.020933334
04/07/2016 14:49:31: Finished Epoch[20 of 30]:     Evaluation Node [err] Per Sample = 0.020933334
04/07/2016 14:49:31: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.20'

04/07/2016 14:49:31: Starting Epoch 21: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 20 at record count 1200000, and file position 0
already there from last epoch

04/07/2016 14:49:31: Starting minibatch loop.
04/07/2016 14:49:31:  Epoch[21 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.06996849; EvalErr[0]PerSample = 0.01900000; EvalErr[1]PerSample = 0.01900000; TotalTime = 0.4846s; SamplesPerSecond = 33014.6
04/07/2016 14:49:32:  Epoch[21 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.07442801; EvalErr[0]PerSample = 0.02100000; EvalErr[1]PerSample = 0.02100000; TotalTime = 0.4574s; SamplesPerSecond = 34981.2
04/07/2016 14:49:32:  Epoch[21 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.07649426; EvalErr[0]PerSample = 0.02143750; EvalErr[1]PerSample = 0.02143750; TotalTime = 0.4427s; SamplesPerSecond = 36140.6
04/07/2016 14:49:32: Finished Epoch[21 of 30]: [Training Set] TrainLossPerSample = 0.072139725; TotalSamplesSeen = 1260000; EvalErrPerSample [0]=0.019916667; [1]=0.019916667; AvgLearningRatePerSample = 0.003125; EpochTime=1.71984
04/07/2016 14:49:32: Finished Epoch[21 of 30]:     Criterion Node [ce] Per Sample = 0.072139725
04/07/2016 14:49:32: Finished Epoch[21 of 30]:     Evaluation Node [errTop5] Per Sample = 0.019916667
04/07/2016 14:49:32: Finished Epoch[21 of 30]:     Evaluation Node [err] Per Sample = 0.019916667
04/07/2016 14:49:32: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.21'

04/07/2016 14:49:32: Starting Epoch 22: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 21 at record count 1260000, and file position 0
already there from last epoch

04/07/2016 14:49:32: Starting minibatch loop.
04/07/2016 14:49:33:  Epoch[22 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.06658476; EvalErr[0]PerSample = 0.01781250; EvalErr[1]PerSample = 0.01781250; TotalTime = 0.4218s; SamplesPerSecond = 37928.7
04/07/2016 14:49:33:  Epoch[22 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.07104192; EvalErr[0]PerSample = 0.01968750; EvalErr[1]PerSample = 0.01968750; TotalTime = 0.4471s; SamplesPerSecond = 35785.3
04/07/2016 14:49:34:  Epoch[22 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.07310529; EvalErr[0]PerSample = 0.02025000; EvalErr[1]PerSample = 0.02025000; TotalTime = 0.4293s; SamplesPerSecond = 37272.8
04/07/2016 14:49:34: Finished Epoch[22 of 30]: [Training Set] TrainLossPerSample = 0.068810955; TotalSamplesSeen = 1320000; EvalErrPerSample [0]=0.0188; [1]=0.0188; AvgLearningRatePerSample = 0.003125; EpochTime=1.61324
04/07/2016 14:49:34: Finished Epoch[22 of 30]:     Criterion Node [ce] Per Sample = 0.068810955
04/07/2016 14:49:34: Finished Epoch[22 of 30]:     Evaluation Node [errTop5] Per Sample = 0.0188
04/07/2016 14:49:34: Finished Epoch[22 of 30]:     Evaluation Node [err] Per Sample = 0.0188
04/07/2016 14:49:34: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.22'

04/07/2016 14:49:34: Starting Epoch 23: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 22 at record count 1320000, and file position 0
already there from last epoch

04/07/2016 14:49:34: Starting minibatch loop.
04/07/2016 14:49:34:  Epoch[23 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.06346445; EvalErr[0]PerSample = 0.01668750; EvalErr[1]PerSample = 0.01668750; TotalTime = 0.4318s; SamplesPerSecond = 37052.0
04/07/2016 14:49:35:  Epoch[23 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.06788847; EvalErr[0]PerSample = 0.01906250; EvalErr[1]PerSample = 0.01906250; TotalTime = 0.4527s; SamplesPerSecond = 35346.5
04/07/2016 14:49:35:  Epoch[23 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.06994334; EvalErr[0]PerSample = 0.01962500; EvalErr[1]PerSample = 0.01962500; TotalTime = 0.4259s; SamplesPerSecond = 37570.6
04/07/2016 14:49:36: Finished Epoch[23 of 30]: [Training Set] TrainLossPerSample = 0.065717839; TotalSamplesSeen = 1380000; EvalErrPerSample [0]=0.018066667; [1]=0.018066667; AvgLearningRatePerSample = 0.003125; EpochTime=1.62343
04/07/2016 14:49:36: Finished Epoch[23 of 30]:     Criterion Node [ce] Per Sample = 0.065717839
04/07/2016 14:49:36: Finished Epoch[23 of 30]:     Evaluation Node [errTop5] Per Sample = 0.018066667
04/07/2016 14:49:36: Finished Epoch[23 of 30]:     Evaluation Node [err] Per Sample = 0.018066667
04/07/2016 14:49:36: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.23'

04/07/2016 14:49:36: Starting Epoch 24: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 23 at record count 1380000, and file position 0
already there from last epoch

04/07/2016 14:49:36: Starting minibatch loop.
04/07/2016 14:49:36:  Epoch[24 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.06057711; EvalErr[0]PerSample = 0.01612500; EvalErr[1]PerSample = 0.01612500; TotalTime = 0.4343s; SamplesPerSecond = 36837.6
04/07/2016 14:49:37:  Epoch[24 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.06494395; EvalErr[0]PerSample = 0.01787500; EvalErr[1]PerSample = 0.01787500; TotalTime = 0.4401s; SamplesPerSecond = 36357.6
04/07/2016 14:49:37:  Epoch[24 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.06698516; EvalErr[0]PerSample = 0.01881250; EvalErr[1]PerSample = 0.01881250; TotalTime = 0.4206s; SamplesPerSecond = 38040.4
04/07/2016 14:49:37: Finished Epoch[24 of 30]: [Training Set] TrainLossPerSample = 0.062835939; TotalSamplesSeen = 1440000; EvalErrPerSample [0]=0.017183334; [1]=0.017183334; AvgLearningRatePerSample = 0.003125; EpochTime=1.63118
04/07/2016 14:49:37: Finished Epoch[24 of 30]:     Criterion Node [ce] Per Sample = 0.062835939
04/07/2016 14:49:37: Finished Epoch[24 of 30]:     Evaluation Node [errTop5] Per Sample = 0.017183334
04/07/2016 14:49:37: Finished Epoch[24 of 30]:     Evaluation Node [err] Per Sample = 0.017183334
04/07/2016 14:49:37: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.24'

04/07/2016 14:49:37: Starting Epoch 25: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 24 at record count 1440000, and file position 0
already there from last epoch

04/07/2016 14:49:37: Starting minibatch loop.
04/07/2016 14:49:38:  Epoch[25 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.05789647; EvalErr[0]PerSample = 0.01525000; EvalErr[1]PerSample = 0.01525000; TotalTime = 0.4240s; SamplesPerSecond = 37739.9
04/07/2016 14:49:38:  Epoch[25 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.06218763; EvalErr[0]PerSample = 0.01693750; EvalErr[1]PerSample = 0.01693750; TotalTime = 0.4049s; SamplesPerSecond = 39519.1
04/07/2016 14:49:39:  Epoch[25 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.06421169; EvalErr[0]PerSample = 0.01775000; EvalErr[1]PerSample = 0.01775000; TotalTime = 0.3995s; SamplesPerSecond = 40050.9
04/07/2016 14:49:39: Finished Epoch[25 of 30]: [Training Set] TrainLossPerSample = 0.060144316; TotalSamplesSeen = 1500000; EvalErrPerSample [0]=0.016216667; [1]=0.016216667; AvgLearningRatePerSample = 0.003125; EpochTime=1.55418
04/07/2016 14:49:39: Finished Epoch[25 of 30]:     Criterion Node [ce] Per Sample = 0.060144316
04/07/2016 14:49:39: Finished Epoch[25 of 30]:     Evaluation Node [errTop5] Per Sample = 0.016216667
04/07/2016 14:49:39: Finished Epoch[25 of 30]:     Evaluation Node [err] Per Sample = 0.016216667
04/07/2016 14:49:39: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.25'

04/07/2016 14:49:39: Starting Epoch 26: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 25 at record count 1500000, and file position 0
already there from last epoch

04/07/2016 14:49:39: Starting minibatch loop.
04/07/2016 14:49:39:  Epoch[26 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.05540020; EvalErr[0]PerSample = 0.01456250; EvalErr[1]PerSample = 0.01456250; TotalTime = 0.4228s; SamplesPerSecond = 37840.8
04/07/2016 14:49:40:  Epoch[26 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.05960179; EvalErr[0]PerSample = 0.01625000; EvalErr[1]PerSample = 0.01625000; TotalTime = 0.4376s; SamplesPerSecond = 36564.9
04/07/2016 14:49:40:  Epoch[26 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.06160596; EvalErr[0]PerSample = 0.01693750; EvalErr[1]PerSample = 0.01693750; TotalTime = 0.4307s; SamplesPerSecond = 37152.7
04/07/2016 14:49:41: Finished Epoch[26 of 30]: [Training Set] TrainLossPerSample = 0.05762472; TotalSamplesSeen = 1560000; EvalErrPerSample [0]=0.015433334; [1]=0.015433334; AvgLearningRatePerSample = 0.003125; EpochTime=1.61449
04/07/2016 14:49:41: Finished Epoch[26 of 30]:     Criterion Node [ce] Per Sample = 0.05762472
04/07/2016 14:49:41: Finished Epoch[26 of 30]:     Evaluation Node [errTop5] Per Sample = 0.015433334
04/07/2016 14:49:41: Finished Epoch[26 of 30]:     Evaluation Node [err] Per Sample = 0.015433334
04/07/2016 14:49:41: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.26'

04/07/2016 14:49:41: Starting Epoch 27: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 26 at record count 1560000, and file position 0
already there from last epoch

04/07/2016 14:49:41: Starting minibatch loop.
04/07/2016 14:49:41:  Epoch[27 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.05306902; EvalErr[0]PerSample = 0.01381250; EvalErr[1]PerSample = 0.01381250; TotalTime = 0.4103s; SamplesPerSecond = 38991.7
04/07/2016 14:49:41:  Epoch[27 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.05717074; EvalErr[0]PerSample = 0.01531250; EvalErr[1]PerSample = 0.01531250; TotalTime = 0.4080s; SamplesPerSecond = 39212.8
04/07/2016 14:49:42:  Epoch[27 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.05915296; EvalErr[0]PerSample = 0.01600000; EvalErr[1]PerSample = 0.01600000; TotalTime = 0.4068s; SamplesPerSecond = 39331.4
04/07/2016 14:49:42: Finished Epoch[27 of 30]: [Training Set] TrainLossPerSample = 0.05526093; TotalSamplesSeen = 1620000; EvalErrPerSample [0]=0.0146; [1]=0.0146; AvgLearningRatePerSample = 0.003125; EpochTime=1.53385
04/07/2016 14:49:42: Finished Epoch[27 of 30]:     Criterion Node [ce] Per Sample = 0.05526093
04/07/2016 14:49:42: Finished Epoch[27 of 30]:     Evaluation Node [errTop5] Per Sample = 0.0146
04/07/2016 14:49:42: Finished Epoch[27 of 30]:     Evaluation Node [err] Per Sample = 0.0146
04/07/2016 14:49:42: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.27'

04/07/2016 14:49:42: Starting Epoch 28: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 27 at record count 1620000, and file position 0
already there from last epoch

04/07/2016 14:49:42: Starting minibatch loop.
04/07/2016 14:49:43:  Epoch[28 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.05088624; EvalErr[0]PerSample = 0.01306250; EvalErr[1]PerSample = 0.01306250; TotalTime = 0.4000s; SamplesPerSecond = 39995.6
04/07/2016 14:49:43:  Epoch[28 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.05488034; EvalErr[0]PerSample = 0.01493750; EvalErr[1]PerSample = 0.01493750; TotalTime = 0.4062s; SamplesPerSecond = 39388.1
04/07/2016 14:49:43:  Epoch[28 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.05683998; EvalErr[0]PerSample = 0.01481250; EvalErr[1]PerSample = 0.01481250; TotalTime = 0.4049s; SamplesPerSecond = 39512.5
04/07/2016 14:49:44: Finished Epoch[28 of 30]: [Training Set] TrainLossPerSample = 0.053038687; TotalSamplesSeen = 1680000; EvalErrPerSample [0]=0.013816667; [1]=0.013816667; AvgLearningRatePerSample = 0.003125; EpochTime=1.51778
04/07/2016 14:49:44: Finished Epoch[28 of 30]:     Criterion Node [ce] Per Sample = 0.053038687
04/07/2016 14:49:44: Finished Epoch[28 of 30]:     Evaluation Node [errTop5] Per Sample = 0.013816667
04/07/2016 14:49:44: Finished Epoch[28 of 30]:     Evaluation Node [err] Per Sample = 0.013816667
04/07/2016 14:49:44: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.28'

04/07/2016 14:49:44: Starting Epoch 29: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 28 at record count 1680000, and file position 0
already there from last epoch

04/07/2016 14:49:44: Starting minibatch loop.
04/07/2016 14:49:44:  Epoch[29 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.04883759; EvalErr[0]PerSample = 0.01231250; EvalErr[1]PerSample = 0.01231250; TotalTime = 0.4081s; SamplesPerSecond = 39202.2
04/07/2016 14:49:45:  Epoch[29 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.05271794; EvalErr[0]PerSample = 0.01462500; EvalErr[1]PerSample = 0.01462500; TotalTime = 0.4544s; SamplesPerSecond = 35210.6
04/07/2016 14:49:45:  Epoch[29 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.05465497; EvalErr[0]PerSample = 0.01431250; EvalErr[1]PerSample = 0.01431250; TotalTime = 0.4455s; SamplesPerSecond = 35918.0
04/07/2016 14:49:45: Finished Epoch[29 of 30]: [Training Set] TrainLossPerSample = 0.050945017; TotalSamplesSeen = 1740000; EvalErrPerSample [0]=0.013233334; [1]=0.013233334; AvgLearningRatePerSample = 0.003125; EpochTime=1.64353
04/07/2016 14:49:45: Finished Epoch[29 of 30]:     Criterion Node [ce] Per Sample = 0.050945017
04/07/2016 14:49:45: Finished Epoch[29 of 30]:     Evaluation Node [errTop5] Per Sample = 0.013233334
04/07/2016 14:49:45: Finished Epoch[29 of 30]:     Evaluation Node [err] Per Sample = 0.013233334
04/07/2016 14:49:45: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden.29'

04/07/2016 14:49:45: Starting Epoch 30: learning rate per sample = 0.003125  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 29 at record count 1740000, and file position 0
already there from last epoch

04/07/2016 14:49:45: Starting minibatch loop.
04/07/2016 14:49:46:  Epoch[30 of 30]-Minibatch[   1- 500, 26.67%]: SamplesSeen = 16000; TrainLossPerSample =  0.04691060; EvalErr[0]PerSample = 0.01168750; EvalErr[1]PerSample = 0.01168750; TotalTime = 0.4178s; SamplesPerSecond = 38293.3
04/07/2016 14:49:46:  Epoch[30 of 30]-Minibatch[ 501-1000, 53.33%]: SamplesSeen = 16000; TrainLossPerSample =  0.05067239; EvalErr[0]PerSample = 0.01362500; EvalErr[1]PerSample = 0.01362500; TotalTime = 0.4200s; SamplesPerSecond = 38092.6
04/07/2016 14:49:47:  Epoch[30 of 30]-Minibatch[1001-1500, 80.00%]: SamplesSeen = 16000; TrainLossPerSample =  0.05258816; EvalErr[0]PerSample = 0.01350000; EvalErr[1]PerSample = 0.01350000; TotalTime = 0.4476s; SamplesPerSecond = 35746.8
04/07/2016 14:49:47: Finished Epoch[30 of 30]: [Training Set] TrainLossPerSample = 0.048968919; TotalSamplesSeen = 1800000; EvalErrPerSample [0]=0.01245; [1]=0.01245; AvgLearningRatePerSample = 0.003125; EpochTime=1.60951
04/07/2016 14:49:47: Finished Epoch[30 of 30]:     Criterion Node [ce] Per Sample = 0.048968919
04/07/2016 14:49:47: Finished Epoch[30 of 30]:     Evaluation Node [errTop5] Per Sample = 0.01245
04/07/2016 14:49:47: Finished Epoch[30 of 30]:     Evaluation Node [err] Per Sample = 0.01245
04/07/2016 14:49:47: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160407154856.106529\Examples\Image\MNIST_01_OneHidden@release_gpu/Models/01_OneHidden'
04/07/2016 14:49:47: CNTKCommandTrainEnd: MNISTtrain

04/07/2016 14:49:47: Action "train" complete.


04/07/2016 14:49:47: ##############################################################################
04/07/2016 14:49:47: #                                                                            #
04/07/2016 14:49:47: # Action "test"                                                              #
04/07/2016 14:49:47: #                                                                            #
04/07/2016 14:49:47: ##############################################################################

Reading UCI file C:\R\CNTK3\Examples\Image\MNIST\Data/Test-28x28.txt

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	errTop5 = ErrorPrediction()
	ol.z = Plus()

Validating network. 17 nodes to process in pass 1.


Validating network. 9 nodes to process in pass 2.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [10 x *]
Validating --> ol.W = LearnableParameter() :  -> [10 x 200]
Validating --> h1.W = LearnableParameter() :  -> [200 x 784]
Validating --> featScale = LearnableParameter() :  -> [1 x 1]
Validating --> features = InputValue() :  -> [784 x *]
Validating --> featScaled = ElementTimes (featScale, features) : [1 x 1], [784 x *] -> [784 x 1 x *]
Validating --> h1.t = Times (h1.W, featScaled) : [200 x 784], [784 x 1 x *] -> [200 x 1 x *]
Validating --> h1.b = LearnableParameter() :  -> [200 x 1]
Validating --> h1.z = Plus (h1.t, h1.b) : [200 x 1 x *], [200 x 1] -> [200 x 1 x *]
Validating --> h1.y = Sigmoid (h1.z) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> ol.t = Times (ol.W, h1.y) : [10 x 200], [200 x 1 x *] -> [10 x 1 x *]
Validating --> ol.b = LearnableParameter() :  -> [10 x 1]
Validating --> ol.z = Plus (ol.t, ol.b) : [10 x 1 x *], [10 x 1] -> [10 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, ol.z) : [10 x *], [10 x 1 x *] -> [1]
Validating --> err = ErrorPrediction (labels, ol.z) : [10 x *], [10 x 1 x *] -> [1]
Validating --> unnamed81 = LearnableParameter() :  -> [1 x 1]
Validating --> errTop5 = ErrorPrediction (labels, ol.z, unnamed81) : [10 x *], [10 x 1 x *], [1 x 1] -> [1]


9 out of 17 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.
UCIFastReader: Starting at epoch 0, counting lines to determine record count...
 10000 records found.
starting epoch 0 at record count 0, and file position 0
already there from last epoch
RandomOrdering: 1989 retries for 10000 elements (19.9%) to ensure window condition
RandomOrdering: recached sequence for seed 0: 2334, 3830, ...
Minibatch[1-500]: SamplesSeen = 8000    errTop5: ErrorPrediction/Sample = 0.024625    err: ErrorPrediction/Sample = 0.024625    ce: CrossEntropyWithSoftmax/Sample = 0.079777001    
Minibatch[501-625]: SamplesSeen = 2000    errTop5: ErrorPrediction/Sample = 0.0165    err: ErrorPrediction/Sample = 0.0165    ce: CrossEntropyWithSoftmax/Sample = 0.065022096    
Final Results: Minibatch[1-625]: SamplesSeen = 10000    errTop5: ErrorPrediction/Sample = 0.023    err: ErrorPrediction/Sample = 0.023    ce: CrossEntropyWithSoftmax/Sample = 0.07682602    Perplexity = 1.0798542    

04/07/2016 14:49:48: Action "test" complete.

04/07/2016 14:49:48: __COMPLETED__