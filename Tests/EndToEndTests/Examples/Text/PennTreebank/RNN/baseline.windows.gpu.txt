=== Running /cygdrive/c/src/cntk_github/x64/release/cntk.exe configFile=C:\src\cntk_github\Examples\Text\PennTreebank\Config/rnn.cntk currentDirectory=C:\src\cntk_github\Examples\Text\PennTreebank\Data RunDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu DataDir=C:\src\cntk_github\Examples\Text\PennTreebank\Data ConfigDir=C:\src\cntk_github\Examples\Text\PennTreebank\Config OutputDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu DeviceId=0 timestamping=true command=writeWordAndClassInfo:train:test train=[SGD=[maxEpochs=3]] train=[epochSize=2048]] test=[SGD=[maxEpochs=3]] train=[epochSize=2048]]
-------------------------------------------------------------------
Build info: 

		Built time: Apr 15 2016 13:55:12
		Last modified date: Thu Apr  7 11:05:47 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: E:\lib\cub-1.4.1
		CUDNN_PATH: E:\lib\cuDNN_v4
		Build Branch: alrezni/examples_text
		Build SHA1: cdc80135ceb8776544a67596b9fdaefd2b934b2e (modified)
		Built by alrezni on DIFFENG
		Build Path: C:\src\cntk_github\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\src\cntk_github\Examples\Text\PennTreebank\Data
04/15/2016 13:06:42: -------------------------------------------------------------------
04/15/2016 13:06:42: Build info: 

04/15/2016 13:06:42: 		Built time: Apr 15 2016 13:55:12
04/15/2016 13:06:42: 		Last modified date: Thu Apr  7 11:05:47 2016
04/15/2016 13:06:42: 		Build type: Release
04/15/2016 13:06:42: 		Build target: GPU
04/15/2016 13:06:42: 		With 1bit-SGD: no
04/15/2016 13:06:42: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
04/15/2016 13:06:42: 		CUB_PATH: E:\lib\cub-1.4.1
04/15/2016 13:06:42: 		CUDNN_PATH: E:\lib\cuDNN_v4
04/15/2016 13:06:42: 		Build Branch: alrezni/examples_text
04/15/2016 13:06:42: 		Build SHA1: cdc80135ceb8776544a67596b9fdaefd2b934b2e (modified)
04/15/2016 13:06:42: 		Built by alrezni on DIFFENG
04/15/2016 13:06:42: 		Build Path: C:\src\cntk_github\Source\CNTK\
04/15/2016 13:06:42: -------------------------------------------------------------------

04/15/2016 13:06:42: Running on DIFFENG at 2016/04/15 13:06:42
04/15/2016 13:06:42: Command line: 
C:\src\cntk_github\x64\release\cntk.exe  configFile=C:\src\cntk_github\Examples\Text\PennTreebank\Config/rnn.cntk  currentDirectory=C:\src\cntk_github\Examples\Text\PennTreebank\Data  RunDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu  DataDir=C:\src\cntk_github\Examples\Text\PennTreebank\Data  ConfigDir=C:\src\cntk_github\Examples\Text\PennTreebank\Config  OutputDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu  DeviceId=0  timestamping=true  command=writeWordAndClassInfo:train:test  train=[SGD=[maxEpochs=3]]  train=[epochSize=2048]]  test=[SGD=[maxEpochs=3]]  train=[epochSize=2048]]



04/15/2016 13:06:42: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/15/2016 13:06:42: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
deviceId = "auto"
command = writeWordAndClassInfo:train:test:write
precision  = "float"
traceLevel = 1
modelPath  = "$ModelDir$/rnn.dnn"
numCPUThreads = 1
confVocabSize = 10000
confClassSize = 50
trainFile = "ptb.train.txt"
validFile = "ptb.valid.txt"
testFile  = "ptb.test.txt"
writeWordAndClassInfo = [
    action = "writeWordAndClass"
    inputFile = "$DataDir$/$trainFile$"
    beginSequence = "</s>"
    endSequence   = "</s>"
    outputVocabFile = "$ModelDir$/vocab.txt"
    outputWord2Cls  = "$ModelDir$/word2cls.txt"
    outputCls2Index = "$ModelDir$/cls2idx.txt"
    vocabSize = "$confVocabSize$"
    nbrClass = "$confClassSize$"
    cutoff = 0
    printValues = true
]
train = [
    action = "train"
    traceLevel = 1
epochSize = 0               
    SimpleNetworkBuilder = [
rnnType = "CLASSLSTM"   
recurrentLayer = 1      
        trainingCriterion = "classCrossEntropyWithSoftmax"
        evalCriterion     = "classCrossEntropyWithSoftmax"
        initValueScale = 6.0
        uniformInit = true
        layerSizes = "$confVocabSize$:150:200:10000"
defaultHiddenActivity = 0.1 
        addPrior = false
        addDropoutNodes = false
        applyMeanVarNorm = false
lookupTableOrder = 1        
        vocabSize = "$confVocabSize$"
        nbrClass  = "$confClassSize$"
    ]
    SGD = [
        minibatchSize = 128:256:512
        learningRatesPerSample = 0.1
        momentumPerMB = 0
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 15.0
        maxEpochs = 16
        numMBsToShowResult = 100
        gradUpdateType = "none"
        loadBestModel = true
        dropoutRate = 0.0
        AutoAdjust = [
            autoAdjustLR = "adjustAfterEpoch"
            reduceLearnRateIfImproveLessThan = 0.001
            continueReduce = false
            increaseLearnRateIfImproveMoreThan = 1000000000
            learnRateDecreaseFactor = 0.5
            learnRateIncreaseFactor = 1.382
            numMiniBatch4LRSearch = 100
            numPrevLearnRates = 5
            numBestSearchEpoch = 1
        ]
    ]
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$trainFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11                
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = categoryLabels
            ]
        ]
    ]
    cvReader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.valid.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$validFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
test = [
    action = "eval"
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$testFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
write = [
    action = "write"
    outputPath = "$OutputDir$/Write"
outputNodeNames = TrainNodeClassBasedCrossEntropy 
    format = [
sequencePrologue = "log P(W)="    
        type = "real"
    ]
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 1  
cacheBlockSize = 1              
        wordclass = "$ModelDir$/vocab.txt"
        wfile = "$OutputDir$/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "$confVocabSize$"
        file = "$DataDir$/$testFile$"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "$confVocabSize$"
            labelMappingFile = "$OutputDir$/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
currentDirectory=C:\src\cntk_github\Examples\Text\PennTreebank\Data
RunDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu
DataDir=C:\src\cntk_github\Examples\Text\PennTreebank\Data
ConfigDir=C:\src\cntk_github\Examples\Text\PennTreebank\Config
OutputDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu
DeviceId=0
timestamping=true
command=writeWordAndClassInfo:train:test
train=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]
test=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]

04/15/2016 13:06:42: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/15/2016 13:06:42: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/15/2016 13:06:42: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models"
deviceId = "auto"
command = writeWordAndClassInfo:train:test:write
precision  = "float"
traceLevel = 1
modelPath  = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/rnn.dnn"
numCPUThreads = 1
confVocabSize = 10000
confClassSize = 50
trainFile = "ptb.train.txt"
validFile = "ptb.valid.txt"
testFile  = "ptb.test.txt"
writeWordAndClassInfo = [
    action = "writeWordAndClass"
    inputFile = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.train.txt"
    beginSequence = "</s>"
    endSequence   = "</s>"
    outputVocabFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
    outputWord2Cls  = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/word2cls.txt"
    outputCls2Index = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/cls2idx.txt"
    vocabSize = "10000"
    nbrClass = "50"
    cutoff = 0
    printValues = true
]
train = [
    action = "train"
    traceLevel = 1
epochSize = 0               
    SimpleNetworkBuilder = [
rnnType = "CLASSLSTM"   
recurrentLayer = 1      
        trainingCriterion = "classCrossEntropyWithSoftmax"
        evalCriterion     = "classCrossEntropyWithSoftmax"
        initValueScale = 6.0
        uniformInit = true
        layerSizes = "10000:150:200:10000"
defaultHiddenActivity = 0.1 
        addPrior = false
        addDropoutNodes = false
        applyMeanVarNorm = false
lookupTableOrder = 1        
        vocabSize = "10000"
        nbrClass  = "50"
    ]
    SGD = [
        minibatchSize = 128:256:512
        learningRatesPerSample = 0.1
        momentumPerMB = 0
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 15.0
        maxEpochs = 16
        numMBsToShowResult = 100
        gradUpdateType = "none"
        loadBestModel = true
        dropoutRate = 0.0
        AutoAdjust = [
            autoAdjustLR = "adjustAfterEpoch"
            reduceLearnRateIfImproveLessThan = 0.001
            continueReduce = false
            increaseLearnRateIfImproveMoreThan = 1000000000
            learnRateDecreaseFactor = 0.5
            learnRateIncreaseFactor = 1.382
            numMiniBatch4LRSearch = 100
            numPrevLearnRates = 5
            numBestSearchEpoch = 1
        ]
    ]
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.train.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11                
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = categoryLabels
            ]
        ]
    ]
    cvReader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.valid.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.valid.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
test = [
    action = "eval"
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
write = [
    action = "write"
    outputPath = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Write"
outputNodeNames = TrainNodeClassBasedCrossEntropy 
    format = [
sequencePrologue = "log P(W)="    
        type = "real"
    ]
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 1  
cacheBlockSize = 1              
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]
currentDirectory=C:\src\cntk_github\Examples\Text\PennTreebank\Data
RunDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu
DataDir=C:\src\cntk_github\Examples\Text\PennTreebank\Data
ConfigDir=C:\src\cntk_github\Examples\Text\PennTreebank\Config
OutputDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu
DeviceId=0
timestamping=true
command=writeWordAndClassInfo:train:test
train=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]
test=[SGD=[maxEpochs=3]]
train=[epochSize=2048]]

04/15/2016 13:06:42: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/15/2016 13:06:42: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: rnn.cntk:]=true
configparameters: rnn.cntk:command=writeWordAndClassInfo:train:test
configparameters: rnn.cntk:confClassSize=50
configparameters: rnn.cntk:ConfigDir=C:\src\cntk_github\Examples\Text\PennTreebank\Config
configparameters: rnn.cntk:confVocabSize=10000
configparameters: rnn.cntk:currentDirectory=C:\src\cntk_github\Examples\Text\PennTreebank\Data
configparameters: rnn.cntk:DataDir=C:\src\cntk_github\Examples\Text\PennTreebank\Data
configparameters: rnn.cntk:deviceId=0
configparameters: rnn.cntk:ModelDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models
configparameters: rnn.cntk:modelPath=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/rnn.dnn
configparameters: rnn.cntk:numCPUThreads=1
configparameters: rnn.cntk:OutputDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu
configparameters: rnn.cntk:precision=float
configparameters: rnn.cntk:RootDir=..
configparameters: rnn.cntk:RunDir=E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu
configparameters: rnn.cntk:test=[
    action = "eval"
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
] [SGD=[maxEpochs=3]]

configparameters: rnn.cntk:testFile=ptb.test.txt
configparameters: rnn.cntk:timestamping=true
configparameters: rnn.cntk:traceLevel=1
configparameters: rnn.cntk:train=[
    action = "train"
    traceLevel = 1
epochSize = 0               
    SimpleNetworkBuilder = [
rnnType = "CLASSLSTM"   
recurrentLayer = 1      
        trainingCriterion = "classCrossEntropyWithSoftmax"
        evalCriterion     = "classCrossEntropyWithSoftmax"
        initValueScale = 6.0
        uniformInit = true
        layerSizes = "10000:150:200:10000"
defaultHiddenActivity = 0.1 
        addPrior = false
        addDropoutNodes = false
        applyMeanVarNorm = false
lookupTableOrder = 1        
        vocabSize = "10000"
        nbrClass  = "50"
    ]
    SGD = [
        minibatchSize = 128:256:512
        learningRatesPerSample = 0.1
        momentumPerMB = 0
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 15.0
        maxEpochs = 16
        numMBsToShowResult = 100
        gradUpdateType = "none"
        loadBestModel = true
        dropoutRate = 0.0
        AutoAdjust = [
            autoAdjustLR = "adjustAfterEpoch"
            reduceLearnRateIfImproveLessThan = 0.001
            continueReduce = false
            increaseLearnRateIfImproveMoreThan = 1000000000
            learnRateDecreaseFactor = 0.5
            learnRateIncreaseFactor = 1.382
            numMiniBatch4LRSearch = 100
            numPrevLearnRates = 5
            numBestSearchEpoch = 1
        ]
    ]
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.train.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11                
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = categoryLabels
            ]
        ]
    ]
    cvReader = [
        readerType = "LMSequenceReader"
        randomize = "none"
nbruttsineachrecurrentiter = 0  
cacheBlockSize = 2000000        
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.valid.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.valid.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
] [SGD=[maxEpochs=3]] [epochSize=2048] [epochSize=2048]

configparameters: rnn.cntk:trainFile=ptb.train.txt
configparameters: rnn.cntk:validFile=ptb.valid.txt
configparameters: rnn.cntk:write=[
    action = "write"
    outputPath = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Write"
outputNodeNames = TrainNodeClassBasedCrossEntropy 
    format = [
sequencePrologue = "log P(W)="    
        type = "real"
    ]
minibatchSize = 8192                
    traceLevel = 1
    epochSize = 0
    reader = [
        readerType = "LMSequenceReader"
randomize = "none"              
nbruttsineachrecurrentiter = 1  
cacheBlockSize = 1              
        wordclass = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
        wfile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sequenceSentence.bin"
        wsize = 256
        wrecords = 1000
        windowSize = "10000"
        file = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.test.txt"
        features = [
            dim = 0
            sectionType = "data"
        ]
        labelIn = [
            dim = 1
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt"
            labelType = "Category"
            beginSequence = "</s>"
            endSequence = "</s>"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 11
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 11
                sectionType = "categoryLabels"
            ]
        ]
        labels = [
            dim = 1
            labelType = "NextWord"
            beginSequence = "O"
            endSequence = "O"
            labelDim = "10000"
            labelMappingFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt"
            elementSize = 4
            sectionType = "labels"
            mapping = [
                wrecords = 3
                elementSize = 10
                sectionType = "labelMapping"
            ]
            category = [
                dim = 3
                sectionType = "categoryLabels"
            ]
        ]
    ]
]

configparameters: rnn.cntk:writeWordAndClassInfo=[
    action = "writeWordAndClass"
    inputFile = "C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.train.txt"
    beginSequence = "</s>"
    endSequence   = "</s>"
    outputVocabFile = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt"
    outputWord2Cls  = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/word2cls.txt"
    outputCls2Index = "E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/cls2idx.txt"
    vocabSize = "10000"
    nbrClass = "50"
    cutoff = 0
    printValues = true
]

04/15/2016 13:06:42: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/15/2016 13:06:42: Commands: writeWordAndClassInfo train test
04/15/2016 13:06:42: Precision = "float"
04/15/2016 13:06:42: Using 1 CPU threads.
04/15/2016 13:06:42: CNTKModelPath: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/rnn.dnn
04/15/2016 13:06:42: CNTKCommandTrainInfo: train : 3
04/15/2016 13:06:42: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3

04/15/2016 13:06:42: ##############################################################################
04/15/2016 13:06:42: #                                                                            #
04/15/2016 13:06:42: # Action "writeWordAndClass"                                                 #
04/15/2016 13:06:42: #                                                                            #
04/15/2016 13:06:42: ##############################################################################

Vocabulary file    --> E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/vocab.txt
Word-to-class map  --> E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/word2cls.txt
Class-to-index map --> E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/cls2idx.txt

Reading input file inputFile: C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.train.txt
Vocabulary size 10000.
Created vocabulary file with 10000 entries.
Created word-to-class map with 10000 entries.
Created class-to-index map with 50 entries.

04/15/2016 13:06:43: Action "writeWordAndClass" complete.


04/15/2016 13:06:43: ##############################################################################
04/15/2016 13:06:43: #                                                                            #
04/15/2016 13:06:43: # Action "train"                                                             #
04/15/2016 13:06:43: #                                                                            #
04/15/2016 13:06:43: ##############################################################################

04/15/2016 13:06:43: CNTKCommandTrainBegin: train
SimpleNetworkBuilder Using GPU 0
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt
LMSequenceReader: Input file is 'C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.train.txt'.
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt
LMSequenceReader: Input file is 'C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.valid.txt'.

04/15/2016 13:06:43: Creating virgin network.
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

3 roots:
	PosteriorProb = Softmax()
	TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax()
	outputs = TransposeTimes()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Validating network. 63 nodes to process in pass 1.


Validating network. 43 nodes to process in pass 2.


Validating network. 14 nodes to process in pass 3.


Validating network, final pass.

Validating --> W2 = LearnableParameter() :  -> [200 x 10000]
Validating --> WXO0 = LearnableParameter() :  -> [200 x 150]
Validating --> E0 = LearnableParameter() :  -> [150 x 10000]
Validating --> features = SparseInputValue() :  -> [10000 x *]
Validating --> LookupTable = LookupTable (E0, features) : [150 x 10000], [10000 x *] -> [150 x *]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bo0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHO0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCO0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bf0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHF0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCF0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bi0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHI0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCI0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> WHC0 = LearnableParameter() :  -> [200 x 200]
Validating --> bc0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName2 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName1 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName5 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName26 = Sigmoid (AutoName25) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName6 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName0 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName4 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName13 = Sigmoid (AutoName12) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName3 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [200 x 1 x *], [200 x 1] -> [200 x 1 x *]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [200 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName18 = Tanh (AutoName17) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName35 = Sigmoid (AutoName34) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName36 = Tanh (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> outputs = TransposeTimes (W2, AutoName37) : [200 x 10000], [200 x 1 x *] -> [10000 x 1 x *]
Validating --> PosteriorProb = Softmax (outputs) : [10000 x 1 x *] -> [10000 x 1 x *]
Validating --> labels = InputValue() :  -> [4 x *]
Validating --> WeightForClassPostProb = LearnableParameter() :  -> [50 x 200]
Validating --> ClassPostProb = Times (WeightForClassPostProb, AutoName37) : [50 x 200], [200 x 1 x *] -> [50 x 1 x *]
Validating --> TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax (labels, AutoName37, W2, ClassPostProb) : [4 x *], [200 x 1 x *], [200 x 10000], [50 x 1 x *] -> [1]


19 out of 63 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/15/2016 13:06:43: Created model with 63 nodes on GPU 0.

04/15/2016 13:06:43: Training criterion node(s):
04/15/2016 13:06:43: 	TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax


Allocating matrices for forward and/or backward propagation.
04/15/2016 13:06:43: No PreCompute nodes found, skipping PreCompute step.

04/15/2016 13:06:44: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

04/15/2016 13:06:44: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
WARNING: The same matrix with dim [4, 112] has been transferred between different devices for 20 times.
04/15/2016 13:06:45: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 6.863862; TotalSamplesSeen = 2061; AvgLearningRatePerSample = 0.1; EpochTime=1.81256
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
Final Results: Minibatch[1-704]: SamplesSeen = 73760    TrainNodeClassBasedCrossEntropy: ClassBasedCrossEntropyWithSoftmax/Sample = 6.6827192    Perplexity = 798.48738    
04/15/2016 13:07:06: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 6.6827192
04/15/2016 13:07:06: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/rnn.dnn.1'

04/15/2016 13:07:07: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

04/15/2016 13:07:07: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
04/15/2016 13:07:08: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 6.6756201; TotalSamplesSeen = 4142; AvgLearningRatePerSample = 0.1; EpochTime=1.19109
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
Final Results: Minibatch[1-353]: SamplesSeen = 73760    TrainNodeClassBasedCrossEntropy: ClassBasedCrossEntropyWithSoftmax/Sample = 6.6803532    Perplexity = 796.60041    
04/15/2016 13:07:22: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 6.6803532
04/15/2016 13:07:22: learnRatePerSample reduced to 0.050000001
04/15/2016 13:07:23: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/rnn.dnn.2'

04/15/2016 13:07:23: Starting Epoch 3: learning rate per sample = 0.050000  effective momentum = 0.000000  momentum as time constant = 0.0 samples

04/15/2016 13:07:23: Starting minibatch loop.
LMSequenceReader: Reading epoch data... 42068 sequences read.
04/15/2016 13:07:24: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 6.6446691; TotalSamplesSeen = 6485; AvgLearningRatePerSample = 0.050000001; EpochTime=1.17407
LMSequenceReader: Reading epoch data... 3370 sequences read.
LMSequenceReader: Reading epoch data... 0 sequences read.
Final Results: Minibatch[1-193]: SamplesSeen = 73760    TrainNodeClassBasedCrossEntropy: ClassBasedCrossEntropyWithSoftmax/Sample = 7.0153574    Perplexity = 1113.6046    
04/15/2016 13:07:36: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 7.0153574
04/15/2016 13:07:36: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/rnn.dnn.2.
04/15/2016 13:07:37: learnRatePerSample reduced to 0.025
04/15/2016 13:07:37: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/Models/rnn.dnn'
04/15/2016 13:07:37: CNTKCommandTrainEnd: train

04/15/2016 13:07:37: Action "train" complete.


04/15/2016 13:07:37: ##############################################################################
04/15/2016 13:07:37: #                                                                            #
04/15/2016 13:07:37: # Action "eval"                                                              #
04/15/2016 13:07:37: #                                                                            #
04/15/2016 13:07:37: ##############################################################################

LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.txt
LMSequenceReader: Label mapping will be created internally on the fly because the labelMappingFile was not found: E:\cygwin64\tmp\cntk-test-20160415140106.507551\Examples\Text\PennTreebank_RNN@release_gpu/sentenceLabels.out.txt
LMSequenceReader: Input file is 'C:\src\cntk_github\Examples\Text\PennTreebank\Data/ptb.test.txt'.

Post-processing network...

3 roots:
	PosteriorProb = Softmax()
	TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax()
	outputs = TransposeTimes()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Validating network. 63 nodes to process in pass 1.


Validating network. 43 nodes to process in pass 2.


Validating network. 14 nodes to process in pass 3.


Validating network, final pass.

Validating --> W2 = LearnableParameter() :  -> [200 x 10000]
Validating --> WXO0 = LearnableParameter() :  -> [200 x 150]
Validating --> E0 = LearnableParameter() :  -> [150 x 10000]
Validating --> features = SparseInputValue() :  -> [10000 x *]
Validating --> LookupTable = LookupTable (E0, features) : [150 x 10000], [10000 x *] -> [150 x *]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bo0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHO0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCO0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bf0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHF0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCF0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> bi0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [200 x *], [200 x 1] -> [200 x 1 x *]
Validating --> WHI0 = LearnableParameter() :  -> [200 x 200]
Validating --> WCI0 = LearnableParameter() :  -> [200 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [200 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [200 x 150], [150 x *] -> [200 x *]
Validating --> WHC0 = LearnableParameter() :  -> [200 x 200]
Validating --> bc0 = LearnableParameter() :  -> [200 x 1]
Validating --> AutoName2 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName1 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName5 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName26 = Sigmoid (AutoName25) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName6 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName0 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName4 = PastValue (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName13 = Sigmoid (AutoName12) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName3 = PastValue (AutoName37) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [200 x 200], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [200 x 1 x *], [200 x 1] -> [200 x 1 x *]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [200 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName18 = Tanh (AutoName17) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [200 x 1], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName35 = Sigmoid (AutoName34) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName36 = Tanh (AutoName28) : [200 x 1 x *] -> [200 x 1 x *]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [200 x 1 x *], [200 x 1 x *] -> [200 x 1 x *]
Validating --> outputs = TransposeTimes (W2, AutoName37) : [200 x 10000], [200 x 1 x *] -> [10000 x 1 x *]
Validating --> PosteriorProb = Softmax (outputs) : [10000 x 1 x *] -> [10000 x 1 x *]
Validating --> labels = InputValue() :  -> [4 x *]
Validating --> WeightForClassPostProb = LearnableParameter() :  -> [50 x 200]
Validating --> ClassPostProb = Times (WeightForClassPostProb, AutoName37) : [50 x 200], [200 x 1 x *] -> [50 x 1 x *]
Validating --> TrainNodeClassBasedCrossEntropy = ClassBasedCrossEntropyWithSoftmax (labels, AutoName37, W2, ClassPostProb) : [4 x *], [200 x 1 x *], [200 x 10000], [50 x 1 x *] -> [1]


19 out of 63 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.
LMSequenceReader: Reading epoch data... 3760 sequences read.
WARNING: The same matrix with dim [4, 2900] has been transferred between different devices for 20 times.
LMSequenceReader: Reading epoch data... 0 sequences read.
Minibatch[1-60]: SamplesSeen = 82402    TrainNodeClassBasedCrossEntropy: ClassBasedCrossEntropyWithSoftmax/Sample = 6.6424143    
Final Results: Minibatch[1-60]: SamplesSeen = 82402    TrainNodeClassBasedCrossEntropy: ClassBasedCrossEntropyWithSoftmax/Sample = 6.6424143    Perplexity = 766.9444    

04/15/2016 13:07:48: Action "eval" complete.

04/15/2016 13:07:48: __COMPLETED__