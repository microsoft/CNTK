=== Running /cygdrive/c/src/cntk_github/x64/release/cntk.exe configFile=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU/rnnlu.cntk currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu DeviceId=0 timestamping=true NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
-------------------------------------------------------------------
Build info: 

		Built time: Apr 11 2016 13:32:44
		Last modified date: Thu Apr  7 11:05:47 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: E:\lib\cub-1.4.1
		CUDNN_PATH: E:\lib\cuDNN_v4
		Build Branch: alrezni/examples_text
		Build SHA1: 110e330e5b490c97d4836374ed83fbe642e4f857 (modified)
		Built by alrezni on DIFFENG
		Build Path: C:\src\cntk_github\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
04/11/2016 14:34:54: -------------------------------------------------------------------
04/11/2016 14:34:54: Build info: 

04/11/2016 14:34:54: 		Built time: Apr 11 2016 13:32:44
04/11/2016 14:34:54: 		Last modified date: Thu Apr  7 11:05:47 2016
04/11/2016 14:34:54: 		Build type: Release
04/11/2016 14:34:54: 		Build target: GPU
04/11/2016 14:34:54: 		With 1bit-SGD: no
04/11/2016 14:34:54: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
04/11/2016 14:34:54: 		CUB_PATH: E:\lib\cub-1.4.1
04/11/2016 14:34:54: 		CUDNN_PATH: E:\lib\cuDNN_v4
04/11/2016 14:34:54: 		Build Branch: alrezni/examples_text
04/11/2016 14:34:54: 		Build SHA1: 110e330e5b490c97d4836374ed83fbe642e4f857 (modified)
04/11/2016 14:34:54: 		Built by alrezni on DIFFENG
04/11/2016 14:34:54: 		Build Path: C:\src\cntk_github\Source\CNTK\
04/11/2016 14:34:54: -------------------------------------------------------------------

04/11/2016 14:34:54: Running on DIFFENG at 2016/04/11 14:34:54
04/11/2016 14:34:54: Command line: 
C:\src\cntk_github\x64\release\cntk.exe  configFile=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU/rnnlu.cntk  currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU  RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu  DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU  ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU  OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu  DeviceId=0  timestamping=true  NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU  ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu  OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu



04/11/2016 14:34:54: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/11/2016 14:34:54: precision="float"
deviceId = $DeviceId$
command=LSTM:LSTMTest
traceLevel=1
LSTM=[
    action=train
	makeMode=true
    modelPath=$ExpDir$/cntkdebug.dnn
    SimpleNetworkBuilder=[
        rnnType=LSTM
        layerSizes=2832:50:300:300:300:127
        lookupTableOrder=3
        recurrentLayer=2:3:4
        defaultHiddenActivity=0.1
        initValueScale=6.0
        trainingCriterion=crossentropywithsoftmax
        evalCriterion=crossentropywithsoftmax
    ]
    SGD=[
maxEpochs=100   
epochSize=71524     
        minibatchSize=10000
        learningRatesPerSample=0.1
        momentumAsTimeConstant=1000
        gradientClippingWithTruncation=true
        clippingThresholdPerSample=15.0
        numMBsToShowResult=50
        loadBestModel=true
        AutoAdjust=[
            autoAdjustLR=adjustafterepoch
            reduceLearnRateIfImproveLessThan=0
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
        ]
    ]
    reader=[
        readerType=LUSequenceReader
        wordContext=0:1:2
        randomize=None
nbruttsineachrecurrentiter=10  
        equalLength = false
        wfile=$ExpDir$/sequenceSentence.bin
        wsize=256
        wrecords=1000
        windowSize=10000
        unk="<unk>"
          wordmap=$DataDir$/inputmap.txt
          file=$DataDir$/atis.train.apos.pred.pos.head.IOB.simple
          features=[
            dim=0
            sectionType=data
          ]
          sequence=[
            dim=1
            wrecords=2
            sectionType=data
          ]
          labelIn=[
            dim=1
            usewordmap=true
            labelDim=10000
            labelMappingFile=$ExpDir$/sentenceLabels.txt
            labelType=Category
            beginSequence="BOS"
            endSequence="EOS"
            usewordmap=true
            token=$DataDir$/input.txt
            elementSize=4
            sectionType=labels
            mapping=[
              wrecords=11
              elementSize=10
              sectionType=labelMapping
            ]
            category=[
              dim=11
              sectionType=categoryLabels
            ]
          ]
          labels=[
            dim=1
            labelType=Category
            token=$DataDir$/output.txt
            labelMappingFile=$ExpDir$/sentenceLabels.out.txt
            sectionType=labels
            mapping=[
              sectionType=labelMapping
            ]
            category=[
              sectionType=categoryLabels
            ]
          ]
    ]
    cvReader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      nbruttsineachrecurrentiter=200
      equalLength = false
      wfile=$ExpDir$/sequenceSentence.valid.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      unk="<unk>"
      wordmap=$DataDir$/inputmap.txt
      file=$DataDir$/atis.dev.IOB.simple
      features=[
        dim=0
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=$ExpDir$/sentenceLabels.in.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=$DataDir$/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        token=$DataDir$/output.txt
        labelDim=10000
        labelMappingFile=$ExpDir$/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
]
LSTMTest=[
    action=write
    epochSize=4430000
    defaultHiddenActivity=0.1
    modelPath=$ExpDir$/cntkdebug.dnn
    outputNodeNames=outputs:labels
    reader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      unk="<unk>"
      wordmap=$DataDir$/inputmap.txt
      file=$DataDir$/atis.test.apos.pred.pos.head.IOB.simple
      wfile=$ExpDir$/sequenceSentence.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      features=[
        dim=0 
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=$ExpDir$/sentenceLabels.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=$DataDir$/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        token=$DataDir$/output.txt
        labelDim=127
        labelMappingFile=$ExpDir$/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
    writer=[
        writerType=LUSequenceWriter
        outputs=[
            file=$OutDir$/output.rec.txt
            token=$DataDir$/output.txt
        ]
        labels=[
            file=$OutDir$/output.lbl.txt
            token=$DataDir$/output.txt
        ]
    ]
]
currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU
OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
DeviceId=0
timestamping=true
NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU
ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu

04/11/2016 14:34:54: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/11/2016 14:34:54: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/11/2016 14:34:54: precision="float"
deviceId = 0
command=LSTM:LSTMTest
traceLevel=1
LSTM=[
    action=train
	makeMode=true
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn
    SimpleNetworkBuilder=[
        rnnType=LSTM
        layerSizes=2832:50:300:300:300:127
        lookupTableOrder=3
        recurrentLayer=2:3:4
        defaultHiddenActivity=0.1
        initValueScale=6.0
        trainingCriterion=crossentropywithsoftmax
        evalCriterion=crossentropywithsoftmax
    ]
    SGD=[
maxEpochs=100   
epochSize=71524     
        minibatchSize=10000
        learningRatesPerSample=0.1
        momentumAsTimeConstant=1000
        gradientClippingWithTruncation=true
        clippingThresholdPerSample=15.0
        numMBsToShowResult=50
        loadBestModel=true
        AutoAdjust=[
            autoAdjustLR=adjustafterepoch
            reduceLearnRateIfImproveLessThan=0
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
        ]
    ]
    reader=[
        readerType=LUSequenceReader
        wordContext=0:1:2
        randomize=None
nbruttsineachrecurrentiter=10  
        equalLength = false
        wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sequenceSentence.bin
        wsize=256
        wrecords=1000
        windowSize=10000
        unk="<unk>"
          wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
          file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.train.apos.pred.pos.head.IOB.simple
          features=[
            dim=0
            sectionType=data
          ]
          sequence=[
            dim=1
            wrecords=2
            sectionType=data
          ]
          labelIn=[
            dim=1
            usewordmap=true
            labelDim=10000
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.txt
            labelType=Category
            beginSequence="BOS"
            endSequence="EOS"
            usewordmap=true
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
            elementSize=4
            sectionType=labels
            mapping=[
              wrecords=11
              elementSize=10
              sectionType=labelMapping
            ]
            category=[
              dim=11
              sectionType=categoryLabels
            ]
          ]
          labels=[
            dim=1
            labelType=Category
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.out.txt
            sectionType=labels
            mapping=[
              sectionType=labelMapping
            ]
            category=[
              sectionType=categoryLabels
            ]
          ]
    ]
    cvReader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      nbruttsineachrecurrentiter=200
      equalLength = false
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sequenceSentence.valid.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.dev.IOB.simple
      features=[
        dim=0
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.in.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
]
LSTMTest=[
    action=write
    epochSize=4430000
    defaultHiddenActivity=0.1
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn
    outputNodeNames=outputs:labels
    reader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.test.apos.pred.pos.head.IOB.simple
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sequenceSentence.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      features=[
        dim=0 
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=127
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
    writer=[
        writerType=LUSequenceWriter
        outputs=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/output.rec.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
        labels=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/output.lbl.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
    ]
]
currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU
OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
DeviceId=0
timestamping=true
NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU
ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu

04/11/2016 14:34:54: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/11/2016 14:34:54: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: rnnlu.cntk:command=LSTM:LSTMTest
configparameters: rnnlu.cntk:ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU
configparameters: rnnlu.cntk:currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
configparameters: rnnlu.cntk:DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
configparameters: rnnlu.cntk:deviceId=0
configparameters: rnnlu.cntk:ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
configparameters: rnnlu.cntk:LSTM=[
    action=train
	makeMode=true
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn
    SimpleNetworkBuilder=[
        rnnType=LSTM
        layerSizes=2832:50:300:300:300:127
        lookupTableOrder=3
        recurrentLayer=2:3:4
        defaultHiddenActivity=0.1
        initValueScale=6.0
        trainingCriterion=crossentropywithsoftmax
        evalCriterion=crossentropywithsoftmax
    ]
    SGD=[
maxEpochs=100   
epochSize=71524     
        minibatchSize=10000
        learningRatesPerSample=0.1
        momentumAsTimeConstant=1000
        gradientClippingWithTruncation=true
        clippingThresholdPerSample=15.0
        numMBsToShowResult=50
        loadBestModel=true
        AutoAdjust=[
            autoAdjustLR=adjustafterepoch
            reduceLearnRateIfImproveLessThan=0
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
        ]
    ]
    reader=[
        readerType=LUSequenceReader
        wordContext=0:1:2
        randomize=None
nbruttsineachrecurrentiter=10  
        equalLength = false
        wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sequenceSentence.bin
        wsize=256
        wrecords=1000
        windowSize=10000
        unk="<unk>"
          wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
          file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.train.apos.pred.pos.head.IOB.simple
          features=[
            dim=0
            sectionType=data
          ]
          sequence=[
            dim=1
            wrecords=2
            sectionType=data
          ]
          labelIn=[
            dim=1
            usewordmap=true
            labelDim=10000
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.txt
            labelType=Category
            beginSequence="BOS"
            endSequence="EOS"
            usewordmap=true
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
            elementSize=4
            sectionType=labels
            mapping=[
              wrecords=11
              elementSize=10
              sectionType=labelMapping
            ]
            category=[
              dim=11
              sectionType=categoryLabels
            ]
          ]
          labels=[
            dim=1
            labelType=Category
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.out.txt
            sectionType=labels
            mapping=[
              sectionType=labelMapping
            ]
            category=[
              sectionType=categoryLabels
            ]
          ]
    ]
    cvReader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      nbruttsineachrecurrentiter=200
      equalLength = false
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sequenceSentence.valid.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.dev.IOB.simple
      features=[
        dim=0
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.in.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
]

configparameters: rnnlu.cntk:LSTMTest=[
    action=write
    epochSize=4430000
    defaultHiddenActivity=0.1
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn
    outputNodeNames=outputs:labels
    reader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.test.apos.pred.pos.head.IOB.simple
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sequenceSentence.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      features=[
        dim=0 
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=127
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
    writer=[
        writerType=LUSequenceWriter
        outputs=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/output.rec.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
        labels=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/output.lbl.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
    ]
]

configparameters: rnnlu.cntk:NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU
configparameters: rnnlu.cntk:OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
configparameters: rnnlu.cntk:OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
configparameters: rnnlu.cntk:precision=float
configparameters: rnnlu.cntk:RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu
configparameters: rnnlu.cntk:timestamping=true
configparameters: rnnlu.cntk:traceLevel=1
04/11/2016 14:34:54: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/11/2016 14:34:54: Commands: LSTM LSTMTest
04/11/2016 14:34:54: Precision = "float"
04/11/2016 14:34:54: CNTKModelPath: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn
04/11/2016 14:34:54: CNTKCommandTrainInfo: LSTM : 100
04/11/2016 14:34:54: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 100

04/11/2016 14:34:54: ##############################################################################
04/11/2016 14:34:54: #                                                                            #
04/11/2016 14:34:54: # Action "train"                                                             #
04/11/2016 14:34:54: #                                                                            #
04/11/2016 14:34:54: ##############################################################################

04/11/2016 14:34:54: CNTKCommandTrainBegin: LSTM
SimpleNetworkBuilder Using GPU 0
BatchLUSequenceReader: Input file is C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.train.apos.pred.pos.head.IOB.simple
BatchLUSequenceReader: Input file is C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.dev.IOB.simple

04/11/2016 14:34:54: Creating virgin network.
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

3 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	PosteriorProb = Softmax()
	outputs = Times()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Loop[1] --> Loop_AutoName75 -> 31 nodes

	AutoName40	AutoName68	AutoName71
	AutoName39	AutoName59	AutoName62
	AutoName43	AutoName58	AutoName63
	AutoName64	AutoName44	AutoName65
	AutoName38	AutoName46	AutoName49
	AutoName42	AutoName45	AutoName50
	AutoName51	AutoName41	AutoName52
	AutoName53	AutoName55	AutoName56
	AutoName57	AutoName66	AutoName67
	AutoName72	AutoName73	AutoName74
	AutoName75

Loop[2] --> Loop_AutoName113 -> 31 nodes

	AutoName78	AutoName106	AutoName109
	AutoName77	AutoName97	AutoName100
	AutoName81	AutoName96	AutoName101
	AutoName102	AutoName82	AutoName103
	AutoName76	AutoName84	AutoName87
	AutoName80	AutoName83	AutoName88
	AutoName89	AutoName79	AutoName90
	AutoName91	AutoName93	AutoName94
	AutoName95	AutoName104	AutoName105
	AutoName110	AutoName111	AutoName112
	AutoName113

Validating network. 168 nodes to process in pass 1.


Validating network. 119 nodes to process in pass 2.


Validating network. 42 nodes to process in pass 3.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [127 x *]
Validating --> W4 = LearnableParameter() :  -> [127 x 300]
Validating --> WXO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO0 = LearnableParameter() :  -> [300 x 150]
Validating --> E0 = LearnableParameter() :  -> [50 x 944]
Validating --> features = InputValue() :  -> [2832 x *]
Validating --> LookupTable = LookupTable (E0, features) : [50 x 944], [2832 x *] -> [150 x *]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bo0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bf0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bi0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> WHC0 = LearnableParameter() :  -> [300 x 300]
Validating --> bc0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName2 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName1 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName5 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName26 = Sigmoid (AutoName25) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName6 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName0 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName4 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName13 = Sigmoid (AutoName12) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName3 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [300 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName18 = Tanh (AutoName17) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName35 = Sigmoid (AutoName34) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName36 = Tanh (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName69 = Times (WXO2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName70 = Plus (AutoName69, bo2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName60 = Times (WXF2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName61 = Plus (AutoName60, bf2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName47 = Times (WXI2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName48 = Plus (AutoName47, bi2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName54 = Times (WXC2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC2 = LearnableParameter() :  -> [300 x 300]
Validating --> bc2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName40 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName68 = Times (WHO2, AutoName40) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName71 = Plus (AutoName70, AutoName68) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName39 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName59 = Times (WHF2, AutoName39) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName62 = Plus (AutoName61, AutoName59) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName43 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName58 = DiagTimes (WCF2, AutoName43) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName63 = Plus (AutoName62, AutoName58) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName64 = Sigmoid (AutoName63) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName44 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName65 = ElementTimes (AutoName64, AutoName44) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName38 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName46 = Times (WHI2, AutoName38) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName49 = Plus (AutoName48, AutoName46) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName42 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName45 = DiagTimes (WCI2, AutoName42) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName50 = Plus (AutoName49, AutoName45) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName51 = Sigmoid (AutoName50) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName41 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName52 = Times (WHC2, AutoName41) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName53 = Plus (AutoName52, bc2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName55 = Plus (AutoName54, AutoName53) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName56 = Tanh (AutoName55) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName57 = ElementTimes (AutoName51, AutoName56) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName66 = Plus (AutoName65, AutoName57) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName67 = DiagTimes (WCO2, AutoName66) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName72 = Plus (AutoName71, AutoName67) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName73 = Sigmoid (AutoName72) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName74 = Tanh (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName75 = ElementTimes (AutoName73, AutoName74) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName107 = Times (WXO3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName108 = Plus (AutoName107, bo3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName98 = Times (WXF3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName99 = Plus (AutoName98, bf3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName85 = Times (WXI3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName86 = Plus (AutoName85, bi3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName92 = Times (WXC3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC3 = LearnableParameter() :  -> [300 x 300]
Validating --> bc3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName78 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName106 = Times (WHO3, AutoName78) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName109 = Plus (AutoName108, AutoName106) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName77 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName97 = Times (WHF3, AutoName77) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName100 = Plus (AutoName99, AutoName97) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName81 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName96 = DiagTimes (WCF3, AutoName81) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName101 = Plus (AutoName100, AutoName96) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName102 = Sigmoid (AutoName101) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName82 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName103 = ElementTimes (AutoName102, AutoName82) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName76 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName84 = Times (WHI3, AutoName76) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName87 = Plus (AutoName86, AutoName84) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName80 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName83 = DiagTimes (WCI3, AutoName80) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName88 = Plus (AutoName87, AutoName83) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName89 = Sigmoid (AutoName88) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName79 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName90 = Times (WHC3, AutoName79) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName91 = Plus (AutoName90, bc3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName93 = Plus (AutoName92, AutoName91) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName94 = Tanh (AutoName93) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName95 = ElementTimes (AutoName89, AutoName94) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName104 = Plus (AutoName103, AutoName95) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName105 = DiagTimes (WCO3, AutoName104) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName110 = Plus (AutoName109, AutoName105) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName111 = Sigmoid (AutoName110) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName112 = Tanh (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName113 = ElementTimes (AutoName111, AutoName112) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName114 = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, AutoName114) : [127 x *], [127 x 1 x *] -> [1]
Validating --> outputs = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> PosteriorProb = Softmax (outputs) : [127 x 1 x *] -> [127 x 1 x *]


48 out of 168 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/11/2016 14:34:55: Created model with 168 nodes on GPU 0.

04/11/2016 14:34:55: Training criterion node(s):
04/11/2016 14:34:55: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax


Allocating matrices for forward and/or backward propagation.
04/11/2016 14:34:55: No PreCompute nodes found, skipping PreCompute step.

04/11/2016 14:34:55: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:55: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:55: Finished Epoch[ 1 of 100]: [Training Set] TrainLossPerSample = 4.8416042; TotalSamplesSeen = 81; AvgLearningRatePerSample = 0.1; EpochTime=0.343531
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.8031251    Perplexity = 121.89074    
04/11/2016 14:34:55: Finished Epoch[ 1 of 100]: [Validation Set] TrainLossPerSample = 4.8031251
04/11/2016 14:34:56: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.1'

04/11/2016 14:34:56: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:56: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:56: Finished Epoch[ 2 of 100]: [Training Set] TrainLossPerSample = 4.8031249; TotalSamplesSeen = 162; AvgLearningRatePerSample = 0.1; EpochTime=0.121017
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.7298275    Perplexity = 113.27602    
04/11/2016 14:34:56: Finished Epoch[ 2 of 100]: [Validation Set] TrainLossPerSample = 4.7298275
04/11/2016 14:34:56: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.2'

04/11/2016 14:34:56: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:56: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:56: Finished Epoch[ 3 of 100]: [Training Set] TrainLossPerSample = 4.7298274; TotalSamplesSeen = 243; AvgLearningRatePerSample = 0.1; EpochTime=0.119749
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.6221419    Perplexity = 101.71165    
04/11/2016 14:34:56: Finished Epoch[ 3 of 100]: [Validation Set] TrainLossPerSample = 4.6221419
04/11/2016 14:34:57: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.3'

04/11/2016 14:34:57: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:57: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:57: Finished Epoch[ 4 of 100]: [Training Set] TrainLossPerSample = 4.6221418; TotalSamplesSeen = 324; AvgLearningRatePerSample = 0.1; EpochTime=0.134194
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.4740789    Perplexity = 87.71377    
04/11/2016 14:34:57: Finished Epoch[ 4 of 100]: [Validation Set] TrainLossPerSample = 4.4740789
04/11/2016 14:34:57: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.4'

04/11/2016 14:34:57: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:57: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:57: Finished Epoch[ 5 of 100]: [Training Set] TrainLossPerSample = 4.4740791; TotalSamplesSeen = 405; AvgLearningRatePerSample = 0.1; EpochTime=0.130155
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
WARNING: The same matrix with dim [127, 120] has been transferred between different devices for 20 times.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.2694951    Perplexity = 71.485532    
04/11/2016 14:34:57: Finished Epoch[ 5 of 100]: [Validation Set] TrainLossPerSample = 4.2694951
04/11/2016 14:34:58: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.5'

04/11/2016 14:34:58: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:58: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:58: Finished Epoch[ 6 of 100]: [Training Set] TrainLossPerSample = 4.269495; TotalSamplesSeen = 486; AvgLearningRatePerSample = 0.1; EpochTime=0.128263
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 3.9782376    Perplexity = 53.422798    
04/11/2016 14:34:58: Finished Epoch[ 6 of 100]: [Validation Set] TrainLossPerSample = 3.9782376
04/11/2016 14:34:58: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.6'

04/11/2016 14:34:58: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:58: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:58: Finished Epoch[ 7 of 100]: [Training Set] TrainLossPerSample = 3.9782376; TotalSamplesSeen = 567; AvgLearningRatePerSample = 0.1; EpochTime=0.119943
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 3.554747    Perplexity = 34.97897    
04/11/2016 14:34:59: Finished Epoch[ 7 of 100]: [Validation Set] TrainLossPerSample = 3.554747
04/11/2016 14:34:59: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.7'

04/11/2016 14:34:59: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:59: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:59: Finished Epoch[ 8 of 100]: [Training Set] TrainLossPerSample = 3.5547471; TotalSamplesSeen = 648; AvgLearningRatePerSample = 0.1; EpochTime=0.124914
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9633591    Perplexity = 19.362905    
04/11/2016 14:34:59: Finished Epoch[ 8 of 100]: [Validation Set] TrainLossPerSample = 2.9633591
04/11/2016 14:34:59: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.8'

04/11/2016 14:34:59: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:59: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:00: Finished Epoch[ 9 of 100]: [Training Set] TrainLossPerSample = 2.9633591; TotalSamplesSeen = 729; AvgLearningRatePerSample = 0.1; EpochTime=0.139941
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.4028002    Perplexity = 11.054087    
04/11/2016 14:35:00: Finished Epoch[ 9 of 100]: [Validation Set] TrainLossPerSample = 2.4028002
04/11/2016 14:35:00: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.9'

04/11/2016 14:35:00: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:00: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:00: Finished Epoch[10 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.1; EpochTime=0.137341
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5592167    Perplexity = 12.925689    
04/11/2016 14:35:00: Finished Epoch[10 of 100]: [Validation Set] TrainLossPerSample = 2.5592167
04/11/2016 14:35:00: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.9.
04/11/2016 14:35:00: learnRatePerSample reduced to 0.050000001
04/11/2016 14:35:01: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.10'

04/11/2016 14:35:01: Starting Epoch 11: learning rate per sample = 0.050000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:01: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:01: Finished Epoch[11 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.050000001; EpochTime=0.134765
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5335413    Perplexity = 12.59804    
04/11/2016 14:35:01: Finished Epoch[11 of 100]: [Validation Set] TrainLossPerSample = 2.5335413
04/11/2016 14:35:01: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.10.
04/11/2016 14:35:01: learnRatePerSample reduced to 0.025
04/11/2016 14:35:01: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.11'

04/11/2016 14:35:02: Starting Epoch 12: learning rate per sample = 0.025000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:02: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:02: Finished Epoch[12 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.025; EpochTime=0.119832
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5215607    Perplexity = 12.448009    
04/11/2016 14:35:02: Finished Epoch[12 of 100]: [Validation Set] TrainLossPerSample = 2.5215607
04/11/2016 14:35:02: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.11.
04/11/2016 14:35:02: learnRatePerSample reduced to 0.0125
04/11/2016 14:35:02: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.12'

04/11/2016 14:35:02: Starting Epoch 13: learning rate per sample = 0.012500  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:02: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:02: Finished Epoch[13 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.0125; EpochTime=0.11972
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5157878    Perplexity = 12.376355    
04/11/2016 14:35:03: Finished Epoch[13 of 100]: [Validation Set] TrainLossPerSample = 2.5157878
04/11/2016 14:35:03: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.12.
04/11/2016 14:35:03: learnRatePerSample reduced to 0.0062500001
04/11/2016 14:35:03: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.13'

04/11/2016 14:35:03: Starting Epoch 14: learning rate per sample = 0.006250  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:03: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:03: Finished Epoch[14 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.0062500001; EpochTime=0.120291
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5129564    Perplexity = 12.341362    
04/11/2016 14:35:03: Finished Epoch[14 of 100]: [Validation Set] TrainLossPerSample = 2.5129564
04/11/2016 14:35:03: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.13.
04/11/2016 14:35:04: learnRatePerSample reduced to 0.003125
04/11/2016 14:35:04: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.14'

04/11/2016 14:35:04: Starting Epoch 15: learning rate per sample = 0.003125  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:04: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:04: Finished Epoch[15 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.003125; EpochTime=0.120629
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5115547    Perplexity = 12.324075    
04/11/2016 14:35:04: Finished Epoch[15 of 100]: [Validation Set] TrainLossPerSample = 2.5115547
04/11/2016 14:35:04: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.14.
04/11/2016 14:35:04: learnRatePerSample reduced to 0.0015625
04/11/2016 14:35:04: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.15'

04/11/2016 14:35:05: Starting Epoch 16: learning rate per sample = 0.001563  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:05: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:05: Finished Epoch[16 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.0015625; EpochTime=0.158144
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5108567    Perplexity = 12.315476    
04/11/2016 14:35:05: Finished Epoch[16 of 100]: [Validation Set] TrainLossPerSample = 2.5108567
04/11/2016 14:35:05: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.15.
04/11/2016 14:35:05: learnRatePerSample reduced to 0.00078125001
04/11/2016 14:35:05: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.16'

04/11/2016 14:35:06: Starting Epoch 17: learning rate per sample = 0.000781  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:06: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:06: Finished Epoch[17 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.00078125001; EpochTime=0.120415
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510509    Perplexity = 12.311195    
04/11/2016 14:35:06: Finished Epoch[17 of 100]: [Validation Set] TrainLossPerSample = 2.510509
04/11/2016 14:35:06: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.16.
04/11/2016 14:35:06: learnRatePerSample reduced to 0.00039062501
04/11/2016 14:35:06: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.17'

04/11/2016 14:35:06: Starting Epoch 18: learning rate per sample = 0.000391  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:06: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:06: Finished Epoch[18 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.00039062501; EpochTime=0.13036
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5103353    Perplexity = 12.309056    
04/11/2016 14:35:06: Finished Epoch[18 of 100]: [Validation Set] TrainLossPerSample = 2.5103353
04/11/2016 14:35:06: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.17.
04/11/2016 14:35:07: learnRatePerSample reduced to 0.0001953125
04/11/2016 14:35:07: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.18'

04/11/2016 14:35:07: Starting Epoch 19: learning rate per sample = 0.000195  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:07: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:07: Finished Epoch[19 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.0001953125; EpochTime=0.133762
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5102486    Perplexity = 12.30799    
04/11/2016 14:35:07: Finished Epoch[19 of 100]: [Validation Set] TrainLossPerSample = 2.5102486
04/11/2016 14:35:07: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.18.
04/11/2016 14:35:07: learnRatePerSample reduced to 9.7656251e-005
04/11/2016 14:35:08: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.19'

04/11/2016 14:35:08: Starting Epoch 20: learning rate per sample = 0.000098  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:08: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:08: Finished Epoch[20 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=0.141954
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5102053    Perplexity = 12.307457    
04/11/2016 14:35:08: Finished Epoch[20 of 100]: [Validation Set] TrainLossPerSample = 2.5102053
04/11/2016 14:35:08: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.19.
04/11/2016 14:35:08: learnRatePerSample reduced to 4.8828126e-005
04/11/2016 14:35:08: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.20'

04/11/2016 14:35:09: Starting Epoch 21: learning rate per sample = 0.000049  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:09: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:09: Finished Epoch[21 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 4.8828126e-005; EpochTime=0.119886
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5101835    Perplexity = 12.307188    
04/11/2016 14:35:09: Finished Epoch[21 of 100]: [Validation Set] TrainLossPerSample = 2.5101835
04/11/2016 14:35:09: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.20.
04/11/2016 14:35:09: learnRatePerSample reduced to 2.4414063e-005
04/11/2016 14:35:09: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.21'

04/11/2016 14:35:09: Starting Epoch 22: learning rate per sample = 0.000024  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:09: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:10: Finished Epoch[22 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 2.4414063e-005; EpochTime=0.152458
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5101723    Perplexity = 12.307051    
04/11/2016 14:35:10: Finished Epoch[22 of 100]: [Validation Set] TrainLossPerSample = 2.5101723
04/11/2016 14:35:10: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.21.
04/11/2016 14:35:10: learnRatePerSample reduced to 1.2207031e-005
04/11/2016 14:35:10: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.22'

04/11/2016 14:35:10: Starting Epoch 23: learning rate per sample = 0.000012  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:10: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:10: Finished Epoch[23 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 1.2207031e-005; EpochTime=0.141392
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5101669    Perplexity = 12.306984    
04/11/2016 14:35:10: Finished Epoch[23 of 100]: [Validation Set] TrainLossPerSample = 2.5101669
04/11/2016 14:35:10: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.22.
04/11/2016 14:35:11: learnRatePerSample reduced to 6.1035157e-006
04/11/2016 14:35:11: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.23'

04/11/2016 14:35:11: Starting Epoch 24: learning rate per sample = 0.000006  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:11: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:11: Finished Epoch[24 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 6.1035157e-006; EpochTime=0.123768
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5101646    Perplexity = 12.306956    
04/11/2016 14:35:11: Finished Epoch[24 of 100]: [Validation Set] TrainLossPerSample = 2.5101646
04/11/2016 14:35:11: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.23.
04/11/2016 14:35:11: learnRatePerSample reduced to 3.0517579e-006
04/11/2016 14:35:12: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.24'

04/11/2016 14:35:12: Starting Epoch 25: learning rate per sample = 0.000003  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:12: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:12: Finished Epoch[25 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 3.0517579e-006; EpochTime=0.129668
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5101631    Perplexity = 12.306937    
04/11/2016 14:35:12: Finished Epoch[25 of 100]: [Validation Set] TrainLossPerSample = 2.5101631
04/11/2016 14:35:12: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.24.
04/11/2016 14:35:12: learnRatePerSample reduced to 1.5258789e-006
04/11/2016 14:35:12: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.25'

04/11/2016 14:35:13: Starting Epoch 26: learning rate per sample = 0.000002  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:13: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:13: Finished Epoch[26 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 1.5258789e-006; EpochTime=0.1211
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5101625    Perplexity = 12.30693    
04/11/2016 14:35:13: Finished Epoch[26 of 100]: [Validation Set] TrainLossPerSample = 2.5101625
04/11/2016 14:35:13: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.25.
04/11/2016 14:35:13: learnRatePerSample reduced to 7.6293946e-007
04/11/2016 14:35:13: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.26'

04/11/2016 14:35:13: Starting Epoch 27: learning rate per sample = 0.000001  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:13: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:13: Finished Epoch[27 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 7.6293946e-007; EpochTime=0.123978
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5101622    Perplexity = 12.306926    
04/11/2016 14:35:14: Finished Epoch[27 of 100]: [Validation Set] TrainLossPerSample = 2.5101622
04/11/2016 14:35:14: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.26.
04/11/2016 14:35:14: learnRatePerSample reduced to 3.8146973e-007
04/11/2016 14:35:14: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.27'

04/11/2016 14:35:14: Starting Epoch 28: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:14: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:14: Finished Epoch[28 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 3.8146973e-007; EpochTime=0.120169
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:14: Finished Epoch[28 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:14: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.27.
04/11/2016 14:35:15: learnRatePerSample reduced to 1.9073487e-007
04/11/2016 14:35:15: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.28'

04/11/2016 14:35:15: Starting Epoch 29: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:15: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:15: Finished Epoch[29 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 1.9073487e-007; EpochTime=0.125757
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:15: Finished Epoch[29 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:15: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.28.
04/11/2016 14:35:15: learnRatePerSample reduced to 9.5367433e-008
04/11/2016 14:35:16: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.29'

04/11/2016 14:35:16: Starting Epoch 30: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:16: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:16: Finished Epoch[30 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 9.5367433e-008; EpochTime=0.119964
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:16: Finished Epoch[30 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:16: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.29.
04/11/2016 14:35:16: learnRatePerSample reduced to 4.7683717e-008
04/11/2016 14:35:16: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.30'

04/11/2016 14:35:17: Starting Epoch 31: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:17: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:17: Finished Epoch[31 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 4.7683717e-008; EpochTime=0.145194
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:17: Finished Epoch[31 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:17: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.30.
04/11/2016 14:35:17: learnRatePerSample reduced to 2.3841858e-008
04/11/2016 14:35:17: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.31'

04/11/2016 14:35:17: Starting Epoch 32: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:17: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:17: Finished Epoch[32 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 2.3841858e-008; EpochTime=0.130469
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:17: Finished Epoch[32 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:17: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.31.
04/11/2016 14:35:18: learnRatePerSample reduced to 1.1920929e-008
04/11/2016 14:35:18: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.32'

04/11/2016 14:35:18: Starting Epoch 33: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:18: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:18: Finished Epoch[33 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 1.1920929e-008; EpochTime=0.122201
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:18: Finished Epoch[33 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:18: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.32.
04/11/2016 14:35:19: learnRatePerSample reduced to 5.9604646e-009
04/11/2016 14:35:19: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.33'

04/11/2016 14:35:19: Starting Epoch 34: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:19: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:19: Finished Epoch[34 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 5.9604646e-009; EpochTime=0.121087
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:19: Finished Epoch[34 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:19: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.33.
04/11/2016 14:35:19: learnRatePerSample reduced to 2.9802323e-009
04/11/2016 14:35:19: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.34'

04/11/2016 14:35:20: Starting Epoch 35: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:20: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:20: Finished Epoch[35 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 2.9802323e-009; EpochTime=0.120056
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:20: Finished Epoch[35 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:20: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.34.
04/11/2016 14:35:20: learnRatePerSample reduced to 1.4901161e-009
04/11/2016 14:35:20: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.35'

04/11/2016 14:35:20: Starting Epoch 36: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:35:20: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:35:21: Finished Epoch[36 of 100]: [Training Set] TrainLossPerSample = 2.4028003; TotalSamplesSeen = 810; AvgLearningRatePerSample = 1.4901161e-009; EpochTime=0.143631
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.510162    Perplexity = 12.306923    
04/11/2016 14:35:21: Finished Epoch[36 of 100]: [Validation Set] TrainLossPerSample = 2.510162
04/11/2016 14:35:21: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.35.
04/11/2016 14:35:21: learnRatePerSample reduced to 7.4505807e-010
04/11/2016 14:35:21: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_gpu/cntkdebug.dnn.36'
04/11/2016 14:35:21: Learn Rate Per Sample for Epoch[37] = 7.4505807e-010 is less than minLearnRate 9.9999997e-010. Training complete.
04/11/2016 14:35:21: CNTKCommandTrainEnd: LSTM

04/11/2016 14:35:21: Action "train" complete.


04/11/2016 14:35:21: ##############################################################################
04/11/2016 14:35:21: #                                                                            #
04/11/2016 14:35:21: # Action "write"                                                             #
04/11/2016 14:35:21: #                                                                            #
04/11/2016 14:35:21: ##############################################################################

BatchLUSequenceReader: Input file is C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.test.apos.pred.pos.head.IOB.simple

Post-processing network...

4 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	PosteriorProb = Softmax()
	labels = InputValue()
	outputs = Times()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Loop[1] --> Loop_AutoName75 -> 31 nodes

	AutoName40	AutoName68	AutoName71
	AutoName39	AutoName59	AutoName62
	AutoName43	AutoName58	AutoName63
	AutoName64	AutoName44	AutoName65
	AutoName38	AutoName46	AutoName49
	AutoName42	AutoName45	AutoName50
	AutoName51	AutoName41	AutoName52
	AutoName53	AutoName55	AutoName56
	AutoName57	AutoName66	AutoName67
	AutoName72	AutoName73	AutoName74
	AutoName75

Loop[2] --> Loop_AutoName113 -> 31 nodes

	AutoName78	AutoName106	AutoName109
	AutoName77	AutoName97	AutoName100
	AutoName81	AutoName96	AutoName101
	AutoName102	AutoName82	AutoName103
	AutoName76	AutoName84	AutoName87
	AutoName80	AutoName83	AutoName88
	AutoName89	AutoName79	AutoName90
	AutoName91	AutoName93	AutoName94
	AutoName95	AutoName104	AutoName105
	AutoName110	AutoName111	AutoName112
	AutoName113

Validating network. 168 nodes to process in pass 1.


Validating network. 119 nodes to process in pass 2.


Validating network. 42 nodes to process in pass 3.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [127 x *]
Validating --> W4 = LearnableParameter() :  -> [127 x 300]
Validating --> WXO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO0 = LearnableParameter() :  -> [300 x 150]
Validating --> E0 = LearnableParameter() :  -> [50 x 944]
Validating --> features = InputValue() :  -> [2832 x *]
Validating --> LookupTable = LookupTable (E0, features) : [50 x 944], [2832 x *] -> [150 x *]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bo0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bf0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bi0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> WHC0 = LearnableParameter() :  -> [300 x 300]
Validating --> bc0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName2 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName1 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName5 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName26 = Sigmoid (AutoName25) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName6 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName0 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName4 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName13 = Sigmoid (AutoName12) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName3 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [300 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName18 = Tanh (AutoName17) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName35 = Sigmoid (AutoName34) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName36 = Tanh (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName69 = Times (WXO2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName70 = Plus (AutoName69, bo2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName60 = Times (WXF2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName61 = Plus (AutoName60, bf2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName47 = Times (WXI2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName48 = Plus (AutoName47, bi2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName54 = Times (WXC2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC2 = LearnableParameter() :  -> [300 x 300]
Validating --> bc2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName40 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName68 = Times (WHO2, AutoName40) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName71 = Plus (AutoName70, AutoName68) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName39 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName59 = Times (WHF2, AutoName39) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName62 = Plus (AutoName61, AutoName59) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName43 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName58 = DiagTimes (WCF2, AutoName43) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName63 = Plus (AutoName62, AutoName58) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName64 = Sigmoid (AutoName63) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName44 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName65 = ElementTimes (AutoName64, AutoName44) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName38 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName46 = Times (WHI2, AutoName38) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName49 = Plus (AutoName48, AutoName46) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName42 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName45 = DiagTimes (WCI2, AutoName42) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName50 = Plus (AutoName49, AutoName45) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName51 = Sigmoid (AutoName50) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName41 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName52 = Times (WHC2, AutoName41) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName53 = Plus (AutoName52, bc2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName55 = Plus (AutoName54, AutoName53) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName56 = Tanh (AutoName55) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName57 = ElementTimes (AutoName51, AutoName56) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName66 = Plus (AutoName65, AutoName57) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName67 = DiagTimes (WCO2, AutoName66) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName72 = Plus (AutoName71, AutoName67) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName73 = Sigmoid (AutoName72) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName74 = Tanh (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName75 = ElementTimes (AutoName73, AutoName74) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName107 = Times (WXO3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName108 = Plus (AutoName107, bo3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName98 = Times (WXF3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName99 = Plus (AutoName98, bf3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName85 = Times (WXI3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName86 = Plus (AutoName85, bi3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName92 = Times (WXC3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC3 = LearnableParameter() :  -> [300 x 300]
Validating --> bc3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName78 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName106 = Times (WHO3, AutoName78) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName109 = Plus (AutoName108, AutoName106) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName77 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName97 = Times (WHF3, AutoName77) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName100 = Plus (AutoName99, AutoName97) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName81 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName96 = DiagTimes (WCF3, AutoName81) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName101 = Plus (AutoName100, AutoName96) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName102 = Sigmoid (AutoName101) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName82 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName103 = ElementTimes (AutoName102, AutoName82) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName76 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName84 = Times (WHI3, AutoName76) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName87 = Plus (AutoName86, AutoName84) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName80 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName83 = DiagTimes (WCI3, AutoName80) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName88 = Plus (AutoName87, AutoName83) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName89 = Sigmoid (AutoName88) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName79 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName90 = Times (WHC3, AutoName79) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName91 = Plus (AutoName90, bc3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName93 = Plus (AutoName92, AutoName91) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName94 = Tanh (AutoName93) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName95 = ElementTimes (AutoName89, AutoName94) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName104 = Plus (AutoName103, AutoName95) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName105 = DiagTimes (WCO3, AutoName104) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName110 = Plus (AutoName109, AutoName105) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName111 = Sigmoid (AutoName110) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName112 = Tanh (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName113 = ElementTimes (AutoName111, AutoName112) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName114 = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, AutoName114) : [127 x *], [127 x 1 x *] -> [1]
Validating --> outputs = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> PosteriorProb = Softmax (outputs) : [127 x 1 x *] -> [127 x 1 x *]


48 out of 168 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 5 lines with a total of 92+5 tokens.
O O O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O O O O B-stoploc.city_name I-stoploc.city_name O 
O O O O O O O O O O O O O O O O O O O O O 
O O B-depart_date.month_name B-depart_date.day_number O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_time.time_relative B-depart_time.time I-depart_time.time O 
O O O O O O O O O O O O O O O O O O 
O O B-depart_date.month_name B-depart_date.day_number O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O 
O O O O O O O O O O O O O O O 
O O O O O O O B-round_trip I-round_trip O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O 
O O O O O O O O O O O O O O O O O O 
O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O B-airline_name I-airline_name O 
O O O O O O O O O O O O O O O O O O O 
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Total Samples Evaluated = 91

04/11/2016 14:35:22: Action "write" complete.

04/11/2016 14:35:22: __COMPLETED__