=== Running /cygdrive/c/src/cntk_github/x64/release/cntk.exe configFile=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU/rnnlu.cntk currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu DeviceId=-1 timestamping=true NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
-------------------------------------------------------------------
Build info: 

		Built time: Apr 11 2016 13:32:44
		Last modified date: Thu Apr  7 11:05:47 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: E:\lib\cub-1.4.1
		CUDNN_PATH: E:\lib\cuDNN_v4
		Build Branch: alrezni/examples_text
		Build SHA1: 110e330e5b490c97d4836374ed83fbe642e4f857 (modified)
		Built by alrezni on DIFFENG
		Build Path: C:\src\cntk_github\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
04/11/2016 14:32:23: -------------------------------------------------------------------
04/11/2016 14:32:23: Build info: 

04/11/2016 14:32:23: 		Built time: Apr 11 2016 13:32:44
04/11/2016 14:32:23: 		Last modified date: Thu Apr  7 11:05:47 2016
04/11/2016 14:32:23: 		Build type: Release
04/11/2016 14:32:23: 		Build target: GPU
04/11/2016 14:32:23: 		With 1bit-SGD: no
04/11/2016 14:32:23: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
04/11/2016 14:32:23: 		CUB_PATH: E:\lib\cub-1.4.1
04/11/2016 14:32:23: 		CUDNN_PATH: E:\lib\cuDNN_v4
04/11/2016 14:32:23: 		Build Branch: alrezni/examples_text
04/11/2016 14:32:23: 		Build SHA1: 110e330e5b490c97d4836374ed83fbe642e4f857 (modified)
04/11/2016 14:32:23: 		Built by alrezni on DIFFENG
04/11/2016 14:32:23: 		Build Path: C:\src\cntk_github\Source\CNTK\
04/11/2016 14:32:23: -------------------------------------------------------------------

04/11/2016 14:32:23: Running on DIFFENG at 2016/04/11 14:32:23
04/11/2016 14:32:23: Command line: 
C:\src\cntk_github\x64\release\cntk.exe  configFile=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU/rnnlu.cntk  currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU  RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu  DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU  ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU  OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu  DeviceId=-1  timestamping=true  NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU  ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu  OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu



04/11/2016 14:32:23: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/11/2016 14:32:23: precision="float"
deviceId = $DeviceId$
command=LSTM:LSTMTest
traceLevel=1
LSTM=[
    action=train
	makeMode=true
    modelPath=$ExpDir$/cntkdebug.dnn
    SimpleNetworkBuilder=[
        rnnType=LSTM
        layerSizes=2832:50:300:300:300:127
        lookupTableOrder=3
        recurrentLayer=2:3:4
        defaultHiddenActivity=0.1
        initValueScale=6.0
        trainingCriterion=crossentropywithsoftmax
        evalCriterion=crossentropywithsoftmax
    ]
    SGD=[
maxEpochs=100   
epochSize=71524     
        minibatchSize=10000
        learningRatesPerSample=0.1
        momentumAsTimeConstant=1000
        gradientClippingWithTruncation=true
        clippingThresholdPerSample=15.0
        numMBsToShowResult=50
        loadBestModel=true
        AutoAdjust=[
            autoAdjustLR=adjustafterepoch
            reduceLearnRateIfImproveLessThan=0
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
        ]
    ]
    reader=[
        readerType=LUSequenceReader
        wordContext=0:1:2
        randomize=None
nbruttsineachrecurrentiter=10  
        equalLength = false
        wfile=$ExpDir$/sequenceSentence.bin
        wsize=256
        wrecords=1000
        windowSize=10000
        unk="<unk>"
          wordmap=$DataDir$/inputmap.txt
          file=$DataDir$/atis.train.apos.pred.pos.head.IOB.simple
          features=[
            dim=0
            sectionType=data
          ]
          sequence=[
            dim=1
            wrecords=2
            sectionType=data
          ]
          labelIn=[
            dim=1
            usewordmap=true
            labelDim=10000
            labelMappingFile=$ExpDir$/sentenceLabels.txt
            labelType=Category
            beginSequence="BOS"
            endSequence="EOS"
            usewordmap=true
            token=$DataDir$/input.txt
            elementSize=4
            sectionType=labels
            mapping=[
              wrecords=11
              elementSize=10
              sectionType=labelMapping
            ]
            category=[
              dim=11
              sectionType=categoryLabels
            ]
          ]
          labels=[
            dim=1
            labelType=Category
            token=$DataDir$/output.txt
            labelMappingFile=$ExpDir$/sentenceLabels.out.txt
            sectionType=labels
            mapping=[
              sectionType=labelMapping
            ]
            category=[
              sectionType=categoryLabels
            ]
          ]
    ]
    cvReader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      nbruttsineachrecurrentiter=200
      equalLength = false
      wfile=$ExpDir$/sequenceSentence.valid.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      unk="<unk>"
      wordmap=$DataDir$/inputmap.txt
      file=$DataDir$/atis.dev.IOB.simple
      features=[
        dim=0
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=$ExpDir$/sentenceLabels.in.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=$DataDir$/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        token=$DataDir$/output.txt
        labelDim=10000
        labelMappingFile=$ExpDir$/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
]
LSTMTest=[
    action=write
    epochSize=4430000
    defaultHiddenActivity=0.1
    modelPath=$ExpDir$/cntkdebug.dnn
    outputNodeNames=outputs:labels
    reader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      unk="<unk>"
      wordmap=$DataDir$/inputmap.txt
      file=$DataDir$/atis.test.apos.pred.pos.head.IOB.simple
      wfile=$ExpDir$/sequenceSentence.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      features=[
        dim=0 
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=$ExpDir$/sentenceLabels.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=$DataDir$/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        token=$DataDir$/output.txt
        labelDim=127
        labelMappingFile=$ExpDir$/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
    writer=[
        writerType=LUSequenceWriter
        outputs=[
            file=$OutDir$/output.rec.txt
            token=$DataDir$/output.txt
        ]
        labels=[
            file=$OutDir$/output.lbl.txt
            token=$DataDir$/output.txt
        ]
    ]
]
currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU
OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
DeviceId=-1
timestamping=true
NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU
ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu

04/11/2016 14:32:23: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/11/2016 14:32:23: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/11/2016 14:32:23: precision="float"
deviceId = -1
command=LSTM:LSTMTest
traceLevel=1
LSTM=[
    action=train
	makeMode=true
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn
    SimpleNetworkBuilder=[
        rnnType=LSTM
        layerSizes=2832:50:300:300:300:127
        lookupTableOrder=3
        recurrentLayer=2:3:4
        defaultHiddenActivity=0.1
        initValueScale=6.0
        trainingCriterion=crossentropywithsoftmax
        evalCriterion=crossentropywithsoftmax
    ]
    SGD=[
maxEpochs=100   
epochSize=71524     
        minibatchSize=10000
        learningRatesPerSample=0.1
        momentumAsTimeConstant=1000
        gradientClippingWithTruncation=true
        clippingThresholdPerSample=15.0
        numMBsToShowResult=50
        loadBestModel=true
        AutoAdjust=[
            autoAdjustLR=adjustafterepoch
            reduceLearnRateIfImproveLessThan=0
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
        ]
    ]
    reader=[
        readerType=LUSequenceReader
        wordContext=0:1:2
        randomize=None
nbruttsineachrecurrentiter=10  
        equalLength = false
        wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sequenceSentence.bin
        wsize=256
        wrecords=1000
        windowSize=10000
        unk="<unk>"
          wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
          file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.train.apos.pred.pos.head.IOB.simple
          features=[
            dim=0
            sectionType=data
          ]
          sequence=[
            dim=1
            wrecords=2
            sectionType=data
          ]
          labelIn=[
            dim=1
            usewordmap=true
            labelDim=10000
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.txt
            labelType=Category
            beginSequence="BOS"
            endSequence="EOS"
            usewordmap=true
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
            elementSize=4
            sectionType=labels
            mapping=[
              wrecords=11
              elementSize=10
              sectionType=labelMapping
            ]
            category=[
              dim=11
              sectionType=categoryLabels
            ]
          ]
          labels=[
            dim=1
            labelType=Category
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.out.txt
            sectionType=labels
            mapping=[
              sectionType=labelMapping
            ]
            category=[
              sectionType=categoryLabels
            ]
          ]
    ]
    cvReader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      nbruttsineachrecurrentiter=200
      equalLength = false
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sequenceSentence.valid.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.dev.IOB.simple
      features=[
        dim=0
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.in.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
]
LSTMTest=[
    action=write
    epochSize=4430000
    defaultHiddenActivity=0.1
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn
    outputNodeNames=outputs:labels
    reader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.test.apos.pred.pos.head.IOB.simple
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sequenceSentence.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      features=[
        dim=0 
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=127
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
    writer=[
        writerType=LUSequenceWriter
        outputs=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/output.rec.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
        labels=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/output.lbl.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
    ]
]
currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU
OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
DeviceId=-1
timestamping=true
NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU
ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu

04/11/2016 14:32:23: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/11/2016 14:32:23: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: rnnlu.cntk:command=LSTM:LSTMTest
configparameters: rnnlu.cntk:ConfigDir=C:\src\cntk_github\Examples\Text\Miscellaneous\SLU
configparameters: rnnlu.cntk:currentDirectory=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
configparameters: rnnlu.cntk:DataDir=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU
configparameters: rnnlu.cntk:deviceId=-1
configparameters: rnnlu.cntk:ExpDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
configparameters: rnnlu.cntk:LSTM=[
    action=train
	makeMode=true
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn
    SimpleNetworkBuilder=[
        rnnType=LSTM
        layerSizes=2832:50:300:300:300:127
        lookupTableOrder=3
        recurrentLayer=2:3:4
        defaultHiddenActivity=0.1
        initValueScale=6.0
        trainingCriterion=crossentropywithsoftmax
        evalCriterion=crossentropywithsoftmax
    ]
    SGD=[
maxEpochs=100   
epochSize=71524     
        minibatchSize=10000
        learningRatesPerSample=0.1
        momentumAsTimeConstant=1000
        gradientClippingWithTruncation=true
        clippingThresholdPerSample=15.0
        numMBsToShowResult=50
        loadBestModel=true
        AutoAdjust=[
            autoAdjustLR=adjustafterepoch
            reduceLearnRateIfImproveLessThan=0
            increaseLearnRateIfImproveMoreThan=1000000000
            learnRateDecreaseFactor=0.5
            learnRateIncreaseFactor=1.382
        ]
    ]
    reader=[
        readerType=LUSequenceReader
        wordContext=0:1:2
        randomize=None
nbruttsineachrecurrentiter=10  
        equalLength = false
        wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sequenceSentence.bin
        wsize=256
        wrecords=1000
        windowSize=10000
        unk="<unk>"
          wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
          file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.train.apos.pred.pos.head.IOB.simple
          features=[
            dim=0
            sectionType=data
          ]
          sequence=[
            dim=1
            wrecords=2
            sectionType=data
          ]
          labelIn=[
            dim=1
            usewordmap=true
            labelDim=10000
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.txt
            labelType=Category
            beginSequence="BOS"
            endSequence="EOS"
            usewordmap=true
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
            elementSize=4
            sectionType=labels
            mapping=[
              wrecords=11
              elementSize=10
              sectionType=labelMapping
            ]
            category=[
              dim=11
              sectionType=categoryLabels
            ]
          ]
          labels=[
            dim=1
            labelType=Category
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
            labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.out.txt
            sectionType=labels
            mapping=[
              sectionType=labelMapping
            ]
            category=[
              sectionType=categoryLabels
            ]
          ]
    ]
    cvReader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      nbruttsineachrecurrentiter=200
      equalLength = false
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sequenceSentence.valid.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.dev.IOB.simple
      features=[
        dim=0
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.in.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
]

configparameters: rnnlu.cntk:LSTMTest=[
    action=write
    epochSize=4430000
    defaultHiddenActivity=0.1
    modelPath=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn
    outputNodeNames=outputs:labels
    reader=[
      readerType=LUSequenceReader
      randomize=None
      wordContext=0:1:2
      unk="<unk>"
      wordmap=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/inputmap.txt
      file=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.test.apos.pred.pos.head.IOB.simple
      wfile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sequenceSentence.bin
      wsize=256
      wrecords=1000
      windowSize=10000
      features=[
        dim=0 
        sectionType=data
      ]
      sequence=[
        dim=1
        wrecords=2
        sectionType=data
      ]
      labelIn=[
        dim=1
        labelDim=10000
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.txt
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        usewordmap=true
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/input.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=11
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=11
          sectionType=categoryLabels
        ]
      ]
      labels=[
        dim=1
        labelType=Category
        beginSequence="BOS"
        endSequence="EOS"
        token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        labelDim=127
        labelMappingFile=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/sentenceLabels.out.txt
        elementSize=4
        sectionType=labels
        mapping=[
          wrecords=3
          elementSize=10
          sectionType=labelMapping
        ]
        category=[
          dim=3
          sectionType=categoryLabels
        ]
      ]
    ]
    writer=[
        writerType=LUSequenceWriter
        outputs=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/output.rec.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
        labels=[
            file=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/output.lbl.txt
            token=C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/output.txt
        ]
    ]
]

configparameters: rnnlu.cntk:NdlDir=C:\src\cntk_github\Tests\EndToEndTests\Examples\Text\Miscellaneous\SLU
configparameters: rnnlu.cntk:OutDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
configparameters: rnnlu.cntk:OutputDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
configparameters: rnnlu.cntk:precision=float
configparameters: rnnlu.cntk:RunDir=E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu
configparameters: rnnlu.cntk:timestamping=true
configparameters: rnnlu.cntk:traceLevel=1
04/11/2016 14:32:23: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/11/2016 14:32:23: Commands: LSTM LSTMTest
04/11/2016 14:32:23: Precision = "float"
04/11/2016 14:32:23: CNTKModelPath: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn
04/11/2016 14:32:23: CNTKCommandTrainInfo: LSTM : 100
04/11/2016 14:32:23: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 100

04/11/2016 14:32:23: ##############################################################################
04/11/2016 14:32:23: #                                                                            #
04/11/2016 14:32:23: # Action "train"                                                             #
04/11/2016 14:32:23: #                                                                            #
04/11/2016 14:32:23: ##############################################################################

04/11/2016 14:32:23: CNTKCommandTrainBegin: LSTM
SimpleNetworkBuilder Using CPU
BatchLUSequenceReader: Input file is C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.train.apos.pred.pos.head.IOB.simple
BatchLUSequenceReader: Input file is C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.dev.IOB.simple

04/11/2016 14:32:23: Creating virgin network.

Post-processing network...

3 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	PosteriorProb = Softmax()
	outputs = Times()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Loop[1] --> Loop_AutoName75 -> 31 nodes

	AutoName40	AutoName68	AutoName71
	AutoName39	AutoName59	AutoName62
	AutoName43	AutoName58	AutoName63
	AutoName64	AutoName44	AutoName65
	AutoName38	AutoName46	AutoName49
	AutoName42	AutoName45	AutoName50
	AutoName51	AutoName41	AutoName52
	AutoName53	AutoName55	AutoName56
	AutoName57	AutoName66	AutoName67
	AutoName72	AutoName73	AutoName74
	AutoName75

Loop[2] --> Loop_AutoName113 -> 31 nodes

	AutoName78	AutoName106	AutoName109
	AutoName77	AutoName97	AutoName100
	AutoName81	AutoName96	AutoName101
	AutoName102	AutoName82	AutoName103
	AutoName76	AutoName84	AutoName87
	AutoName80	AutoName83	AutoName88
	AutoName89	AutoName79	AutoName90
	AutoName91	AutoName93	AutoName94
	AutoName95	AutoName104	AutoName105
	AutoName110	AutoName111	AutoName112
	AutoName113

Validating network. 168 nodes to process in pass 1.


Validating network. 119 nodes to process in pass 2.


Validating network. 42 nodes to process in pass 3.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [127 x *]
Validating --> W4 = LearnableParameter() :  -> [127 x 300]
Validating --> WXO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO0 = LearnableParameter() :  -> [300 x 150]
Validating --> E0 = LearnableParameter() :  -> [50 x 944]
Validating --> features = InputValue() :  -> [2832 x *]
Validating --> LookupTable = LookupTable (E0, features) : [50 x 944], [2832 x *] -> [150 x *]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bo0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bf0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bi0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> WHC0 = LearnableParameter() :  -> [300 x 300]
Validating --> bc0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName2 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName1 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName5 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName26 = Sigmoid (AutoName25) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName6 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName0 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName4 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName13 = Sigmoid (AutoName12) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName3 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [300 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName18 = Tanh (AutoName17) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName35 = Sigmoid (AutoName34) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName36 = Tanh (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName69 = Times (WXO2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName70 = Plus (AutoName69, bo2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName60 = Times (WXF2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName61 = Plus (AutoName60, bf2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName47 = Times (WXI2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName48 = Plus (AutoName47, bi2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName54 = Times (WXC2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC2 = LearnableParameter() :  -> [300 x 300]
Validating --> bc2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName40 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName68 = Times (WHO2, AutoName40) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName71 = Plus (AutoName70, AutoName68) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName39 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName59 = Times (WHF2, AutoName39) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName62 = Plus (AutoName61, AutoName59) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName43 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName58 = DiagTimes (WCF2, AutoName43) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName63 = Plus (AutoName62, AutoName58) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName64 = Sigmoid (AutoName63) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName44 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName65 = ElementTimes (AutoName64, AutoName44) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName38 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName46 = Times (WHI2, AutoName38) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName49 = Plus (AutoName48, AutoName46) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName42 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName45 = DiagTimes (WCI2, AutoName42) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName50 = Plus (AutoName49, AutoName45) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName51 = Sigmoid (AutoName50) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName41 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName52 = Times (WHC2, AutoName41) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName53 = Plus (AutoName52, bc2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName55 = Plus (AutoName54, AutoName53) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName56 = Tanh (AutoName55) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName57 = ElementTimes (AutoName51, AutoName56) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName66 = Plus (AutoName65, AutoName57) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName67 = DiagTimes (WCO2, AutoName66) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName72 = Plus (AutoName71, AutoName67) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName73 = Sigmoid (AutoName72) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName74 = Tanh (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName75 = ElementTimes (AutoName73, AutoName74) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName107 = Times (WXO3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName108 = Plus (AutoName107, bo3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName98 = Times (WXF3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName99 = Plus (AutoName98, bf3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName85 = Times (WXI3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName86 = Plus (AutoName85, bi3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName92 = Times (WXC3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC3 = LearnableParameter() :  -> [300 x 300]
Validating --> bc3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName78 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName106 = Times (WHO3, AutoName78) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName109 = Plus (AutoName108, AutoName106) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName77 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName97 = Times (WHF3, AutoName77) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName100 = Plus (AutoName99, AutoName97) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName81 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName96 = DiagTimes (WCF3, AutoName81) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName101 = Plus (AutoName100, AutoName96) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName102 = Sigmoid (AutoName101) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName82 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName103 = ElementTimes (AutoName102, AutoName82) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName76 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName84 = Times (WHI3, AutoName76) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName87 = Plus (AutoName86, AutoName84) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName80 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName83 = DiagTimes (WCI3, AutoName80) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName88 = Plus (AutoName87, AutoName83) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName89 = Sigmoid (AutoName88) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName79 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName90 = Times (WHC3, AutoName79) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName91 = Plus (AutoName90, bc3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName93 = Plus (AutoName92, AutoName91) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName94 = Tanh (AutoName93) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName95 = ElementTimes (AutoName89, AutoName94) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName104 = Plus (AutoName103, AutoName95) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName105 = DiagTimes (WCO3, AutoName104) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName110 = Plus (AutoName109, AutoName105) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName111 = Sigmoid (AutoName110) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName112 = Tanh (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName113 = ElementTimes (AutoName111, AutoName112) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName114 = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, AutoName114) : [127 x *], [127 x 1 x *] -> [1]
Validating --> outputs = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> PosteriorProb = Softmax (outputs) : [127 x 1 x *] -> [127 x 1 x *]


48 out of 168 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/11/2016 14:32:23: Created model with 168 nodes on CPU.

04/11/2016 14:32:23: Training criterion node(s):
04/11/2016 14:32:23: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax


Allocating matrices for forward and/or backward propagation.
04/11/2016 14:32:23: No PreCompute nodes found, skipping PreCompute step.

04/11/2016 14:32:23: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:32:23: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:32:27: Finished Epoch[ 1 of 100]: [Training Set] TrainLossPerSample = 4.8437672; TotalSamplesSeen = 81; AvgLearningRatePerSample = 0.1; EpochTime=4.30016
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.8095164    Perplexity = 122.67228    
04/11/2016 14:32:31: Finished Epoch[ 1 of 100]: [Validation Set] TrainLossPerSample = 4.8095164
04/11/2016 14:32:31: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.1'

04/11/2016 14:32:31: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:32:31: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:32:36: Finished Epoch[ 2 of 100]: [Training Set] TrainLossPerSample = 4.8095164; TotalSamplesSeen = 162; AvgLearningRatePerSample = 0.1; EpochTime=5.4871
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.7445012    Perplexity = 114.95045    
04/11/2016 14:32:39: Finished Epoch[ 2 of 100]: [Validation Set] TrainLossPerSample = 4.7445012
04/11/2016 14:32:39: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.2'

04/11/2016 14:32:39: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:32:39: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:32:44: Finished Epoch[ 3 of 100]: [Training Set] TrainLossPerSample = 4.7445011; TotalSamplesSeen = 243; AvgLearningRatePerSample = 0.1; EpochTime=4.92963
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.6495007    Perplexity = 104.53278    
04/11/2016 14:32:48: Finished Epoch[ 3 of 100]: [Validation Set] TrainLossPerSample = 4.6495007
04/11/2016 14:32:48: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.3'

04/11/2016 14:32:48: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:32:48: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:32:52: Finished Epoch[ 4 of 100]: [Training Set] TrainLossPerSample = 4.6495008; TotalSamplesSeen = 324; AvgLearningRatePerSample = 0.1; EpochTime=3.69782
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.5197878    Perplexity = 91.816115    
04/11/2016 14:32:55: Finished Epoch[ 4 of 100]: [Validation Set] TrainLossPerSample = 4.5197878
04/11/2016 14:32:55: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.4'

04/11/2016 14:32:55: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:32:55: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:33:04: Finished Epoch[ 5 of 100]: [Training Set] TrainLossPerSample = 4.5197878; TotalSamplesSeen = 405; AvgLearningRatePerSample = 0.1; EpochTime=8.74394
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.3419837    Perplexity = 76.859859    
04/11/2016 14:33:08: Finished Epoch[ 5 of 100]: [Validation Set] TrainLossPerSample = 4.3419837
04/11/2016 14:33:08: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.5'

04/11/2016 14:33:08: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:33:08: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:33:17: Finished Epoch[ 6 of 100]: [Training Set] TrainLossPerSample = 4.3419838; TotalSamplesSeen = 486; AvgLearningRatePerSample = 0.1; EpochTime=8.59016
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 4.0908196    Perplexity = 59.788872    
04/11/2016 14:33:22: Finished Epoch[ 6 of 100]: [Validation Set] TrainLossPerSample = 4.0908196
04/11/2016 14:33:22: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.6'

04/11/2016 14:33:22: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:33:22: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:33:30: Finished Epoch[ 7 of 100]: [Training Set] TrainLossPerSample = 4.0908194; TotalSamplesSeen = 567; AvgLearningRatePerSample = 0.1; EpochTime=8.26845
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 3.7267305    Perplexity = 41.543062    
04/11/2016 14:33:34: Finished Epoch[ 7 of 100]: [Validation Set] TrainLossPerSample = 3.7267305
04/11/2016 14:33:34: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.7'

04/11/2016 14:33:34: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:33:34: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:33:43: Finished Epoch[ 8 of 100]: [Training Set] TrainLossPerSample = 3.7267306; TotalSamplesSeen = 648; AvgLearningRatePerSample = 0.1; EpochTime=8.61273
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 3.20414    Perplexity = 24.634305    
04/11/2016 14:33:43: Finished Epoch[ 8 of 100]: [Validation Set] TrainLossPerSample = 3.20414
04/11/2016 14:33:43: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.8'

04/11/2016 14:33:44: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:33:44: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:33:49: Finished Epoch[ 9 of 100]: [Training Set] TrainLossPerSample = 3.2041399; TotalSamplesSeen = 729; AvgLearningRatePerSample = 0.1; EpochTime=5.0201
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.5716033    Perplexity = 13.086789    
04/11/2016 14:33:52: Finished Epoch[ 9 of 100]: [Validation Set] TrainLossPerSample = 2.5716033
04/11/2016 14:33:52: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.9'

04/11/2016 14:33:52: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:33:52: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:33:55: Finished Epoch[10 of 100]: [Training Set] TrainLossPerSample = 2.5716033; TotalSamplesSeen = 810; AvgLearningRatePerSample = 0.1; EpochTime=2.74755
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.3767195    Perplexity = 10.769516    
04/11/2016 14:33:56: Finished Epoch[10 of 100]: [Validation Set] TrainLossPerSample = 2.3767195
04/11/2016 14:33:56: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.10'

04/11/2016 14:33:56: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:33:56: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:04: Finished Epoch[11 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.1; EpochTime=7.20116
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.7659349    Perplexity = 15.893892    
04/11/2016 14:34:07: Finished Epoch[11 of 100]: [Validation Set] TrainLossPerSample = 2.7659349
04/11/2016 14:34:07: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.10.
04/11/2016 14:34:07: learnRatePerSample reduced to 0.050000001
04/11/2016 14:34:07: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.11'

04/11/2016 14:34:07: Starting Epoch 12: learning rate per sample = 0.050000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:07: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:16: Finished Epoch[12 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.050000001; EpochTime=9.29286
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.8386635    Perplexity = 17.092906    
04/11/2016 14:34:19: Finished Epoch[12 of 100]: [Validation Set] TrainLossPerSample = 2.8386635
04/11/2016 14:34:19: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.11.
04/11/2016 14:34:19: learnRatePerSample reduced to 0.025
04/11/2016 14:34:19: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.12'

04/11/2016 14:34:19: Starting Epoch 13: learning rate per sample = 0.025000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:19: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:23: Finished Epoch[13 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.025; EpochTime=4.0824
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.8763944    Perplexity = 17.750158    
04/11/2016 14:34:26: Finished Epoch[13 of 100]: [Validation Set] TrainLossPerSample = 2.8763944
04/11/2016 14:34:26: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.12.
04/11/2016 14:34:26: learnRatePerSample reduced to 0.0125
04/11/2016 14:34:26: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.13'

04/11/2016 14:34:26: Starting Epoch 14: learning rate per sample = 0.012500  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:26: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:27: Finished Epoch[14 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.0125; EpochTime=1.30897
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.8955982    Perplexity = 18.094323    
04/11/2016 14:34:28: Finished Epoch[14 of 100]: [Validation Set] TrainLossPerSample = 2.8955982
04/11/2016 14:34:28: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.13.
04/11/2016 14:34:28: learnRatePerSample reduced to 0.0062500001
04/11/2016 14:34:28: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.14'

04/11/2016 14:34:28: Starting Epoch 15: learning rate per sample = 0.006250  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:28: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:29: Finished Epoch[15 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.0062500001; EpochTime=0.893572
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9052842    Perplexity = 18.270435    
04/11/2016 14:34:29: Finished Epoch[15 of 100]: [Validation Set] TrainLossPerSample = 2.9052842
04/11/2016 14:34:29: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.14.
04/11/2016 14:34:30: learnRatePerSample reduced to 0.003125
04/11/2016 14:34:30: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.15'

04/11/2016 14:34:30: Starting Epoch 16: learning rate per sample = 0.003125  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:30: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:30: Finished Epoch[16 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.003125; EpochTime=0.418448
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.910148    Perplexity = 18.359515    
04/11/2016 14:34:30: Finished Epoch[16 of 100]: [Validation Set] TrainLossPerSample = 2.910148
04/11/2016 14:34:30: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.15.
04/11/2016 14:34:31: learnRatePerSample reduced to 0.0015625
04/11/2016 14:34:31: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.16'

04/11/2016 14:34:31: Starting Epoch 17: learning rate per sample = 0.001563  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:31: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:31: Finished Epoch[17 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.0015625; EpochTime=0.266235
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9125856    Perplexity = 18.404323    
04/11/2016 14:34:31: Finished Epoch[17 of 100]: [Validation Set] TrainLossPerSample = 2.9125856
04/11/2016 14:34:31: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.16.
04/11/2016 14:34:32: learnRatePerSample reduced to 0.00078125001
04/11/2016 14:34:32: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.17'

04/11/2016 14:34:32: Starting Epoch 18: learning rate per sample = 0.000781  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:32: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:32: Finished Epoch[18 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.00078125001; EpochTime=0.167948
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9138054    Perplexity = 18.426786    
04/11/2016 14:34:32: Finished Epoch[18 of 100]: [Validation Set] TrainLossPerSample = 2.9138054
04/11/2016 14:34:32: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.17.
04/11/2016 14:34:33: learnRatePerSample reduced to 0.00039062501
04/11/2016 14:34:33: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.18'

04/11/2016 14:34:33: Starting Epoch 19: learning rate per sample = 0.000391  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:33: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:33: Finished Epoch[19 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.00039062501; EpochTime=0.165858
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9144155    Perplexity = 18.438033    
04/11/2016 14:34:33: Finished Epoch[19 of 100]: [Validation Set] TrainLossPerSample = 2.9144155
04/11/2016 14:34:33: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.18.
04/11/2016 14:34:34: learnRatePerSample reduced to 0.0001953125
04/11/2016 14:34:34: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.19'

04/11/2016 14:34:34: Starting Epoch 20: learning rate per sample = 0.000195  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:34: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:34: Finished Epoch[20 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 0.0001953125; EpochTime=0.189544
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9147207    Perplexity = 18.44366    
04/11/2016 14:34:34: Finished Epoch[20 of 100]: [Validation Set] TrainLossPerSample = 2.9147207
04/11/2016 14:34:34: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.19.
04/11/2016 14:34:34: learnRatePerSample reduced to 9.7656251e-005
04/11/2016 14:34:34: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.20'

04/11/2016 14:34:35: Starting Epoch 21: learning rate per sample = 0.000098  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:35: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:35: Finished Epoch[21 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=0.628249
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9148737    Perplexity = 18.446482    
04/11/2016 14:34:35: Finished Epoch[21 of 100]: [Validation Set] TrainLossPerSample = 2.9148737
04/11/2016 14:34:35: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.20.
04/11/2016 14:34:36: learnRatePerSample reduced to 4.8828126e-005
04/11/2016 14:34:36: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.21'

04/11/2016 14:34:36: Starting Epoch 22: learning rate per sample = 0.000049  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:36: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:36: Finished Epoch[22 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 4.8828126e-005; EpochTime=0.157974
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9149498    Perplexity = 18.447886    
04/11/2016 14:34:36: Finished Epoch[22 of 100]: [Validation Set] TrainLossPerSample = 2.9149498
04/11/2016 14:34:36: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.21.
04/11/2016 14:34:36: learnRatePerSample reduced to 2.4414063e-005
04/11/2016 14:34:37: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.22'

04/11/2016 14:34:37: Starting Epoch 23: learning rate per sample = 0.000024  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:37: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:37: Finished Epoch[23 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 2.4414063e-005; EpochTime=0.1817
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.914988    Perplexity = 18.448591    
04/11/2016 14:34:37: Finished Epoch[23 of 100]: [Validation Set] TrainLossPerSample = 2.914988
04/11/2016 14:34:37: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.22.
04/11/2016 14:34:37: learnRatePerSample reduced to 1.2207031e-005
04/11/2016 14:34:37: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.23'

04/11/2016 14:34:38: Starting Epoch 24: learning rate per sample = 0.000012  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:38: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:38: Finished Epoch[24 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 1.2207031e-005; EpochTime=0.490109
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.915007    Perplexity = 18.448942    
04/11/2016 14:34:38: Finished Epoch[24 of 100]: [Validation Set] TrainLossPerSample = 2.915007
04/11/2016 14:34:38: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.23.
04/11/2016 14:34:38: learnRatePerSample reduced to 6.1035157e-006
04/11/2016 14:34:39: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.24'

04/11/2016 14:34:39: Starting Epoch 25: learning rate per sample = 0.000006  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:39: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:39: Finished Epoch[25 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 6.1035157e-006; EpochTime=0.158359
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150165    Perplexity = 18.449116    
04/11/2016 14:34:39: Finished Epoch[25 of 100]: [Validation Set] TrainLossPerSample = 2.9150165
04/11/2016 14:34:39: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.24.
04/11/2016 14:34:39: learnRatePerSample reduced to 3.0517579e-006
04/11/2016 14:34:39: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.25'

04/11/2016 14:34:40: Starting Epoch 26: learning rate per sample = 0.000003  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:40: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:40: Finished Epoch[26 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 3.0517579e-006; EpochTime=0.206152
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150214    Perplexity = 18.449206    
04/11/2016 14:34:40: Finished Epoch[26 of 100]: [Validation Set] TrainLossPerSample = 2.9150214
04/11/2016 14:34:40: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.25.
04/11/2016 14:34:40: learnRatePerSample reduced to 1.5258789e-006
04/11/2016 14:34:40: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.26'

04/11/2016 14:34:40: Starting Epoch 27: learning rate per sample = 0.000002  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:40: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:41: Finished Epoch[27 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 1.5258789e-006; EpochTime=0.496847
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150238    Perplexity = 18.449252    
04/11/2016 14:34:41: Finished Epoch[27 of 100]: [Validation Set] TrainLossPerSample = 2.9150238
04/11/2016 14:34:41: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.26.
04/11/2016 14:34:41: learnRatePerSample reduced to 7.6293946e-007
04/11/2016 14:34:41: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.27'

04/11/2016 14:34:42: Starting Epoch 28: learning rate per sample = 0.000001  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:42: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:42: Finished Epoch[28 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 7.6293946e-007; EpochTime=0.54656
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150251    Perplexity = 18.449276    
04/11/2016 14:34:42: Finished Epoch[28 of 100]: [Validation Set] TrainLossPerSample = 2.9150251
04/11/2016 14:34:42: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.27.
04/11/2016 14:34:43: learnRatePerSample reduced to 3.8146973e-007
04/11/2016 14:34:43: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.28'

04/11/2016 14:34:43: Starting Epoch 29: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:43: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:43: Finished Epoch[29 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 3.8146973e-007; EpochTime=0.157691
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150255    Perplexity = 18.449283    
04/11/2016 14:34:43: Finished Epoch[29 of 100]: [Validation Set] TrainLossPerSample = 2.9150255
04/11/2016 14:34:43: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.28.
04/11/2016 14:34:44: learnRatePerSample reduced to 1.9073487e-007
04/11/2016 14:34:44: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.29'

04/11/2016 14:34:44: Starting Epoch 30: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:44: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:44: Finished Epoch[30 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 1.9073487e-007; EpochTime=0.16037
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150259    Perplexity = 18.44929    
04/11/2016 14:34:44: Finished Epoch[30 of 100]: [Validation Set] TrainLossPerSample = 2.9150259
04/11/2016 14:34:44: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.29.
04/11/2016 14:34:44: learnRatePerSample reduced to 9.5367433e-008
04/11/2016 14:34:44: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.30'

04/11/2016 14:34:45: Starting Epoch 31: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:45: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:45: Finished Epoch[31 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 9.5367433e-008; EpochTime=0.411954
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150261    Perplexity = 18.449293    
04/11/2016 14:34:45: Finished Epoch[31 of 100]: [Validation Set] TrainLossPerSample = 2.9150261
04/11/2016 14:34:45: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.30.
04/11/2016 14:34:45: learnRatePerSample reduced to 4.7683717e-008
04/11/2016 14:34:45: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.31'

04/11/2016 14:34:46: Starting Epoch 32: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:46: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:46: Finished Epoch[32 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 4.7683717e-008; EpochTime=0.177328
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150263    Perplexity = 18.449297    
04/11/2016 14:34:46: Finished Epoch[32 of 100]: [Validation Set] TrainLossPerSample = 2.9150263
04/11/2016 14:34:46: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.31.
04/11/2016 14:34:46: learnRatePerSample reduced to 2.3841858e-008
04/11/2016 14:34:46: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.32'

04/11/2016 14:34:47: Starting Epoch 33: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:47: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:47: Finished Epoch[33 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 2.3841858e-008; EpochTime=0.264581
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150263    Perplexity = 18.449297    
04/11/2016 14:34:47: Finished Epoch[33 of 100]: [Validation Set] TrainLossPerSample = 2.9150263
04/11/2016 14:34:47: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.32.
04/11/2016 14:34:47: learnRatePerSample reduced to 1.1920929e-008
04/11/2016 14:34:48: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.33'

04/11/2016 14:34:48: Starting Epoch 34: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:48: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:48: Finished Epoch[34 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 1.1920929e-008; EpochTime=0.219949
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150261    Perplexity = 18.449293    
04/11/2016 14:34:48: Finished Epoch[34 of 100]: [Validation Set] TrainLossPerSample = 2.9150261
04/11/2016 14:34:48: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.33.
04/11/2016 14:34:48: learnRatePerSample reduced to 5.9604646e-009
04/11/2016 14:34:48: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.34'

04/11/2016 14:34:49: Starting Epoch 35: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:49: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:49: Finished Epoch[35 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 5.9604646e-009; EpochTime=0.768469
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150261    Perplexity = 18.449293    
04/11/2016 14:34:50: Finished Epoch[35 of 100]: [Validation Set] TrainLossPerSample = 2.9150261
04/11/2016 14:34:50: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.34.
04/11/2016 14:34:50: learnRatePerSample reduced to 2.9802323e-009
04/11/2016 14:34:50: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.35'

04/11/2016 14:34:50: Starting Epoch 36: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:50: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:51: Finished Epoch[36 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 2.9802323e-009; EpochTime=0.55856
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150263    Perplexity = 18.449297    
04/11/2016 14:34:51: Finished Epoch[36 of 100]: [Validation Set] TrainLossPerSample = 2.9150263
04/11/2016 14:34:51: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.35.
04/11/2016 14:34:51: learnRatePerSample reduced to 1.4901161e-009
04/11/2016 14:34:51: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.36'

04/11/2016 14:34:51: Starting Epoch 37: learning rate per sample = 0.000000  effective momentum = 0.000045  momentum as time constant = 1000.0 samples

04/11/2016 14:34:51: Starting minibatch loop.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
04/11/2016 14:34:51: Finished Epoch[37 of 100]: [Training Set] TrainLossPerSample = 2.3767195; TotalSamplesSeen = 891; AvgLearningRatePerSample = 1.4901161e-009; EpochTime=0.161827
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 6 lines with a total of 81+6 tokens.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Final Results: Minibatch[1-1]: SamplesSeen = 81    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 2.9150261    Perplexity = 18.449293    
04/11/2016 14:34:52: Finished Epoch[37 of 100]: [Validation Set] TrainLossPerSample = 2.9150261
04/11/2016 14:34:52: Loading previous model with best training-criterion value: E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.36.
04/11/2016 14:34:52: learnRatePerSample reduced to 7.4505807e-010
04/11/2016 14:34:52: SGD: Saving checkpoint model 'E:\cygwin64\tmp\cntk-test-20160411152701.530490\Examples\Text\Miscellaneous_SLU@release_cpu/cntkdebug.dnn.37'
04/11/2016 14:34:52: Learn Rate Per Sample for Epoch[38] = 7.4505807e-010 is less than minLearnRate 9.9999997e-010. Training complete.
04/11/2016 14:34:53: CNTKCommandTrainEnd: LSTM

04/11/2016 14:34:53: Action "train" complete.


04/11/2016 14:34:53: ##############################################################################
04/11/2016 14:34:53: #                                                                            #
04/11/2016 14:34:53: # Action "write"                                                             #
04/11/2016 14:34:53: #                                                                            #
04/11/2016 14:34:53: ##############################################################################

BatchLUSequenceReader: Input file is C:\src\cntk_github\Tests\EndToEndTests\Text\SLU/atis.test.apos.pred.pos.head.IOB.simple

Post-processing network...

4 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	PosteriorProb = Softmax()
	labels = InputValue()
	outputs = Times()

Loop[0] --> Loop_AutoName37 -> 31 nodes

	AutoName2	AutoName30	AutoName33
	AutoName1	AutoName21	AutoName24
	AutoName5	AutoName20	AutoName25
	AutoName26	AutoName6	AutoName27
	AutoName0	AutoName8	AutoName11
	AutoName4	AutoName7	AutoName12
	AutoName13	AutoName3	AutoName14
	AutoName15	AutoName17	AutoName18
	AutoName19	AutoName28	AutoName29
	AutoName34	AutoName35	AutoName36
	AutoName37

Loop[1] --> Loop_AutoName75 -> 31 nodes

	AutoName40	AutoName68	AutoName71
	AutoName39	AutoName59	AutoName62
	AutoName43	AutoName58	AutoName63
	AutoName64	AutoName44	AutoName65
	AutoName38	AutoName46	AutoName49
	AutoName42	AutoName45	AutoName50
	AutoName51	AutoName41	AutoName52
	AutoName53	AutoName55	AutoName56
	AutoName57	AutoName66	AutoName67
	AutoName72	AutoName73	AutoName74
	AutoName75

Loop[2] --> Loop_AutoName113 -> 31 nodes

	AutoName78	AutoName106	AutoName109
	AutoName77	AutoName97	AutoName100
	AutoName81	AutoName96	AutoName101
	AutoName102	AutoName82	AutoName103
	AutoName76	AutoName84	AutoName87
	AutoName80	AutoName83	AutoName88
	AutoName89	AutoName79	AutoName90
	AutoName91	AutoName93	AutoName94
	AutoName95	AutoName104	AutoName105
	AutoName110	AutoName111	AutoName112
	AutoName113

Validating network. 168 nodes to process in pass 1.


Validating network. 119 nodes to process in pass 2.


Validating network. 42 nodes to process in pass 3.


Validating network, final pass.

Validating --> labels = InputValue() :  -> [127 x *]
Validating --> W4 = LearnableParameter() :  -> [127 x 300]
Validating --> WXO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WXO0 = LearnableParameter() :  -> [300 x 150]
Validating --> E0 = LearnableParameter() :  -> [50 x 944]
Validating --> features = InputValue() :  -> [2832 x *]
Validating --> LookupTable = LookupTable (E0, features) : [50 x 944], [2832 x *] -> [150 x *]
Validating --> AutoName31 = Times (WXO0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bo0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName32 = Plus (AutoName31, bo0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName22 = Times (WXF0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bf0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName23 = Plus (AutoName22, bf0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName9 = Times (WXI0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> bi0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName10 = Plus (AutoName9, bi0) : [300 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI0 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI0 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC0 = LearnableParameter() :  -> [300 x 150]
Validating --> AutoName16 = Times (WXC0, LookupTable) : [300 x 150], [150 x *] -> [300 x *]
Validating --> WHC0 = LearnableParameter() :  -> [300 x 300]
Validating --> bc0 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName2 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName30 = Times (WHO0, AutoName2) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName33 = Plus (AutoName32, AutoName30) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName1 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName21 = Times (WHF0, AutoName1) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName24 = Plus (AutoName23, AutoName21) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName5 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName20 = DiagTimes (WCF0, AutoName5) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName25 = Plus (AutoName24, AutoName20) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName26 = Sigmoid (AutoName25) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName6 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName27 = ElementTimes (AutoName26, AutoName6) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName0 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName8 = Times (WHI0, AutoName0) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName11 = Plus (AutoName10, AutoName8) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName4 = PastValue (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName7 = DiagTimes (WCI0, AutoName4) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName12 = Plus (AutoName11, AutoName7) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName13 = Sigmoid (AutoName12) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName3 = PastValue (AutoName37) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName14 = Times (WHC0, AutoName3) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName15 = Plus (AutoName14, bc0) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName17 = Plus (AutoName16, AutoName15) : [300 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName18 = Tanh (AutoName17) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName19 = ElementTimes (AutoName13, AutoName18) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName28 = Plus (AutoName27, AutoName19) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName29 = DiagTimes (WCO0, AutoName28) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName34 = Plus (AutoName33, AutoName29) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName35 = Sigmoid (AutoName34) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName36 = Tanh (AutoName28) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName37 = ElementTimes (AutoName35, AutoName36) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName69 = Times (WXO2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName70 = Plus (AutoName69, bo2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName60 = Times (WXF2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName61 = Plus (AutoName60, bf2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName47 = Times (WXI2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName48 = Plus (AutoName47, bi2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI2 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI2 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC2 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName54 = Times (WXC2, AutoName37) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC2 = LearnableParameter() :  -> [300 x 300]
Validating --> bc2 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName40 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName68 = Times (WHO2, AutoName40) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName71 = Plus (AutoName70, AutoName68) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName39 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName59 = Times (WHF2, AutoName39) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName62 = Plus (AutoName61, AutoName59) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName43 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName58 = DiagTimes (WCF2, AutoName43) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName63 = Plus (AutoName62, AutoName58) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName64 = Sigmoid (AutoName63) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName44 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName65 = ElementTimes (AutoName64, AutoName44) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName38 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName46 = Times (WHI2, AutoName38) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName49 = Plus (AutoName48, AutoName46) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName42 = PastValue (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName45 = DiagTimes (WCI2, AutoName42) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName50 = Plus (AutoName49, AutoName45) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName51 = Sigmoid (AutoName50) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName41 = PastValue (AutoName75) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName52 = Times (WHC2, AutoName41) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName53 = Plus (AutoName52, bc2) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName55 = Plus (AutoName54, AutoName53) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName56 = Tanh (AutoName55) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName57 = ElementTimes (AutoName51, AutoName56) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName66 = Plus (AutoName65, AutoName57) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName67 = DiagTimes (WCO2, AutoName66) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName72 = Plus (AutoName71, AutoName67) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName73 = Sigmoid (AutoName72) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName74 = Tanh (AutoName66) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName75 = ElementTimes (AutoName73, AutoName74) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName107 = Times (WXO3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bo3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName108 = Plus (AutoName107, bo3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHO3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCO3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXF3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName98 = Times (WXF3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bf3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName99 = Plus (AutoName98, bf3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHF3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCF3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXI3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName85 = Times (WXI3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> bi3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName86 = Plus (AutoName85, bi3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> WHI3 = LearnableParameter() :  -> [300 x 300]
Validating --> WCI3 = LearnableParameter() :  -> [300 x 1]
Validating --> WXC3 = LearnableParameter() :  -> [300 x 300]
Validating --> AutoName92 = Times (WXC3, AutoName75) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> WHC3 = LearnableParameter() :  -> [300 x 300]
Validating --> bc3 = LearnableParameter() :  -> [300 x 1]
Validating --> AutoName78 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName106 = Times (WHO3, AutoName78) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName109 = Plus (AutoName108, AutoName106) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName77 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName97 = Times (WHF3, AutoName77) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName100 = Plus (AutoName99, AutoName97) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName81 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName96 = DiagTimes (WCF3, AutoName81) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName101 = Plus (AutoName100, AutoName96) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName102 = Sigmoid (AutoName101) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName82 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName103 = ElementTimes (AutoName102, AutoName82) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName76 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName84 = Times (WHI3, AutoName76) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName87 = Plus (AutoName86, AutoName84) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName80 = PastValue (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName83 = DiagTimes (WCI3, AutoName80) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName88 = Plus (AutoName87, AutoName83) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName89 = Sigmoid (AutoName88) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName79 = PastValue (AutoName113) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName90 = Times (WHC3, AutoName79) : [300 x 300], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName91 = Plus (AutoName90, bc3) : [300 x 1 x *], [300 x 1] -> [300 x 1 x *]
Validating --> AutoName93 = Plus (AutoName92, AutoName91) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName94 = Tanh (AutoName93) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName95 = ElementTimes (AutoName89, AutoName94) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName104 = Plus (AutoName103, AutoName95) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName105 = DiagTimes (WCO3, AutoName104) : [300 x 1], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName110 = Plus (AutoName109, AutoName105) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName111 = Sigmoid (AutoName110) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName112 = Tanh (AutoName104) : [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName113 = ElementTimes (AutoName111, AutoName112) : [300 x 1 x *], [300 x 1 x *] -> [300 x 1 x *]
Validating --> AutoName114 = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, AutoName114) : [127 x *], [127 x 1 x *] -> [1]
Validating --> outputs = Times (W4, AutoName113) : [127 x 300], [300 x 1 x *] -> [127 x 1 x *]
Validating --> PosteriorProb = Softmax (outputs) : [127 x 1 x *] -> [127 x 1 x *]


48 out of 168 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 5 lines with a total of 92+5 tokens.
O O O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O O O O B-stoploc.city_name I-stoploc.city_name O 
O O O O O O O O O O O O O O O O O O O O O 
O O B-depart_date.month_name B-depart_date.day_number O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_time.time_relative B-depart_time.time I-depart_time.time O 
O O O O O O O O O O O O O O O O O O 
O O B-depart_date.month_name B-depart_date.day_number O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O 
O O O O O O O O O O O O O O O 
O O O O O O O B-round_trip I-round_trip O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O 
O O O O O O O O O O O O O O O O O O 
O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name I-toloc.city_name O B-depart_date.month_name B-depart_date.day_number O B-airline_name I-airline_name O 
O O O O O O O O O O O O O O O O O O O 
BatchLUSequenceParser: Parsing input data...
BatchLUSequenceParser: Parsed 0 lines with a total of 0+0 tokens.
EnsureDataAvailable: No more data.
Total Samples Evaluated = 91

04/11/2016 14:34:53: Action "write" complete.

04/11/2016 14:34:53: __COMPLETED__