CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3565 @ 3.20GHz
    Hardware threads: 8
    Total Memory: 12580436 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 16 2016 02:54:53
		Last modified date: Fri Aug 12 05:31:21 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
		Built by svcphil on Philly-Pool3
		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
08/16/2016 03:09:55: -------------------------------------------------------------------
08/16/2016 03:09:55: Build info: 

08/16/2016 03:09:55: 		Built time: Aug 16 2016 02:54:53
08/16/2016 03:09:55: 		Last modified date: Fri Aug 12 05:31:21 2016
08/16/2016 03:09:55: 		Build type: Release
08/16/2016 03:09:55: 		Build target: GPU
08/16/2016 03:09:55: 		With 1bit-SGD: no
08/16/2016 03:09:55: 		Math lib: mkl
08/16/2016 03:09:55: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/16/2016 03:09:55: 		CUB_PATH: c:\src\cub-1.4.1
08/16/2016 03:09:55: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/16/2016 03:09:55: 		Build Branch: HEAD
08/16/2016 03:09:55: 		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
08/16/2016 03:09:55: 		Built by svcphil on Philly-Pool3
08/16/2016 03:09:55: 		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/16/2016 03:09:55: -------------------------------------------------------------------
08/16/2016 03:09:56: -------------------------------------------------------------------
08/16/2016 03:09:56: GPU info:

08/16/2016 03:09:56: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/16/2016 03:09:56: -------------------------------------------------------------------

08/16/2016 03:09:56: Running on cntk-muc01 at 2016/08/16 03:09:56
08/16/2016 03:09:56: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu  DeviceId=0  timestamping=true



08/16/2016 03:09:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:09:56: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
command=Train 
deviceId = $DeviceId$
modelPath="$ModelDir$/seqcla.dnn"
makeMode = false 
vocabDim = 2000
Train=[
    action="train"
    BrainScriptNetworkBuilder=[
        lstmDim = 25
        cellDim = 25
        numLabels = 5
        vocabDim = $vocabDim$
        embedDim = 50
        model = Sequential
        (
EmbeddingLayer {embedDim, embeddingPath='embeddingmatrix.txt', transpose=true} :  
            RecurrentLSTMLayer {lstmDim, cellShape=cellDim} :
            BS.Sequences.Last :
            DenseLayer {numLabels}
        )
        t = DynamicAxis{}
features = SparseInput {$vocabDim$, dynamicAxis=t}  
labels   =       Input {numLabels}                  
        z = model (features)
        zp = ReconcileDynamicAxis(z, labels)
        ce  = CrossEntropyWithSoftmax (labels, zp)  // this is the training objective
        err = ClassificationError         (labels, zp)  // this also gets tracked
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (err)
        outputNodes     = (z)
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.ctf"
        input = [
            features = [ alias = "x" ; dim = $vocabDim$ ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
Write=[
action="test"   
    modelFile = "$ModelDir$/seqcla.dnn"    
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.txt"            
        input = [
            features = [ alias = "x" ; dim = $vocabDim$ ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DeviceId=0
timestamping=true

08/16/2016 03:09:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:09:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:09:56: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models"
command=Train 
deviceId = 0
modelPath="C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn"
makeMode = false 
vocabDim = 2000
Train=[
    action="train"
    BrainScriptNetworkBuilder=[
        lstmDim = 25
        cellDim = 25
        numLabels = 5
        vocabDim = 2000
        embedDim = 50
        model = Sequential
        (
EmbeddingLayer {embedDim, embeddingPath='embeddingmatrix.txt', transpose=true} :  
            RecurrentLSTMLayer {lstmDim, cellShape=cellDim} :
            BS.Sequences.Last :
            DenseLayer {numLabels}
        )
        t = DynamicAxis{}
features = SparseInput {2000, dynamicAxis=t}  
labels   =       Input {numLabels}                  
        z = model (features)
        zp = ReconcileDynamicAxis(z, labels)
        ce  = CrossEntropyWithSoftmax (labels, zp)  // this is the training objective
        err = ClassificationError         (labels, zp)  // this also gets tracked
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (err)
        outputNodes     = (z)
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.ctf"
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]
Write=[
action="test"   
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn"    
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DeviceId=0
timestamping=true

08/16/2016 03:09:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:09:56: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: seqcla.cntk:command=Train
configparameters: seqcla.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
configparameters: seqcla.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:deviceId=0
configparameters: seqcla.cntk:makeMode=false
configparameters: seqcla.cntk:ModelDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models
configparameters: seqcla.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn
configparameters: seqcla.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
configparameters: seqcla.cntk:RootDir=..
configparameters: seqcla.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
configparameters: seqcla.cntk:timestamping=true
configparameters: seqcla.cntk:Train=[
    action="train"
    BrainScriptNetworkBuilder=[
        lstmDim = 25
        cellDim = 25
        numLabels = 5
        vocabDim = 2000
        embedDim = 50
        model = Sequential
        (
EmbeddingLayer {embedDim, embeddingPath='embeddingmatrix.txt', transpose=true} :  
            RecurrentLSTMLayer {lstmDim, cellShape=cellDim} :
            BS.Sequences.Last :
            DenseLayer {numLabels}
        )
        t = DynamicAxis{}
features = SparseInput {2000, dynamicAxis=t}  
labels   =       Input {numLabels}                  
        z = model (features)
        zp = ReconcileDynamicAxis(z, labels)
        ce  = CrossEntropyWithSoftmax (labels, zp)  // this is the training objective
        err = ClassificationError         (labels, zp)  // this also gets tracked
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (err)
        outputNodes     = (z)
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.ctf"
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]

configparameters: seqcla.cntk:vocabDim=2000
configparameters: seqcla.cntk:Write=[
action="test"   
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn"    
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]

08/16/2016 03:09:56: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/16/2016 03:09:56: Commands: Train
08/16/2016 03:09:56: Precision = "float"
08/16/2016 03:09:56: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn
08/16/2016 03:09:56: CNTKCommandTrainInfo: Train : 5
08/16/2016 03:09:56: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5

08/16/2016 03:09:56: ##############################################################################
08/16/2016 03:09:56: #                                                                            #
08/16/2016 03:09:56: # Action "train"                                                             #
08/16/2016 03:09:56: #                                                                            #
08/16/2016 03:09:56: ##############################################################################

08/16/2016 03:09:56: CNTKCommandTrainBegin: Train

08/16/2016 03:09:56: Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[5 x 0] as uniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[25 x 0] as uniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[25 x 0] as uniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[25 x 0] as uniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[25 x 0] as uniform later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[25 x 25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[5] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[5] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[1] <- 0.000000.
Node '<placeholder>' (LearnableParameter operation): Initializing Parameter[1] <- 0.000000.

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ClassificationError()
	t = DynamicAxis()
	z = Plus()

Loop[0] --> Loop_z.x.x.lstmState._.ht -> 25 nodes

	z.x.x.prevState.h	z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1]	z.x.x.lstmState._.ot._.PlusArgs[0]
	z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1]	z.x.x.lstmState._.ft._.PlusArgs[0]	z.x.x.prevState.c
	z.x.x.lstmState._.ft._.PlusArgs[1]	z.x.x.lstmState._.ft._	z.x.x.lstmState._.ft
	z.x.x.lstmState._.bft	z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1]	z.x.x.lstmState._.it._.PlusArgs[0]
	z.x.x.lstmState._.it._.PlusArgs[1]	z.x.x.lstmState._.it._	z.x.x.lstmState._.it
	z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1]	z.x.x.lstmState._.bit.ElementTimesArgs[1].z	z.x.x.lstmState._.bit.ElementTimesArgs[1]
	z.x.x.lstmState._.bit	z.x.x.lstmState._.ct	z.x.x.lstmState._.ot._.PlusArgs[1]
	z.x.x.lstmState._.ot._	z.x.x.lstmState._.ot	z.x.x.lstmState._.ht.ElementTimesArgs[1]
	z.x.x.lstmState._.ht

Validating network. 68 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [5 x *]
Validating --> model.arrayOfFunctions[3].arrayOfFunctions[0].W = LearnableParameter() :  -> [5 x 0]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 0]
Validating --> model.arrayOfFunctions[0].E = LearnableParameter() :  -> [2000 x 50]
Validating --> features = SparseInputValue() :  -> [2000 x t]
Validating --> z.x.x.x = TransposeTimes (model.arrayOfFunctions[0].E, features) : [2000 x 50], [2000 x t] -> [50 x t]
Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) operation: Tensor shape was inferred as [25 x 50].
Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation): Initializing Parameter[25 x 50] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0] = Plus (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 0]
Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) operation: Tensor shape was inferred as [25 x 50].
Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation): Initializing Parameter[25 x 50] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0] = Plus (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 0]
Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) operation: Tensor shape was inferred as [25 x 50].
Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation): Initializing Parameter[25 x 50] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0] = Plus (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 0]
Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) operation: Tensor shape was inferred as [25 x 50].
Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation): Initializing Parameter[25 x 50] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0] = Plus (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [0] -> [25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0] = Plus (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [0] -> [25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0] = Plus (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [0] -> [25]
Validating --> z.x.x.lstmState._.ft._ = Plus (z.x.x.lstmState._.ft._.PlusArgs[0], z.x.x.lstmState._.ft._.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> z.x.x.lstmState._.ft = Sigmoid (z.x.x.lstmState._.ft._) : [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.bft = ElementTimes (z.x.x.lstmState._.ft, z.x.x.prevState.c) : [25 x t], [0] -> [25 x t]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [0] -> [25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0] = Plus (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> z.x.x.lstmState._.it._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [0] -> [25]
Validating --> z.x.x.lstmState._.it._ = Plus (z.x.x.lstmState._.it._.PlusArgs[0], z.x.x.lstmState._.it._.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> z.x.x.lstmState._.it = Sigmoid (z.x.x.lstmState._.it._) : [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [0] -> [25]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z = Plus (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0], z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1] = Tanh (z.x.x.lstmState._.bit.ElementTimesArgs[1].z) : [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.bit = ElementTimes (z.x.x.lstmState._.it, z.x.x.lstmState._.bit.ElementTimesArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ct = Plus (z.x.x.lstmState._.bft, z.x.x.lstmState._.bit) : [25 x t], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0], z.x.x.lstmState._.ct) : [25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ot._ = Plus (z.x.x.lstmState._.ot._.PlusArgs[0], z.x.x.lstmState._.ot._.PlusArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ot = Sigmoid (z.x.x.lstmState._.ot._) : [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ht.ElementTimesArgs[1] = Tanh (z.x.x.lstmState._.ct) : [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ht = ElementTimes (z.x.x.lstmState._.ot, z.x.x.lstmState._.ht.ElementTimesArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> z.x.beginFlags.input.z.ElementTimesArgs[0] = Slice (z.x.x.lstmState._.ht) : [25 x t] -> [1 x t]
Validating --> BS.Constants.Zero = LearnableParameter() :  -> [1]
Validating --> z.x.beginFlags.input.z = ElementTimes (z.x.beginFlags.input.z.ElementTimesArgs[0], BS.Constants.Zero) : [1 x t], [1] -> [1 x t]
Validating --> z.x.beginFlags.input = SumColumnElements (z.x.beginFlags.input.z) : [1 x t] -> [1 x t]
Validating --> z.x.beginFlags = FutureValue (z.x.beginFlags.input) : [1 x t] -> [1 x t]
Validating --> z.x.out.indexSequence.indexSequence = Where (z.x.beginFlags) : [1 x t] -> [1 x WhereNodeAxis]
Validating --> z.x.out.indexSequence = PackedIndex (z.x.x.lstmState._.ht, z.x.out.indexSequence.indexSequence) : [25 x t], [1 x WhereNodeAxis] -> [1 x WhereNodeAxis]
Validating --> z.x.out = GatherPacked (z.x.out.indexSequence, z.x.x.lstmState._.ht) : [1 x WhereNodeAxis], [25 x t] -> [25 x WhereNodeAxis]
Node 'model.arrayOfFunctions[3].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [5 x 25].
Node 'model.arrayOfFunctions[3].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[5 x 25] <- uniform(seed=1, range=0.050000*1.000000, onCPU=true).
Validating --> z.x.PlusArgs[0] = Times (model.arrayOfFunctions[3].arrayOfFunctions[0].W, z.x.out) : [5 x 25], [25 x WhereNodeAxis] -> [5 x WhereNodeAxis]
Validating --> model.arrayOfFunctions[3].arrayOfFunctions[0].b = LearnableParameter() :  -> [5]
Validating --> z = Plus (z.x.PlusArgs[0], model.arrayOfFunctions[3].arrayOfFunctions[0].b) : [5 x WhereNodeAxis], [5] -> [5 x WhereNodeAxis]
Validating --> zp = ReconcileDynamicAxis (z, labels) : [5 x WhereNodeAxis], [5 x *] -> [5 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, zp) : [5 x *], [5 x *] -> [1]
Validating --> err = ClassificationError (labels, zp) : [5 x *], [5 x *] -> [1]
Validating --> t = DynamicAxis() :  -> [1 x 1 x t]

Validating network. 46 nodes to process in pass 2.

Validating --> z.x.x.prevState.h = PastValue (z.x.x.lstmState._.ht) : [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> z.x.x.prevState.c = PastValue (z.x.x.lstmState._.ct) : [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.it._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [25 x t] -> [25 x t]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t] -> [25 x t]

Validating network. 8 nodes to process in pass 3.


Validating network, final pass.



66 out of 68 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/16/2016 03:09:56: Created model with 68 nodes on GPU 0.

08/16/2016 03:09:56: Training criterion node(s):
08/16/2016 03:09:56: 	ce = CrossEntropyWithSoftmax

08/16/2016 03:09:56: Evaluation criterion node(s):
08/16/2016 03:09:56: 	err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 129 matrices, 48 are shared as 19, and 81 are not shared.

	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] : [25] (gradient)
	  z.x.x.prevState.h : [25 x t] }
	{ z.x.beginFlags.input.z.ElementTimesArgs[0] : [1 x t]
	  z.x.x.lstmState._.ot : [25 x t] (gradient) }
	{ z.x.beginFlags.input.z : [1 x t]
	  z.x.x.lstmState._.ct : [25 x t] (gradient) }
	{ z.x.beginFlags.input : [1 x t]
	  z.x.beginFlags.input.z.ElementTimesArgs[0] : [1 x t] (gradient)
	  z.x.x.lstmState._.ht.ElementTimesArgs[1] : [25 x t] (gradient) }
	{ z.x.beginFlags.input : [1 x t] (gradient)
	  z.x.out : [25 x WhereNodeAxis]
	  z.x.out.indexSequence.indexSequence : [1 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[0] : [25 x t] (gradient) }
	{ z.x.PlusArgs[0] : [5 x WhereNodeAxis]
	  z.x.beginFlags : [1 x t] (gradient)
	  z.x.out.indexSequence : [1 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[1] : [25 x t] (gradient) }
	{ z.x.PlusArgs[0] : [5 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ht : [25 x t] (gradient)
	  zp : [5 x *] }
	{ z.x.beginFlags : [1 x t]
	  z.x.beginFlags.input.z : [1 x t] (gradient)
	  z.x.x.lstmState._.ot._ : [25 x t] (gradient) }
	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0] : [25 x t]
	  z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }
	{ model.arrayOfFunctions[3].arrayOfFunctions[0].b : [5] (gradient)
	  zp : [5 x *] (gradient) }
	{ model.arrayOfFunctions[3].arrayOfFunctions[0].W : [5 x 25] (gradient)
	  z : [5 x WhereNodeAxis] (gradient) }
	{ z.x.out : [25 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0] : [25] (gradient) }
	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] : [25 x t] (gradient)
	  z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t] (gradient)
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t] (gradient)
	  z.x.x.prevState.h : [25 x t] (gradient) }
	{ z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] : [25] (gradient)
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t] }
	{ z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0] : [25 x t]
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }
	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] : [25 x t]
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] : [25] (gradient) }
	{ z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t]
	  z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] : [25] (gradient) }
	{ z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0] : [25 x t]
	  z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }
	{ z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0] : [25 x t]
	  z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }


08/16/2016 03:09:56: Training 7805 parameters in 17 out of 17 parameter tensors and 61 nodes with gradient:

08/16/2016 03:09:56: 	Node 'model.arrayOfFunctions[3].arrayOfFunctions[0].W' (LearnableParameter operation) : [5 x 25]
08/16/2016 03:09:56: 	Node 'model.arrayOfFunctions[3].arrayOfFunctions[0].b' (LearnableParameter operation) : [5]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:09:56: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0]' (LearnableParameter operation) : [25]

08/16/2016 03:09:56: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/16/2016 03:09:56: Starting Epoch 1: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..5433] (first sequence at sample 0), data subset 0 of 1

08/16/2016 03:09:56: Starting minibatch loop.
WARNING: The same matrix with dim [1, 45] has been transferred between different devices for 20 times.
08/16/2016 03:09:57: Finished Epoch[ 1 of 5]: [Training] ce = 1.58149481 * 1247; err = 0.47634322 * 1247; totalSamplesSeen = 1247; learningRatePerSample = 0.00050000002; epochTime=1.05952s
08/16/2016 03:09:57: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn.1'

08/16/2016 03:09:57: Starting Epoch 2: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 1: frames [5433..10866] (first sequence at sample 5433), data subset 0 of 1

08/16/2016 03:09:57: Starting minibatch loop.
08/16/2016 03:09:58: Finished Epoch[ 2 of 5]: [Training] ce = 1.49422706 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 2494; learningRatePerSample = 0.00050000002; epochTime=0.895396s
08/16/2016 03:09:58: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn.2'

08/16/2016 03:09:58: Starting Epoch 3: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 2: frames [10866..16299] (first sequence at sample 10866), data subset 0 of 1

08/16/2016 03:09:58: Starting minibatch loop.
08/16/2016 03:09:59: Finished Epoch[ 3 of 5]: [Training] ce = 1.42176468 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 3741; learningRatePerSample = 0.00050000002; epochTime=0.811854s
08/16/2016 03:09:59: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn.3'

08/16/2016 03:09:59: Starting Epoch 4: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 3: frames [16299..21732] (first sequence at sample 16299), data subset 0 of 1

08/16/2016 03:09:59: Starting minibatch loop.
08/16/2016 03:10:00: Finished Epoch[ 4 of 5]: [Training] ce = 1.36895453 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 4988; learningRatePerSample = 0.00050000002; epochTime=0.81539s
08/16/2016 03:10:00: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn.4'

08/16/2016 03:10:00: Starting Epoch 5: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 4: frames [21732..27165] (first sequence at sample 21732), data subset 0 of 1

08/16/2016 03:10:00: Starting minibatch loop.
08/16/2016 03:10:01: Finished Epoch[ 5 of 5]: [Training] ce = 1.33163117 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 6235; learningRatePerSample = 0.00050000002; epochTime=0.841607s
08/16/2016 03:10:01: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn'
08/16/2016 03:10:01: CNTKCommandTrainEnd: Train

08/16/2016 03:10:01: Action "train" complete.

08/16/2016 03:10:01: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 16 2016 02:54:53
		Last modified date: Fri Aug 12 05:31:21 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
		Built by svcphil on Philly-Pool3
		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
08/16/2016 03:10:02: -------------------------------------------------------------------
08/16/2016 03:10:02: Build info: 

08/16/2016 03:10:02: 		Built time: Aug 16 2016 02:54:53
08/16/2016 03:10:02: 		Last modified date: Fri Aug 12 05:31:21 2016
08/16/2016 03:10:02: 		Build type: Release
08/16/2016 03:10:02: 		Build target: GPU
08/16/2016 03:10:02: 		With 1bit-SGD: no
08/16/2016 03:10:02: 		Math lib: mkl
08/16/2016 03:10:02: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/16/2016 03:10:02: 		CUB_PATH: c:\src\cub-1.4.1
08/16/2016 03:10:02: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/16/2016 03:10:02: 		Build Branch: HEAD
08/16/2016 03:10:02: 		Build SHA1: 026b1e772b963461e189f8f00aa7ed6951298f84
08/16/2016 03:10:02: 		Built by svcphil on Philly-Pool3
08/16/2016 03:10:02: 		Build Path: c:\Jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/16/2016 03:10:02: -------------------------------------------------------------------
08/16/2016 03:10:03: -------------------------------------------------------------------
08/16/2016 03:10:03: GPU info:

08/16/2016 03:10:03: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/16/2016 03:10:03: -------------------------------------------------------------------

08/16/2016 03:10:03: Running on cntk-muc01 at 2016/08/16 03:10:03
08/16/2016 03:10:03: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config/seqcla.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu  DeviceId=0  timestamping=true  makeMode=true



08/16/2016 03:10:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:10:03: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
command=Train 
deviceId = $DeviceId$
modelPath="$ModelDir$/seqcla.dnn"
makeMode = false 
vocabDim = 2000
Train=[
    action="train"
    BrainScriptNetworkBuilder=[
        lstmDim = 25
        cellDim = 25
        numLabels = 5
        vocabDim = $vocabDim$
        embedDim = 50
        model = Sequential
        (
EmbeddingLayer {embedDim, embeddingPath='embeddingmatrix.txt', transpose=true} :  
            RecurrentLSTMLayer {lstmDim, cellShape=cellDim} :
            BS.Sequences.Last :
            DenseLayer {numLabels}
        )
        t = DynamicAxis{}
features = SparseInput {$vocabDim$, dynamicAxis=t}  
labels   =       Input {numLabels}                  
        z = model (features)
        zp = ReconcileDynamicAxis(z, labels)
        ce  = CrossEntropyWithSoftmax (labels, zp)  // this is the training objective
        err = ClassificationError         (labels, zp)  // this also gets tracked
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (err)
        outputNodes     = (z)
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.ctf"
        input = [
            features = [ alias = "x" ; dim = $vocabDim$ ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
Write=[
action="test"   
    modelFile = "$ModelDir$/seqcla.dnn"    
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.txt"            
        input = [
            features = [ alias = "x" ; dim = $vocabDim$ ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/16/2016 03:10:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:10:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/16/2016 03:10:03: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models"
command=Train 
deviceId = 0
modelPath="C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn"
makeMode = false 
vocabDim = 2000
Train=[
    action="train"
    BrainScriptNetworkBuilder=[
        lstmDim = 25
        cellDim = 25
        numLabels = 5
        vocabDim = 2000
        embedDim = 50
        model = Sequential
        (
EmbeddingLayer {embedDim, embeddingPath='embeddingmatrix.txt', transpose=true} :  
            RecurrentLSTMLayer {lstmDim, cellShape=cellDim} :
            BS.Sequences.Last :
            DenseLayer {numLabels}
        )
        t = DynamicAxis{}
features = SparseInput {2000, dynamicAxis=t}  
labels   =       Input {numLabels}                  
        z = model (features)
        zp = ReconcileDynamicAxis(z, labels)
        ce  = CrossEntropyWithSoftmax (labels, zp)  // this is the training objective
        err = ClassificationError         (labels, zp)  // this also gets tracked
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (err)
        outputNodes     = (z)
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.ctf"
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]
Write=[
action="test"   
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn"    
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/16/2016 03:10:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/16/2016 03:10:03: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: seqcla.cntk:command=Train
configparameters: seqcla.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Config
configparameters: seqcla.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data
configparameters: seqcla.cntk:deviceId=0
configparameters: seqcla.cntk:makeMode=true
configparameters: seqcla.cntk:ModelDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models
configparameters: seqcla.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn
configparameters: seqcla.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
configparameters: seqcla.cntk:RootDir=..
configparameters: seqcla.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu
configparameters: seqcla.cntk:timestamping=true
configparameters: seqcla.cntk:Train=[
    action="train"
    BrainScriptNetworkBuilder=[
        lstmDim = 25
        cellDim = 25
        numLabels = 5
        vocabDim = 2000
        embedDim = 50
        model = Sequential
        (
EmbeddingLayer {embedDim, embeddingPath='embeddingmatrix.txt', transpose=true} :  
            RecurrentLSTMLayer {lstmDim, cellShape=cellDim} :
            BS.Sequences.Last :
            DenseLayer {numLabels}
        )
        t = DynamicAxis{}
features = SparseInput {2000, dynamicAxis=t}  
labels   =       Input {numLabels}                  
        z = model (features)
        zp = ReconcileDynamicAxis(z, labels)
        ce  = CrossEntropyWithSoftmax (labels, zp)  // this is the training objective
        err = ClassificationError         (labels, zp)  // this also gets tracked
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (err)
        outputNodes     = (z)
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.ctf"
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]

configparameters: seqcla.cntk:vocabDim=2000
configparameters: seqcla.cntk:Write=[
action="test"   
    modelFile = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn"    
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SequenceClassification\Data/Train.txt"            
        input = [
            features = [ alias = "x" ; dim = 2000 ; format = "sparse" ]
            labels =   [ alias = "y" ; dim = 5          ; format = "dense" ]
        ]
   ]    
outputPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/output.txt"        
]

08/16/2016 03:10:03: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/16/2016 03:10:03: Commands: Train
08/16/2016 03:10:03: Precision = "float"
08/16/2016 03:10:03: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn
08/16/2016 03:10:03: CNTKCommandTrainInfo: Train : 5
08/16/2016 03:10:03: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5

08/16/2016 03:10:03: ##############################################################################
08/16/2016 03:10:03: #                                                                            #
08/16/2016 03:10:03: # Action "train"                                                             #
08/16/2016 03:10:03: #                                                                            #
08/16/2016 03:10:03: ##############################################################################

08/16/2016 03:10:03: CNTKCommandTrainBegin: Train

08/16/2016 03:10:03: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn.4'.

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ClassificationError()
	t = DynamicAxis()
	z = Plus()

Loop[0] --> Loop_z.x.x.lstmState._.ht -> 25 nodes

	z.x.x.prevState.h	z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1]	z.x.x.lstmState._.ot._.PlusArgs[0]
	z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1]	z.x.x.lstmState._.ft._.PlusArgs[0]	z.x.x.prevState.c
	z.x.x.lstmState._.ft._.PlusArgs[1]	z.x.x.lstmState._.ft._	z.x.x.lstmState._.ft
	z.x.x.lstmState._.bft	z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1]	z.x.x.lstmState._.it._.PlusArgs[0]
	z.x.x.lstmState._.it._.PlusArgs[1]	z.x.x.lstmState._.it._	z.x.x.lstmState._.it
	z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1]	z.x.x.lstmState._.bit.ElementTimesArgs[1].z	z.x.x.lstmState._.bit.ElementTimesArgs[1]
	z.x.x.lstmState._.bit	z.x.x.lstmState._.ct	z.x.x.lstmState._.ot._.PlusArgs[1]
	z.x.x.lstmState._.ot._	z.x.x.lstmState._.ot	z.x.x.lstmState._.ht.ElementTimesArgs[1]
	z.x.x.lstmState._.ht

Validating network. 68 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [5 x *]
Validating --> model.arrayOfFunctions[3].arrayOfFunctions[0].W = LearnableParameter() :  -> [5 x 25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> model.arrayOfFunctions[0].E = LearnableParameter() :  -> [2000 x 50]
Validating --> features = SparseInputValue() :  -> [2000 x t1]
Validating --> z.x.x.x = TransposeTimes (model.arrayOfFunctions[0].E, features) : [2000 x 50], [2000 x t1] -> [50 x t1]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0] = Plus (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0] = Plus (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0] = Plus (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.x) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0] = Plus (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25] -> [25]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0] = Plus (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25] -> [25]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0] = Plus (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [25] -> [25]
Validating --> z.x.x.lstmState._.ft._ = Plus (z.x.x.lstmState._.ft._.PlusArgs[0], z.x.x.lstmState._.ft._.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> z.x.x.lstmState._.ft = Sigmoid (z.x.x.lstmState._.ft._) : [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.bft = ElementTimes (z.x.x.lstmState._.ft, z.x.x.prevState.c) : [25 x t1], [25] -> [25 x t1]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25] -> [25]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0] = Plus (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0], z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> z.x.x.lstmState._.it._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [25] -> [25]
Validating --> z.x.x.lstmState._.it._ = Plus (z.x.x.lstmState._.it._.PlusArgs[0], z.x.x.lstmState._.it._.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> z.x.x.lstmState._.it = Sigmoid (z.x.x.lstmState._.it._) : [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25] -> [25]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z = Plus (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0], z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1] = Tanh (z.x.x.lstmState._.bit.ElementTimesArgs[1].z) : [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.bit = ElementTimes (z.x.x.lstmState._.it, z.x.x.lstmState._.bit.ElementTimesArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ct = Plus (z.x.x.lstmState._.bft, z.x.x.lstmState._.bit) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0], z.x.x.lstmState._.ct) : [25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ot._ = Plus (z.x.x.lstmState._.ot._.PlusArgs[0], z.x.x.lstmState._.ot._.PlusArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ot = Sigmoid (z.x.x.lstmState._.ot._) : [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ht.ElementTimesArgs[1] = Tanh (z.x.x.lstmState._.ct) : [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ht = ElementTimes (z.x.x.lstmState._.ot, z.x.x.lstmState._.ht.ElementTimesArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> z.x.beginFlags.input.z.ElementTimesArgs[0] = Slice (z.x.x.lstmState._.ht) : [25 x t1] -> [1 x t1]
Validating --> BS.Constants.Zero = LearnableParameter() :  -> [1]
Validating --> z.x.beginFlags.input.z = ElementTimes (z.x.beginFlags.input.z.ElementTimesArgs[0], BS.Constants.Zero) : [1 x t1], [1] -> [1 x t1]
Validating --> z.x.beginFlags.input = SumColumnElements (z.x.beginFlags.input.z) : [1 x t1] -> [1 x t1]
Validating --> z.x.beginFlags = FutureValue (z.x.beginFlags.input) : [1 x t1] -> [1 x t1]
Validating --> z.x.out.indexSequence.indexSequence = Where (z.x.beginFlags) : [1 x t1] -> [1 x WhereNodeAxis]
Validating --> z.x.out.indexSequence = PackedIndex (z.x.x.lstmState._.ht, z.x.out.indexSequence.indexSequence) : [25 x t1], [1 x WhereNodeAxis] -> [1 x WhereNodeAxis]
Validating --> z.x.out = GatherPacked (z.x.out.indexSequence, z.x.x.lstmState._.ht) : [1 x WhereNodeAxis], [25 x t1] -> [25 x WhereNodeAxis]
Validating --> z.x.PlusArgs[0] = Times (model.arrayOfFunctions[3].arrayOfFunctions[0].W, z.x.out) : [5 x 25], [25 x WhereNodeAxis] -> [5 x WhereNodeAxis]
Validating --> model.arrayOfFunctions[3].arrayOfFunctions[0].b = LearnableParameter() :  -> [5]
Validating --> z = Plus (z.x.PlusArgs[0], model.arrayOfFunctions[3].arrayOfFunctions[0].b) : [5 x WhereNodeAxis], [5] -> [5 x WhereNodeAxis]
Validating --> zp = ReconcileDynamicAxis (z, labels) : [5 x WhereNodeAxis], [5 x *] -> [5 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, zp) : [5 x *], [5 x *] -> [1]
Validating --> err = ClassificationError (labels, zp) : [5 x *], [5 x *] -> [1]
Validating --> t = DynamicAxis() :  -> [1 x 1 x t1]

Validating network. 46 nodes to process in pass 2.

Validating --> z.x.x.prevState.h = PastValue (z.x.x.lstmState._.ht) : [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.prevState.c = PastValue (z.x.x.lstmState._.ct) : [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.ft._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1] = Times (z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.it._.PlusArgs[1] = ElementTimes (z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0], z.x.x.prevState.c) : [25], [25 x t1] -> [25 x t1]
Validating --> z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], z.x.x.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]

Validating network. 8 nodes to process in pass 3.


Validating network, final pass.



66 out of 68 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/16/2016 03:10:03: Loaded model with 68 nodes on GPU 0.

08/16/2016 03:10:03: Training criterion node(s):
08/16/2016 03:10:03: 	ce = CrossEntropyWithSoftmax

08/16/2016 03:10:03: Evaluation criterion node(s):
08/16/2016 03:10:03: 	err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 129 matrices, 48 are shared as 19, and 81 are not shared.

	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] : [25] (gradient)
	  z.x.x.prevState.h : [25 x t1] }
	{ z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t1]
	  z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] : [25] (gradient) }
	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0] : [25 x t1]
	  z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }
	{ z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] : [25] (gradient)
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t1] }
	{ z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0] : [25 x t1]
	  z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }
	{ z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0] : [25 x t1]
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }
	{ z.x.beginFlags.input.z.ElementTimesArgs[0] : [1 x t1]
	  z.x.x.lstmState._.ot : [25 x t1] (gradient) }
	{ z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0] : [25 x t1]
	  z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] : [25 x 50] (gradient) }
	{ z.x.beginFlags.input.z : [1 x t1]
	  z.x.x.lstmState._.ct : [25 x t1] (gradient) }
	{ z.x.beginFlags.input : [1 x t1]
	  z.x.beginFlags.input.z.ElementTimesArgs[0] : [1 x t1] (gradient)
	  z.x.x.lstmState._.ht.ElementTimesArgs[1] : [25 x t1] (gradient) }
	{ z.x.beginFlags.input : [1 x t1] (gradient)
	  z.x.out : [25 x WhereNodeAxis]
	  z.x.out.indexSequence.indexSequence : [1 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[0] : [25 x t1] (gradient) }
	{ z.x.PlusArgs[0] : [5 x WhereNodeAxis]
	  z.x.beginFlags : [1 x t1] (gradient)
	  z.x.out.indexSequence : [1 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[1] : [25 x t1] (gradient) }
	{ z.x.PlusArgs[0] : [5 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ht : [25 x t1] (gradient)
	  zp : [5 x *] }
	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] : [25 x t1]
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] : [25] (gradient) }
	{ z.x.beginFlags : [1 x t1]
	  z.x.beginFlags.input.z : [1 x t1] (gradient)
	  z.x.x.lstmState._.ot._ : [25 x t1] (gradient) }
	{ model.arrayOfFunctions[3].arrayOfFunctions[0].W : [5 x 25] (gradient)
	  z : [5 x WhereNodeAxis] (gradient) }
	{ z.x.out : [25 x WhereNodeAxis] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0] : [25] (gradient) }
	{ model.arrayOfFunctions[3].arrayOfFunctions[0].b : [5] (gradient)
	  zp : [5 x *] (gradient) }
	{ z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] : [25 x t1] (gradient)
	  z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t1] (gradient)
	  z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t1] (gradient)
	  z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] : [25 x t1] (gradient)
	  z.x.x.prevState.h : [25 x t1] (gradient) }


08/16/2016 03:10:03: Training 7805 parameters in 17 out of 17 parameter tensors and 61 nodes with gradient:

08/16/2016 03:10:03: 	Node 'model.arrayOfFunctions[3].arrayOfFunctions[0].W' (LearnableParameter operation) : [5 x 25]
08/16/2016 03:10:03: 	Node 'model.arrayOfFunctions[3].arrayOfFunctions[0].b' (LearnableParameter operation) : [5]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ft._.PlusArgs[1].ElementTimesArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.it._.PlusArgs[1].ElementTimesArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0]' (LearnableParameter operation) : [25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 50]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0]' (LearnableParameter operation) : [25 x 25]
08/16/2016 03:10:03: 	Node 'z.x.x.lstmState._.ot._.PlusArgs[1].ElementTimesArgs[0]' (LearnableParameter operation) : [25]

08/16/2016 03:10:03: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/16/2016 03:10:03: Starting Epoch 5: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 4: frames [21732..27165] (first sequence at sample 21732), data subset 0 of 1

08/16/2016 03:10:03: Starting minibatch loop.
WARNING: The same matrix with dim [1, 48] has been transferred between different devices for 20 times.
08/16/2016 03:10:04: Finished Epoch[ 5 of 5]: [Training] ce = 1.33163117 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 6235; learningRatePerSample = 0.00050000002; epochTime=1.02452s
08/16/2016 03:10:04: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160816030157.855216\Text_SequenceClassification@release_gpu/Models/seqcla.dnn'
08/16/2016 03:10:04: CNTKCommandTrainEnd: Train

08/16/2016 03:10:04: Action "train" complete.

08/16/2016 03:10:04: __COMPLETED__