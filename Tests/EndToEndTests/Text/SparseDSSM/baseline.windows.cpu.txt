=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 2 in a gearbox of 4
mpihelper: we are cog 0 in a gearbox of 4
mpihelper: we are cog 1 in a gearbox of 4
mpihelper: we are cog 3 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank0
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: Build info: 
MPI Rank 0: 
MPI Rank 0: 		Built time: Mar  3 2016 14:41:54
MPI Rank 0: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 0: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 0: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 0: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 		Build Branch: HEAD
MPI Rank 0: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 0: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 0: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: running on SAADSRNRDEV040 at 2016/03/04 00:08:44
MPI Rank 0: command line: 
MPI Rank 0: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=$RunDir$/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=-1
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=-1
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=-1
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=-1
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: command: train 
MPI Rank 0: precision = float
MPI Rank 0: Using 10 CPU threads
MPI Rank 0: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0: CNTKCommandTrainInfo: train : 3
MPI Rank 0: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using CPU
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: SGD using CPU.
MPI Rank 0: 
MPI Rank 0: Training criterion node(s):
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: No PreCompute nodes found, skipping PreCompute step
MPI Rank 0: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 0: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.41944122; TotalTime = 17.5796s; SamplesPerSecond = 582.5
MPI Rank 0:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.38406754; TotalTime = 16.5473s; SamplesPerSecond = 618.8
MPI Rank 0: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6788689; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=43.1807
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 2.5110212    Perplexity = 12.317502    
MPI Rank 0: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5110212
MPI Rank 0: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.29922523; TotalTime = 15.5020s; SamplesPerSecond = 660.6
MPI Rank 0:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.08742409; TotalTime = 15.8390s; SamplesPerSecond = 646.5
MPI Rank 0: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1805767; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.7397
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.9751821    Perplexity = 7.2079319    
MPI Rank 0: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9751821
MPI Rank 0: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.90042439; TotalTime = 15.5077s; SamplesPerSecond = 660.3
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.85719700; TotalTime = 16.0274s; SamplesPerSecond = 638.9
MPI Rank 0: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8883394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.2866
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.8119593    Perplexity = 6.1224311    
MPI Rank 0: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8119593
MPI Rank 0: CNTKCommandTrainEnd: train
MPI Rank 0: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank1
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: Build info: 
MPI Rank 1: 
MPI Rank 1: 		Built time: Mar  3 2016 14:41:54
MPI Rank 1: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 1: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 1: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 1: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 		Build Branch: HEAD
MPI Rank 1: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 1: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 1: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: running on SAADSRNRDEV040 at 2016/03/04 00:08:44
MPI Rank 1: command line: 
MPI Rank 1: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=$RunDir$/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=-1
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=-1
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=-1
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=-1
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: command: train 
MPI Rank 1: precision = float
MPI Rank 1: Using 10 CPU threads
MPI Rank 1: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1: CNTKCommandTrainInfo: train : 3
MPI Rank 1: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using CPU
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: SGD using CPU.
MPI Rank 1: 
MPI Rank 1: Training criterion node(s):
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: No PreCompute nodes found, skipping PreCompute step
MPI Rank 1: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 1: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.42829742; TotalTime = 17.7166s; SamplesPerSecond = 578.0
MPI Rank 1:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.38771057; TotalTime = 16.2755s; SamplesPerSecond = 629.2
MPI Rank 1: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6788689; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=43.1757
MPI Rank 1: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.34065857; TotalTime = 16.1174s; SamplesPerSecond = 635.3
MPI Rank 1:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11009483; TotalTime = 15.8116s; SamplesPerSecond = 647.6
MPI Rank 1: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1805767; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.7355
MPI Rank 1: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93978729; TotalTime = 15.5855s; SamplesPerSecond = 657.0
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86772957; TotalTime = 16.2062s; SamplesPerSecond = 631.9
MPI Rank 1: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8883394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.2826
MPI Rank 1: CNTKCommandTrainEnd: train
MPI Rank 1: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank2
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: Build info: 
MPI Rank 2: 
MPI Rank 2: 		Built time: Mar  3 2016 14:41:54
MPI Rank 2: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 2: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 2: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 2: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 		Build Branch: HEAD
MPI Rank 2: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 2: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 2: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: running on SAADSRNRDEV040 at 2016/03/04 00:08:45
MPI Rank 2: command line: 
MPI Rank 2: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=$RunDir$/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=-1
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=-1
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=-1
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=-1
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: command: train 
MPI Rank 2: precision = float
MPI Rank 2: Using 10 CPU threads
MPI Rank 2: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2: CNTKCommandTrainInfo: train : 3
MPI Rank 2: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using CPU
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: SGD using CPU.
MPI Rank 2: 
MPI Rank 2: Training criterion node(s):
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: No PreCompute nodes found, skipping PreCompute step
MPI Rank 2: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 2: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.44101410; TotalTime = 17.5831s; SamplesPerSecond = 582.4
MPI Rank 2:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.39723740; TotalTime = 16.6279s; SamplesPerSecond = 615.8
MPI Rank 2: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6788689; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=43.1806
MPI Rank 2: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.34435482; TotalTime = 16.0019s; SamplesPerSecond = 639.9
MPI Rank 2:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.13005276; TotalTime = 15.8394s; SamplesPerSecond = 646.5
MPI Rank 2: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1805767; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.7397
MPI Rank 2: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95727196; TotalTime = 16.2714s; SamplesPerSecond = 629.3
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.88702583; TotalTime = 15.9308s; SamplesPerSecond = 642.8
MPI Rank 2: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8883394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.2866
MPI Rank 2: CNTKCommandTrainEnd: train
MPI Rank 2: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank3
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: Build info: 
MPI Rank 3: 
MPI Rank 3: 		Built time: Mar  3 2016 14:41:54
MPI Rank 3: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 3: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 3: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 3: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 		Build Branch: HEAD
MPI Rank 3: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 3: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 3: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: running on SAADSRNRDEV040 at 2016/03/04 00:08:45
MPI Rank 3: command line: 
MPI Rank 3: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=$RunDir$/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=-1
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=-1
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=-1
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=-1
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: command: train 
MPI Rank 3: precision = float
MPI Rank 3: Using 10 CPU threads
MPI Rank 3: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3: CNTKCommandTrainInfo: train : 3
MPI Rank 3: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using CPU
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: SGD using CPU.
MPI Rank 3: 
MPI Rank 3: Training criterion node(s):
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: No PreCompute nodes found, skipping PreCompute step
MPI Rank 3: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 3: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.43899651; TotalTime = 17.6870s; SamplesPerSecond = 579.0
MPI Rank 3:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.38633919; TotalTime = 16.3230s; SamplesPerSecond = 627.3
MPI Rank 3: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6788689; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=43.1757
MPI Rank 3: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.29999485; TotalTime = 15.5869s; SamplesPerSecond = 657.0
MPI Rank 3:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11324863; TotalTime = 15.8117s; SamplesPerSecond = 647.6
MPI Rank 3: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1805767; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.735
MPI Rank 3: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.90144348; TotalTime = 15.5983s; SamplesPerSecond = 656.5
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.87299423; TotalTime = 16.2062s; SamplesPerSecond = 631.9
MPI Rank 3: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8883394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=40.2823
MPI Rank 3: CNTKCommandTrainEnd: train
MPI Rank 3: __COMPLETED__
MPI Rank 3: ~MPIWrapper
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 3 in a gearbox of 4
mpihelper: we are cog 1 in a gearbox of 4
mpihelper: we are cog 2 in a gearbox of 4
mpihelper: we are cog 0 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank0
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: Build info: 
MPI Rank 0: 
MPI Rank 0: 		Built time: Mar  3 2016 14:41:54
MPI Rank 0: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 0: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 0: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 0: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 		Build Branch: HEAD
MPI Rank 0: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 0: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 0: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: running on SAADSRNRDEV040 at 2016/03/04 00:11:22
MPI Rank 0: command line: 
MPI Rank 0: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=$RunDir$/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=-1
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=-1
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=-1
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=-1
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: command: train 
MPI Rank 0: precision = float
MPI Rank 0: Using 10 CPU threads
MPI Rank 0: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 0: CNTKCommandTrainInfo: train : 3
MPI Rank 0: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using CPU
MPI Rank 0: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net.2.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: SGD using CPU.
MPI Rank 0: 
MPI Rank 0: Training criterion node(s):
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: No PreCompute nodes found, skipping PreCompute step
MPI Rank 0: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 0: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 0: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93025131; TotalTime = 19.6371s; SamplesPerSecond = 521.5
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93263016; TotalTime = 17.2225s; SamplesPerSecond = 594.6
MPI Rank 0: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9528804; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=46.4048
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.8993035    Perplexity = 6.6812396    
MPI Rank 0: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8993035
MPI Rank 0: CNTKCommandTrainEnd: train
MPI Rank 0: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank1
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: Build info: 
MPI Rank 1: 
MPI Rank 1: 		Built time: Mar  3 2016 14:41:54
MPI Rank 1: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 1: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 1: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 1: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 		Build Branch: HEAD
MPI Rank 1: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 1: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 1: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: running on SAADSRNRDEV040 at 2016/03/04 00:11:22
MPI Rank 1: command line: 
MPI Rank 1: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=$RunDir$/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=-1
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=-1
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=-1
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=-1
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: command: train 
MPI Rank 1: precision = float
MPI Rank 1: Using 10 CPU threads
MPI Rank 1: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 1: CNTKCommandTrainInfo: train : 3
MPI Rank 1: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using CPU
MPI Rank 1: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net.2.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: SGD using CPU.
MPI Rank 1: 
MPI Rank 1: Training criterion node(s):
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: No PreCompute nodes found, skipping PreCompute step
MPI Rank 1: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 1: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 1: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.97015953; TotalTime = 19.1537s; SamplesPerSecond = 534.6
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.94770432; TotalTime = 17.5215s; SamplesPerSecond = 584.4
MPI Rank 1: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9528804; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=46.4912
MPI Rank 1: CNTKCommandTrainEnd: train
MPI Rank 1: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank2
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: Build info: 
MPI Rank 2: 
MPI Rank 2: 		Built time: Mar  3 2016 14:41:54
MPI Rank 2: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 2: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 2: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 2: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 		Build Branch: HEAD
MPI Rank 2: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 2: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 2: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: running on SAADSRNRDEV040 at 2016/03/04 00:11:23
MPI Rank 2: command line: 
MPI Rank 2: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=$RunDir$/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=-1
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=-1
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=-1
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=-1
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: command: train 
MPI Rank 2: precision = float
MPI Rank 2: Using 10 CPU threads
MPI Rank 2: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 2: CNTKCommandTrainInfo: train : 3
MPI Rank 2: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using CPU
MPI Rank 2: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net.2.
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: SGD using CPU.
MPI Rank 2: 
MPI Rank 2: Training criterion node(s):
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: No PreCompute nodes found, skipping PreCompute step
MPI Rank 2: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 2: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 2: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.98702526; TotalTime = 19.7224s; SamplesPerSecond = 519.2
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.96577854; TotalTime = 17.2169s; SamplesPerSecond = 594.8
MPI Rank 2: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9528804; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=46.4944
MPI Rank 2: CNTKCommandTrainEnd: train
MPI Rank 2: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr_train.logrank3
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: Build info: 
MPI Rank 3: 
MPI Rank 3: 		Built time: Mar  3 2016 14:41:54
MPI Rank 3: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 3: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 3: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 3: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 		Build Branch: HEAD
MPI Rank 3: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 3: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 3: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: running on SAADSRNRDEV040 at 2016/03/04 00:11:23
MPI Rank 3: command line: 
MPI Rank 3: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=-1 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr 
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=$RunDir$/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=-1
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=-1
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=-1
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:DeviceId=-1
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/stderr
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=-1
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: command: train 
MPI Rank 3: precision = float
MPI Rank 3: Using 10 CPU threads
MPI Rank 3: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net
MPI Rank 3: CNTKCommandTrainInfo: train : 3
MPI Rank 3: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using CPU
MPI Rank 3: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303160843.247203\Text_SparseDSSM@release_cpu/models/dssm.net.2.
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: SGD using CPU.
MPI Rank 3: 
MPI Rank 3: Training criterion node(s):
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: No PreCompute nodes found, skipping PreCompute step
MPI Rank 3: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 3: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 3: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93149776; TotalTime = 19.2109s; SamplesPerSecond = 533.0
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95135975; TotalTime = 17.5215s; SamplesPerSecond = 584.4
MPI Rank 3: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9528804; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=46.4913
MPI Rank 3: CNTKCommandTrainEnd: train
MPI Rank 3: __COMPLETED__
MPI Rank 3: ~MPIWrapper
