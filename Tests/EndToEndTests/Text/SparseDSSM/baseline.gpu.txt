CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3530 @ 2.80GHz
    Hardware threads: 4
    Total Memory: 12580404 kB
-------------------------------------------------------------------
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu DeviceId=0 timestamping=true numCPUThreads=1 stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:13

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (2) are in (participating)
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:14

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (0) are in (participating)
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:13

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (3) are in (participating)
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:14

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (1) are in (participating)
MPI Rank 0: 12/15/2016 08:35:14: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank0
MPI Rank 0: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:14
MPI Rank 0: 
MPI Rank 0: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 12/15/2016 08:35:14: Using 1 CPU threads.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:14: ##############################################################################
MPI Rank 0: 12/15/2016 08:35:14: #                                                                            #
MPI Rank 0: 12/15/2016 08:35:14: # train command (train action)                                               #
MPI Rank 0: 12/15/2016 08:35:14: #                                                                            #
MPI Rank 0: 12/15/2016 08:35:14: ##############################################################################
MPI Rank 0: 
MPI Rank 0: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 0: 12/15/2016 08:35:14: 
MPI Rank 0: Creating virgin network.
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 12/15/2016 08:35:15: 
MPI Rank 0: Model has 21 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:15: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing: Out of 36 matrices, 16 are shared as 7, and 20 are not shared.
MPI Rank 0: 
MPI Rank 0: 	{ WD0_D : [288 x *]
MPI Rank 0: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 0: 	{ WD0_D : [288 x *] (gradient)
MPI Rank 0: 	  WD1_D : [64 x *] }
MPI Rank 0: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 0: 	  WQ0_Q_Tanh : [288 x *] (gradient)
MPI Rank 0: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 0: 	{ WD1 : [64 x 288] (gradient)
MPI Rank 0: 	  WD1_D_Tanh : [64 x *] }
MPI Rank 0: 	{ WQ1 : [64 x 288] (gradient)
MPI Rank 0: 	  WQ1_Q_Tanh : [64 x *] }
MPI Rank 0: 	{ WQ0_Q : [288 x *] (gradient)
MPI Rank 0: 	  WQ1_Q : [64 x *] }
MPI Rank 0: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 0: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 0: 	  WD1_D_Tanh : [64 x *] (gradient) }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:15: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:15: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 12/15/2016 08:35:15: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 12/15/2016 08:35:15: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 12/15/2016 08:35:15: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 
MPI Rank 0: Parallel training (4 workers) using ModelAveraging
MPI Rank 0: 12/15/2016 08:35:15: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:17: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:35:23:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.34696770 * 10240; time = 5.7967s; samplesPerSecond = 1766.5
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:35:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.34277306 * 10240; time = 5.2689s; samplesPerSecond = 1943.5
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:35:31: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601699 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-005; epochTime=13.83s
MPI Rank 0: 12/15/2016 08:35:32: Final Results: Minibatch[1-26]: ce = 2.49916007 * 102399; perplexity = 12.17226578
MPI Rank 0: 12/15/2016 08:35:32: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916007 * 102399
MPI Rank 0: 12/15/2016 08:35:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net.1'
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:35: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:35:40:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.30270958 * 10240; time = 5.3331s; samplesPerSecond = 1920.1
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:35:45:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.09883766 * 10240; time = 5.2459s; samplesPerSecond = 1952.0
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577522 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-005; epochTime=13.2734s
MPI Rank 0: 12/15/2016 08:35:48: Final Results: Minibatch[1-26]: ce = 1.97005576 * 102399; perplexity = 7.17107634
MPI Rank 0: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005576 * 102399
MPI Rank 0: 12/15/2016 08:35:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net.2'
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:51: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:35:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:35:56:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.89778175 * 10240; time = 5.3327s; samplesPerSecond = 1920.2
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:36:02:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.86335983 * 10240; time = 5.3550s; samplesPerSecond = 1912.2
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:36:04: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.3815s
MPI Rank 0: 12/15/2016 08:36:05: Final Results: Minibatch[1-26]: ce = 1.80751074 * 102399; perplexity = 6.09525583
MPI Rank 0: 12/15/2016 08:36:05: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751074 * 102399
MPI Rank 0: 12/15/2016 08:36:06: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net'
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:07: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:07: __COMPLETED__
MPI Rank 1: 12/15/2016 08:35:15: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank1
MPI Rank 1: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:14
MPI Rank 1: 
MPI Rank 1: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 12/15/2016 08:35:15: Using 1 CPU threads.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:15: ##############################################################################
MPI Rank 1: 12/15/2016 08:35:15: #                                                                            #
MPI Rank 1: 12/15/2016 08:35:15: # train command (train action)                                               #
MPI Rank 1: 12/15/2016 08:35:15: #                                                                            #
MPI Rank 1: 12/15/2016 08:35:15: ##############################################################################
MPI Rank 1: 
MPI Rank 1: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 1: 12/15/2016 08:35:15: 
MPI Rank 1: Creating virgin network.
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 12/15/2016 08:35:15: 
MPI Rank 1: Model has 21 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:15: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing: Out of 36 matrices, 16 are shared as 7, and 20 are not shared.
MPI Rank 1: 
MPI Rank 1: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 1: 	  WQ0_Q_Tanh : [288 x *] (gradient)
MPI Rank 1: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 1: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 1: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 1: 	  WD1_D_Tanh : [64 x *] (gradient) }
MPI Rank 1: 	{ WD1 : [64 x 288] (gradient)
MPI Rank 1: 	  WD1_D_Tanh : [64 x *] }
MPI Rank 1: 	{ WQ0_Q : [288 x *] (gradient)
MPI Rank 1: 	  WQ1_Q : [64 x *] }
MPI Rank 1: 	{ WQ1 : [64 x 288] (gradient)
MPI Rank 1: 	  WQ1_Q_Tanh : [64 x *] }
MPI Rank 1: 	{ WD0_D : [288 x *]
MPI Rank 1: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 1: 	{ WD0_D : [288 x *] (gradient)
MPI Rank 1: 	  WD1_D : [64 x *] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:15: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:15: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 12/15/2016 08:35:15: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 12/15/2016 08:35:15: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 12/15/2016 08:35:15: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 
MPI Rank 1: Parallel training (4 workers) using ModelAveraging
MPI Rank 1: 12/15/2016 08:35:15: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:17: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.13-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.13 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.08 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 1: 12/15/2016 08:35:23:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.32159615 * 10240; time = 5.8096s; samplesPerSecond = 1762.6
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 1: 12/15/2016 08:35:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.33525505 * 10240; time = 5.2644s; samplesPerSecond = 1945.1
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.37 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.37 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.37 seconds , average latency = 0.01 seconds
MPI Rank 1: 12/15/2016 08:35:31: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601699 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-005; epochTime=13.8084s
MPI Rank 1: 12/15/2016 08:35:32: Final Results: Minibatch[1-26]: ce = 2.49916007 * 102399; perplexity = 12.17226578
MPI Rank 1: 12/15/2016 08:35:32: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916007 * 102399
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:35: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 1: 12/15/2016 08:35:40:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.32732925 * 10240; time = 5.3016s; samplesPerSecond = 1931.5
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.01 seconds
MPI Rank 1: 12/15/2016 08:35:45:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.11035995 * 10240; time = 5.2749s; samplesPerSecond = 1941.3
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.01 seconds
MPI Rank 1: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577522 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-005; epochTime=13.2729s
MPI Rank 1: 12/15/2016 08:35:48: Final Results: Minibatch[1-26]: ce = 1.97005576 * 102399; perplexity = 7.17107634
MPI Rank 1: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005576 * 102399
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:51: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:35:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.01 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 1: 12/15/2016 08:35:56:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.92909813 * 10240; time = 5.3280s; samplesPerSecond = 1921.9
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.01 seconds
MPI Rank 1: 12/15/2016 08:36:02:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.86598778 * 10240; time = 5.3643s; samplesPerSecond = 1908.9
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.01 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.01 seconds
MPI Rank 1: 12/15/2016 08:36:04: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.3815s
MPI Rank 1: 12/15/2016 08:36:05: Final Results: Minibatch[1-26]: ce = 1.80751074 * 102399; perplexity = 6.09525583
MPI Rank 1: 12/15/2016 08:36:05: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751074 * 102399
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:07: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:07: __COMPLETED__
MPI Rank 2: 12/15/2016 08:35:15: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank2
MPI Rank 2: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:13
MPI Rank 2: 
MPI Rank 2: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 12/15/2016 08:35:15: Using 1 CPU threads.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:15: ##############################################################################
MPI Rank 2: 12/15/2016 08:35:15: #                                                                            #
MPI Rank 2: 12/15/2016 08:35:15: # train command (train action)                                               #
MPI Rank 2: 12/15/2016 08:35:15: #                                                                            #
MPI Rank 2: 12/15/2016 08:35:15: ##############################################################################
MPI Rank 2: 
MPI Rank 2: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 2: 12/15/2016 08:35:15: 
MPI Rank 2: Creating virgin network.
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 12/15/2016 08:35:16: 
MPI Rank 2: Model has 21 nodes. Using GPU 0.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:16: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 
MPI Rank 2: Memory Sharing: Out of 36 matrices, 16 are shared as 7, and 20 are not shared.
MPI Rank 2: 
MPI Rank 2: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 2: 	  WQ0_Q_Tanh : [288 x *] (gradient)
MPI Rank 2: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 2: 	{ WQ1 : [64 x 288] (gradient)
MPI Rank 2: 	  WQ1_Q_Tanh : [64 x *] }
MPI Rank 2: 	{ WQ0_Q : [288 x *] (gradient)
MPI Rank 2: 	  WQ1_Q : [64 x *] }
MPI Rank 2: 	{ WD0_D : [288 x *] (gradient)
MPI Rank 2: 	  WD1_D : [64 x *] }
MPI Rank 2: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 2: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 2: 	  WD1_D_Tanh : [64 x *] (gradient) }
MPI Rank 2: 	{ WD0_D : [288 x *]
MPI Rank 2: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 2: 	{ WD1 : [64 x 288] (gradient)
MPI Rank 2: 	  WD1_D_Tanh : [64 x *] }
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:16: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:16: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 12/15/2016 08:35:16: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 12/15/2016 08:35:16: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 12/15/2016 08:35:16: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 
MPI Rank 2: Parallel training (4 workers) using ModelAveraging
MPI Rank 2: 12/15/2016 08:35:16: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:17: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:18: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.12-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.12 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.07 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.02 seconds
MPI Rank 2: 12/15/2016 08:35:23:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.32837563 * 10240; time = 5.7715s; samplesPerSecond = 1774.2
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:35:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.35655479 * 10240; time = 5.2681s; samplesPerSecond = 1943.8
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:35:31: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601699 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-005; epochTime=13.8082s
MPI Rank 2: 12/15/2016 08:35:32: Final Results: Minibatch[1-26]: ce = 2.49916007 * 102399; perplexity = 12.17226578
MPI Rank 2: 12/15/2016 08:35:32: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916007 * 102399
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:35: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.00 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.00 seconds
MPI Rank 2: 12/15/2016 08:35:40:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.32893620 * 10240; time = 5.3149s; samplesPerSecond = 1926.7
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:35:45:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.11646900 * 10240; time = 5.2748s; samplesPerSecond = 1941.3
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577522 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-005; epochTime=13.2716s
MPI Rank 2: 12/15/2016 08:35:48: Final Results: Minibatch[1-26]: ce = 1.97005576 * 102399; perplexity = 7.17107634
MPI Rank 2: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005576 * 102399
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:51: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:35:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.04 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:35:56:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.95308418 * 10240; time = 5.3644s; samplesPerSecond = 1908.9
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:36:02:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.87902641 * 10240; time = 5.3220s; samplesPerSecond = 1924.1
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:36:04: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.381s
MPI Rank 2: 12/15/2016 08:36:05: Final Results: Minibatch[1-26]: ce = 1.80751074 * 102399; perplexity = 6.09525583
MPI Rank 2: 12/15/2016 08:36:05: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751074 * 102399
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:07: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:07: __COMPLETED__
MPI Rank 3: 12/15/2016 08:35:16: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 3: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:35:13
MPI Rank 3: 
MPI Rank 3: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 12/15/2016 08:35:16: Using 1 CPU threads.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:16: ##############################################################################
MPI Rank 3: 12/15/2016 08:35:16: #                                                                            #
MPI Rank 3: 12/15/2016 08:35:16: # train command (train action)                                               #
MPI Rank 3: 12/15/2016 08:35:16: #                                                                            #
MPI Rank 3: 12/15/2016 08:35:16: ##############################################################################
MPI Rank 3: 
MPI Rank 3: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 3: 12/15/2016 08:35:16: 
MPI Rank 3: Creating virgin network.
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 12/15/2016 08:35:16: 
MPI Rank 3: Model has 21 nodes. Using GPU 0.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:16: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: 
MPI Rank 3: Memory Sharing: Out of 36 matrices, 16 are shared as 7, and 20 are not shared.
MPI Rank 3: 
MPI Rank 3: 	{ SIM_Scale : [51 x 1 x *]
MPI Rank 3: 	  WQ0_Q_Tanh : [288 x *] (gradient)
MPI Rank 3: 	  WQ1_Q_Tanh : [64 x *] (gradient) }
MPI Rank 3: 	{ SIM_Scale : [51 x 1 x *] (gradient)
MPI Rank 3: 	  WD0_D_Tanh : [288 x *] (gradient)
MPI Rank 3: 	  WD1_D_Tanh : [64 x *] (gradient) }
MPI Rank 3: 	{ WD0_D : [288 x *] (gradient)
MPI Rank 3: 	  WD1_D : [64 x *] }
MPI Rank 3: 	{ WQ0_Q : [288 x *] (gradient)
MPI Rank 3: 	  WQ1_Q : [64 x *] }
MPI Rank 3: 	{ WD0_D : [288 x *]
MPI Rank 3: 	  WQ1_Q : [64 x *] (gradient) }
MPI Rank 3: 	{ WQ1 : [64 x 288] (gradient)
MPI Rank 3: 	  WQ1_Q_Tanh : [64 x *] }
MPI Rank 3: 	{ WD1 : [64 x 288] (gradient)
MPI Rank 3: 	  WD1_D_Tanh : [64 x *] }
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:16: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:16: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 12/15/2016 08:35:16: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 12/15/2016 08:35:16: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 12/15/2016 08:35:16: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 
MPI Rank 3: Parallel training (4 workers) using ModelAveraging
MPI Rank 3: 12/15/2016 08:35:16: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:17: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.18-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.18 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.05 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.04 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.04 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.02 seconds
MPI Rank 3: 12/15/2016 08:35:23:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: ce = 4.32287750 * 10240; time = 5.8136s; samplesPerSecond = 1761.4
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.02 seconds
MPI Rank 3: 12/15/2016 08:35:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: ce = 3.35470428 * 10240; time = 5.2356s; samplesPerSecond = 1955.9
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.34 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 3: 12/15/2016 08:35:31: Finished Epoch[ 1 of 3]: [Training] ce = 3.61601699 * 102399; totalSamplesSeen = 102399; learningRatePerSample = 9.9999997e-005; epochTime=13.8082s
MPI Rank 3: 12/15/2016 08:35:32: Final Results: Minibatch[1-26]: ce = 2.49916007 * 102399; perplexity = 12.17226578
MPI Rank 3: 12/15/2016 08:35:32: Finished Epoch[ 1 of 3]: [Validate] ce = 2.49916007 * 102399
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:35: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.12 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 3: 12/15/2016 08:35:40:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: ce = 2.29653873 * 10240; time = 5.3336s; samplesPerSecond = 1919.9
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.28 seconds , average latency = 0.01 seconds
MPI Rank 3: 12/15/2016 08:35:45:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: ce = 2.11679478 * 10240; time = 5.2751s; samplesPerSecond = 1941.2
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.31 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.33 seconds , average latency = 0.01 seconds
MPI Rank 3: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Training] ce = 2.17577522 * 102399; totalSamplesSeen = 204798; learningRatePerSample = 9.9999997e-005; epochTime=13.2715s
MPI Rank 3: 12/15/2016 08:35:48: Final Results: Minibatch[1-26]: ce = 1.97005576 * 102399; perplexity = 7.17107634
MPI Rank 3: 12/15/2016 08:35:48: Finished Epoch[ 2 of 3]: [Validate] ce = 1.97005576 * 102399
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:51: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:35:51: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.06 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 3: 12/15/2016 08:35:56:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.90347176 * 10240; time = 5.3276s; samplesPerSecond = 1922.1
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.01 seconds
MPI Rank 3: 12/15/2016 08:36:02:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.88304138 * 10240; time = 5.4005s; samplesPerSecond = 1896.1
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.01 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.25 seconds , average latency = 0.01 seconds
MPI Rank 3: 12/15/2016 08:36:04: Finished Epoch[ 3 of 3]: [Training] ce = 1.88563945 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.3798s
MPI Rank 3: 12/15/2016 08:36:05: Final Results: Minibatch[1-26]: ce = 1.80751074 * 102399; perplexity = 6.09525583
MPI Rank 3: 12/15/2016 08:36:05: Finished Epoch[ 3 of 3]: [Validate] ce = 1.80751074 * 102399
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:07: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:07: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu DeviceId=0 timestamping=true numCPUThreads=1 stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (1) are in (participating)
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (0) are in (participating)
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (3) are in (participating)
CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10

C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes on a single host (4 requested); we (2) are in (participating)
MPI Rank 0: 12/15/2016 08:36:11: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank0
MPI Rank 0: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10
MPI Rank 0: 
MPI Rank 0: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 12/15/2016 08:36:11: Using 1 CPU threads.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:11: ##############################################################################
MPI Rank 0: 12/15/2016 08:36:11: #                                                                            #
MPI Rank 0: 12/15/2016 08:36:11: # train command (train action)                                               #
MPI Rank 0: 12/15/2016 08:36:11: #                                                                            #
MPI Rank 0: 12/15/2016 08:36:11: ##############################################################################
MPI Rank 0: 
MPI Rank 0: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 0: 12/15/2016 08:36:11: 
MPI Rank 0: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 12/15/2016 08:36:13: 
MPI Rank 0: Model has 21 nodes. Using GPU 0.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:13: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:13: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:13: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 12/15/2016 08:36:13: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 12/15/2016 08:36:13: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 0: 12/15/2016 08:36:13: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 0: 
MPI Rank 0: Parallel training (4 workers) using ModelAveraging
MPI Rank 0: 12/15/2016 08:36:13: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:17: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.02 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.03 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:36:23:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.87577038 * 10240; time = 5.8987s; samplesPerSecond = 1736.0
MPI Rank 0: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.07 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.11 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:36:28:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.79361134 * 10240; time = 5.2388s; samplesPerSecond = 1954.6
MPI Rank 0: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.14 seconds , average latency = 0.01 seconds
MPI Rank 0: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.01 seconds
MPI Rank 0: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974292 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.9138s
MPI Rank 0: 12/15/2016 08:36:31: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241653
MPI Rank 0: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 0: 12/15/2016 08:36:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net'
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:34: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 12/15/2016 08:36:34: __COMPLETED__
MPI Rank 1: 12/15/2016 08:36:12: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank1
MPI Rank 1: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10
MPI Rank 1: 
MPI Rank 1: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 12/15/2016 08:36:12: Using 1 CPU threads.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:12: ##############################################################################
MPI Rank 1: 12/15/2016 08:36:12: #                                                                            #
MPI Rank 1: 12/15/2016 08:36:12: # train command (train action)                                               #
MPI Rank 1: 12/15/2016 08:36:12: #                                                                            #
MPI Rank 1: 12/15/2016 08:36:12: ##############################################################################
MPI Rank 1: 
MPI Rank 1: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 1: 12/15/2016 08:36:12: 
MPI Rank 1: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 12/15/2016 08:36:14: 
MPI Rank 1: Model has 21 nodes. Using GPU 0.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:14: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:14: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:14: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 12/15/2016 08:36:14: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 12/15/2016 08:36:14: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 1: 12/15/2016 08:36:14: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 1: 
MPI Rank 1: Parallel training (4 workers) using ModelAveraging
MPI Rank 1: 12/15/2016 08:36:14: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:17: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.13-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.13 seconds
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.08 seconds
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 1: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.05 seconds
MPI Rank 1: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.04 seconds
MPI Rank 1: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.03 seconds
MPI Rank 1: 12/15/2016 08:36:23:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.93745022 * 10240; time = 5.9139s; samplesPerSecond = 1731.5
MPI Rank 1: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.34 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.35 seconds , average latency = 0.03 seconds
MPI Rank 1: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.36 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.38 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.41 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.42 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.44 seconds , average latency = 0.02 seconds
MPI Rank 1: 12/15/2016 08:36:28:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.89571209 * 10240; time = 5.2683s; samplesPerSecond = 1943.7
MPI Rank 1: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.46 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.48 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.51 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.51 seconds , average latency = 0.02 seconds
MPI Rank 1: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.52 seconds , average latency = 0.02 seconds
MPI Rank 1: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974292 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.9117s
MPI Rank 1: 12/15/2016 08:36:31: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241653
MPI Rank 1: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:34: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 12/15/2016 08:36:34: __COMPLETED__
MPI Rank 2: 12/15/2016 08:36:12: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank2
MPI Rank 2: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10
MPI Rank 2: 
MPI Rank 2: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 12/15/2016 08:36:12: Using 1 CPU threads.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:12: ##############################################################################
MPI Rank 2: 12/15/2016 08:36:12: #                                                                            #
MPI Rank 2: 12/15/2016 08:36:12: # train command (train action)                                               #
MPI Rank 2: 12/15/2016 08:36:12: #                                                                            #
MPI Rank 2: 12/15/2016 08:36:12: ##############################################################################
MPI Rank 2: 
MPI Rank 2: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 2: 12/15/2016 08:36:12: 
MPI Rank 2: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 12/15/2016 08:36:14: 
MPI Rank 2: Model has 21 nodes. Using GPU 0.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:14: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:14: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:14: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 12/15/2016 08:36:14: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 12/15/2016 08:36:14: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 2: 12/15/2016 08:36:14: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 2: 
MPI Rank 2: Parallel training (4 workers) using ModelAveraging
MPI Rank 2: 12/15/2016 08:36:14: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:17: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.13-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.13 seconds
MPI Rank 2: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.07 seconds
MPI Rank 2: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 2: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.04 seconds
MPI Rank 2: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.03 seconds
MPI Rank 2: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.17 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.02 seconds
MPI Rank 2: 12/15/2016 08:36:23:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.96188030 * 10240; time = 5.9288s; samplesPerSecond = 1727.2
MPI Rank 2: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.22 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.02 seconds
MPI Rank 2: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:36:28:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.90950069 * 10240; time = 5.2993s; samplesPerSecond = 1932.3
MPI Rank 2: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.27 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.01 seconds
MPI Rank 2: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.01 seconds
MPI Rank 2: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974292 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.9307s
MPI Rank 2: 12/15/2016 08:36:31: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241653
MPI Rank 2: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:34: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 12/15/2016 08:36:34: __COMPLETED__
MPI Rank 3: 12/15/2016 08:36:13: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 3: CNTK 2.0.beta6.0+ (HEAD 5f1fab, Dec 15 2016 06:29:34) on cntk-muc03 at 2016/12/15 08:36:10
MPI Rank 3: 
MPI Rank 3: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 12/15/2016 08:36:13: Using 1 CPU threads.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:13: ##############################################################################
MPI Rank 3: 12/15/2016 08:36:13: #                                                                            #
MPI Rank 3: 12/15/2016 08:36:13: # train command (train action)                                               #
MPI Rank 3: 12/15/2016 08:36:13: #                                                                            #
MPI Rank 3: 12/15/2016 08:36:13: ##############################################################################
MPI Rank 3: 
MPI Rank 3: WARNING: option syncFrequencyInFrames in ModelAveragingSGD is going to be deprecated. Please use blockSizePerWorker instead
MPI Rank 3: 12/15/2016 08:36:13: 
MPI Rank 3: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161215082748.614918\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 12/15/2016 08:36:15: 
MPI Rank 3: Model has 21 nodes. Using GPU 0.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:15: Training criterion:   ce = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:15: Training 28429056 parameters in 4 out of 4 parameter tensors and 15 nodes with gradient:
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:15: 	Node 'WD0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 12/15/2016 08:36:15: 	Node 'WD1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 12/15/2016 08:36:15: 	Node 'WQ0' (LearnableParameter operation) : [288 x 49292]
MPI Rank 3: 12/15/2016 08:36:15: 	Node 'WQ1' (LearnableParameter operation) : [64 x 288]
MPI Rank 3: 
MPI Rank 3: Parallel training (4 workers) using ModelAveraging
MPI Rank 3: 12/15/2016 08:36:15: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:17: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.13-seconds latency this time; accumulated time on sync point = 0.13 seconds , average latency = 0.13 seconds
MPI Rank 3: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.07 seconds
MPI Rank 3: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.16 seconds , average latency = 0.05 seconds
MPI Rank 3: 		(model aggregation stats): 4-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.05 seconds
MPI Rank 3: 		(model aggregation stats): 5-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.04 seconds
MPI Rank 3: 		(model aggregation stats): 6-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 7-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.21 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 8-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.23 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 9-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.24 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 10-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.26 seconds , average latency = 0.03 seconds
MPI Rank 3: 12/15/2016 08:36:23:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: ce = 1.91174297 * 10240; time = 5.9429s; samplesPerSecond = 1723.1
MPI Rank 3: 		(model aggregation stats): 11-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.03 seconds
MPI Rank 3: 		(model aggregation stats): 12-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.29 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 13-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.30 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 14-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.32 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 15-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.34 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 16-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.34 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 17-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.37 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 18-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.39 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 19-th sync point was hit, introducing a 0.01-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 20-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.40 seconds , average latency = 0.02 seconds
MPI Rank 3: 12/15/2016 08:36:28:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: ce = 1.91370487 * 10240; time = 5.2681s; samplesPerSecond = 1943.8
MPI Rank 3: 		(model aggregation stats): 21-th sync point was hit, introducing a 0.03-seconds latency this time; accumulated time on sync point = 0.43 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 22-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.45 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 23-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.47 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 24-th sync point was hit, introducing a 0.02-seconds latency this time; accumulated time on sync point = 0.49 seconds , average latency = 0.02 seconds
MPI Rank 3: 		(model aggregation stats): 25-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.49 seconds , average latency = 0.02 seconds
MPI Rank 3: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Training] ce = 1.88974292 * 102399; totalSamplesSeen = 307197; learningRatePerSample = 9.9999997e-005; epochTime=13.9121s
MPI Rank 3: 12/15/2016 08:36:31: Final Results: Minibatch[1-26]: ce = 1.81846899 * 102399; perplexity = 6.16241653
MPI Rank 3: 12/15/2016 08:36:31: Finished Epoch[ 3 of 3]: [Validate] ce = 1.81846899 * 102399
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:34: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 12/15/2016 08:36:34: __COMPLETED__
