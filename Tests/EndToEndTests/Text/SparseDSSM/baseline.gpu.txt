=== Running mpiexec -n 4 /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 3 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 0 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 2 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 1 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank0
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank1
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank2
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: Build info: 
MPI Rank 0: 
MPI Rank 0: 		Built time: Mar  3 2016 16:31:40
MPI Rank 0: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 0: 		Build type: debug
MPI Rank 0: 		Math lib: acml
MPI Rank 0: 		Build Branch: thhoens/tests
MPI Rank 0: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: running on localhost at 2016/03/03 16:37:11
MPI Rank 0: command line: 
MPI Rank 0: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=$RunDir$/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=2
MPI Rank 0: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=2
MPI Rank 0: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: command: train 
MPI Rank 0: precision = float
MPI Rank 0: Using 2 CPU threads
MPI Rank 0: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: CNTKCommandTrainInfo: train : 3
MPI Rank 0: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: SGD using GPU 0.
MPI Rank 0: 
MPI Rank 0: Training criterion node(s):
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: No PreCompute nodes found, skipping PreCompute step
MPI Rank 0: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 0: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.34696770; TotalTime = 5.1160s; SamplesPerSecond = 2001.6
MPI Rank 0:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.34277306; TotalTime = 4.5393s; SamplesPerSecond = 2255.9
MPI Rank 0: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160169; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2966
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 2.5001548    Perplexity = 12.18438    
MPI Rank 0: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001548
MPI Rank 0: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.30270958; TotalTime = 4.5382s; SamplesPerSecond = 2256.4
MPI Rank 0:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.09883766; TotalTime = 16.8837s; SamplesPerSecond = 606.5
MPI Rank 0: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=24.0634
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810993    
MPI Rank 0: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 0: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.89778175; TotalTime = 4.5211s; SamplesPerSecond = 2264.9
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86335983; TotalTime = 4.5357s; SamplesPerSecond = 2257.7
MPI Rank 0: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=11.692
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050027    
MPI Rank 0: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 0: CNTKCommandTrainEnd: train
MPI Rank 0: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: Build info: 
MPI Rank 1: 
MPI Rank 1: 		Built time: Mar  3 2016 16:31:40
MPI Rank 1: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 1: 		Build type: debug
MPI Rank 1: 		Math lib: acml
MPI Rank 1: 		Build Branch: thhoens/tests
MPI Rank 1: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: running on localhost at 2016/03/03 16:37:12
MPI Rank 1: command line: 
MPI Rank 1: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=$RunDir$/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=2
MPI Rank 1: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=2
MPI Rank 1: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: command: train 
MPI Rank 1: precision = float
MPI Rank 1: Using 2 CPU threads
MPI Rank 1: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: CNTKCommandTrainInfo: train : 3
MPI Rank 1: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: SGD using GPU 0.
MPI Rank 1: 
MPI Rank 1: Training criterion node(s):
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: No PreCompute nodes found, skipping PreCompute step
MPI Rank 1: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 1: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32159615; TotalTime = 5.1161s; SamplesPerSecond = 2001.5
MPI Rank 1:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.33525505; TotalTime = 4.5393s; SamplesPerSecond = 2255.9
MPI Rank 1: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160169; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2966
MPI Rank 1: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32732925; TotalTime = 4.5394s; SamplesPerSecond = 2255.8
MPI Rank 1:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11035995; TotalTime = 16.8838s; SamplesPerSecond = 606.5
MPI Rank 1: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=24.0634
MPI Rank 1: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.92909813; TotalTime = 4.5223s; SamplesPerSecond = 2264.3
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86598778; TotalTime = 4.5356s; SamplesPerSecond = 2257.7
MPI Rank 1: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=11.692
MPI Rank 1: CNTKCommandTrainEnd: train
MPI Rank 1: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: Build info: 
MPI Rank 2: 
MPI Rank 2: 		Built time: Mar  3 2016 16:31:40
MPI Rank 2: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 2: 		Build type: debug
MPI Rank 2: 		Math lib: acml
MPI Rank 2: 		Build Branch: thhoens/tests
MPI Rank 2: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: running on localhost at 2016/03/03 16:37:12
MPI Rank 2: command line: 
MPI Rank 2: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=$RunDir$/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=2
MPI Rank 2: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=2
MPI Rank 2: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: command: train 
MPI Rank 2: precision = float
MPI Rank 2: Using 2 CPU threads
MPI Rank 2: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: CNTKCommandTrainInfo: train : 3
MPI Rank 2: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: SGD using GPU 0.
MPI Rank 2: 
MPI Rank 2: Training criterion node(s):
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: No PreCompute nodes found, skipping PreCompute step
MPI Rank 2: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 2: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32837563; TotalTime = 5.1162s; SamplesPerSecond = 2001.5
MPI Rank 2:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35655479; TotalTime = 4.5393s; SamplesPerSecond = 2255.8
MPI Rank 2: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160169; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2966
MPI Rank 2: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32893581; TotalTime = 4.5352s; SamplesPerSecond = 2257.9
MPI Rank 2:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11646938; TotalTime = 16.8838s; SamplesPerSecond = 606.5
MPI Rank 2: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=24.0634
MPI Rank 2: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95308418; TotalTime = 4.5216s; SamplesPerSecond = 2264.7
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.87902641; TotalTime = 4.5357s; SamplesPerSecond = 2257.7
MPI Rank 2: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=11.692
MPI Rank 2: CNTKCommandTrainEnd: train
MPI Rank 2: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: Build info: 
MPI Rank 3: 
MPI Rank 3: 		Built time: Mar  3 2016 16:31:40
MPI Rank 3: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 3: 		Build type: debug
MPI Rank 3: 		Math lib: acml
MPI Rank 3: 		Build Branch: thhoens/tests
MPI Rank 3: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: running on localhost at 2016/03/03 16:37:13
MPI Rank 3: command line: 
MPI Rank 3: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=$RunDir$/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=2
MPI Rank 3: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=2
MPI Rank 3: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: command: train 
MPI Rank 3: precision = float
MPI Rank 3: Using 2 CPU threads
MPI Rank 3: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: CNTKCommandTrainInfo: train : 3
MPI Rank 3: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: SGD using GPU 0.
MPI Rank 3: 
MPI Rank 3: Training criterion node(s):
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: No PreCompute nodes found, skipping PreCompute step
MPI Rank 3: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 3: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32287788; TotalTime = 5.1259s; SamplesPerSecond = 1997.7
MPI Rank 3:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35470390; TotalTime = 4.5393s; SamplesPerSecond = 2255.9
MPI Rank 3: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160169; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2966
MPI Rank 3: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.29653873; TotalTime = 4.5477s; SamplesPerSecond = 2251.7
MPI Rank 3:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11679478; TotalTime = 16.8838s; SamplesPerSecond = 606.5
MPI Rank 3: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=24.0634
MPI Rank 3: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.90347176; TotalTime = 4.5312s; SamplesPerSecond = 2259.9
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.88304176; TotalTime = 4.5357s; SamplesPerSecond = 2257.6
MPI Rank 3: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=11.692
MPI Rank 3: CNTKCommandTrainEnd: train
MPI Rank 3: __COMPLETED__
MPI Rank 3: ~MPIWrapper
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running mpiexec -n 4 /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 16:31:40
		Last modified date: Thu Mar  3 16:25:02 2016
		Build type: debug
		Math lib: acml
		Build Branch: thhoens/tests
		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
-------------------------------------------------------------------
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 0 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 1 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
mpihelper: we are cog 3 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 2 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank0
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank1
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank2
Redirecting stderr to file /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: Build info: 
MPI Rank 0: 
MPI Rank 0: 		Built time: Mar  3 2016 16:31:40
MPI Rank 0: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 0: 		Build type: debug
MPI Rank 0: 		Math lib: acml
MPI Rank 0: 		Build Branch: thhoens/tests
MPI Rank 0: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: running on localhost at 2016/03/03 16:38:10
MPI Rank 0: command line: 
MPI Rank 0: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=$RunDir$/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=2
MPI Rank 0: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=2
MPI Rank 0: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: command: train 
MPI Rank 0: precision = float
MPI Rank 0: Using 2 CPU threads
MPI Rank 0: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: CNTKCommandTrainInfo: train : 3
MPI Rank 0: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: Starting from checkpoint. Load Network From File /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: SGD using GPU 0.
MPI Rank 0: 
MPI Rank 0: Training criterion node(s):
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: No PreCompute nodes found, skipping PreCompute step
MPI Rank 0: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 0: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 0: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.92903252; TotalTime = 5.0533s; SamplesPerSecond = 2026.4
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.94077110; TotalTime = 4.5332s; SamplesPerSecond = 2258.9
MPI Rank 0: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2322
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.8982234    Perplexity = 6.6740266    
MPI Rank 0: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8982234
MPI Rank 0: CNTKCommandTrainEnd: train
MPI Rank 0: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: Build info: 
MPI Rank 1: 
MPI Rank 1: 		Built time: Mar  3 2016 16:31:40
MPI Rank 1: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 1: 		Build type: debug
MPI Rank 1: 		Math lib: acml
MPI Rank 1: 		Build Branch: thhoens/tests
MPI Rank 1: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: running on localhost at 2016/03/03 16:38:10
MPI Rank 1: command line: 
MPI Rank 1: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=$RunDir$/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=2
MPI Rank 1: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=2
MPI Rank 1: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: command: train 
MPI Rank 1: precision = float
MPI Rank 1: Using 2 CPU threads
MPI Rank 1: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: CNTKCommandTrainInfo: train : 3
MPI Rank 1: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: Starting from checkpoint. Load Network From File /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: SGD using GPU 0.
MPI Rank 1: 
MPI Rank 1: Training criterion node(s):
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: No PreCompute nodes found, skipping PreCompute step
MPI Rank 1: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 1: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 1: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95954418; TotalTime = 5.0533s; SamplesPerSecond = 2026.4
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.94722424; TotalTime = 4.5333s; SamplesPerSecond = 2258.9
MPI Rank 1: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2322
MPI Rank 1: CNTKCommandTrainEnd: train
MPI Rank 1: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: Build info: 
MPI Rank 2: 
MPI Rank 2: 		Built time: Mar  3 2016 16:31:40
MPI Rank 2: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 2: 		Build type: debug
MPI Rank 2: 		Math lib: acml
MPI Rank 2: 		Build Branch: thhoens/tests
MPI Rank 2: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: running on localhost at 2016/03/03 16:38:11
MPI Rank 2: command line: 
MPI Rank 2: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=$RunDir$/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=2
MPI Rank 2: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=2
MPI Rank 2: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: command: train 
MPI Rank 2: precision = float
MPI Rank 2: Using 2 CPU threads
MPI Rank 2: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: CNTKCommandTrainInfo: train : 3
MPI Rank 2: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: Starting from checkpoint. Load Network From File /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: SGD using GPU 0.
MPI Rank 2: 
MPI Rank 2: Training criterion node(s):
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: No PreCompute nodes found, skipping PreCompute step
MPI Rank 2: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 2: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 2: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.98175964; TotalTime = 5.0537s; SamplesPerSecond = 2026.2
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95635300; TotalTime = 4.5332s; SamplesPerSecond = 2258.9
MPI Rank 2: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2322
MPI Rank 2: CNTKCommandTrainEnd: train
MPI Rank 2: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: Build info: 
MPI Rank 3: 
MPI Rank 3: 		Built time: Mar  3 2016 16:31:40
MPI Rank 3: 		Last modified date: Thu Mar  3 16:25:02 2016
MPI Rank 3: 		Build type: debug
MPI Rank 3: 		Math lib: acml
MPI Rank 3: 		Build Branch: thhoens/tests
MPI Rank 3: 		Build SHA1: 4848f0e1b49ff50d6a1e3a0a84a1d559d5ebe76c
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: running on localhost at 2016/03/03 16:38:11
MPI Rank 3: command line: 
MPI Rank 3: /home/thhoens/cntk/build/gpu/release/bin/cntk configFile=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.cntk currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/ DeviceId=0 numCPUThreads=2 stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr 
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=$RunDir$/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=2
MPI Rank 3: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=2
MPI Rank 3: stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=/home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM//dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=2
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = /home/thhoens/cntk/Tests/EndToEndTests/Text/SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=/tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: command: train 
MPI Rank 3: precision = float
MPI Rank 3: Using 2 CPU threads
MPI Rank 3: CNTKModelPath: /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: CNTKCommandTrainInfo: train : 3
MPI Rank 3: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: Starting from checkpoint. Load Network From File /tmp/cntk-test-20160303163710.473326/Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: SGD using GPU 0.
MPI Rank 3: 
MPI Rank 3: Training criterion node(s):
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: No PreCompute nodes found, skipping PreCompute step
MPI Rank 3: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 3: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 3: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93374424; TotalTime = 5.0634s; SamplesPerSecond = 2022.4
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95965519; TotalTime = 4.5333s; SamplesPerSecond = 2258.9
MPI Rank 3: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-05; EpochTime=12.2322
MPI Rank 3: CNTKCommandTrainEnd: train
MPI Rank 3: __COMPLETED__
MPI Rank 3: ~MPIWrapper
