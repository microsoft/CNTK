=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 D:\thhoens\CNTK\x64\debug\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu DeviceId=0 timestamping=true numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 0 in a gearbox of 4
mpihelper: we are cog 2 in a gearbox of 4
mpihelper: we are cog 3 in a gearbox of 4
mpihelper: we are cog 1 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: 04/05/2016 20:20:56: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank0
MPI Rank 0: 04/05/2016 20:20:56: -------------------------------------------------------------------
MPI Rank 0: 04/05/2016 20:20:56: Build info: 
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: 		Built time: Apr  5 2016 11:43:24
MPI Rank 0: 04/05/2016 20:20:56: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 0: 04/05/2016 20:20:56: 		Build type: Debug
MPI Rank 0: 04/05/2016 20:20:56: 		Build target: GPU
MPI Rank 0: 04/05/2016 20:20:56: 		With 1bit-SGD: yes
MPI Rank 0: 04/05/2016 20:20:56: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 0: 04/05/2016 20:20:56: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 0: 04/05/2016 20:20:56: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 04/05/2016 20:20:56: 		Build Branch: thhoens/matrixmerge
MPI Rank 0: 04/05/2016 20:20:56: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 0: 04/05/2016 20:20:56: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 0: 04/05/2016 20:20:56: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 0: 04/05/2016 20:20:56: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: Running on SAADSRNRDEV040 at 2016/04/05 20:20:56
MPI Rank 0: 04/05/2016 20:20:56: Command line: 
MPI Rank 0: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/05/2016 20:20:56: modelPath=$RunDir$/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/05/2016 20:20:56: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 0: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:timestamping=true
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 04/05/2016 20:20:56: Commands: train
MPI Rank 0: 04/05/2016 20:20:56: Precision = "float"
MPI Rank 0: 04/05/2016 20:20:56: Using 10 CPU threads.
MPI Rank 0: 04/05/2016 20:20:56: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0: 04/05/2016 20:20:56: CNTKCommandTrainInfo: train : 3
MPI Rank 0: 04/05/2016 20:20:56: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: ##############################################################################
MPI Rank 0: 04/05/2016 20:20:56: #                                                                            #
MPI Rank 0: 04/05/2016 20:20:56: # Action "train"                                                             #
MPI Rank 0: 04/05/2016 20:20:56: #                                                                            #
MPI Rank 0: 04/05/2016 20:20:56: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:56: Creating virgin network.
MPI Rank 0: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	CE = CrossEntropyWithSoftmax()
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 0: 
MPI Rank 0: Validating network. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 0: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 0: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 0: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 0: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 0: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 0: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 0: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:57: Created model with 21 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:20:57: Training criterion node(s):
MPI Rank 0: 04/05/2016 20:20:57: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 04/05/2016 20:20:57: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:21:05: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:21:06: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/05/2016 20:21:17:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.34696808; TotalTime = 11.8101s; SamplesPerSecond = 867.1
MPI Rank 0: 04/05/2016 20:21:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.34277420; TotalTime = 11.4725s; SamplesPerSecond = 892.6
MPI Rank 0: 04/05/2016 20:21:35: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7377
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001548    Perplexity = 12.184379    
MPI Rank 0: 04/05/2016 20:21:36: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001548
MPI Rank 0: 04/05/2016 20:21:42: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net.1'
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:21:48: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:21:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/05/2016 20:22:00:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.30270958; TotalTime = 11.5038s; SamplesPerSecond = 890.1
MPI Rank 0: 04/05/2016 20:22:12:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.09883766; TotalTime = 11.5204s; SamplesPerSecond = 888.9
MPI Rank 0: 04/05/2016 20:22:18: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757751; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7464
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810992    
MPI Rank 0: 04/05/2016 20:22:19: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 0: 04/05/2016 20:22:25: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net.2'
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:22:30: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:22:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/05/2016 20:22:42:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.89778175; TotalTime = 11.0936s; SamplesPerSecond = 923.1
MPI Rank 0: 04/05/2016 20:22:54:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86335983; TotalTime = 11.4219s; SamplesPerSecond = 896.5
MPI Rank 0: 04/05/2016 20:22:59: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=28.7825
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050028    
MPI Rank 0: 04/05/2016 20:23:01: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 0: 04/05/2016 20:23:07: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net'
MPI Rank 0: 04/05/2016 20:23:12: CNTKCommandTrainEnd: train
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:12: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:12: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 04/05/2016 20:20:57: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank1
MPI Rank 1: 04/05/2016 20:20:57: -------------------------------------------------------------------
MPI Rank 1: 04/05/2016 20:20:57: Build info: 
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: 		Built time: Apr  5 2016 11:43:24
MPI Rank 1: 04/05/2016 20:20:57: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 1: 04/05/2016 20:20:57: 		Build type: Debug
MPI Rank 1: 04/05/2016 20:20:57: 		Build target: GPU
MPI Rank 1: 04/05/2016 20:20:57: 		With 1bit-SGD: yes
MPI Rank 1: 04/05/2016 20:20:57: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 1: 04/05/2016 20:20:57: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 1: 04/05/2016 20:20:57: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 04/05/2016 20:20:57: 		Build Branch: thhoens/matrixmerge
MPI Rank 1: 04/05/2016 20:20:57: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 1: 04/05/2016 20:20:57: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 1: 04/05/2016 20:20:57: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 1: 04/05/2016 20:20:57: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: Running on SAADSRNRDEV040 at 2016/04/05 20:20:57
MPI Rank 1: 04/05/2016 20:20:57: Command line: 
MPI Rank 1: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/05/2016 20:20:57: modelPath=$RunDir$/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/05/2016 20:20:57: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 1: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:timestamping=true
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 04/05/2016 20:20:57: Commands: train
MPI Rank 1: 04/05/2016 20:20:57: Precision = "float"
MPI Rank 1: 04/05/2016 20:20:57: Using 10 CPU threads.
MPI Rank 1: 04/05/2016 20:20:57: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1: 04/05/2016 20:20:57: CNTKCommandTrainInfo: train : 3
MPI Rank 1: 04/05/2016 20:20:57: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: ##############################################################################
MPI Rank 1: 04/05/2016 20:20:57: #                                                                            #
MPI Rank 1: 04/05/2016 20:20:57: # Action "train"                                                             #
MPI Rank 1: 04/05/2016 20:20:57: #                                                                            #
MPI Rank 1: 04/05/2016 20:20:57: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:57: Creating virgin network.
MPI Rank 1: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	CE = CrossEntropyWithSoftmax()
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 1: 
MPI Rank 1: Validating network. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 1: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 1: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 1: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 1: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 1: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 1: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 1: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:58: Created model with 21 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:20:58: Training criterion node(s):
MPI Rank 1: 04/05/2016 20:20:58: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 04/05/2016 20:20:58: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:21:05: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:21:06: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/05/2016 20:21:17:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32159615; TotalTime = 11.8069s; SamplesPerSecond = 867.3
MPI Rank 1: 04/05/2016 20:21:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.33525505; TotalTime = 11.4725s; SamplesPerSecond = 892.6
MPI Rank 1: 04/05/2016 20:21:35: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7376
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001548    Perplexity = 12.184379    
MPI Rank 1: 04/05/2016 20:21:36: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001548
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:21:48: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:21:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/05/2016 20:22:00:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32732925; TotalTime = 11.5791s; SamplesPerSecond = 884.4
MPI Rank 1: 04/05/2016 20:22:12:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11035995; TotalTime = 11.5204s; SamplesPerSecond = 888.9
MPI Rank 1: 04/05/2016 20:22:18: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757751; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7464
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810992    
MPI Rank 1: 04/05/2016 20:22:19: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:22:30: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:22:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/05/2016 20:22:42:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.92909813; TotalTime = 11.0873s; SamplesPerSecond = 923.6
MPI Rank 1: 04/05/2016 20:22:54:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86598778; TotalTime = 11.4220s; SamplesPerSecond = 896.5
MPI Rank 1: 04/05/2016 20:22:59: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=28.7825
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050028    
MPI Rank 1: 04/05/2016 20:23:01: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 1: 04/05/2016 20:23:12: CNTKCommandTrainEnd: train
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:12: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:12: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: 04/05/2016 20:20:57: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank2
MPI Rank 2: 04/05/2016 20:20:57: -------------------------------------------------------------------
MPI Rank 2: 04/05/2016 20:20:57: Build info: 
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: 		Built time: Apr  5 2016 11:43:24
MPI Rank 2: 04/05/2016 20:20:57: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 2: 04/05/2016 20:20:57: 		Build type: Debug
MPI Rank 2: 04/05/2016 20:20:57: 		Build target: GPU
MPI Rank 2: 04/05/2016 20:20:57: 		With 1bit-SGD: yes
MPI Rank 2: 04/05/2016 20:20:57: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 2: 04/05/2016 20:20:57: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 2: 04/05/2016 20:20:57: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 04/05/2016 20:20:57: 		Build Branch: thhoens/matrixmerge
MPI Rank 2: 04/05/2016 20:20:57: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 2: 04/05/2016 20:20:57: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 2: 04/05/2016 20:20:57: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 2: 04/05/2016 20:20:57: -------------------------------------------------------------------
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: Running on SAADSRNRDEV040 at 2016/04/05 20:20:57
MPI Rank 2: 04/05/2016 20:20:57: Command line: 
MPI Rank 2: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/05/2016 20:20:57: modelPath=$RunDir$/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/05/2016 20:20:57: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 2: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:timestamping=true
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 04/05/2016 20:20:57: Commands: train
MPI Rank 2: 04/05/2016 20:20:57: Precision = "float"
MPI Rank 2: 04/05/2016 20:20:57: Using 10 CPU threads.
MPI Rank 2: 04/05/2016 20:20:57: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2: 04/05/2016 20:20:57: CNTKCommandTrainInfo: train : 3
MPI Rank 2: 04/05/2016 20:20:57: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: ##############################################################################
MPI Rank 2: 04/05/2016 20:20:57: #                                                                            #
MPI Rank 2: 04/05/2016 20:20:57: # Action "train"                                                             #
MPI Rank 2: 04/05/2016 20:20:57: #                                                                            #
MPI Rank 2: 04/05/2016 20:20:57: ##############################################################################
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:57: Creating virgin network.
MPI Rank 2: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	CE = CrossEntropyWithSoftmax()
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 2: 
MPI Rank 2: Validating network. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network, final pass.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 2: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 2: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 2: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 2: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 2: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 2: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 2: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:58: Created model with 21 nodes on GPU 0.
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:20:58: Training criterion node(s):
MPI Rank 2: 04/05/2016 20:20:58: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 04/05/2016 20:20:58: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:21:05: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:21:06: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/05/2016 20:21:17:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32837563; TotalTime = 11.8147s; SamplesPerSecond = 866.7
MPI Rank 2: 04/05/2016 20:21:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35655479; TotalTime = 11.4725s; SamplesPerSecond = 892.6
MPI Rank 2: 04/05/2016 20:21:35: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7376
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001548    Perplexity = 12.184379    
MPI Rank 2: 04/05/2016 20:21:36: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001548
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:21:48: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:21:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/05/2016 20:22:00:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32893620; TotalTime = 11.5124s; SamplesPerSecond = 889.5
MPI Rank 2: 04/05/2016 20:22:12:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11646862; TotalTime = 11.5204s; SamplesPerSecond = 888.9
MPI Rank 2: 04/05/2016 20:22:18: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757751; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7464
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810992    
MPI Rank 2: 04/05/2016 20:22:19: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:22:30: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:22:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/05/2016 20:22:42:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95308418; TotalTime = 11.1187s; SamplesPerSecond = 921.0
MPI Rank 2: 04/05/2016 20:22:54:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.87902641; TotalTime = 11.4221s; SamplesPerSecond = 896.5
MPI Rank 2: 04/05/2016 20:22:59: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=28.7825
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050028    
MPI Rank 2: 04/05/2016 20:23:01: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 2: 04/05/2016 20:23:12: CNTKCommandTrainEnd: train
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:12: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:12: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: 04/05/2016 20:20:58: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank3
MPI Rank 3: 04/05/2016 20:20:58: -------------------------------------------------------------------
MPI Rank 3: 04/05/2016 20:20:58: Build info: 
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: 		Built time: Apr  5 2016 11:43:24
MPI Rank 3: 04/05/2016 20:20:58: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 3: 04/05/2016 20:20:58: 		Build type: Debug
MPI Rank 3: 04/05/2016 20:20:58: 		Build target: GPU
MPI Rank 3: 04/05/2016 20:20:58: 		With 1bit-SGD: yes
MPI Rank 3: 04/05/2016 20:20:58: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 3: 04/05/2016 20:20:58: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 3: 04/05/2016 20:20:58: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 04/05/2016 20:20:58: 		Build Branch: thhoens/matrixmerge
MPI Rank 3: 04/05/2016 20:20:58: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 3: 04/05/2016 20:20:58: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 3: 04/05/2016 20:20:58: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 3: 04/05/2016 20:20:58: -------------------------------------------------------------------
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: Running on SAADSRNRDEV040 at 2016/04/05 20:20:58
MPI Rank 3: 04/05/2016 20:20:58: Command line: 
MPI Rank 3: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/05/2016 20:20:58: modelPath=$RunDir$/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/05/2016 20:20:58: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 3: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:timestamping=true
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 04/05/2016 20:20:58: Commands: train
MPI Rank 3: 04/05/2016 20:20:58: Precision = "float"
MPI Rank 3: 04/05/2016 20:20:58: Using 10 CPU threads.
MPI Rank 3: 04/05/2016 20:20:58: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3: 04/05/2016 20:20:58: CNTKCommandTrainInfo: train : 3
MPI Rank 3: 04/05/2016 20:20:58: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: ##############################################################################
MPI Rank 3: 04/05/2016 20:20:58: #                                                                            #
MPI Rank 3: 04/05/2016 20:20:58: # Action "train"                                                             #
MPI Rank 3: 04/05/2016 20:20:58: #                                                                            #
MPI Rank 3: 04/05/2016 20:20:58: ##############################################################################
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:58: Creating virgin network.
MPI Rank 3: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	CE = CrossEntropyWithSoftmax()
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 3: 
MPI Rank 3: Validating network. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating network. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating network, final pass.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 3: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 3: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 3: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 3: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 3: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 3: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 3: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:59: Created model with 21 nodes on GPU 0.
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:20:59: Training criterion node(s):
MPI Rank 3: 04/05/2016 20:20:59: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: 04/05/2016 20:20:59: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:21:05: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:21:06: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/05/2016 20:21:17:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32287750; TotalTime = 11.7323s; SamplesPerSecond = 872.8
MPI Rank 3: 04/05/2016 20:21:29:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35470428; TotalTime = 11.4725s; SamplesPerSecond = 892.6
MPI Rank 3: 04/05/2016 20:21:35: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7376
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001548    Perplexity = 12.184379    
MPI Rank 3: 04/05/2016 20:21:36: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001548
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:21:48: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:21:48: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/05/2016 20:22:00:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.29653873; TotalTime = 11.5798s; SamplesPerSecond = 884.3
MPI Rank 3: 04/05/2016 20:22:12:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11679478; TotalTime = 11.5231s; SamplesPerSecond = 888.6
MPI Rank 3: 04/05/2016 20:22:18: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757751; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.7464
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810992    
MPI Rank 3: 04/05/2016 20:22:19: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:22:30: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:22:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/05/2016 20:22:42:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.90347176; TotalTime = 10.9264s; SamplesPerSecond = 937.2
MPI Rank 3: 04/05/2016 20:22:54:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.88304138; TotalTime = 11.4220s; SamplesPerSecond = 896.5
MPI Rank 3: 04/05/2016 20:22:59: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=28.7825
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050028    
MPI Rank 3: 04/05/2016 20:23:01: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 3: 04/05/2016 20:23:12: CNTKCommandTrainEnd: train
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:12: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:12: __COMPLETED__
MPI Rank 3: ~MPIWrapper
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 D:\thhoens\CNTK\x64\debug\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu DeviceId=0 timestamping=true numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr  5 2016 11:43:24
		Last modified date: Mon Apr  4 18:59:26 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: thhoens/matrixmerge
		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
		Built by thhoens on SAADSRNRDEV040
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 0 in a gearbox of 4
mpihelper: we are cog 2 in a gearbox of 4
mpihelper: we are cog 3 in a gearbox of 4
mpihelper: we are cog 1 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: 04/05/2016 20:23:15: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank0
MPI Rank 0: 04/05/2016 20:23:15: -------------------------------------------------------------------
MPI Rank 0: 04/05/2016 20:23:15: Build info: 
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: 		Built time: Apr  5 2016 11:43:24
MPI Rank 0: 04/05/2016 20:23:15: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 0: 04/05/2016 20:23:15: 		Build type: Debug
MPI Rank 0: 04/05/2016 20:23:15: 		Build target: GPU
MPI Rank 0: 04/05/2016 20:23:15: 		With 1bit-SGD: yes
MPI Rank 0: 04/05/2016 20:23:15: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 0: 04/05/2016 20:23:15: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 0: 04/05/2016 20:23:15: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 04/05/2016 20:23:15: 		Build Branch: thhoens/matrixmerge
MPI Rank 0: 04/05/2016 20:23:15: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 0: 04/05/2016 20:23:15: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 0: 04/05/2016 20:23:15: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 0: 04/05/2016 20:23:15: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: Running on SAADSRNRDEV040 at 2016/04/05 20:23:15
MPI Rank 0: 04/05/2016 20:23:15: Command line: 
MPI Rank 0: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/05/2016 20:23:15: modelPath=$RunDir$/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/05/2016 20:23:15: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 0: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:timestamping=true
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 04/05/2016 20:23:15: Commands: train
MPI Rank 0: 04/05/2016 20:23:15: Precision = "float"
MPI Rank 0: 04/05/2016 20:23:15: Using 10 CPU threads.
MPI Rank 0: 04/05/2016 20:23:15: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 0: 04/05/2016 20:23:15: CNTKCommandTrainInfo: train : 3
MPI Rank 0: 04/05/2016 20:23:15: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: ##############################################################################
MPI Rank 0: 04/05/2016 20:23:15: #                                                                            #
MPI Rank 0: 04/05/2016 20:23:15: # Action "train"                                                             #
MPI Rank 0: 04/05/2016 20:23:15: #                                                                            #
MPI Rank 0: 04/05/2016 20:23:15: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:15: Starting from checkpoint. Loading network from 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	CE = CrossEntropyWithSoftmax()
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 0: 
MPI Rank 0: Validating network. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 0: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 0: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 0: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 0: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 0: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 0: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 0: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:24: Loaded model with 21 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:24: Training criterion node(s):
MPI Rank 0: 04/05/2016 20:23:24: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 04/05/2016 20:23:24: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 0: 04/05/2016 20:23:24: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:26: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:23:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/05/2016 20:23:39:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.92903233; TotalTime = 12.0747s; SamplesPerSecond = 848.1
MPI Rank 0: 04/05/2016 20:23:50:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.94077091; TotalTime = 11.0735s; SamplesPerSecond = 924.7
MPI Rank 0: 04/05/2016 20:23:56: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504801; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.9667
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8982234    Perplexity = 6.6740265    
MPI Rank 0: 04/05/2016 20:23:57: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8982234
MPI Rank 0: 04/05/2016 20:24:03: SGD: Saving checkpoint model 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net'
MPI Rank 0: 04/05/2016 20:24:08: CNTKCommandTrainEnd: train
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:24:08: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 04/05/2016 20:24:08: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 04/05/2016 20:23:15: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank1
MPI Rank 1: 04/05/2016 20:23:15: -------------------------------------------------------------------
MPI Rank 1: 04/05/2016 20:23:15: Build info: 
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: 		Built time: Apr  5 2016 11:43:24
MPI Rank 1: 04/05/2016 20:23:15: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 1: 04/05/2016 20:23:15: 		Build type: Debug
MPI Rank 1: 04/05/2016 20:23:15: 		Build target: GPU
MPI Rank 1: 04/05/2016 20:23:15: 		With 1bit-SGD: yes
MPI Rank 1: 04/05/2016 20:23:15: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 1: 04/05/2016 20:23:15: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 1: 04/05/2016 20:23:15: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 04/05/2016 20:23:15: 		Build Branch: thhoens/matrixmerge
MPI Rank 1: 04/05/2016 20:23:15: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 1: 04/05/2016 20:23:15: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 1: 04/05/2016 20:23:15: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 1: 04/05/2016 20:23:15: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: Running on SAADSRNRDEV040 at 2016/04/05 20:23:15
MPI Rank 1: 04/05/2016 20:23:15: Command line: 
MPI Rank 1: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/05/2016 20:23:15: modelPath=$RunDir$/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/05/2016 20:23:15: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 1: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:timestamping=true
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 04/05/2016 20:23:15: Commands: train
MPI Rank 1: 04/05/2016 20:23:15: Precision = "float"
MPI Rank 1: 04/05/2016 20:23:15: Using 10 CPU threads.
MPI Rank 1: 04/05/2016 20:23:15: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 1: 04/05/2016 20:23:15: CNTKCommandTrainInfo: train : 3
MPI Rank 1: 04/05/2016 20:23:15: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: ##############################################################################
MPI Rank 1: 04/05/2016 20:23:15: #                                                                            #
MPI Rank 1: 04/05/2016 20:23:15: # Action "train"                                                             #
MPI Rank 1: 04/05/2016 20:23:15: #                                                                            #
MPI Rank 1: 04/05/2016 20:23:15: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:15: Starting from checkpoint. Loading network from 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	CE = CrossEntropyWithSoftmax()
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 1: 
MPI Rank 1: Validating network. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 1: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 1: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 1: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 1: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 1: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 1: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 1: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:25: Loaded model with 21 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:25: Training criterion node(s):
MPI Rank 1: 04/05/2016 20:23:25: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 04/05/2016 20:23:25: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 1: 04/05/2016 20:23:25: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:26: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:23:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/05/2016 20:23:39:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95954418; TotalTime = 12.0824s; SamplesPerSecond = 847.5
MPI Rank 1: 04/05/2016 20:23:50:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.94722385; TotalTime = 11.0734s; SamplesPerSecond = 924.7
MPI Rank 1: 04/05/2016 20:23:56: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504801; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.9669
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8982234    Perplexity = 6.6740265    
MPI Rank 1: 04/05/2016 20:23:57: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8982234
MPI Rank 1: 04/05/2016 20:24:08: CNTKCommandTrainEnd: train
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:24:08: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 04/05/2016 20:24:08: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: 04/05/2016 20:23:16: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank2
MPI Rank 2: 04/05/2016 20:23:16: -------------------------------------------------------------------
MPI Rank 2: 04/05/2016 20:23:16: Build info: 
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: 		Built time: Apr  5 2016 11:43:24
MPI Rank 2: 04/05/2016 20:23:16: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 2: 04/05/2016 20:23:16: 		Build type: Debug
MPI Rank 2: 04/05/2016 20:23:16: 		Build target: GPU
MPI Rank 2: 04/05/2016 20:23:16: 		With 1bit-SGD: yes
MPI Rank 2: 04/05/2016 20:23:16: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 2: 04/05/2016 20:23:16: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 2: 04/05/2016 20:23:16: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 04/05/2016 20:23:16: 		Build Branch: thhoens/matrixmerge
MPI Rank 2: 04/05/2016 20:23:16: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 2: 04/05/2016 20:23:16: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 2: 04/05/2016 20:23:16: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 2: 04/05/2016 20:23:16: -------------------------------------------------------------------
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: Running on SAADSRNRDEV040 at 2016/04/05 20:23:16
MPI Rank 2: 04/05/2016 20:23:16: Command line: 
MPI Rank 2: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/05/2016 20:23:16: modelPath=$RunDir$/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/05/2016 20:23:16: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 2: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:timestamping=true
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 04/05/2016 20:23:16: Commands: train
MPI Rank 2: 04/05/2016 20:23:16: Precision = "float"
MPI Rank 2: 04/05/2016 20:23:16: Using 10 CPU threads.
MPI Rank 2: 04/05/2016 20:23:16: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 2: 04/05/2016 20:23:16: CNTKCommandTrainInfo: train : 3
MPI Rank 2: 04/05/2016 20:23:16: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: ##############################################################################
MPI Rank 2: 04/05/2016 20:23:16: #                                                                            #
MPI Rank 2: 04/05/2016 20:23:16: # Action "train"                                                             #
MPI Rank 2: 04/05/2016 20:23:16: #                                                                            #
MPI Rank 2: 04/05/2016 20:23:16: ##############################################################################
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:16: Starting from checkpoint. Loading network from 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	CE = CrossEntropyWithSoftmax()
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 2: 
MPI Rank 2: Validating network. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network, final pass.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 2: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 2: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 2: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 2: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 2: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 2: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 2: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:25: Loaded model with 21 nodes on GPU 0.
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:25: Training criterion node(s):
MPI Rank 2: 04/05/2016 20:23:25: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 04/05/2016 20:23:25: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 2: 04/05/2016 20:23:25: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:26: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:23:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/05/2016 20:23:39:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.98175926; TotalTime = 12.3213s; SamplesPerSecond = 831.1
MPI Rank 2: 04/05/2016 20:23:50:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95635300; TotalTime = 11.0735s; SamplesPerSecond = 924.7
MPI Rank 2: 04/05/2016 20:23:56: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504801; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.9667
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8982234    Perplexity = 6.6740265    
MPI Rank 2: 04/05/2016 20:23:57: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8982234
MPI Rank 2: 04/05/2016 20:24:08: CNTKCommandTrainEnd: train
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:24:08: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 04/05/2016 20:24:08: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: 04/05/2016 20:23:16: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr_train.logrank3
MPI Rank 3: 04/05/2016 20:23:16: -------------------------------------------------------------------
MPI Rank 3: 04/05/2016 20:23:16: Build info: 
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: 		Built time: Apr  5 2016 11:43:24
MPI Rank 3: 04/05/2016 20:23:16: 		Last modified date: Mon Apr  4 18:59:26 2016
MPI Rank 3: 04/05/2016 20:23:16: 		Build type: Debug
MPI Rank 3: 04/05/2016 20:23:16: 		Build target: GPU
MPI Rank 3: 04/05/2016 20:23:16: 		With 1bit-SGD: yes
MPI Rank 3: 04/05/2016 20:23:16: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 3: 04/05/2016 20:23:16: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 3: 04/05/2016 20:23:16: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 04/05/2016 20:23:16: 		Build Branch: thhoens/matrixmerge
MPI Rank 3: 04/05/2016 20:23:16: 		Build SHA1: c855efaa83651f0552749fd791fbd0a214d38bf2 (modified)
MPI Rank 3: 04/05/2016 20:23:16: 		Built by thhoens on SAADSRNRDEV040
MPI Rank 3: 04/05/2016 20:23:16: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 3: 04/05/2016 20:23:16: -------------------------------------------------------------------
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: Running on SAADSRNRDEV040 at 2016/04/05 20:23:16
MPI Rank 3: 04/05/2016 20:23:16: Command line: 
MPI Rank 3: D:\thhoens\CNTK\x64\debug\cntk.exe  configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData  ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=10  stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/05/2016 20:23:16: modelPath=$RunDir$/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/05/2016 20:23:16: modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 3: configparameters: dssm.cntk:OutputDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:timestamping=true
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 04/05/2016 20:23:16: Commands: train
MPI Rank 3: 04/05/2016 20:23:16: Precision = "float"
MPI Rank 3: 04/05/2016 20:23:16: Using 10 CPU threads.
MPI Rank 3: 04/05/2016 20:23:16: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net
MPI Rank 3: 04/05/2016 20:23:16: CNTKCommandTrainInfo: train : 3
MPI Rank 3: 04/05/2016 20:23:16: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: ##############################################################################
MPI Rank 3: 04/05/2016 20:23:16: #                                                                            #
MPI Rank 3: 04/05/2016 20:23:16: # Action "train"                                                             #
MPI Rank 3: 04/05/2016 20:23:16: #                                                                            #
MPI Rank 3: 04/05/2016 20:23:16: ##############################################################################
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:16: Starting from checkpoint. Loading network from 'C:\cygwin64\tmp\cntk-test-20160405122055.860319\Text_SparseDSSM@debug_gpu/Models/dssm.net.2'.
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	CE = CrossEntropyWithSoftmax()
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 3: 
MPI Rank 3: Validating network. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating network. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating network, final pass.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 3: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 3: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 3: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 3: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 3: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 3: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 3: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:26: Loaded model with 21 nodes on GPU 0.
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:26: Training criterion node(s):
MPI Rank 3: 04/05/2016 20:23:26: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: 04/05/2016 20:23:26: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 3: 04/05/2016 20:23:26: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:26: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:23:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/05/2016 20:23:39:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93374424; TotalTime = 12.1359s; SamplesPerSecond = 843.8
MPI Rank 3: 04/05/2016 20:23:50:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95965519; TotalTime = 11.0735s; SamplesPerSecond = 924.7
MPI Rank 3: 04/05/2016 20:23:56: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504801; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=29.9669
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8982234    Perplexity = 6.6740265    
MPI Rank 3: 04/05/2016 20:23:57: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8982234
MPI Rank 3: 04/05/2016 20:24:08: CNTKCommandTrainEnd: train
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:24:08: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 04/05/2016 20:24:08: __COMPLETED__
MPI Rank 3: ~MPIWrapper
