=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 3 in a gearbox of 4
mpihelper: we are cog 1 in a gearbox of 4
mpihelper: we are cog 0 in a gearbox of 4
mpihelper: we are cog 2 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank0
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: Build info: 
MPI Rank 0: 
MPI Rank 0: 		Built time: Mar  3 2016 14:41:54
MPI Rank 0: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 0: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 0: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 0: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 		Build Branch: HEAD
MPI Rank 0: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 0: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 0: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: running on SAADSRNRDEV040 at 2016/03/03 23:47:11
MPI Rank 0: command line: 
MPI Rank 0: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=$RunDir$/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: command: train 
MPI Rank 0: precision = float
MPI Rank 0: Using 10 CPU threads
MPI Rank 0: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: CNTKCommandTrainInfo: train : 3
MPI Rank 0: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: SGD using GPU 0.
MPI Rank 0: 
MPI Rank 0: Training criterion node(s):
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: No PreCompute nodes found, skipping PreCompute step
MPI Rank 0: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 0: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.34696808; TotalTime = 9.4644s; SamplesPerSecond = 1081.9
MPI Rank 0:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.34277420; TotalTime = 7.3300s; SamplesPerSecond = 1397.0
MPI Rank 0: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=21.7436
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 2.5001547    Perplexity = 12.184379    
MPI Rank 0: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001547
MPI Rank 0: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.30270958; TotalTime = 8.1645s; SamplesPerSecond = 1254.2
MPI Rank 0:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.09883804; TotalTime = 7.8825s; SamplesPerSecond = 1299.1
MPI Rank 0: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.4866
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810993    
MPI Rank 0: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 0: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.89778175; TotalTime = 8.3942s; SamplesPerSecond = 1219.9
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86335983; TotalTime = 8.0798s; SamplesPerSecond = 1267.4
MPI Rank 0: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.8703
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050028    
MPI Rank 0: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 0: CNTKCommandTrainEnd: train
MPI Rank 0: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank1
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: Build info: 
MPI Rank 1: 
MPI Rank 1: 		Built time: Mar  3 2016 14:41:54
MPI Rank 1: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 1: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 1: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 1: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 		Build Branch: HEAD
MPI Rank 1: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 1: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 1: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: running on SAADSRNRDEV040 at 2016/03/03 23:47:11
MPI Rank 1: command line: 
MPI Rank 1: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=$RunDir$/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: command: train 
MPI Rank 1: precision = float
MPI Rank 1: Using 10 CPU threads
MPI Rank 1: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: CNTKCommandTrainInfo: train : 3
MPI Rank 1: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: SGD using GPU 0.
MPI Rank 1: 
MPI Rank 1: Training criterion node(s):
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: No PreCompute nodes found, skipping PreCompute step
MPI Rank 1: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 1: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32159615; TotalTime = 9.4668s; SamplesPerSecond = 1081.7
MPI Rank 1:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.33525505; TotalTime = 7.3300s; SamplesPerSecond = 1397.0
MPI Rank 1: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=21.7436
MPI Rank 1: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32732925; TotalTime = 8.1731s; SamplesPerSecond = 1252.9
MPI Rank 1:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11035995; TotalTime = 7.8825s; SamplesPerSecond = 1299.1
MPI Rank 1: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.4866
MPI Rank 1: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.92909813; TotalTime = 8.4392s; SamplesPerSecond = 1213.4
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86598778; TotalTime = 8.0798s; SamplesPerSecond = 1267.4
MPI Rank 1: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.8703
MPI Rank 1: CNTKCommandTrainEnd: train
MPI Rank 1: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank2
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: Build info: 
MPI Rank 2: 
MPI Rank 2: 		Built time: Mar  3 2016 14:41:54
MPI Rank 2: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 2: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 2: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 2: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 		Build Branch: HEAD
MPI Rank 2: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 2: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 2: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: running on SAADSRNRDEV040 at 2016/03/03 23:47:12
MPI Rank 2: command line: 
MPI Rank 2: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=$RunDir$/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: command: train 
MPI Rank 2: precision = float
MPI Rank 2: Using 10 CPU threads
MPI Rank 2: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: CNTKCommandTrainInfo: train : 3
MPI Rank 2: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: SGD using GPU 0.
MPI Rank 2: 
MPI Rank 2: Training criterion node(s):
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: No PreCompute nodes found, skipping PreCompute step
MPI Rank 2: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 2: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32837563; TotalTime = 9.4674s; SamplesPerSecond = 1081.6
MPI Rank 2:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35655479; TotalTime = 7.3300s; SamplesPerSecond = 1397.0
MPI Rank 2: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=21.7436
MPI Rank 2: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32893581; TotalTime = 8.1756s; SamplesPerSecond = 1252.5
MPI Rank 2:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11646900; TotalTime = 7.8825s; SamplesPerSecond = 1299.1
MPI Rank 2: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.4866
MPI Rank 2: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95308418; TotalTime = 8.4366s; SamplesPerSecond = 1213.8
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.87902641; TotalTime = 8.0798s; SamplesPerSecond = 1267.4
MPI Rank 2: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.8703
MPI Rank 2: CNTKCommandTrainEnd: train
MPI Rank 2: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: Build info: 
MPI Rank 3: 
MPI Rank 3: 		Built time: Mar  3 2016 14:41:54
MPI Rank 3: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 3: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 3: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 3: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 		Build Branch: HEAD
MPI Rank 3: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 3: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 3: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: running on SAADSRNRDEV040 at 2016/03/03 23:47:12
MPI Rank 3: command line: 
MPI Rank 3: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=$RunDir$/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: command: train 
MPI Rank 3: precision = float
MPI Rank 3: Using 10 CPU threads
MPI Rank 3: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: CNTKCommandTrainInfo: train : 3
MPI Rank 3: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: SGD using GPU 0.
MPI Rank 3: 
MPI Rank 3: Training criterion node(s):
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: No PreCompute nodes found, skipping PreCompute step
MPI Rank 3: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 3: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32287788; TotalTime = 9.4867s; SamplesPerSecond = 1079.4
MPI Rank 3:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35470390; TotalTime = 7.3300s; SamplesPerSecond = 1397.0
MPI Rank 3: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=21.7436
MPI Rank 3: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.29653873; TotalTime = 8.1958s; SamplesPerSecond = 1249.4
MPI Rank 3:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11679478; TotalTime = 7.8817s; SamplesPerSecond = 1299.2
MPI Rank 3: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757753; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.4866
MPI Rank 3: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.90347176; TotalTime = 8.4605s; SamplesPerSecond = 1210.3
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.88304138; TotalTime = 8.0823s; SamplesPerSecond = 1267.0
MPI Rank 3: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=20.8703
MPI Rank 3: CNTKCommandTrainEnd: train
MPI Rank 3: __COMPLETED__
MPI Rank 3: ~MPIWrapper
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Mar  3 2016 14:41:54
		Last modified date: Thu Mar  3 14:28:26 2016
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
		Built by thhoens on SAADSRNRDEV040           
		Build Path: D:\thhoens\CNTK\Source\CNTK\
-------------------------------------------------------------------
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 2 in a gearbox of 4
mpihelper: we are cog 1 in a gearbox of 4
mpihelper: we are cog 0 in a gearbox of 4
mpihelper: we are cog 3 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank0
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: Build info: 
MPI Rank 0: 
MPI Rank 0: 		Built time: Mar  3 2016 14:41:54
MPI Rank 0: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 0: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 0: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 0: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 		Build Branch: HEAD
MPI Rank 0: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 0: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 0: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 0: -------------------------------------------------------------------
MPI Rank 0: running on SAADSRNRDEV040 at 2016/03/03 23:48:38
MPI Rank 0: command line: 
MPI Rank 0: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=$RunDir$/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: DeviceId=0
MPI Rank 0: numCPUThreads=10
MPI Rank 0: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: command: train 
MPI Rank 0: precision = float
MPI Rank 0: Using 10 CPU threads
MPI Rank 0: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 0: CNTKCommandTrainInfo: train : 3
MPI Rank 0: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 0: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: Validating for node CE, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 0: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: Validating for node SIM, final verification.
MPI Rank 0: 
MPI Rank 0: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 0: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 0: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 0: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 0: 
MPI Rank 0: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: SGD using GPU 0.
MPI Rank 0: 
MPI Rank 0: Training criterion node(s):
MPI Rank 0: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: No PreCompute nodes found, skipping PreCompute step
MPI Rank 0: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 0: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 0: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.92903252; TotalTime = 9.3380s; SamplesPerSecond = 1096.6
MPI Rank 0:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.94077148; TotalTime = 8.1200s; SamplesPerSecond = 1261.1
MPI Rank 0: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=22.0648
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: Final Results: Minibatch[1-25]: Samples Seen = 102399    CE: CrossEntropyWithSoftmax/Sample = 1.8982234    Perplexity = 6.6740265    
MPI Rank 0: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8982234
MPI Rank 0: CNTKCommandTrainEnd: train
MPI Rank 0: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank1
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: Build info: 
MPI Rank 1: 
MPI Rank 1: 		Built time: Mar  3 2016 14:41:54
MPI Rank 1: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 1: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 1: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 1: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 		Build Branch: HEAD
MPI Rank 1: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 1: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 1: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 1: -------------------------------------------------------------------
MPI Rank 1: running on SAADSRNRDEV040 at 2016/03/03 23:48:38
MPI Rank 1: command line: 
MPI Rank 1: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=$RunDir$/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: DeviceId=0
MPI Rank 1: numCPUThreads=10
MPI Rank 1: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: command: train 
MPI Rank 1: precision = float
MPI Rank 1: Using 10 CPU threads
MPI Rank 1: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 1: CNTKCommandTrainInfo: train : 3
MPI Rank 1: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 1: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: Validating for node CE, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 1: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: Validating for node SIM, final verification.
MPI Rank 1: 
MPI Rank 1: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 1: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 1: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 1: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 1: 
MPI Rank 1: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: SGD using GPU 0.
MPI Rank 1: 
MPI Rank 1: Training criterion node(s):
MPI Rank 1: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: No PreCompute nodes found, skipping PreCompute step
MPI Rank 1: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 1: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 1: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95954418; TotalTime = 9.3550s; SamplesPerSecond = 1094.6
MPI Rank 1:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.94722424; TotalTime = 8.1200s; SamplesPerSecond = 1261.1
MPI Rank 1: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=22.065
MPI Rank 1: CNTKCommandTrainEnd: train
MPI Rank 1: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank2
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: Build info: 
MPI Rank 2: 
MPI Rank 2: 		Built time: Mar  3 2016 14:41:54
MPI Rank 2: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 2: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 2: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 2: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 		Build Branch: HEAD
MPI Rank 2: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 2: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 2: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 2: -------------------------------------------------------------------
MPI Rank 2: running on SAADSRNRDEV040 at 2016/03/03 23:48:39
MPI Rank 2: command line: 
MPI Rank 2: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=$RunDir$/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: DeviceId=0
MPI Rank 2: numCPUThreads=10
MPI Rank 2: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: command: train 
MPI Rank 2: precision = float
MPI Rank 2: Using 10 CPU threads
MPI Rank 2: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 2: CNTKCommandTrainInfo: train : 3
MPI Rank 2: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 2: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: Validating for node CE, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 2: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: Validating for node SIM, final verification.
MPI Rank 2: 
MPI Rank 2: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 2: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 2: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 2: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 2: 
MPI Rank 2: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: SGD using GPU 0.
MPI Rank 2: 
MPI Rank 2: Training criterion node(s):
MPI Rank 2: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: No PreCompute nodes found, skipping PreCompute step
MPI Rank 2: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 2: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 2: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.98175926; TotalTime = 8.9122s; SamplesPerSecond = 1149.0
MPI Rank 2:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95635300; TotalTime = 8.1200s; SamplesPerSecond = 1261.1
MPI Rank 2: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=22.0648
MPI Rank 2: CNTKCommandTrainEnd: train
MPI Rank 2: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: Redirecting stderr to file C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: Build info: 
MPI Rank 3: 
MPI Rank 3: 		Built time: Mar  3 2016 14:41:54
MPI Rank 3: 		Last modified date: Thu Mar  3 14:28:26 2016
MPI Rank 3: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 3: 		CUB_PATH: D:\thhoens\cub-1.4.1\cub-1.4.1
MPI Rank 3: 		CUDNN_PATH: C:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 		Build Branch: HEAD
MPI Rank 3: 		Build SHA1: 31a164602c629d10741761443e6e46b2ab787ad5
MPI Rank 3: 		Built by thhoens on SAADSRNRDEV040           
MPI Rank 3: 		Build Path: D:\thhoens\CNTK\Source\CNTK\
MPI Rank 3: -------------------------------------------------------------------
MPI Rank 3: running on SAADSRNRDEV040 at 2016/03/03 23:48:39
MPI Rank 3: command line: 
MPI Rank 3: D:\thhoens\CNTK\x64\release\cntk.exe configFile=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM DeviceId=0 numCPUThreads=10 stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr 
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=$RunDir$/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: DeviceId=0
MPI Rank 3: numCPUThreads=10
MPI Rank 3: stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=10
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = D:\thhoens\CNTK\Tests\EndToEndTests\Text\SparseDSSM/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: command: train 
MPI Rank 3: precision = float
MPI Rank 3: Using 10 CPU threads
MPI Rank 3: CNTKModelPath: C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net
MPI Rank 3: CNTKCommandTrainInfo: train : 3
MPI Rank 3: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: Starting from checkpoint. Load Network From File C:\cygwin64\tmp\cntk-test-20160303154710.317558\Text_SparseDSSM@release_gpu/models/dssm.net.2.
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for SIM CosDistanceWithNegativeSamples operation
MPI Rank 3: FormNestedNetwork: WARNING: Was called twice for CE CrossEntropyWithSoftmax operation
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 17 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM. 9 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: Validating for node SIM, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: 
MPI Rank 3: 6 out of 17 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: Validating for node CE, final verification.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue -> [51 [51 x 1], MBSize 0]
MPI Rank 3: Validating --> G = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Query = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q = Times(WQ0[288, 49292], Query[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh(WQ0_Q[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q = Times(WQ1[64, 288], WQ0_Q_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh(WQ1_Q[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1 = LearnableParameter -> [64 [64], 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter -> [288 [288], 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue -> [49292 [49292], MBSize 0]
MPI Rank 3: Validating --> WD0_D = Times(WD0[288, 49292], Keyword[49292, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh(WD0_D[288, MBSize 0]) -> [288 [288], MBSize 0]
MPI Rank 3: Validating --> WD1_D = Times(WD1[64, 288], WD0_D_Tanh[288, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh(WD1_D[64, MBSize 0]) -> [64 [64], MBSize 0]
MPI Rank 3: Validating --> S = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> N = LearnableParameter -> [1 [1], 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples(WQ1_Q_Tanh[64, MBSize 0], WD1_D_Tanh[64, MBSize 0], S[1, 1], N[1, 1]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes(G[1, 1], SIM[51, MBSize 0]) -> [51 [51], MBSize 0]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax(DSSMLabel[51 [51 x 1], MBSize 0], SIM_Scale[51, MBSize 0]) -> [1 [1], 1]
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: SGD using GPU 0.
MPI Rank 3: 
MPI Rank 3: Training criterion node(s):
MPI Rank 3: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: No PreCompute nodes found, skipping PreCompute step
MPI Rank 3: Warning: checkpoint file is missing. learning parameters will be initialized from 0
MPI Rank 3: Set Max Temp Mem Size For Convolution Nodes to 0 samples.
MPI Rank 3: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93374424; TotalTime = 9.3941s; SamplesPerSecond = 1090.0
MPI Rank 3:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95965519; TotalTime = 8.1200s; SamplesPerSecond = 1261.1
MPI Rank 3: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.9504802; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=22.065
MPI Rank 3: CNTKCommandTrainEnd: train
MPI Rank 3: __COMPLETED__
MPI Rank 3: ~MPIWrapper
