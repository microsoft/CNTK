% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layers-layers.R
\name{Dense}
\alias{Dense}
\title{Dense}
\usage{
Dense(shape, activation = activation_identity, init = init_glorot_uniform(),
  input_rank = NULL, map_rank = NULL, bias = TRUE, init_bias = 0,
  name = "")
}
\arguments{
\item{name}{string for the name of the function instance in the network}
}
\description{
Layer factory function to create an instance of a fully-connected linear
layer of the form activation(input @ W + b) with weights W and bias b, and
activation and b being optional. shape may describe a tensor as well.
}
\details{
A Dense layer instance owns its parameter tensors W and b, and exposes them
as attributes .W and .b.

The Dense layer can be applied to inputs that are tensors, not just vectors.
This is useful, e.g., at the top of a image-processing cascade, where after
many convolutions with padding and strides it is difficult to know the
precise dimensions. For this case, CNTK has an extended definition of matrix
product, in which the input tensor will be treated as if it had been
automatically flattened. The weight matrix will be a tensor that reflects
the “flattened” dimensions in its axes.

This behavior can be modified by telling CNTK either the number of axes that
should not be projected (map_rank) or the rank of the input (input_rank). If
neither is specified, all input dimensions are projected, as in the example
above.
}
