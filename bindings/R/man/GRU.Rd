% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layers-blocks.R
\name{GRU}
\alias{GRU}
\title{GRU}
\usage{
GRU(shape, cell_shape = NULL, activation = op_tanh,
  init = init_glorot_uniform(), init_bias = 0,
  enable_self_stabilization = FALSE, name = "")
}
\arguments{
\item{shape}{- list of ints representing tensor shape}

\item{activation}{(Function) - optional activation Function}

\item{init}{(scalar or matrix or initializer, defaults to init_glorot_uniform()) – initial value of weights W}

\item{name}{string (optional) the name of the Function instance in the network}

\item{init}{(scalar or matrix or initializer, defaults to init_glorot_uniform()) – initial value of weights W_bias}
}
\description{
Layer factory function to create a GRU block for use inside a recurrence.
The GRU block implements one step of the recurrence and is stateless. It
accepts the previous state as its first argument, and outputs its new state.
}
