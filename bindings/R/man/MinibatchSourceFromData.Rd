% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/io.R
\name{MinibatchSourceFromData}
\alias{MinibatchSourceFromData}
\title{MinibatchSourceFromData}
\usage{
MinibatchSourceFromData(data_streams, max_samples = IO_INFINITELY_REPEAT)
}
\arguments{
\item{data_streams}{data streams}

\item{max_samples}{max samples}
}
\description{
This wraps in-memory data as a CNTK MinibatchSource object (aka “reader”),
used to feed the data into a TrainingSession.
}
\details{
Use this if your data is small enough to be loaded into RAM in its entirety,
and the data is already sufficiently randomized.

While CNTK allows user code to iterate through minibatches by itself and
feed data minibatch by minibatch through `train_minibatch()`, the standard
way is to iterate through data using a MinibatchSource object. For example,
the high-level TrainingSession interface, which manages a full training
including checkpointing and cross validation, operates on this level.

A MinibatchSource created as a MinibatchSourceFromData linearly iterates
through the data provided by the caller as numpy arrays or
scipy.sparse.csr_matrix objects, without randomization. The data is not
copied, so if you want to modify the data while being read through a
MinibatchSourceFromData, please pass a copy.
}
\seealso{
\code{get_minibatch_checkpoint_state} \code{next_minibatch} \code{restore_mb_from_checkpoint} \code{mb_stream_infos}
}
