<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>CIFAR-10 Image Classification with Convolutional Neural Networks and CNTK • cntk</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">cntk</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/cifar10_example.html">CIFAR-10 Image Classification with Convolutional Neural Networks and CNTK</a>
    </li>
    <li>
      <a href="../articles/installation.html">Installing CNTK and the CNTK Package on Your System</a>
    </li>
    <li>
      <a href="../articles/mnist_example.html">Convolutional Neural Netowrks with MNIST</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/Microsoft/CNTK">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>CIFAR-10 Image Classification with Convolutional Neural Networks and CNTK</h1>
            
            <h4 class="date">2017-07-21</h4>
          </div>

    
    
<div class="contents">
<div id="goals-and-overview" class="section level2">
<h2 class="hasAnchor">
<a href="#goals-and-overview" class="anchor"></a>Goals and Overview</h2>
<p>In this vignette, we will describe the core functionality of the CNTK framework, and how to use it’s R bindings to ingest data, train a model, and evaluate it on a test set. We will train our model using the CIFAR-10 dataset, developed by Alex Krizhevsky while a student at the University of Toronto, and available for download online <a href="https://www.cs.toronto.edu/~kriz/cifar.html">here</a>. A sample of each class is shown in the image below:</p>
<p><img src="https://cntk.ai/jup/201/cifar-10.png" alt="Drawing" style="width: 500px;"></p>
</div>
<div id="load-cntk-environment" class="section level2">
<h2 class="hasAnchor">
<a href="#load-cntk-environment" class="anchor"></a>Load CNTK Environment</h2>
<p>Before loading the CNTK package, ensure that your <code>RETICULATE_PYTHON</code> environment variable is pointing to your Python environment containing CNTK:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Sys.setenv</span>(<span class="dt">RETICULATE_PYTHON =</span> <span class="st">"/home/alizaidi/anaconda3/envs/cntk-py35/bin/python"</span>)
<span class="kw">library</span>(reticulate)
<span class="kw">library</span>(cntk)
<span class="kw">library</span>(magrittr)
<span class="kw">py_module_available</span>(<span class="st">"cntk"</span>)
[<span class="dv">1</span>] <span class="ot">TRUE</span></code></pre></div>
</div>
<div id="feeding-data-to-cntk" class="section level2">
<h2 class="hasAnchor">
<a href="#feeding-data-to-cntk" class="anchor"></a>Feeding Data to CNTK</h2>
<p>One of the crucial components in effectively training neural network models is the ability to feed data efficiently. Ideally, data would be fed into the neural network optimizer in mini-batches, <a href="https://arxiv.org/abs/1502.03167">normalized</a> and within sizes that accomdate as much parallelism as possible while minimizing network and I/O latency.</p>
<p>CNTK is equipped with an extensible API to read in data from data sources and passed on to training objects and optimization routines as efficiently as possible, even when working with distributed data sources and multiple GPUs/devices. When working with data that is small enough to fit in memory, users can pass <code>Numpy/SciPy</code> arrays/CSR matrices directly to CNTK. When working with R, users can also pass R arrays and matrices to CNTK, but that will incur an additional performance penalty due differences in the underlying data structures of <code>Numpy</code> objects and R arrays.</p>
<p>The preferred method, especially when working with data that is larger than the client’s memory (in this case, the R process), is to use the built-in <code>MinibatchSource</code> class in CNTK. This class has pre-built methods for reading in data with a multitude of highly useful parameters for configuring mini-batch ingestion of data in neural network architectures.</p>
<p>In this example, we will look at the CNTK <code>CTFDeserializer</code> function for reading in data using the <strong>CNTK text format (CTF)</strong>, which is an efficient format for storing data for CNTK.</p>
<p>First you should download the CIFAR-10 dataset. In this vignette, we will download the data to a location in the <em>Examples/Image/DataSets/CIFAR-10</em> directory. This directory ships with the CNTK package, and includes a convenient Python script for downloading the CIFAR-10 data.</p>
<p>To execute the script, follow the instructions <a href="https://github.com/Microsoft/CNTK/tree/master/Examples/Image/DataSets/CIFAR-10">here</a>.</p>
<p>If you examine the data directory, you’ll see there are a few data files now populated. In particular, there is a file called <code>Train_cntk_text.txt</code> and <code>Test_cntk_text.txt</code>. If you peek at the format of these files, you’ll see that they are stored in a dense string format:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">alizaidi@azvm</span>:CNTK/Examples/Image/DataSets/CIFAR-10$ head Train_cntk_text.txt -n 1
<span class="kw">|</span><span class="ex">labels</span> 0 0 0 0 0 0 1 0 0 0 <span class="kw">|</span><span class="ex">features</span> 59 43 50 68 98 119 139 145 149 149 131 125 142 144 137 129 137 134 124 139 139 133 136 139 152 163 168 159 158 158 152 148 16 0 18 51 88 120 128 127 126 116 106 101 105 113 109 112 119 109 105 125 127 122 131 124 121 131 132 133 133 1 (omitted)<span class="ex">...</span></code></pre></div>
<p>The data is represented in a long string, with the labels represented using a one-hot representation and the features as a long string of pixel values of the image.</p>
</div>
<div id="define-minibatch-reader-functions" class="section level2">
<h2 class="hasAnchor">
<a href="#define-minibatch-reader-functions" class="anchor"></a>Define Minibatch Reader Functions</h2>
<p>Our first step is to define a function for reading in minibatches. We will define a function named <code>create_reader</code> which will be our entry point into the text dataset for training and evaluation. The function relies on CNTK’s text-format-reader, <code>CTFDeserializer</code> to read in the text data you imported earlier. The <code>CTFDeserializer</code> function takes two arguments, first argument is the path of the data you want to import, and the second is a dictionary mapping stream names to <code>StreamDef</code> objects. In our case, the stream names are the <code>features</code> and <code>labels</code> respectively. For training, we have the ability to make multiple random passes through our data, which can greatly improve training performance, while for evaluation we will make a single deterministic pass-through.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">create_reader &lt;-<span class="st"> </span><span class="cf">function</span>(path, is_training, input_dim, label_dim) {
    <span class="kw"><a href="../reference/MinibatchSource.html">MinibatchSource</a></span>(<span class="kw"><a href="../reference/CTFDeserializer.html">CTFDeserializer</a></span>(path, <span class="kw"><a href="../reference/StreamDefs.html">StreamDefs</a></span>(
        <span class="dt">features =</span> <span class="kw"><a href="../reference/StreamDef.html">StreamDef</a></span>(<span class="dt">field =</span> <span class="st">"features"</span>, <span class="dt">shape =</span> input_dim),
        <span class="dt">labels =</span> <span class="kw"><a href="../reference/StreamDef.html">StreamDef</a></span>(<span class="dt">field =</span> <span class="st">"labels"</span>, <span class="dt">shape =</span> label_dim)
    )), <span class="dt">randomize =</span> is_training, <span class="dt">max_sweeps =</span> <span class="kw">ifelse</span>(is_training, IO_INFINITELY_REPEAT, <span class="dv">1</span>))
}</code></pre></div>
</div>
<div id="defining-the-network-architecture" class="section level2">
<h2 class="hasAnchor">
<a href="#defining-the-network-architecture" class="anchor"></a>Defining the Network Architecture</h2>
<p>Now that we have our function to feed data into our network, let’s define the parameters of our network architecture. The reader function itself needs the path to the data, <code>input</code> features dimension and <code>output</code> labels dimensions, but we also need to define training parameters such as epoch size and minibatch size. The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class, so we can define the <code>input_dim</code> by multiplying the pixel rate by the number of channels (three).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ensure the path leads to the data where you have saved the CIFAR-10 images</span>
data_path &lt;-<span class="st"> </span><span class="kw">file.path</span>(<span class="st">"../../../"</span>,
                       <span class="st">"Examples"</span>, <span class="st">"Image"</span>, <span class="st">"DataSets"</span>, <span class="st">"CIFAR-10"</span>)
<span class="cf">if</span> (<span class="op">!</span>(<span class="kw">file.exists</span>(data_path))) <span class="kw">message</span>(<span class="st">"Ensure your data_path is correct!"</span>)</code></pre></div>
<pre><code>## Ensure your data_path is correct!</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">epoch_size &lt;-<span class="st"> </span><span class="dv">50000</span>
minibatch_size &lt;-<span class="st"> </span><span class="dv">64</span>
max_epochs &lt;-<span class="st"> </span><span class="dv">30</span>
image_height &lt;-<span class="st"> </span><span class="dv">32</span>
image_width &lt;-<span class="st"> </span><span class="dv">32</span>
num_channels &lt;-<span class="st"> </span><span class="dv">3</span>
input_dim &lt;-<span class="st"> </span>image_height <span class="op">*</span><span class="st"> </span>image_width <span class="op">*</span><span class="st"> </span>num_channels
num_output_classes &lt;-<span class="st"> </span><span class="dv">10</span></code></pre></div>
<p>Next, we define the input variables denoting the features and label data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">input_var &lt;-<span class="st"> </span><span class="kw"><a href="../reference/op_input_variable.html">op_input_variable</a></span>(<span class="kw">c</span>(num_channels, image_height, image_width), 
                               <span class="dt">name =</span> <span class="st">"input"</span>)
label_var &lt;-<span class="st"> </span><span class="kw"><a href="../reference/op_input_variable.html">op_input_variable</a></span>(num_output_classes, 
                               <span class="dt">name =</span> <span class="st">"label"</span>)</code></pre></div>
<p>We will also normalize the input variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">input_remove_mean &lt;-<span class="st"> </span><span class="kw">op_minus</span>(input_var, <span class="kw">op_constant</span>(<span class="dv">128</span>))
normalized_input &lt;-<span class="st"> </span><span class="kw">op_element_times</span>(<span class="kw">op_constant</span>(<span class="fl">0.00390625</span>), input_remove_mean)</code></pre></div>
<p>Now we are ready to define our network architecture. The functions we use are all part of the CNTK <a href="https://www.cntk.ai/pythondocs/layerref.html">Layers</a> library. Please refer to those Python docs for a complete reference about these functions.</p>
<p>In our case, we are going to define a convolutional neural network with four convolutional layers and two max-pooling layers.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw"><a href="../reference/Sequential.html">Sequential</a></span>(
    <span class="kw">For</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="cf">function</span>() { 
        <span class="kw">c</span>(
            <span class="kw"><a href="../reference/Convolution2D.html">Convolution2D</a></span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">64</span>, op_relu, <span class="dt">pad =</span> <span class="ot">TRUE</span>),
            <span class="kw"><a href="../reference/Convolution2D.html">Convolution2D</a></span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">64</span>, op_relu, <span class="dt">pad =</span> <span class="ot">TRUE</span>),
            <span class="kw"><a href="../reference/MaxPooling.html">MaxPooling</a></span>(<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">pad =</span> <span class="ot">TRUE</span>)
        )
    }),
    <span class="kw"><a href="../reference/Dense.html">Dense</a></span>(<span class="dv">256</span>, op_relu),
    <span class="kw"><a href="../reference/Dropout.html">Dropout</a></span>(<span class="fl">0.5</span>),
    <span class="kw"><a href="../reference/Dense.html">Dense</a></span>(<span class="dv">128</span>, op_relu),
    <span class="kw"><a href="../reference/Dropout.html">Dropout</a></span>(<span class="fl">0.5</span>),
    <span class="kw"><a href="../reference/Dense.html">Dense</a></span>(num_output_classes, <span class="dt">activation =</span> <span class="ot">NULL</span>)
)(normalized_input)</code></pre></div>
<div id="visualize-network" class="section level3">
<h3 class="hasAnchor">
<a href="#visualize-network" class="anchor"></a>Visualize Network</h3>
<p>We can visualize this network using the SVG display:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/visualize_network.html">visualize_network</a></span>(z)</code></pre></div>
<p><img src="cifar10_example_files/figure-html/unnamed-chunk-7-1.png" width="672"></p>
</div>
</div>
<div id="training" class="section level2">
<h2 class="hasAnchor">
<a href="#training" class="anchor"></a>Training</h2>
<p>Now we are ready to train our network. To do so, we first define the loss function. As is typical for image classification tasks, we will use a cross-entropy softmax loss function, and our evaluation metric will be the classification error.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loss &lt;-<span class="st"> </span><span class="kw"><a href="../reference/loss_cross_entropy_with_softmax.html">loss_cross_entropy_with_softmax</a></span>(z, label_var)
metric &lt;-<span class="st"> </span><span class="kw"><a href="../reference/classification_error.html">classification_error</a></span>(z, label_var)</code></pre></div>
<p>We will create a pointer to our training dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reader_train &lt;-<span class="st"> </span><span class="kw">create_reader</span>(<span class="kw">file.path</span>(data_path, <span class="st">'Train_cntk_text.txt'</span>), 
                              <span class="ot">TRUE</span>, input_dim, num_output_classes)</code></pre></div>
<p>For optimization, we will use the minibatch SGD with momentum, for which we’ll define a learning rate and momentum schedules. We’ll also add <span class="math inline">\(\ell_1\)</span> and <span class="math inline">\(\ell_2\)</span> regularization penalty on each minibatch sample to increase regularization.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lr_per_sample &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="fl">0.0015625</span>), <span class="dv">10</span>), <span class="kw">rep</span>(<span class="kw">c</span>(<span class="fl">0.00046875</span>), <span class="dv">10</span>), <span class="fl">0.00015625</span>)
lr_schedule &lt;-<span class="st"> </span><span class="kw">learning_rate_schedule</span>(<span class="fl">0.001</span>, <span class="kw">UnitType</span>(<span class="st">'sample'</span>), epoch_size)
mm_time_constant &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">20</span>), <span class="op">-</span>minibatch_size <span class="op">/</span><span class="st"> </span><span class="kw">log</span>(<span class="fl">0.9</span>))
mm_schedule &lt;-<span class="st"> </span><span class="kw">momentum_as_time_constant_schedule</span>(mm_time_constant, epoch_size)
l2_reg_weight &lt;-<span class="st"> </span><span class="fl">0.002</span></code></pre></div>
<p>We can now define our training algorithm:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">learner &lt;-<span class="st"> </span><span class="kw"><a href="../reference/learner_momentum_sgd.html">learner_momentum_sgd</a></span>(z<span class="op">$</span>parameters, lr_schedule, mm_schedule,
                                <span class="dt">l2_regularization_weight =</span> l2_reg_weight)
progress_printer &lt;-<span class="st"> </span><span class="kw">ProgressPrinter</span>(<span class="dt">tag =</span> <span class="st">'Training'</span>, <span class="dt">num_epochs =</span> max_epochs)
trainer &lt;-<span class="st"> </span><span class="kw">Trainer</span>(z, <span class="kw">c</span>(loss, metric), learner, progress_printer)</code></pre></div>
<p>Create mapping from features to data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">input_map =<span class="st"> </span><span class="kw">list</span>(
  <span class="st">"input"</span> =<span class="st"> </span>reader_train<span class="op">$</span>streams<span class="op">$</span>features,
  <span class="st">"label"</span> =<span class="st"> </span>reader_train<span class="op">$</span>streams<span class="op">$</span>labels
)</code></pre></div>
<p>We now define a loop over which to train our network’s weights. To do so, at each minibatch we iterate over our MinibatchSource and test our evaluation function <code>test_minibatch</code> over each minibatch of data. Upon evaluation, we can backpropagate and update our model parameters using the <code>train_minibatch</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loss_over_time &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">for</span> (epoch <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>max_epochs) {
    sample_count &lt;-<span class="st"> </span><span class="dv">0</span>
    <span class="cf">while</span> (sample_count <span class="op">&lt;</span><span class="st"> </span>epoch_size) {
        current_minibatch &lt;-<span class="st"> </span><span class="kw">min</span>(minibatch_size, epoch_size <span class="op">-</span><span class="st"> </span>sample_count)
        data &lt;-<span class="st"> </span>reader_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/next_minibatch.html">next_minibatch</a></span>(current_minibatch, <span class="dt">input_map =</span> input_map)
        result &lt;-<span class="st"> </span>trainer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">test_minibatch</span>(data)
        loss_over_time &lt;-<span class="st"> </span><span class="kw">c</span>(loss_over_time, result)
        trainer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">train_minibatch</span>(data)
        sample_count &lt;-<span class="st"> </span>sample_count <span class="op">+</span><span class="st"> </span>trainer<span class="op">$</span>previous_minibatch_sample_count
    }
    <span class="kw">summarize_training_progress</span>(trainer)
}</code></pre></div>
<p>We can visualize our training loss:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="kw">data.frame</span>(<span class="dt">loss =</span> loss_over_time, 
                  <span class="dt">iterations =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(loss_over_time))) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_point">geom_point</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> iterations, <span class="dt">y =</span> loss), <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggtheme">theme_minimal</a></span>() <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">labs</a></span>(<span class="dt">title =</span> <span class="st">"Training Loss"</span>)</code></pre></div>
<p><img src="images/loss_cifar10.png" alt="Drawing" style="width: 600px;"></p>
</div>
<div id="evaluation" class="section level2">
<h2 class="hasAnchor">
<a href="#evaluation" class="anchor"></a>Evaluation</h2>
<p>Now that we have our trained model, we can evaluate it on our test set. We will again call on our <code>create_reader</code> function, but this time point to the <strong>Test</strong> CTF file, and we also specify the input dictionary.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reader_test &lt;-<span class="st"> </span><span class="kw">create_reader</span>(<span class="dt">path =</span> <span class="kw">file.path</span>(data_path, <span class="st">'Test_cntk_text.txt'</span>),
                             <span class="dt">is_training =</span>  <span class="ot">FALSE</span>,
                             input_dim, num_output_classes)
input_map &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="st">"input"</span> =<span class="st"> </span>reader_test<span class="op">$</span>streams<span class="op">$</span>features,
    <span class="st">"label"</span> =<span class="st"> </span>reader_test<span class="op">$</span>streams<span class="op">$</span>labels
)</code></pre></div>
<p>We can setup our evaluation parameters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">epoch_size &lt;-<span class="st"> </span><span class="dv">2000</span>
minibatch_size &lt;-<span class="st"> </span><span class="dv">200</span>
metric_numer &lt;-<span class="st"> </span><span class="dv">0</span>
metric_denom &lt;-<span class="st"> </span><span class="dv">0</span>
sample_count &lt;-<span class="st"> </span><span class="dv">0</span>
minibatch_index &lt;-<span class="st"> </span><span class="dv">0</span></code></pre></div>
<p>And evaluate:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_loss &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">while</span> (sample_count <span class="op">&lt;</span><span class="st"> </span>epoch_size) {
    current_minibatch &lt;-<span class="st"> </span><span class="kw">min</span>(minibatch_size, epoch_size <span class="op">-</span><span class="st"> </span>sample_count)
    data &lt;-<span class="st"> </span>reader_test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/next_minibatch.html">next_minibatch</a></span>(current_minibatch, <span class="dt">input_map =</span> input_map)
    metric_numer &lt;-<span class="st">  </span>metric_numer <span class="op">+</span><span class="st"> </span>trainer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">test_minibatch</span>(data) <span class="op">*</span><span class="st"> </span>current_minibatch
    metric_denom &lt;-<span class="st">  </span>metric_denom <span class="op">+</span><span class="st"> </span>current_minibatch
    sample_count &lt;-<span class="st">  </span>sample_count <span class="op">+</span><span class="st"> </span>data<span class="op">$</span>label<span class="op">$</span>num_samples
    minibatch_index =<span class="st"> </span>minibatch_index <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
}

<span class="kw">sprintf</span>(<span class="st">"Final error: %g%%"</span>, metric_numer <span class="op">/</span><span class="st"> </span>metric_denom <span class="op">*</span><span class="st"> </span><span class="dv">100</span>)
[<span class="dv">1</span>] <span class="st">"Final error: 21.25%"</span></code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#goals-and-overview">Goals and Overview</a></li>
      <li><a href="#load-cntk-environment">Load CNTK Environment</a></li>
      <li><a href="#feeding-data-to-cntk">Feeding Data to CNTK</a></li>
      <li><a href="#define-minibatch-reader-functions">Define Minibatch Reader Functions</a></li>
      <li><a href="#defining-the-network-architecture">Defining the Network Architecture</a></li>
      <li><a href="#training">Training</a></li>
      <li><a href="#evaluation">Evaluation</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Joe Davison, Ali Zaidi, Microsoft.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
