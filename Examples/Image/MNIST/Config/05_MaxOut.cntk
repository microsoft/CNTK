# Parameters can be overwritten on the command line
# for example: cntk configFile=myConfigFile RootDir=../.. 
# For running from Visual Studio add
# currentDirectory=$(SolutionDir)/<path to corresponding data folder> 
RootDir = ".."

ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"

deviceId = 0
# NDConvolution nodes support cudnn layout only both on GPU and CPU.
imageLayout = "cudnn"

command = train:test

precision = "float"
modelPath = "$ModelDir$/05_MaxOut"

# uncomment the following line to write logs to a file 
stderr = "$OutputDir$/05_MaxOut_out"
traceLevel=1
numMBsToShowResult=500

prefetch=true

#######################################
#  TRAINING CONFIG                    #
#######################################

train = [
    action = "train"

    BrainScriptNetworkBuilder = [

        MaxNorm = 0.9

        // Macros
        NDConvLayer(inp, kW, kH, inMap, outMap, hStride, vStride, wScale, bValue) = [  // ReLU non-linearity
            convW = Parameter(outMap, kW * kH * inMap, init="uniform", initValueScale=wScale, initOnCPUOnly=false)
            convWClipped = Scale(Min(1, MaxNorm / MatrixL2Reg(convW)), convW)
            conv  = NDConvolution(convWClipped, inp, (kW : kH : inMap), (1 : 1 : outMap), stride=(hStride : vStride : inMap), sharing=true, autoPadding=true, imageLayout="$imageLayout$")
            convB = ParameterTensor((1 : 1 : outMap), init="fixedValue", value=bValue)
            out = Plus(conv, convB);
        ]

        NDMaxPoolLayer(inp, kW, kH, kD, inMap, hS, vS, dS) = [
            out = NDPooling(inp, (kW : kH : kD), poolKind='max', stride=(hS : vS : dS), autoPadding=(true : true : false), imageLayout="$imageLayout$")
        ]

        DNNImageLayer(inW, inH, inC, outDim, x, parmScale) = [
            W = ParameterTensor((outDim: inW : inH : inC), init="uniform", initValueScale=parmScale)
            b = LearnableParameter(outDim, 1,              init="uniform", initValueScale=parmScale) 
            t = Times(W, x)
            out = Plus(t, b)
        ]

        // Network
        imageW = 28
        imageH = 28
        labelDim = 10

        features = ImageInput(imageW, imageH, 1, imageLayout="$imageLayout$", tag="feature")
        featScale = Constant(0.00390625)
        featScaled = Scale(featScale, features)
        labels = Input(labelDim, tag="label")

        wScale = 0.001

        # conv1
        kW1 = 8
        kH1 = 8
        cMap1 = 96
        hS1 = 1
        vS1 = 1
        conv1 = NDConvLayer(featScaled, kW1, kH1, 1, cMap1, hS1, vS1, wScale, 1).out

        pool1W = 4
        pool1H = 4
        pool1D = 2
        pool1hS = 2
        pool1vS = 2
        pool1dS = 2
        pool1 = NDMaxPoolLayer(conv1, pool1W, pool1H, pool1D, cMap1, pool1hS, pool1vS, pool1dS).out

        # conv2
        kW2 = 8
        kH2 = 8
        cMap2 = 96
        hS2 = 1
        vS2 = 1
        conv2 = NDConvLayer(pool1, kW2, kH2, cMap1 / pool1dS, cMap2, hS2, vS2, wScale, 1).out

        pool2W = 4
        pool2H = 4
        pool2D = 2
        pool2hS = 2
        pool2vS = 2
        pool2dS = 2
        pool2 = NDMaxPoolLayer(conv2, pool2W, pool2H, pool2D, cMap2, pool2hS, pool2vS, pool2dS).out

        # conv3
        kW3 = 5
        kH3 = 5
        cMap3 = 96
        hS3 = 1
        vS3 = 1
        conv3 = NDConvLayer(pool2, kW3, kH3, cMap2 / pool2dS, cMap3, hS3, vS3, wScale, 1).out

        pool3W = 2
        pool3H = 2
        pool3D = 4
        pool3hS = 2
        pool3vS = 2
        pool3dS = 4
        pool3 = NDMaxPoolLayer(conv3, pool3W, pool3H, pool3D, cMap3, pool3hS, pool3vS, pool3dS).out

        ol = DNNImageLayer(4, 4, cMap3 / pool3dS, labelDim, pool3, 1).out

        ce = CrossEntropyWithSoftmax(labels, ol, tag="criterion")
        err = ErrorPrediction(labels, ol, tag="eval")
        outputNodes = ol
    ]
    
    SGD = [
        epochSize = 60000
        minibatchSize = 32
        learningRatesPerMB = 0.001
        momentumPerMB = 0*10:0.7
        maxEpochs = 15
    ]
    
    reader = [
        readerType = "UCIFastReader"
        # To get the data (Train-28x28.txt) please run `python mnist_convert.py` 
        # from the 'AdditionalFiles' folder. See REAMDE.md for details.
        file = "$DataDir$/Train-28x28.txt"
        
        features = [
            dim = 784
            start = 1
        ]
        
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "$DataDir$/labelsmap.txt"
        ]
    ]    
]

#######################################
#  TEST CONFIG                        #
#######################################

test = [
    action = test
    minibatchSize = 16
    
    reader = [
        readerType = "UCIFastReader"
        file = "$DataDir$/Test-28x28.txt"
        
        features = [
            dim = 784
            start = 1
        ]
        
        labels = [
            dim = 1
            start = 0
            labelDim = 10
            labelMappingFile = "$DataDir$/labelsmap.txt"
        ]
    ]
]
