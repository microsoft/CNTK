Conv(W, inp, outMap, kW, kH, hStride, vStride)
[
    c = Convolution(W, inp, kW, kH, outMap, hStride, vStride, zeroPadding = true, imageLayout = "cudnn")
]

BN(inp, mapCount, bValue, scValue, bnTimeConst)
[
    b = Parameter(mapCount, 1, init = fixedValue, value = bValue)
    sc = Parameter(mapCount, 1, init = fixedValue, value = scValue)
    m = Parameter(mapCount, 1, init = fixedValue, value = 0, learningRateMultiplier = 0)
    v = Parameter(mapCount, 1, init = fixedValue, value = 0, learningRateMultiplier = 0)
    
    y = BatchNormalization(inp, sc, b, m, v, spatial = true, normalizationTimeConstant = bnTimeConst, epsilon = 0.000000001, imageLayout = "cudnn", engine = "cudnn")
]

ConvBNLayerW(W, inp, outMap, kW, kH, hStride, vStride, bValue, scValue, bnTimeConst)
[
    c = Conv(W, inp, outMap, kW, kH, hStride, vStride)
    y = BN(c, outMap, bValue, scValue, bnTimeConst)
]

ConvBNLayer(inp, outMap, inWCount, kW, kH, hStride, vStride, wScale, bValue, scValue, bnTimeConst)
[
    W = Parameter(outMap, inWCount, init = Gaussian, initValueScale = wScale)
    c = Conv(W, inp, outMap, kW, kH, hStride, vStride)
    y = BN(c, outMap, bValue, scValue, bnTimeConst)
]

ConvBNReLULayer(inp, outMap, inWCount, kW, kH, hStride, vStride, wScale, bValue, scValue, bnTimeConst)
[
    c = ConvBNLayer(inp, outMap, inWCount, kW, kH, hStride, vStride, wScale, bValue, scValue, bnTimeConst)
    y = RectifiedLinear(c)
]

Conv1x1(inp, outMap, inMap, hStride, vStride, wScale, bValue, scValue, bnTimeConst)
[
    W = Parameter(outMap, inMap, init = Gaussian, initValueScale = wScale)
    c = Convolution(W, inp, 1, 1, outMap, hStride, vStride, zeroPadding = false, imageLayout = "cudnn")
    y = BN(c, outMap, bValue, scValue, bnTimeConst)
]

Conv1x1ReLU(inp, outMap, inMap, hStride, vStride, wScale, bValue, scValue, bnTimeConst)
[
    c = Conv1x1(inp, outMap, inMap, hStride, vStride, wScale, bValue, scValue, bnTimeConst)
    y = RectifiedLinear(c)
]

# Standard building block for ResNet with identity shortcut (option A).
ResNetNode2A(inp, outMap, inWCount, kW, kH, wScale, bValue, scValue)
[
    # First convolution layer.
    c1 = ConvBNReLULayer(inp, outMap, inWCount, kW, kH, 1, 1, wScale, bValue, scValue, bnTimeConst)
    # Second convolution layer, no ReLU.
    c2 = ConvBNLayer(c1, outMap, inWCount, kW, kH, 1, 1, wScale, bValue, scValue, bnTimeConst)
    # Identity shortcut.
    p = Plus(c2, inp)
    y = RectifiedLinear(p)
]

# Standard building block for ResNet with padding (option A).
ResNetNode2AInc(inp, outMap, inWCount, wCount, kW, kH, wScale, bValue, scValue, bnTimeConst, Wproj)
[
    # First convolution layer.
    c1 = ConvBNReLULayer(inp, outMap, inWCount, kW, kH, 2, 2, wScale, bValue, scValue, bnTimeConst)
    # Second convolution layer, no ReLU.
    c2 = ConvBNLayer(c1, outMap, wCount, kW, kH, 1, 1, wScale, bValue, scValue, bnTimeConst)
    
    # Projection convolution layer.
    c_proj = ConvBNLayerW(Wproj, inp, outMap, 1, 1, 2, 2, bValue, scValue, bnTimeConst)
    
    p = Plus(c2, c_proj)
    y2 = RectifiedLinear(p)
]

# Standard building block for ResNet with padding (option B).
ResNetNode2BInc(inp, outMap, inMap, inWCount, wCount, kW, kH, wScale, bValue, scValue, bnTimeConst, stride1x1, stride3x3)
[
    # First convolution layer.
    c1 = ConvBNReLULayer(inp, outMap, inWCount, kW, kH, stride1x1, stride1x1, wScale, bValue, scValue, bnTimeConst)
    # Second convolution layer, no ReLU.
    c2 = ConvBNLayer(c1, outMap, wCount, kW, kH, stride3x3, stride3x3, wScale, bValue, scValue, bnTimeConst)
    
    # Projection convolution layer.
    c_proj = Conv1x1(inp, outMap, inMap, 2, 2, wScale, bValue, scValue, bnTimeConst)
    
    p = Plus(c2, c_proj)
    y2 = RectifiedLinear(p)
]

# Bottleneck building block for ResNet.
ResNetNode3A(inp, inMap, convMap, outMap, convWCount, wScale, bValue, scValue, bnTimeConst)
[
    # 1x1 reducing convolution.
    c1 = Conv1x1ReLU(inp, convMap, inMap, 1, 1, wScale, bValue, scValue, bnTimeConst)
    # 3x3 convolution.
    c2 = ConvBNReLULayer(c1, convMap, convWCount, 3, 3, 1, 1, wScale, bValue, scValue, bnTimeConst)
    # 1x1 expanding convolution, no ReLU.
    c3 = Conv1x1(c2, outMap, convMap, 1, 1, wScale, bValue, scValue, bnTimeConst)
    
    p = Plus(c3, inp)
    y = RectifiedLinear(p)
]

ResNetNode3AInc(inp, inMap, convMap, outMap, convWCount, wScale, bValue, scValue, bnTimeConst, wProj, projStride)
[
    # 1x1 reducing convolution.
    c1 = Conv1x1ReLU(inp, convMap, inMap, projStride, projStride, wScale, bValue, scValue, bnTimeConst)
    # 3x3 convolution.
    c2 = ConvBNReLULayer(c1, convMap, convWCount, 3, 3, 1, 1, wScale, bValue, scValue, bnTimeConst)
    # 1x1 expanding convolution, no ReLU.
    c3 = Conv1x1(c2, outMap, convMap, 1, 1, wScale, bValue, scValue, bnTimeConst)
    # Input-to-output mapping convolution.
    c_proj = ConvBNLayerW(wProj, inp, outMap, 1, 1, projStride, projStride, wScale, bValue, scValue, bnTimeConst)
    
    p = Plus(c3, c_proj)
    y = RectifiedLinear(p)
]

ResNetNode3BInc(inp, inMap, convMap, outMap, convWCount, wScale, bValue, scValue, bnTimeConst, projStride, stride1x1, stride3x3)
[
    # 1x1 reducing convolution.
    c1 = Conv1x1ReLU(inp, convMap, inMap, stride1x1, stride1x1, wScale, bValue, scValue, bnTimeConst)
    # 3x3 convolution.
    c2 = ConvBNReLULayer(c1, convMap, convWCount, 3, 3, stride3x3, stride3x3, wScale, bValue, scValue, bnTimeConst)
    # 1x1 expanding convolution, no ReLU.
    c3 = Conv1x1(c2, outMap, convMap, 1, 1, wScale, bValue, scValue, bnTimeConst)
    # Input-to-output mapping convolution.
    c_proj = Conv1x1(inp, outMap, inMap, projStride, projStride, wScale, bValue, scValue, bnTimeConst)
    
    p = Plus(c3, c_proj)
    y = RectifiedLinear(p)
]

DnnLayer(hiddenDim, labelDim, x, wScale, bValue)
[
    W = Parameter(labelDim, hiddenDim, init = Gaussian, initValueScale = wScale)
    b = Parameter(labelDim, init = fixedValue, value = bValue)
    t = Times(W, x)
    z = Plus(t, b)
]

MaxNDPooling(inp, kW, kH, hStride, vStride)
[
    p = Pooling(inp, "max", {kW, kH, 1}, stride = {hStride, vStride, 1}, autoPadding = {true, true, false}, imageLayout = "cudnn")
]
