# Simple CIFAR-10 convnet, without and with BatchNormalization.

command = TrainConvNetWithBN:Eval

makeMode = false ; traceLevel = 1 ; deviceId = 0

RootDir = "." ; DataDir  = "$RootDir$" ; ModelDir = "$RootDir$/Output/Models"

modelPath = "$ModelDir$/ConvNetBN"

# Training with BN
TrainConvNetWithBN = {
    action = "train"

    BrainScriptNetworkBuilder = {
        imageShape = 32:32:3
        labelDim = 10

        Subtract128 (x) = x - Constant (128)

        model = Sequential (
            Subtract128 :
            ConvolutionalLayer {32, (5:5), pad = true, bias = false, init = "heNormal", initValueScale=0.00390625} :
              BatchNormalizationLayer {spatialRank = 2, normalizationTimeConstant = 4096} : ReLU :
                MaxPoolingLayer {(3:3), stride = (2:2)} :
            ConvolutionalLayer {32, (5:5), pad = true, bias = false, init = "heNormal"} :
              BatchNormalizationLayer {spatialRank = 2, normalizationTimeConstant = 4096} : ReLU :
                MaxPoolingLayer {(3:3), stride = (2:2)} :
            ConvolutionalLayer {64, (5:5), pad = true, bias = false, init = "heNormal"} :
              BatchNormalizationLayer {spatialRank = 2, normalizationTimeConstant = 4096} : ReLU :
                MaxPoolingLayer {(3:3), stride = (2:2)} :
            LinearLayer {64, bias = false, init = "heNormal", initValueScale=0.1} :
              BatchNormalizationLayer {normalizationTimeConstant = 4096} : ReLU :
            LinearLayer {labelDim, init = "heNormal", initValueScale=0.1}
        )

        # inputs
        features = Input {imageShape}
        labels   = Input {labelDim}

        # apply model to features
        z = model (features)

        # connect to system
        ce       = CrossEntropyWithSoftmax (labels, z)
        errs     = ClassificationError         (labels, z)
        top5Errs = ClassificationError         (labels, z, topN=5)

        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (ce)
        evaluationNodes = (errs)
        outputNodes     = (z)
    }

    SGD = {
        epochSize = 49984 ; minibatchSize = 64

        learningRatesPerSample = 0.00046875*5:0.00015625
        momentumAsTimeConstant = 0
        maxEpochs = 10
        L2RegWeight = 0.003
        dropoutRate = 0

        firstMBsToShowResult = 10 ; numMBsToShowResult = 500
    }

    reader = {
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train_cntk_text.txt"
        input = {
            features = { dim = 3072 ; format = "dense" }
            labels   = { dim = 10 ;   format = "dense" }
        }
    }
}

# Eval action
Eval = {
    action = "eval"
    minibatchSize = 16
    evalNodeNames = errs:top5Errs  # also test top-5 error rate
    reader = {
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Test_cntk_text.txt"
        input = {
            features = { dim = 3072 ; format = "dense" }
            labels   = { dim = 10 ;   format = "dense" }
        }
    }
}
