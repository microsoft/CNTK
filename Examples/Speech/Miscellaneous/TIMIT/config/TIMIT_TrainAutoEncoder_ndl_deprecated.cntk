# Note: This sample uses the deprecated NdlNetworkBuilder.
#       An updated version using BrainScript is coming soon.
#       Please find updated samples on Github, https://github.com/Microsoft/CNTK/tree/master/Examples /...
#
# If set to true, always initialize the network on CPU, making initialization consistent across CPU and GPU targets (for testing).
initOnCPUOnly=true

command=TIMIT_TrainAutoEncoder

precision=float

#######################################
#  TRAINING CONFIG (Simple, Fixed LR) #
#######################################

TIMIT_TrainAutoEncoder=[
    action=train

    modelPath=$ExpDir$/TrainAutoEncoder/model/cntkSpeech.dnn

    # deviceId=-1 for CPU, >=0 for GPU devices 
    deviceId=$DeviceNumber$

    traceLevel=1

    # notation xxx:yyy*n:zzz is equivalent to xxx, then yyy repeated n times, then zzz
    # example: 10:20*3:5 is equivalent to 10:20:20:20:5
    NDLNetworkBuilder=[
        ndlMacros=$NdlDir$/default_macros.ndl
        NetworkDescription=$NdlDir$/ae.ndl
    ]

    SGD=[
        # epochSize=0 means epochSize is the size of the training set
        epochSize=0 
        minibatchSize=256
        learningRatesPerMB=0.1
        momentumPerMB=0.9
        dropoutRate=0.0
        maxEpochs=25
    ]
       
    # Parameter values for the reader
    reader=[
        # reader to use
        readerType=HTKMLFReader
        readMethod=blockRandomize

        miniBatchMode=Partial
        randomize=Auto
        verbosity=0

        featIn=[
            dim=792
            scpFile=$ScpDir$/TIMIT.train.scp.fbank.fullpath.rnn
        ]

        featOut=[
            scpFile=$ScpDir$/TIMIT.train.scp.fbank.fullpath.rnn
            dim=792
        ]
    ]
]