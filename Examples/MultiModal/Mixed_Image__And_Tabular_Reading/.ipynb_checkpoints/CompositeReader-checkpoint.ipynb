{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Composite Data Readers Tutorial**\n",
    "\n",
    "**Composite Reader** is a reader which takes several data deserializers and composes them into a single input read, which can then be used as an input map for a computation graph.\n",
    "\n",
    "**This Tutorial** walks through how to compose image data along side a feature vector for training where the prediction is 4 regressor outputs.  A common example of this might be in a robotics scenario where you need to compose the current image data with a feature vector representing the robot's current state which then produces 4 servo outputs or perhaps 4 different reward values for different possible actions to take.  The possibilities are really endless and therefor the need to understand this level of flexibility.\n",
    "\n",
    "**Key Concepts** Beyond the ability to just compose data, this tutorial highlights the ability to use specific types of neural network layers for specific data inputs and then compose those together into a prediction where it is best.  This is not unlike the human sensory system with individual sensory systems specifically tuned to the type of signal input which produces more or less a feature map that is then consumed by the judgement engine to produce signal outputs that are understood by the rest of your body to produce actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
    }
   },
   "outputs": [],
   "source": [
    "#Just some import statements\n",
    "from __future__ import print_function \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cntk as C\n",
    "import cntk.io.transforms as xforms \n",
    "\n",
    "# Define Image dimensions for this experiment.\n",
    "# Since we use CNTK's image deserializer, we are\n",
    "# able to configure this out and experiment to \n",
    "# our hearts content with out re-processing our data.\n",
    "num_channels = 3\n",
    "image_width = 32\n",
    "image_height = 32\n",
    "\n",
    "# images are 32 x 32 with 3 channels of color\n",
    "# grey scale is 1 channel of color\n",
    "# this can really be any multi dimensional 3 axis data.\n",
    "image_shape = (num_channels, image_width, image_height) \n",
    "\n",
    "# number of features to produce from the convolutional processing\n",
    "# no reason for 8, I felt like 8 today.  This will likely have\n",
    "# a large impact on performance and probably relates to input image size\n",
    "# and image complexities and nuances.\n",
    "conv_feature_map_size = 8\n",
    "\n",
    "# number of features coming from our \n",
    "# CTF file, which is 3.\n",
    "tab_features = 3\n",
    "\n",
    "# number of regressor outputs to create\n",
    "num_regression_outputs = 4\n",
    "\n",
    "# place holder variables for our image data\n",
    "x_i = C.input_variable(image_shape)\n",
    "\n",
    "# place holder variable for our tabular data\n",
    "x_t = C.input_variable(tab_features)\n",
    "\n",
    "# place holder variable for our predictions\n",
    "y = C.input_variable(num_regression_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Format** \n",
    "\n",
    "You can find the actual file examples in this directory as .map (for the image files) and .ctf (for the feature data).  The combination of CTF files and image map files allows you to compose whatever kind of labels with any type of data you wish.  For example; you can use a 0 index class identifier in the images file should you be performing classification; however in this instance, we are performing regression on 4 output nodes and therefor take advantage of the label flexibility provided in the CTF format.\n",
    "\n",
    "**The image map file looks like:**\n",
    "\n",
    "  images/image1.png    0  \n",
    "  images/image3.png    0\n",
    "\n",
    "Note:  You can also use fully qualified paths such as c:/data/images/image1.png to refer to your image as well.  The class labels in this specific scenario are unused, so we just use 0's.\n",
    "\n",
    "**The CTF file looks like:**\n",
    "\n",
    "  |features 0 0 1 |label 1 2 3 4   \n",
    "  |features 0 1 0 |label 4 3 2 1 \n",
    "\n",
    "All features must be in float format.  Either as integers or decimal point representation.  All features and labels must also be of the same shape.  If you have variable sized data, you should be using a sequence representation of that data, which is documented here: https://www.cntk.ai/pythondocs/cntk.io.html?highlight=ctf#cntk.io.CTFDeserializer.\n",
    "\n",
    "**Finally & Importantly:** The index in which each example exists in the files is the index they are pulled together.  For example the first line in each file is index 0 and the second is index 1.  If a minibatch pulls index 1 into the batch, then it will be pulling the second line from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read a COMPOSITE reader to read data from both the image map and CTF files\n",
    "def create_reader(map_file, ctf_file, is_training, num_regression_outputs):\n",
    "    \n",
    "    # create transforms\n",
    "    transforms = []        \n",
    "    if is_training:\n",
    "        # don't want to do this for validation, just a data augmentation technique, \n",
    "        # and why we like CNTK's image deserializer with composition :D\n",
    "        transforms += [ xforms.crop(crop_type='randomside', side_ratio=0.8)  ]        \n",
    "    transforms +=    [\n",
    "        # gets all images to the correct shape.\n",
    "        xforms.scale(width=image_width, height=image_height, channels=num_channels, interpolations='linear')]\n",
    "\n",
    "    # create IMAGE DESERIALIZER for map file\n",
    "    image_source = C.io.ImageDeserializer(map_file, C.io.StreamDefs(\n",
    "        features_image = C.io.StreamDef(field='image', transforms=transforms)))\n",
    "    \n",
    "    # create CTF DESERIALIZER for CTF file\n",
    "    ctf_source = C.io.CTFDeserializer(ctf_file, C.io.StreamDefs(\n",
    "        labels = C.io.StreamDef(field=\"label\", shape=num_regression_outputs, is_sparse=False),\n",
    "        features_tabular = C.io.StreamDef(field=\"features\", shape=3)))\n",
    "\n",
    "    # create a minibatch source by compositing them together \n",
    "    return C.io.MinibatchSource([image_source, ctf_source], max_samples=sys.maxsize, randomize=is_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Note\n",
    "The names of the variables fed by StreamDef are features_image, labels and features_tabular.  We will be able to extract those and use those specifically within our input map configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "Here we actual build a model.  Notice it takes in two inputs x_i and x_t.  x_i is the image input data after it has been deserialized and x_t is the features from the ctf file after it has been deserialized.  Each of these are brought into the same model definition and can be used and composed within this model.  We first push x_i through a typical convolutional model.  Instead of producing a prediction though, we produce a feature map.  \n",
    "\n",
    "*You can think of a feature map as a set of features that you let the neural network figure out and tune on that are the best simplistic representation of the data which can be merged with other data sets.*\n",
    "\n",
    "We then take the feature map, which is essentially a numpy array and append the features from our ctf file, which is also essentially a numpy array.  These then form the input for a standard feed forward network to produce our 4 regressor outputs.\n",
    "\n",
    "*Notice that we use relu as the standard activation function, but on the final layer we specify an activation of None* a None activation essentially just computes a final linear regression on each output node with no extra function on top of it.  This allows you the ability to produce outputs from -infinity to +infinity.\n",
    "\n",
    "**Loss and Errors:**  Notice that we use squared_error as our loss.  This is because we are predicting regressors as our output and not a classifier.  errs = loss when you are predicting regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to build model\n",
    "def create_model(x_i, x_t):\n",
    "    with C.layers.default_options(init = C.layers.glorot_uniform(), activation = C.relu):\n",
    "            h = x_i\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), num_filters=8, strides=(1,1), pad=True, name=\"conv_1\")(h)            \n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), strides=(2,2), name=\"max_1\")(h)            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), num_filters=16, strides=(1,1), pad=True, name=\"conv_2\")(h)            \n",
    "            h = C.layers.MaxPooling(filter_shape=(3,3), strides=(3,3), name=\"max_2\")(h)\n",
    "            \n",
    "            # create a feature map\n",
    "            h = C.layers.Dense(conv_feature_map_size, name=\"conv_feature_map\")(h)\n",
    "            \n",
    "            #merge the convolutional feature map with raw tabular data\n",
    "            h = C.splice(h, x_t, axis=0)\n",
    "            \n",
    "            #mix up the data in a dense output sequence\n",
    "            p = C.layers.Dense(num_regression_outputs, activation = None, name=\"prediction\")(h)\n",
    "            \n",
    "            return p\n",
    "        \n",
    "def create_errors(model, labels):\n",
    "    loss = C.losses.squared_error(model, labels)\n",
    "    errs = loss\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training Progress Printer\n",
    "\n",
    "Basically this just takes in the trainer, the current minibatch, a frequency and prints out the current statistics from this minibatch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this evaluation metric only for regressor nodes\n",
    "#This unfurls MSE, if using RMSE, the equation is different.\n",
    "def calc_avg_per_out_error(eval_error, num_outputs):\n",
    "    '''\n",
    "    Unfurls Mean Squared Error to a per output\n",
    "    error in either positive or negative direction\n",
    "    '''\n",
    "    per_out = eval_error / num_outputs\n",
    "    sqrt_per_out = math.sqrt(per_out)\n",
    "    return sqrt_per_out / 2.0\n",
    "    \n",
    "\n",
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, num_outputs, train = True):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        avg_out_error = calc_avg_per_out_error(eval_error, num_outputs)\n",
    "        print (\"Minibatch: {0}, Loss: {1:.4f}, +/- error per output: {2:.4f}\".format(mb, training_loss, avg_out_error))\n",
    "        \n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Train and Test Loop\n",
    "\n",
    "This is pretty much boiler plate as well, but I would suggest reading some of the other articles that really focus on this area because there are some great optimizations you could make here that I just left out for the sake of simplicity.\n",
    "\n",
    "**The big things to notice here are: ** the input map is very important.  input_map and test_input_map.  Notice they pull out those specific streamdef variables we defined in our reader and populate our placeholder variables y, x_i and x_t.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(train_reader, test_reader, num_outputs, num_sweeps_to_train_with=10):\n",
    "    \n",
    "    # Instantiate the loss and error function\n",
    "    # z comes from a global scope outside of this function (defined later).\n",
    "    loss, label_error = create_errors(z, y)\n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    # we use a super low learning rate so we don't get exploding gradients\n",
    "    # which is common for regressors in large networks.\n",
    "    learning_rate = .00001 \n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "    \n",
    "    # Initialize the parameters for the trainer\n",
    "    minibatch_size = 64\n",
    "    num_samples_per_sweep = 60000\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "    \n",
    "    # Map the data streams to the input and labels.\n",
    "    # this is where we can pull in our label pairs\n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x_i  : train_reader.streams.features_image,\n",
    "        x_t  : train_reader.streams.features_tabular\n",
    "    } \n",
    "    \n",
    "    training_progress_output_freq = 500\n",
    "     \n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training data file\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map)         \n",
    "        # train with this minibatch\n",
    "        trainer.train_minibatch(data)        \n",
    "        # print progress \n",
    "        print_training_progress(trainer, i, training_progress_output_freq, num_outputs)\n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "    \n",
    "    # Test the model\n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x_i  : test_reader.streams.features_image,\n",
    "        x_t : test_reader.streams.features_tabular\n",
    "    }\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 512\n",
    "    num_samples = 10000\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0   \n",
    "    for i in range(num_minibatches_to_test):    \n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n",
    "        # with one pixel per dimension that we will encode / decode with the \n",
    "        # trained model.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    full_test_result = test_result / num_minibatches_to_test\n",
    "    print(\"Average test error: {0:.2f}\".format(full_test_result))\n",
    "    print(\"Average test +/- per output: {0:.2f}\".format(calc_avg_per_out_error(full_test_result, num_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train this THING!!!\n",
    "Alright, time for rubber to hit the pavement on this thing.  We create our model by passing it the placeholder x_i and x_t which will be populated by our readers for each mini batch during training.\n",
    "\n",
    "Create those readers, and call into the loop we created above with our readers.  Our model lives outside of the function, because we want to be able to persist it outside or possibly continue training it after this first loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 5321.8608, +/- error per output: 18.2378\n",
      "Minibatch: 500, Loss: 9.9625, +/- error per output: 0.7891\n",
      "Minibatch: 1000, Loss: 5.8511, +/- error per output: 0.6047\n",
      "Minibatch: 1500, Loss: 5.2203, +/- error per output: 0.5712\n",
      "Minibatch: 2000, Loss: 5.1687, +/- error per output: 0.5684\n",
      "Minibatch: 2500, Loss: 5.0380, +/- error per output: 0.5611\n",
      "Minibatch: 3000, Loss: 4.9820, +/- error per output: 0.5580\n",
      "Minibatch: 3500, Loss: 4.9751, +/- error per output: 0.5576\n",
      "Minibatch: 4000, Loss: 4.8813, +/- error per output: 0.5523\n",
      "Minibatch: 4500, Loss: 4.8034, +/- error per output: 0.5479\n",
      "Minibatch: 5000, Loss: 4.7744, +/- error per output: 0.5463\n",
      "Minibatch: 5500, Loss: 4.7277, +/- error per output: 0.5436\n",
      "Minibatch: 6000, Loss: 4.6617, +/- error per output: 0.5398\n",
      "Minibatch: 6500, Loss: 4.5907, +/- error per output: 0.5356\n",
      "Minibatch: 7000, Loss: 4.5727, +/- error per output: 0.5346\n",
      "Minibatch: 7500, Loss: 4.5116, +/- error per output: 0.5310\n",
      "Minibatch: 8000, Loss: 4.4790, +/- error per output: 0.5291\n",
      "Minibatch: 8500, Loss: 4.4420, +/- error per output: 0.5269\n",
      "Minibatch: 9000, Loss: 4.3528, +/- error per output: 0.5216\n",
      "Training took 70.6 sec\n",
      "Average test error: 4.40\n",
      "Average test +/- per output: 0.52\n"
     ]
    }
   ],
   "source": [
    "z = create_model(x_i, x_t)\n",
    "reader_train = create_reader(\"train.map\", \"train.ctf\", True, num_regression_outputs)\n",
    "reader_test = create_reader(\"test.map\", \"test.ctf\", False, num_regression_outputs)\n",
    "\n",
    "train_test(reader_train, reader_test, num_regression_outputs, num_sweeps_to_train_with = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Output\n",
    "\n",
    "**Errors**\n",
    "The average error is important to understand as it helps understand across all possible outputs what your error is.  I also like to be able to break the average error back into the same numerical space as the question.  Here we basically just undo the MSE and assume same error across all nodes and calculate RMSE as it would exist per output node.  Basically, you can think of this as on average each node is going to be + or - 0.52.  So if the actual value is 2, you are likely to predict a value roughly around 1.48 or 2.52 on average.\n",
    "\n",
    "**Trends in Errors**\n",
    "We see a very solid drop in error with no backstepping.  Even on our last minibatch, we continued to drop significantly.  This tells us that this learner can still keep learning and our error will continue to drop if we let it keep going.  In summary, although our final error is .5216 per node, we know there is still significant learning that can happen thereby dropping our error.  Make sure your test error shows the same trend (helps prevent overfitting).  Our test error reflects our train error; so we know there is more to learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ** SUMMARY **\n",
    "Alright, so thats about it.  You now know how to create multiple data files with different kinds of data in them and then compose that data together into a single model.  Congratulations!  See what you can do with this on Kaggle.  This particular challenge looks very ripe for this type of approach: https://www.kaggle.com/c/zillow-prize-1 \n",
    "\n",
    "You can find some additional details here: http://dacrook.com/complex-neural-network-data-modelling-with-cntk/ "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
